{
  "generatedAt": "2026-02-14T06:59:44.014Z",
  "technologies": [
    {
      "slug": "docker",
      "meta": {
        "title": "Docker Interview Preparation",
        "description": "Learn how to answer Docker interview questions on images, containers, networking, security, and debugging with real commands."
      },
      "topics": [
        {
          "id": "docker-basics",
          "title": "Docker Core Concepts",
          "category": "Docker Basics",
          "description": "Understanding containers, images, and the Docker architecture.",
          "explanation": "Docker is a platform for developing, shipping, and running applications in containers. A container is a lightweight, standalone package that includes everything needed to run software: code, runtime, libraries, and system tools. Unlike virtual machines, containers share the host OS kernel, making them faster and more efficient.\n\nCore architecture: The Docker Engine consists of a daemon (dockerd) that manages images/containers, a REST API, and a CLI client. Images are read-only templates built from layers (each Dockerfile instruction = one layer). Containers are writable instances of images with an isolated filesystem, network, and process namespace.\n\nContainers vs VMs: VMs virtualize hardware and run a full guest OS (GB-sized, minutes to boot). Containers virtualize the OS, sharing the host kernel (MB-sized, milliseconds to start). Containers achieve isolation via Linux namespaces (pid, net, mnt, uts, ipc, user) and cgroups (CPU/memory limits).\n\nContainer lifecycle: Created → Running → Paused → Stopped → Removed. Key flags: `-d` (detach), `-it` (interactive TTY), `--rm` (auto-remove on exit), `--name` (assign name), `-p` (port mapping host:container), `-e` (env vars), `-v` (volumes).\n\nImage layers and caching: Each layer is cached and shared across images. Changing a layer invalidates all subsequent layers. This is why you COPY package.json before COPY . . — npm install layer is cached until package.json changes.\n\nCommon pitfalls: Running as root (security risk), not cleaning up stopped containers/dangling images (disk bloat), hardcoding configs instead of using env vars, ignoring .dockerignore (slow builds).",
          "code": "# Pull an image from Docker Hub\ndocker pull nginx:latest\n\n# List local images\ndocker images\n\n# Run a container\ndocker run -d -p 80:80 --name my-nginx nginx\n\n# List running containers\ndocker ps\n\n# List all containers (including stopped)\ndocker ps -a\n\n# Stop a container\ndocker stop my-nginx\n\n# Start a stopped container\ndocker start my-nginx\n\n# Remove a container\ndocker rm my-nginx\n\n# Remove an image\ndocker rmi nginx:latest",
          "example": "# Run container with environment variables\ndocker run -d -e POSTGRES_PASSWORD=secret postgres\n\n# Run container with volume mount\ndocker run -d -v /host/path:/container/path nginx\n\n# Execute command in running container\ndocker exec -it my-nginx bash\n\n# View container logs\ndocker logs my-nginx\ndocker logs -f my-nginx  # Follow log output\n\n# Inspect container details\ndocker inspect my-nginx",
          "useCase": "Containerizing applications, development environments, microservices",
          "interviewQuestions": [
            {
              "question": "What is the difference between a Docker image and a container?",
              "answer": "An image is a read-only template with instructions for creating a container, like a class. A container is a runnable instance of an image, like an object. Images are stored, containers are executed."
            },
            {
              "question": "How does Docker differ from a virtual machine?",
              "answer": "Containers share the host OS kernel and isolate at the process level, making them lighter and faster. VMs include a full OS copy with hypervisor overhead, providing stronger isolation but consuming more resources."
            },
            {
              "question": "What happens when you run docker pull?",
              "answer": "Docker pulls image layers from the registry (Docker Hub by default), verifies checksums, and stores them locally. If layers already exist, they're reused."
            },
            {
              "question": "Explain docker run -d -p 8080:80 nginx",
              "answer": "-d runs detached (background), -p maps host port 8080 to container port 80, nginx is the image name. Starts nginx container accessible at localhost:8080."
            },
            {
              "question": "How do you debug a failing container?",
              "answer": "Use docker logs to view output, docker inspect for configuration, docker exec -it container sh to enter and investigate, check resource limits and network connectivity."
            },
            {
              "question": "What is Docker daemon?",
              "answer": "The Docker daemon (dockerd) is a background service that manages Docker containers, images, networks, and volumes. The Docker client communicates with it via REST API."
            },
            {
              "question": "Why would docker ps show no containers but docker ps -a shows stopped ones?",
              "answer": "docker ps shows only running containers. -a flag shows all containers including stopped, exited, and created but not started."
            },
            {
              "question": "What does docker rm vs docker rmi do?",
              "answer": "docker rm removes containers (instances), docker rmi removes images (templates). Must remove containers using an image before removing the image."
            },
            {
              "question": "How do you restart a container automatically?",
              "answer": "Use --restart flag: docker run --restart unless-stopped. Options: no, on-failure, always, unless-stopped. Useful for production services."
            },
            {
              "question": "What is the purpose of docker exec?",
              "answer": "Executes a command inside a running container without starting a new container. Commonly used for debugging (docker exec -it container bash) or running maintenance tasks."
            }
          ],
          "exercises": [
            {
              "type": "command",
              "question": "Write command to run nginx detached on port 3000 named web-server",
              "answer": "docker run -d -p 3000:80 --name web-server nginx"
            },
            {
              "type": "command",
              "question": "How to view last 50 lines of logs from container named api?",
              "answer": "docker logs --tail 50 api"
            },
            {
              "type": "debug",
              "question": "Container exits immediately after docker run. How to investigate?",
              "answer": "Use docker logs container-name to see error output. Check if CMD in Dockerfile is valid. Try docker run -it image sh to enter interactively."
            },
            {
              "type": "scenario",
              "question": "You need to copy a config file into a running container. What command?",
              "answer": "docker cp local-config.yml container-name:/app/config.yml"
            },
            {
              "type": "explain",
              "question": "What happens when you docker stop vs docker kill?",
              "answer": "docker stop sends SIGTERM (graceful shutdown, allows cleanup), waits 10s, then SIGKILL. docker kill sends SIGKILL immediately (force termination)."
            },
            {
              "type": "troubleshoot",
              "question": "Error: port is already allocated. How to resolve?",
              "answer": "Another container or process is using that port. Find using docker ps or netstat, stop conflicting container, or use different port mapping (-p 8081:80)."
            },
            {
              "type": "command",
              "question": "Remove all stopped containers in one command",
              "answer": "docker container prune"
            },
            {
              "type": "scenario",
              "question": "How to run a container that auto-removes after exit?",
              "answer": "docker run --rm image-name. Useful for temporary tasks, testing, CI/CD pipelines."
            },
            {
              "type": "explain",
              "question": "What does docker inspect reveal?",
              "answer": "Full container/image details in JSON: config, mounts, network settings, resource limits, environment variables, state, metadata."
            },
            {
              "type": "command",
              "question": "Start an interactive Alpine container and remove after exit",
              "answer": "docker run -it --rm alpine sh"
            }
          ],
          "programExercises": [
            {
              "type": "scenario",
              "question": "Program 1: Pull postgres:15 image and verify it's downloaded",
              "code": "docker pull postgres:15\ndocker images | grep postgres",
              "output": "postgres   15   <image-id>   <time-ago>   <size>"
            },
            {
              "type": "scenario",
              "question": "Program 2: Run Redis container in background named cache on default port",
              "code": "docker run -d --name cache redis:alpine\ndocker ps | grep cache",
              "output": "CONTAINER ID   IMAGE         STATUS    PORTS      NAMES\n<id>          redis:alpine   Up       6379/tcp   cache"
            },
            {
              "type": "scenario",
              "question": "Program 3: Execute command inside running container to check Redis version",
              "code": "docker exec cache redis-cli --version",
              "output": "redis-cli 7.x.x"
            },
            {
              "type": "scenario",
              "question": "Program 4: Stop container, verify stopped, then remove it",
              "code": "docker stop cache\ndocker ps -a | grep cache\ndocker rm cache",
              "output": "Exited status shown, then cache removed"
            },
            {
              "type": "scenario",
              "question": "Program 5: Run nginx mapped to port 8080, verify access",
              "code": "docker run -d -p 8080:80 --name web nginx\ncurl http://localhost:8080",
              "output": "Welcome to nginx! HTML page returned"
            },
            {
              "type": "scenario",
              "question": "Program 6: Check container logs for last 10 lines",
              "code": "docker logs --tail 10 web",
              "output": "Last 10 log entries from nginx access/error logs"
            },
            {
              "type": "scenario",
              "question": "Program 7: Inspect container to find IP address",
              "code": "docker inspect web --format=\"{{.NetworkSettings.IPAddress}}\"",
              "output": "172.17.0.2 (or container's IP address)"
            },
            {
              "type": "scenario",
              "question": "Program 8: Run container with memory and CPU limits, verify with stats",
              "code": "docker run -d --name limited --memory=256m --cpus=0.5 nginx\ndocker stats limited --no-stream --format 'table {{.Name}}\t{{.MemUsage}}\t{{.CPUPerc}}'\ndocker inspect limited --format='Memory={{.HostConfig.Memory}} CPUs={{.HostConfig.NanoCpus}}'",
              "output": "Memory=268435456 CPUs=500000000 (256MB and 0.5 CPU confirmed)"
            },
            {
              "type": "scenario",
              "question": "Program 9: Run container with restart policy, kill it, verify auto-restart",
              "code": "docker run -d --name resilient --restart=on-failure:3 nginx\ndocker kill resilient\nsleep 2\ndocker ps | grep resilient",
              "output": "Container automatically restarted after being killed"
            },
            {
              "type": "scenario",
              "question": "Program 10: Compare image sizes between alpine and full base",
              "code": "docker pull node:18\ndocker pull node:18-alpine\ndocker images | grep node",
              "output": "node:18 ~900MB vs node:18-alpine ~170MB — alpine is 5x smaller"
            }
          ]
        },
        {
          "id": "dockerfile",
          "title": "Dockerfile",
          "category": "Docker Basics",
          "description": "Create custom Docker images using Dockerfile instructions.",
          "explanation": "A Dockerfile is a text document containing sequential instructions to assemble an image. Each instruction creates a new read-only layer. Understanding instruction behavior, layer optimization, and multi-stage builds is critical for creating efficient, secure images.\n\nKey instructions:\n- FROM: Sets base image. Every Dockerfile starts with FROM. Use specific tags (node:18-alpine), never just 'latest' in production.\n- RUN: Executes commands during build (installs packages, compiles code). Each RUN creates a layer — combine related commands with && to reduce layers.\n- COPY vs ADD: COPY is preferred — it only copies files. ADD can also extract tar archives and fetch URLs, but this implicit behavior is error-prone. Use curl/wget in RUN for downloads.\n- WORKDIR: Sets the working directory for subsequent instructions. Creates the directory if it doesn't exist. Use instead of `RUN mkdir && cd`.\n- ENV vs ARG: ENV persists in the running container (runtime config). ARG is only available during build (build-time config like version numbers). ARG values are visible in image history — never use for secrets.\n- EXPOSE: Documents which port the container listens on. Does NOT actually publish the port — you still need `-p` at runtime. It's metadata for operators.\n- ENTRYPOINT vs CMD: ENTRYPOINT sets the executable (hard to override). CMD provides default arguments (easily overridden). Together: ENTRYPOINT [\"python\"] CMD [\"app.py\"] — default runs `python app.py`, but `docker run image script.py` runs `python script.py`.\n\nMulti-stage builds: Use multiple FROM instructions. Build in one stage (with build tools), copy only artifacts to a minimal final stage. Reduces image size dramatically (e.g., 1.2GB → 50MB for Go apps).\n\nLayer caching strategy: Order instructions from least-changing to most-changing. Copy dependency files first (package.json, requirements.txt), install dependencies, then copy source code. This way dependency installation is cached until lock files change.",
          "code": "# Dockerfile example\nFROM node:18-alpine\n\n# Set working directory\nWORKDIR /app\n\n# Copy package files\nCOPY package*.json ./\n\n# Install dependencies\nRUN npm install --production\n\n# Copy application code\nCOPY . .\n\n# Expose port\nEXPOSE 3000\n\n# Set environment variable\nENV NODE_ENV=production\n\n# Define the command to run the app\nCMD [\"node\", \"server.js\"]",
          "example": "# Multi-stage build\nFROM node:18 AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nRUN npm run build\n\nFROM node:18-alpine\nWORKDIR /app\nCOPY --from=builder /app/dist ./dist\nCOPY package*.json ./\nRUN npm install --production\nCMD [\"node\", \"dist/server.js\"]\n\n# Python Dockerfile\nFROM python:3.11-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY . .\nCMD [\"python\", \"app.py\"]",
          "useCase": "Creating custom images, reproducible builds, CI/CD pipelines",
          "interviewQuestions": [
            {
              "question": "What is the difference between COPY and ADD in Dockerfile?",
              "answer": "COPY simply copies files/directories from source to destination. ADD has additional features: can extract tar files and download files from URLs. Best practice is to use COPY unless you specifically need ADD's extra features."
            },
            {
              "question": "What is the difference between CMD and ENTRYPOINT?",
              "answer": "CMD provides default arguments that can be overridden at runtime. ENTRYPOINT defines the executable and can't be easily overridden. Often used together: ENTRYPOINT for executable, CMD for default arguments. Example: ENTRYPOINT ['python'] CMD ['app.py']"
            },
            {
              "question": "How does Docker layer caching work and why does it matter?",
              "answer": "Docker caches each layer. If an instruction hasn't changed, it reuses cached layer. Order matters: put frequently changing instructions last. Example: COPY package.json before COPY . so dependency installs are cached even when code changes."
            },
            {
              "question": "What is a multi-stage build and why use it?",
              "answer": "Multi-stage builds use multiple FROM statements in one Dockerfile. Build artifacts from earlier stages can be copied to later stages. Benefits: much smaller final images (no build tools), cleaner separation of concerns, better security (fewer attack vectors)."
            },
            {
              "question": "How do you minimize Docker image size?",
              "answer": "Use alpine base images, multi-stage builds, combine RUN commands with &&, remove cache files (apt-get clean, npm cache clean), use .dockerignore, avoid installing unnecessary packages, leverage layer caching properly."
            },
            {
              "question": "What is .dockerignore and why is it important?",
              "answer": ".dockerignore excludes files from build context, similar to .gitignore. Reduces build context size, speeds up builds, prevents sensitive files from being copied. Include node_modules, .git, logs, test files."
            },
            {
              "question": "Explain the exec form vs shell form for CMD and ENTRYPOINT.",
              "answer": "Exec form: CMD ['executable', 'param'] - runs directly, no shell processing, PID 1 is the app. Shell form: CMD executable param - runs in /bin/sh -c, enables variable substitution but app isn't PID 1. Exec form is preferred."
            },
            {
              "question": "What is the purpose of ARG instruction?",
              "answer": "ARG defines build-time variables passed via --build-arg. Only available during build, not in running container. Use for versions, build configs. Example: ARG NODE_VERSION=18, then FROM node:${NODE_VERSION}."
            },
            {
              "question": "Why should you avoid running containers as root?",
              "answer": "Security risk: if container is compromised, attacker has root privileges. Best practice: create non-root user with RUN useradd, then USER username. Limits damage from security vulnerabilities."
            },
            {
              "question": "How do you handle secrets in Dockerfile?",
              "answer": "Never hardcode secrets. Use: Docker secrets (swarm), build-time secrets with --secret mount (BuildKit), ENV vars at runtime, external secret management (Vault). Don't use ARG for secrets (visible in image history)."
            }
          ],
          "exercises": [
            {
              "type": "write",
              "question": "Write a Dockerfile for Node.js app with proper layer caching for npm install.",
              "answer": "FROM node:18-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nEXPOSE 3000\nCMD [\"node\", \"server.js\"]"
            },
            {
              "type": "optimize",
              "question": "How would you optimize a Dockerfile that runs apt-get update and apt-get install in separate RUN commands?",
              "answer": "Combine into one RUN: RUN apt-get update && apt-get install -y package && rm -rf /var/lib/apt/lists/* - reduces layers, prevents stale cache, cleans up."
            },
            {
              "type": "debug",
              "question": "Dockerfile builds successfully but container exits immediately. CMD is 'npm start'. What to check?",
              "answer": "Check if npm start runs in foreground (not daemon). Verify package.json has start script. Check logs with docker logs. Ensure process doesn't exit. Try running interactively first."
            },
            {
              "type": "scenario",
              "question": "You need different Dockerfiles for dev and prod. How to organize?",
              "answer": "Create Dockerfile.dev and Dockerfile.prod. Use docker build -f Dockerfile.prod. Or use multi-stage with target: docker build --target production. Or docker-compose with different build contexts."
            },
            {
              "type": "security",
              "question": "Review: FROM ubuntu, RUN apt-get install curl, USER root. What's wrong?",
              "answer": "Ubuntu base is large (use alpine), missing apt-get update before install, running as root (create non-root user), no cleanup. Should minimize base image and use USER."
            },
            {
              "type": "write",
              "question": "Create multi-stage Dockerfile for Go app: build in one stage, run in alpine.",
              "answer": "FROM golang:1.21 AS builder\nWORKDIR /app\nCOPY . .\nRUN go build -o main .\n\nFROM alpine\nCOPY --from=builder /app/main .\nCMD [\"./main\"]"
            },
            {
              "type": "explain",
              "question": "What happens if you have multiple FROM instructions without AS names?",
              "answer": "Only the last stage is built by default. Previous stages are only built if referenced with --from. Each FROM starts a new build stage."
            },
            {
              "type": "scenario",
              "question": "How to pass database URL at build time without exposing it in image?",
              "answer": "Don't. Pass at runtime with -e or env_file. Build-time secrets stay in layers. Use ARG only for non-sensitive build configs. Use runtime ENV for secrets."
            },
            {
              "type": "optimize",
              "question": "Image is 800MB. How to reduce size for Python Flask app?",
              "answer": "Use python:3.11-slim or alpine instead of full python image, multi-stage build, remove pip cache with --no-cache-dir, use .dockerignore, remove test/dev dependencies."
            },
            {
              "type": "troubleshoot",
              "question": "Build fails with 'COPY failed: stat /var/lib/docker/tmp/file: no such file'. Why?",
              "answer": "File not in build context. Check if file exists relative to Dockerfile location. Verify .dockerignore isn't excluding it. Build context is the directory passed to docker build."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Create Dockerfile for Python app with requirements.txt",
              "code": "FROM python:3.11-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\nCOPY . .\nEXPOSE 5000\nCMD [\"python\", \"app.py\"]",
              "output": "Successfully builds Python Flask/Django app image"
            },
            {
              "type": "program",
              "question": "Program 2: Multi-stage build for React app (build then serve with nginx)",
              "code": "FROM node:18 AS build\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nRUN npm run build\n\nFROM nginx:alpine\nCOPY --from=build /app/build /usr/share/nginx/html\nEXPOSE 80\nCMD [\"nginx\", \"-g\", \"daemon off;\"]",
              "output": "Production-ready React app served by nginx, small image size"
            },
            {
              "type": "program",
              "question": "Program 3: Dockerfile with non-root user for security",
              "code": "FROM node:18-alpine\nRUN addgroup -g 1001 appgroup && adduser -D -u 1001 -G appgroup appuser\nWORKDIR /app\nCOPY --chown=appuser:appgroup . .\nUSER appuser\nEXPOSE 3000\nCMD [\"node\", \"app.js\"]",
              "output": "Container runs as non-root user appuser"
            },
            {
              "type": "program",
              "question": "Program 4: Dockerfile with ARG for configurable Node version",
              "code": "ARG NODE_VERSION=18\nFROM node:${NODE_VERSION}-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nCMD [\"npm\", \"start\"]\n\n# Build: docker build --build-arg NODE_VERSION=20 -t myapp .",
              "output": "Builds with specified Node version from build arg"
            },
            {
              "type": "program",
              "question": "Program 5: Create .dockerignore to exclude node_modules, .git, tests",
              "code": "node_modules\n.git\n.gitignore\n*.md\n.env\n.DS_Store\ntests\n__tests__\n*.test.js\ncoverage",
              "output": "Build context excludes development files, faster builds"
            },
            {
              "type": "program",
              "question": "Program 6: Dockerfile combining multiple RUN commands efficiently",
              "code": "FROM ubuntu:22.04\nRUN apt-get update && \\\n    apt-get install -y curl git && \\\n    rm -rf /var/lib/apt/lists/*\nWORKDIR /app",
              "output": "Single layer with multiple commands, cleaned cache"
            },
            {
              "type": "program",
              "question": "Program 7: ENTRYPOINT and CMD together for flexible container",
              "code": "FROM python:3.11-slim\nWORKDIR /app\nCOPY . .\nENTRYPOINT [\"python\"]\nCMD [\"app.py\"]\n\n# Run: docker run image\n# Or: docker run image script.py",
              "output": "Default runs app.py, can override with different script"
            },
            {
              "type": "program",
              "question": "Program 8: HEALTHCHECK instruction to monitor container health",
              "code": "FROM nginx:alpine\nHEALTHCHECK --interval=10s --timeout=3s --retries=3 \\\n  CMD curl -f http://localhost/ || exit 1\nEXPOSE 80\n\n# Build & run, check health status:\n# docker inspect --format='{{.State.Health.Status}}' my-nginx",
              "output": "Container shows health: healthy after passing check 3 consecutive times"
            },
            {
              "type": "program",
              "question": "Program 9: Use COPY --from to copy from external image (no build stage)",
              "code": "FROM alpine\nCOPY --from=nginx:alpine /etc/nginx/nginx.conf /tmp/nginx.conf\nRUN cat /tmp/nginx.conf | head -5",
              "output": "nginx.conf copied directly from nginx image into alpine container"
            },
            {
              "type": "program",
              "question": "Program 10: Multi-stage build for Go app — build 1.2GB to final 12MB",
              "code": "FROM golang:1.21 AS builder\nWORKDIR /app\nCOPY go.mod go.sum ./\nRUN go mod download\nCOPY . .\nRUN CGO_ENABLED=0 GOOS=linux go build -o server .\n\nFROM scratch\nCOPY --from=builder /app/server /server\nENTRYPOINT [\"/server\"]",
              "output": "Final image ~12MB (scratch base + single binary), vs ~1.2GB builder stage"
            }
          ]
        },
        {
          "id": "docker-build",
          "title": "Building Images",
          "category": "Docker Basics",
          "description": "Build Docker images from Dockerfile and manage them.",
          "explanation": "Building Docker images converts a Dockerfile into a runnable container image. The `docker build` command sends the build context (files in the specified directory) to the Docker daemon, which executes each instruction to create image layers.\n\nBuild context: Everything in the directory passed to `docker build .` is sent to the daemon. A large context slows builds — use .dockerignore to exclude node_modules, .git, tests, etc. The context determines which files COPY/ADD can access.\n\nLayer caching: Docker caches each layer. If a layer's instruction and its input files haven't changed, Docker reuses the cached layer. Cache is invalidated when: instruction changes, source files change, or any previous layer is invalidated. Order instructions from least-changing to most-changing.\n\nTagging strategies: Use semantic versioning (myapp:1.2.3), commit SHA (myapp:sha-abc123), and mutable convenience tags (myapp:latest). In production, always use immutable tags (SHA or exact version) for reproducible deployments.\n\nBuildKit: The modern build backend (default since Docker 23.0). Advantages: parallel stage building, build secrets (`--secret`), SSH agent forwarding (`--ssh`), better caching, inline cache export, and heredoc syntax for multi-line RUN commands.\n\nMulti-platform builds: `docker buildx build --platform linux/amd64,linux/arm64` creates images for multiple architectures. Uses QEMU emulation or cross-compilation. Essential for supporting both x86 and ARM (Apple Silicon, AWS Graviton).\n\nRegistry operations: `docker push` uploads layers to a registry (Docker Hub, ECR, GCR, ACR). Only new/changed layers are pushed. `docker pull` downloads layers. Use `docker save/load` for offline transfer.",
          "command": "# Build image from Dockerfile\ndocker build -t myapp:1.0 .\n\n# Build with build arguments\ndocker build --build-arg VERSION=1.0 -t myapp:1.0 .\n\n# Build with specific Dockerfile\ndocker build -f Dockerfile.prod -t myapp:prod .\n\n# Build without cache\ndocker build --no-cache -t myapp:1.0 .\n\n# Tag an image\ndocker tag myapp:1.0 myapp:latest\ndocker tag myapp:1.0 myregistry.com/myapp:1.0\n\n# Push image to registry\ndocker push myregistry.com/myapp:1.0\n\n# Save image to tar file\ndocker save myapp:1.0 > myapp.tar\n\n# Load image from tar file\ndocker load < myapp.tar",
          "example": "# Build arg in Dockerfile\nARG NODE_VERSION=18\nFROM node:${NODE_VERSION}\nARG APP_VERSION\nENV VERSION=${APP_VERSION}\n\n# Build with args\ndocker build --build-arg NODE_VERSION=20 --build-arg APP_VERSION=2.0 -t myapp .\n\n# Multi-platform build\ndocker buildx build --platform linux/amd64,linux/arm64 -t myapp .",
          "useCase": "Creating deployable images, versioning, registry management",
          "interviewQuestions": [
            {
              "question": "What is the Docker build context?",
              "answer": "Build context is the set of files at the specified PATH or URL sent to Docker daemon. Everything in context is available to COPY/ADD. Large contexts slow builds. Use .dockerignore to exclude unnecessary files."
            },
            {
              "question": "How does Docker determine if it can use cache for a layer?",
              "answer": "Docker checks if instruction and files haven't changed. For COPY/ADD, checks file checksums. For RUN, checks command string. If parent layers changed, cache is invalidated for all subsequent layers."
            },
            {
              "question": "What is the difference between docker save and docker export?",
              "answer": "docker save saves images with all layers, tags, and history (use with docker load). docker export exports container filesystem as flat tar (loses history, use with docker import). Save for images, export for containers."
            },
            {
              "question": "Explain semantic versioning for Docker image tags.",
              "answer": "Use major.minor.patch format (e.g., 1.2.3). Tag with specific version, update minor/major tags: myapp:1.2.3, myapp:1.2, myapp:1, myapp:latest. Allows users to pin to specific version or track updates."
            },
            {
              "question": "What is Docker BuildKit and its advantages?",
              "answer": "BuildKit is the improved Docker build backend. Features: parallel builds, build secrets, SSH forwarding, better caching, build progress output. Enable with DOCKER_BUILDKIT=1 or in daemon config."
            },
            {
              "question": "How do you handle image tags in CI/CD?",
              "answer": "Tag with commit SHA, branch name, semantic version. Example: myapp:sha-abc123, myapp:main, myapp:v1.2.3, myapp:latest. Use immutable tags (SHA) for production, mutable (latest) for dev."
            },
            {
              "question": "What is a Docker registry and how does authentication work?",
              "answer": "Registry stores Docker images (Docker Hub, ECR, GCR). docker login stores credentials. docker push uploads images, docker pull downloads. Private registries require authentication via login or config.json."
            },
            {
              "question": "How do you build images for multiple architectures?",
              "answer": "Use docker buildx with --platform flag: docker buildx build --platform linux/amd64,linux/arm64,linux/arm/v7 -t myapp --push. Requires BuildKit and buildx. Creates manifest list."
            },
            {
              "question": "What is the purpose of docker build --target?",
              "answer": "In multi-stage builds, --target stops at specific stage. Example: docker build --target development for dev image with debug tools, --target production for optimized prod image. Same Dockerfile, different outputs."
            },
            {
              "question": "How do you inspect image layers and history?",
              "answer": "Use docker history imagename to see layers, commands, and sizes. Use docker inspect for detailed JSON metadata. Tools like dive can analyze and optimize layer sizes interactively."
            }
          ],
          "exercises": [
            {
              "type": "command",
              "question": "Build image tagged as myapp:v2.1.0 from current directory",
              "answer": "docker build -t myapp:v2.1.0 ."
            },
            {
              "type": "command",
              "question": "Build without cache using Dockerfile.production, tag as myapp:prod",
              "answer": "docker build --no-cache -f Dockerfile.production -t myapp:prod ."
            },
            {
              "type": "scenario",
              "question": "You need to pass DB_VERSION=postgres:15 at build time. How?",
              "answer": "Add ARG DB_VERSION in Dockerfile. Build with: docker build --build-arg DB_VERSION=postgres:15 -t myapp ."
            },
            {
              "type": "command",
              "question": "Tag existing image localhost:5000/myapp:1.0 to push to Docker Hub as username/myapp:latest",
              "answer": "docker tag localhost:5000/myapp:1.0 username/myapp:latest"
            },
            {
              "type": "troubleshoot",
              "question": "Build is very slow, sending 2GB context. How to diagnose and fix?",
              "answer": "Check build context size with docker build output. Add .dockerignore to exclude node_modules, .git, logs, test files. Only include necessary files."
            },
            {
              "type": "scenario",
              "question": "How to save image to file for offline transfer to another machine?",
              "answer": "docker save myapp:1.0 -o myapp.tar (or > myapp.tar). Transfer file. Load with: docker load -i myapp.tar (or < myapp.tar)."
            },
            {
              "type": "explain",
              "question": "What's the benefit of tagging with both specific version and latest?",
              "answer": "Specific version for reproducibility and rollback. Latest for convenience and dev environments. Tag both: docker tag myapp:1.2.3 myapp:latest."
            },
            {
              "type": "command",
              "question": "View detailed build history and layer sizes for nginx image",
              "answer": "docker history nginx"
            },
            {
              "type": "scenario",
              "question": "Build only the 'builder' stage from multi-stage Dockerfile",
              "answer": "docker build --target builder -t myapp-builder ."
            },
            {
              "type": "security",
              "question": "Why shouldn't you use docker commit for production images?",
              "answer": "Not reproducible, no version control, includes all container changes (may include secrets/temp files), can't leverage caching. Always use Dockerfile."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Build image with version tag and latest tag in one command",
              "code": "docker build -t myapp:1.0.0 -t myapp:latest .\n# Or build once then tag:\ndocker build -t myapp:1.0.0 .\ndocker tag myapp:1.0.0 myapp:latest",
              "output": "Image tagged with both specific version and latest"
            },
            {
              "type": "program",
              "question": "Program 2: Build with build arg, verify ENV is set in container",
              "code": "docker build --build-arg APP_ENV=production -t myapp .\ndocker run --rm myapp env | grep APP_ENV",
              "output": "Shows APP_ENV=production in container environment"
            },
            {
              "type": "program",
              "question": "Program 3: Save image to tar, remove image, reload from tar",
              "code": "docker save myapp:1.0 -o myapp.tar\ndocker rmi myapp:1.0\ndocker load -i myapp.tar\ndocker images | grep myapp",
              "output": "Image successfully restored from tar file"
            },
            {
              "type": "program",
              "question": "Program 4: View image history to identify largest layers",
              "code": "docker history myapp --format \"table {{.Size}}\\t{{.CreatedBy}}\" --no-trunc",
              "output": "Shows layer sizes and commands that created them"
            },
            {
              "type": "program",
              "question": "Program 5: Build without cache, compare build time with cached build",
              "code": "time docker build --no-cache -t myapp:nocache .\ntime docker build -t myapp:cached .",
              "output": "Shows significant time difference, cached build much faster"
            },
            {
              "type": "program",
              "question": "Program 6: Tag image for different registries (Docker Hub and private)",
              "code": "docker tag myapp:1.0 username/myapp:1.0\ndocker tag myapp:1.0 registry.company.com/myapp:1.0\ndocker images | grep myapp",
              "output": "Same image ID with multiple registry tags"
            },
            {
              "type": "program",
              "question": "Program 7: Build target stage from multi-stage Dockerfile",
              "code": "docker build --target development -t myapp:dev .\ndocker build --target production -t myapp:prod .\ndocker images | grep myapp",
              "output": "Two different images from same Dockerfile, different stages"
            },
            {
              "type": "program",
              "question": "Program 8: Build with BuildKit secret (don't bake secrets into image)",
              "code": "# Dockerfile: RUN --mount=type=secret,id=npmrc,target=/root/.npmrc npm install\n# Build command:\nDOCKER_BUILDKIT=1 docker build --secret id=npmrc,src=.npmrc -t myapp .\ndocker history myapp | grep npmrc",
              "output": "Secret used during build but NOT present in any image layer"
            },
            {
              "type": "program",
              "question": "Program 9: Compare image sizes before and after multi-stage build",
              "code": "docker build -t myapp:single -f Dockerfile.single .\ndocker build -t myapp:multi -f Dockerfile.multi .\ndocker images --format '{{.Repository}}:{{.Tag}} {{.Size}}' | grep myapp",
              "output": "myapp:single ~900MB vs myapp:multi ~50MB (multi-stage much smaller)"
            },
            {
              "type": "program",
              "question": "Program 10: Inspect image labels and metadata",
              "code": "# Dockerfile: LABEL maintainer=\"dev@company.com\" version=\"1.0\"\ndocker build -t labeled-app .\ndocker inspect labeled-app --format='{{json .Config.Labels}}' | python3 -m json.tool",
              "output": "{\"maintainer\": \"dev@company.com\", \"version\": \"1.0\"}"
            }
          ]
        },
        {
          "id": "networks",
          "title": "Docker Networks",
          "category": "Docker Networking & Volumes",
          "description": "Container networking for communication between containers.",
          "explanation": "Docker networking enables containers to communicate with each other and external systems. Docker creates isolated network namespaces for each container and provides pluggable network drivers for different use cases.\n\nNetwork drivers:\n- bridge (default): Creates a virtual bridge on the host. Containers on the same bridge talk via IP. User-defined bridges also provide DNS resolution by container name. Best for single-host multi-container apps.\n- host: Removes network isolation — container shares the host's network stack directly. No port mapping needed (or possible). Best for performance-critical apps or when you need to bind to many ports.\n- overlay: Multi-host networking for Docker Swarm or container orchestration. Uses VXLAN to encapsulate traffic between hosts. Enables cross-node container communication.\n- macvlan: Assigns a MAC address to each container, making it appear as a physical device on the network. Containers get IPs from the physical network's DHCP. Best for legacy apps that expect to be directly on the LAN.\n- none: Disables all networking. Container is completely isolated. Use for security-sensitive batch jobs.\n\nDNS resolution: User-defined bridge networks (not the default bridge) provide automatic DNS. Container name = hostname. This is why you should always create custom networks instead of using the default bridge.\n\nPort mapping: `-p 8080:80` maps host port 8080 to container port 80. `-p 80` maps container port 80 to a random host port. `-P` publishes all EXPOSE'd ports to random host ports. Use `docker port <container>` to see mappings.\n\nNetwork isolation: Containers on different networks cannot communicate. Connect a container to multiple networks with `docker network connect`. This pattern is used to create DMZ-like architectures (frontend talks to backend, backend talks to database, frontend cannot reach database).\n\nCommon gotcha: The default bridge network does NOT support DNS. Containers must use IP addresses. Always create a user-defined bridge: `docker network create mynet`.",
          "command": "# List networks\ndocker network ls\n\n# Create network\ndocker network create my-network\n\n# Create bridge network\ndocker network create --driver bridge my-bridge\n\n# Inspect network\ndocker network inspect my-network\n\n# Connect container to network\ndocker network connect my-network container-name\n\n# Disconnect container from network\ndocker network disconnect my-network container-name\n\n# Run container on specific network\ndocker run -d --network my-network --name web nginx\n\n# Remove network\ndocker network rm my-network",
          "example": "# Create custom bridge network\ndocker network create --subnet=172.18.0.0/16 my-custom-network\n\n# Run containers on same network\ndocker run -d --network my-network --name db postgres\ndocker run -d --network my-network --name web -p 80:80 nginx\n\n# Containers can communicate using names\n# From 'web' container: curl http://db:5432\n\n# Host network (share host's network)\ndocker run -d --network host nginx",
          "useCase": "Microservices communication, container isolation, service discovery",
          "interviewQuestions": [
            {
              "question": "What are the different Docker network drivers?",
              "answer": "Bridge (default, isolated network), host (share host network), overlay (multi-host Swarm), macvlan (assign MAC addresses), none (no networking). Each suits different use cases."
            },
            {
              "question": "How do containers on the same custom bridge network communicate?",
              "answer": "By container name via Docker's embedded DNS server. Example: curl http://container-name:port. Default bridge requires --link or IP addresses. Custom bridge is recommended."
            },
            {
              "question": "What is the difference between -p and --expose?",
              "answer": "-p publishes port to host (accessible externally): -p 8080:80. --expose only documents port (doesn't publish). EXPOSE in Dockerfile also just documents, needs -P or -p to publish."
            },
            {
              "question": "When would you use host network mode?",
              "answer": "For maximum performance (no network overhead), when container needs host network stack, or binding to many ports. Drawback: loses network isolation, port conflicts possible."
            },
            {
              "question": "How does Docker DNS work?",
              "answer": "Docker runs embedded DNS server (127.0.0.11). Containers on custom networks can resolve each other by name. Maps container names to IP addresses automatically. Default bridge doesn't have DNS (needs --link)."
            },
            {
              "question": "What is an overlay network?",
              "answer": "Overlay networks span multiple Docker hosts in Swarm mode. Enables container communication across hosts. Uses VXLAN tunneling. Required for multi-host deployments and orchestration."
            },
            {
              "question": "How do you isolate containers from each other?",
              "answer": "Put them on different networks. Containers can only communicate if on same network. Use network segmentation for microservices. Connect containers to multiple networks if needed."
            },
            {
              "question": "What happens to container networking when you docker stop?",
              "answer": "Container keeps its IP and network connections but stops responding. Network interface stays registered. On restart with docker start, same IP is typically reassigned (not guaranteed)."
            },
            {
              "question": "How do you connect a running container to a new network?",
              "answer": "Use docker network connect: docker network connect my-network container-name. Container can be on multiple networks. Each network assigns separate IP address."
            },
            {
              "question": "What is the default Docker bridge network?",
              "answer": "docker0 bridge, created automatically. Containers use it by default. Limited features: no DNS, requires --link. Best practice: create custom bridge networks with docker network create."
            }
          ],
          "exercises": [
            {
              "type": "command",
              "question": "Create custom bridge network named app-network",
              "answer": "docker network create app-network"
            },
            {
              "type": "scenario",
              "question": "Run nginx and postgres on same network so nginx can connect to postgres by name",
              "answer": "docker network create mynet\ndocker run -d --network mynet --name db postgres\ndocker run -d --network mynet --name web nginx\n# Web can access: http://db:5432"
            },
            {
              "type": "command",
              "question": "Inspect network to see connected containers and subnet",
              "answer": "docker network inspect my-network"
            },
            {
              "type": "troubleshoot",
              "question": "Container can't resolve other container by name. Why?",
              "answer": "Likely on default bridge network (no DNS). Create custom bridge network and put both containers on it, or use --link (deprecated)."
            },
            {
              "type": "command",
              "question": "Connect running container named api to network named backend",
              "answer": "docker network connect backend api"
            },
            {
              "type": "explain",
              "question": "What is the output of docker network ls?",
              "answer": "Lists all networks: NETWORK ID, NAME, DRIVER, SCOPE. Shows bridge, host, none by default, plus any custom networks."
            },
            {
              "type": "scenario",
              "question": "You need container to access host services on localhost. How?",
              "answer": "Use host.docker.internal (Mac/Windows) or host network mode (--network host on Linux). Or use host IP address."
            },
            {
              "type": "security",
              "question": "Why is network isolation important?",
              "answer": "Prevents unauthorized access between containers. Apply least privilege: only connect containers that need to communicate. Separate frontend/backend/database networks."
            },
            {
              "type": "command",
              "question": "Remove network (but it fails if containers are connected)",
              "answer": "docker network rm my-network\n# If fails: disconnect containers first or docker network rm -f"
            },
            {
              "type": "scenario",
              "question": "Create network with custom subnet 10.0.0.0/24 and gateway 10.0.0.1",
              "answer": "docker network create --subnet=10.0.0.0/24 --gateway=10.0.0.1 my-network"
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Create network, run two containers, verify they can ping each other by name",
              "code": "docker network create testnet\ndocker run -d --network testnet --name c1 alpine sleep 3600\ndocker run -d --network testnet --name c2 alpine sleep 3600\ndocker exec c1 ping -c 2 c2",
              "output": "Successful ping from c1 to c2 using container name"
            },
            {
              "type": "program",
              "question": "Program 2: Inspect network to find container IP addresses",
              "code": "docker network inspect testnet --format=\"{{json .Containers}}\" | jq",
              "output": "JSON showing containers with their IPs on the network"
            },
            {
              "type": "program",
              "question": "Program 3: Run container on host network, verify it uses host IP",
              "code": "docker run --rm --network host alpine ip addr show\n# Compare with host:\nip addr show",
              "output": "Container shows same network interfaces as host"
            },
            {
              "type": "program",
              "question": "Program 4: Connect existing container to additional network",
              "code": "docker network create net1\ndocker network create net2\ndocker run -d --network net1 --name multi alpine sleep 3600\ndocker network connect net2 multi\ndocker inspect multi --format='{{range .NetworkSettings.Networks}}{{.IPAddress}} {{end}}'",
              "output": "Container has IP address on both networks"
            },
            {
              "type": "program",
              "question": "Program 5: Port mapping - map container port 80 to host port 8080",
              "code": "docker run -d -p 8080:80 --name web nginx\ncurl http://localhost:8080",
              "output": "Nginx welcome page accessible on host port 8080"
            },
            {
              "type": "program",
              "question": "Program 6: Test network isolation - containers on different networks can't communicate",
              "code": "docker network create net-a\ndocker network create net-b\ndocker run -d --network net-a --name container-a alpine sleep 3600\ndocker run -d --network net-b --name container-b alpine sleep 3600\ndocker exec container-a ping -c 2 container-b",
              "output": "Ping fails - containers isolated on separate networks"
            },
            {
              "type": "program",
              "question": "Program 7: Create network with custom subnet and run container in it",
              "code": "docker network create --subnet=192.168.100.0/24 custom-subnet\ndocker run -d --network custom-subnet --ip 192.168.100.10 --name static-ip nginx\ndocker inspect static-ip --format='{{.NetworkSettings.Networks.custom-subnet.IPAddress}}'",
              "output": "Container assigned static IP 192.168.100.10"
            },
            {
              "type": "program",
              "question": "Program 8: Test DNS resolution between containers on user-defined network",
              "code": "docker network create dns-test\ndocker run -d --network dns-test --name webserver nginx\ndocker run --rm --network dns-test alpine nslookup webserver",
              "output": "Name: webserver, Address: 172.x.x.x — DNS resolves container name to IP"
            },
            {
              "type": "program",
              "question": "Program 9: Use host network mode and compare with bridge",
              "code": "docker run -d --network host --name host-nginx nginx\nss -tlnp | grep :80\ndocker run -d -p 8080:80 --name bridge-nginx nginx\ndocker port bridge-nginx",
              "output": "Host mode: nginx binds directly to host port 80. Bridge mode: mapped 8080->80"
            },
            {
              "type": "program",
              "question": "Program 10: Inspect default bridge vs user-defined bridge network differences",
              "code": "docker network inspect bridge --format='{{.IPAM.Config}}'\ndocker network create my-bridge\ndocker network inspect my-bridge --format='Driver={{.Driver}} EnableIPv6={{.EnableIPv6}}'\ndocker network inspect my-bridge --format='{{json .Options}}'",
              "output": "Both use bridge driver, but user-defined enables DNS, ICC, and isolation by default"
            }
          ]
        },
        {
          "id": "volumes",
          "title": "Docker Volumes",
          "category": "Docker Networking & Volumes",
          "description": "Persistent data storage for containers.",
          "explanation": "Docker volumes provide persistent storage that survives container lifecycle events (stop, remove, recreate). Without volumes, all data written inside a container is lost when the container is removed — this is because containers use a writable layer on top of read-only image layers.\n\nThree storage options:\n- Named volumes: Managed by Docker, stored in /var/lib/docker/volumes/. Best for production data (databases, uploads). `docker run -v mydata:/app/data`. Docker handles permissions and cleanup.\n- Bind mounts: Maps a host directory into the container. `docker run -v /host/path:/container/path`. Best for development (live code reload). The host path must exist. Container can modify host files (security consideration).\n- tmpfs mounts: Stored in host memory only, never written to disk. `docker run --tmpfs /app/temp`. Best for sensitive data (secrets, session tokens) that should not persist on disk.\n\nVolume lifecycle: Named volumes persist until explicitly removed with `docker volume rm` or `docker volume prune`. They survive container deletion. Bind mounts follow host filesystem lifecycle.\n\nRead-only volumes: Append `:ro` to prevent writes: `-v mydata:/app/config:ro`. Use for config files, certificates, or shared reference data.\n\nSharing volumes: Multiple containers can mount the same volume simultaneously. Use with caution — no built-in locking. Works well for shared logs or read-only config. For databases, ensure only one writer.\n\nBackup pattern: `docker run --rm -v mydata:/data -v $(pwd):/backup alpine tar czf /backup/backup.tar.gz /data`. This mounts the volume and a host directory, then creates a tarball.\n\nAnonymous volumes: Created without a name (`docker run -v /app/data`). Get a random hash name. Hard to manage — prefer named volumes. Useful for the node_modules trick in development to prevent host node_modules from overwriting container's.\n\nVolume drivers: Plugins like local (default), NFS, AWS EBS, Azure File. Enable remote/cloud storage as Docker volumes. Configure with `docker volume create --driver`.",
          "command": "# Create volume\ndocker volume create my-data\n\n# List volumes\ndocker volume ls\n\n# Inspect volume\ndocker volume inspect my-data\n\n# Run container with volume\ndocker run -d -v my-data:/app/data postgres\n\n# Run with bind mount (host directory)\ndocker run -d -v /host/path:/container/path nginx\n\n# Run with read-only volume\ndocker run -d -v my-data:/app/data:ro nginx\n\n# Remove volume\ndocker volume rm my-data\n\n# Remove all unused volumes\ndocker volume prune",
          "example": "# Named volume\ndocker run -d \\\n  -v postgres-data:/var/lib/postgresql/data \\\n  --name db \\\n  postgres\n\n# Bind mount for development\ndocker run -d \\\n  -v $(pwd):/app \\\n  -v /app/node_modules \\\n  --name dev-server \\\n  node:18\n\n# Anonymous volume\ndocker run -d -v /app/data nginx\n\n# Volume from another container\ndocker run -d --volumes-from container1 container2",
          "useCase": "Data persistence, sharing data between containers, backups",
          "interviewQuestions": [
            {
              "question": "What is the difference between volumes and bind mounts?",
              "answer": "Volumes are managed by Docker (stored in /var/lib/docker/volumes), work cross-platform, can use volume drivers. Bind mounts map any host path, depend on host directory structure. Volumes are recommended for production."
            },
            {
              "question": "When would you use a bind mount instead of a volume?",
              "answer": "Development (live code reload), sharing host config files, accessing host logs, when you need specific host path. Example: -v $(pwd):/app for live development with hot reload."
            },
            {
              "question": "What is an anonymous volume and when is it created?",
              "answer": "Volume without a name, created with VOLUME in Dockerfile or -v /container/path. Docker generates random name. Hard to manage, can't easily reuse. Named volumes are preferred."
            },
            {
              "question": "How do you backup data from a Docker volume?",
              "answer": "Run temporary container with volume mounted and backup destination: docker run --rm -v mydata:/data -v $(pwd):/backup alpine tar czf /backup/backup.tar.gz /data"
            },
            {
              "question": "What happens to volume data when container is removed?",
              "answer": "Volume persists even after container deletion. Data is preserved. Use docker volume rm to delete volume, or docker-compose down -v to remove volumes with containers."
            },
            {
              "question": "What is tmpfs mount and when to use it?",
              "answer": "Temporary filesystem stored in host memory (RAM), not persisted. Use for sensitive data (never touches disk) or temp files. Example: --mount type=tmpfs,destination=/app/cache"
            },
            {
              "question": "How can multiple containers share the same volume?",
              "answer": "Mount same named volume in multiple containers: docker run -v shared-data:/data. All containers can read/write. Useful for shared config, logging, or data processing pipelines."
            },
            {
              "question": "What is the ro flag in volume mounts?",
              "answer": "Read-only mount: -v mydata:/data:ro. Container can read but not write. Security best practice for config files, code in production, or data that shouldn't be modified."
            },
            {
              "question": "What is --volumes-from and when to use it?",
              "answer": "Mounts all volumes from another container: docker run --volumes-from container1 image. Useful for data containers pattern, backup containers, or sharing volumes without knowing volume names."
            },
            {
              "question": "How do volume drivers extend Docker storage capabilities?",
              "answer": "Volume drivers enable remote storage (NFS, cloud storage), encryption, replication. Examples: local (default), nfs, rexray for EBS/EFS. Specified with --driver or VOLUME_DRIVER in compose."
            }
          ],
          "exercises": [
            {
              "type": "command",
              "question": "Create named volume called postgres-data",
              "answer": "docker volume create postgres-data"
            },
            {
              "type": "command",
              "question": "Run postgres container with named volume for data persistence",
              "answer": "docker run -d -v postgres-data:/var/lib/postgresql/data --name db postgres"
            },
            {
              "type": "scenario",
              "question": "Mount current directory as bind mount for live development",
              "answer": "docker run -d -v $(pwd):/app --name dev node:18"
            },
            {
              "type": "command",
              "question": "Inspect volume to see mount point and options",
              "answer": "docker volume inspect postgres-data"
            },
            {
              "type": "scenario",
              "question": "How to prevent container from writing to mounted volume?",
              "answer": "Add :ro flag: docker run -v myvolume:/data:ro image. Makes mount read-only."
            },
            {
              "type": "troubleshoot",
              "question": "Volume data disappeared after docker-compose down. Why?",
              "answer": "Used docker-compose down -v which removes volumes. Use docker-compose down (without -v) to preserve volumes."
            },
            {
              "type": "backup",
              "question": "Backup volume named appdata to tar file",
              "answer": "docker run --rm -v appdata:/data -v $(pwd):/backup alpine tar czf /backup/appdata-backup.tar.gz -C /data ."
            },
            {
              "type": "restore",
              "question": "Restore backup.tar.gz to volume",
              "answer": "docker run --rm -v appdata:/data -v $(pwd):/backup alpine tar xzf /backup/backup.tar.gz -C /data"
            },
            {
              "type": "command",
              "question": "Remove all unused volumes to free space",
              "answer": "docker volume prune"
            },
            {
              "type": "scenario",
              "question": "Share volume between nginx and app container for static files",
              "answer": "docker run -v static-files:/static app\ndocker run -v static-files:/usr/share/nginx/html:ro nginx"
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Create volume, write file from container, verify persistence",
              "code": "docker volume create testdata\ndocker run --rm -v testdata:/data alpine sh -c 'echo Hello > /data/test.txt'\ndocker run --rm -v testdata:/data alpine cat /data/test.txt",
              "output": "Hello - data persists across different containers"
            },
            {
              "type": "program",
              "question": "Program 2: Bind mount local directory, modify file from container",
              "code": "mkdir -p testdir\ndocker run --rm -v $(pwd)/testdir:/work alpine sh -c 'echo mounted > /work/file.txt'\ncat testdir/file.txt",
              "output": "File created in container appears in host directory"
            },
            {
              "type": "program",
              "question": "Program 3: Test read-only volume - write should fail",
              "code": "docker volume create readonly-test\ndocker run --rm -v readonly-test:/data:ro alpine sh -c 'echo test > /data/file.txt'",
              "output": "Error: Read-only file system - write operation fails"
            },
            {
              "type": "program",
              "question": "Program 4: Share volume between two containers",
              "code": "docker volume create shared\ndocker run -d --name writer -v shared:/data alpine sh -c 'while true; do date > /data/time.txt; sleep 2; done'\ndocker run --rm -v shared:/data alpine watch -n 1 cat /data/time.txt",
              "output": "Second container reads data written by first container"
            },
            {
              "type": "program",
              "question": "Program 5: Backup volume to tar, remove volume, restore",
              "code": "docker run --rm -v mydata:/data -v $(pwd):/backup alpine tar czf /backup/data.tar.gz /data\ndocker volume rm mydata\ndocker volume create mydata\ndocker run --rm -v mydata:/data -v $(pwd):/backup alpine tar xzf /backup/data.tar.gz -C /",
              "output": "Data successfully backed up and restored"
            },
            {
              "type": "program",
              "question": "Program 6: Use --volumes-from to access another container's volumes",
              "code": "docker run -d --name data-container -v /data alpine sleep 3600\ndocker run --rm --volumes-from data-container alpine ls /data",
              "output": "Second container accesses first container's volume mount"
            },
            {
              "type": "program",
              "question": "Program 7: Inspect volume to find host mount point",
              "code": "docker volume create inspect-test\ndocker volume inspect inspect-test --format=\"{{.Mountpoint}}\"",
              "output": "/var/lib/docker/volumes/inspect-test/_data (Linux) or similar"
            },
            {
              "type": "program",
              "question": "Program 8: Use tmpfs mount for sensitive data that should never persist",
              "code": "docker run -d --name secure-app --tmpfs /app/secrets:rw,size=10m nginx\ndocker exec secure-app sh -c 'echo SECRET > /app/secrets/token.txt && cat /app/secrets/token.txt'\ndocker stop secure-app && docker start secure-app\ndocker exec secure-app cat /app/secrets/token.txt",
              "output": "First read: SECRET. After restart: cat: can't open — tmpfs data gone"
            },
            {
              "type": "program",
              "question": "Program 9: Anonymous volume trick for node_modules in development",
              "code": "docker run -d --name dev-node \\\n  -v $(pwd):/app \\\n  -v /app/node_modules \\\n  -w /app node:18 npm start",
              "output": "Host code synced to /app, but container's node_modules preserved (not overwritten by host)"
            },
            {
              "type": "program",
              "question": "Program 10: Prune unused volumes and show space reclaimed",
              "code": "docker volume create test1 && docker volume create test2\ndocker volume ls\ndocker volume prune -f\ndocker volume ls",
              "output": "Unused volumes removed, space reclaimed, only in-use volumes remain"
            }
          ]
        },
        {
          "id": "docker-compose",
          "title": "Docker Compose Basics",
          "category": "Docker Compose",
          "description": "Define and run multi-container applications with YAML configuration.",
          "explanation": "Docker Compose is a tool for defining and running multi-container applications using a single YAML file (docker-compose.yml or compose.yml). It manages the entire lifecycle: build images, create networks, start containers, stream logs, and tear everything down with one command.\n\nFile structure: The compose file defines services (containers), networks, volumes, and configs. Each service specifies an image (or build context), ports, environment variables, volumes, dependencies, and health checks.\n\nService dependencies: `depends_on` controls startup order but does NOT wait for a service to be 'ready'. For true readiness, use `depends_on` with `condition: service_healthy` and define HEALTHCHECK in the service. Order: db starts → db healthy → backend starts → backend healthy → frontend starts.\n\nNetworking: Compose creates a default bridge network for all services. Services communicate by service name as hostname (e.g., `http://backend:5000` from frontend). Custom networks isolate groups of services.\n\nEnvironment variables: Three ways — `environment:` (inline), `env_file:` (load from .env file), or shell variable substitution `${VAR}` in compose file. Use .env file in the same directory for default values.\n\nVolumes: Named volumes persist data across container restarts (`db-data:/var/lib/postgresql/data`). Bind mounts sync host directories for development (`./src:/app/src`). Anonymous volume trick: mount node_modules to prevent host override.\n\nDev vs Prod: Use `docker-compose.override.yml` for dev-specific config (bind mounts, debug ports). Compose automatically merges docker-compose.yml + docker-compose.override.yml. For production, use `docker compose -f docker-compose.yml -f docker-compose.prod.yml`.\n\nCommon commands: `up -d` (start detached), `down -v` (stop + remove volumes), `logs -f` (follow logs), `exec <svc> sh` (shell into container), `up --build` (rebuild before starting), `ps` (list services).",
          "code": "# docker-compose.yml\nversion: '3.8'\n\nservices:\n  web:\n    image: nginx:latest\n    ports:\n      - \"80:80\"\n    volumes:\n      - ./html:/usr/share/nginx/html\n    networks:\n      - app-network\n  \n  db:\n    image: postgres:15\n    environment:\n      POSTGRES_PASSWORD: secret\n      POSTGRES_DB: myapp\n    volumes:\n      - db-data:/var/lib/postgresql/data\n    networks:\n      - app-network\n\nnetworks:\n  app-network:\n    driver: bridge\n\nvolumes:\n  db-data:",
          "command": "# Start services\ndocker-compose up\n\n# Start in detached mode\ndocker-compose up -d\n\n# Stop services\ndocker-compose down\n\n# Stop and remove volumes\ndocker-compose down -v\n\n# View logs\ndocker-compose logs\ndocker-compose logs -f web\n\n# List services\ndocker-compose ps\n\n# Execute command in service\ndocker-compose exec web bash\n\n# Rebuild services\ndocker-compose up --build",
          "example": "# Full stack example\nversion: '3.8'\n\nservices:\n  frontend:\n    build: ./frontend\n    ports:\n      - \"3000:3000\"\n    depends_on:\n      - backend\n    environment:\n      - API_URL=http://backend:5000\n  \n  backend:\n    build: ./backend\n    ports:\n      - \"5000:5000\"\n    depends_on:\n      - db\n      - redis\n    env_file:\n      - .env\n  \n  db:\n    image: postgres:15\n    volumes:\n      - db-data:/var/lib/postgresql/data\n    environment:\n      POSTGRES_PASSWORD: ${DB_PASSWORD}\n  \n  redis:\n    image: redis:alpine\n    ports:\n      - \"6379:6379\"\n\nvolumes:\n  db-data:",
          "useCase": "Local development, testing, defining multi-container applications",
          "interviewQuestions": [
            {
              "question": "What is Docker Compose and when should you use it?",
              "answer": "Docker Compose is a tool for defining multi-container applications using YAML. Use it for local development, testing, simple deployments. For production: consider Kubernetes, Docker Swarm, or ECS for better scaling and orchestration."
            },
            {
              "question": "What is the purpose of depends_on in docker-compose.yml?",
              "answer": "depends_on controls startup order. Database starts before app. Warning: only waits for container to start, not for service to be ready. Use healthchecks or wait-for scripts for true readiness."
            },
            {
              "question": "How do environment variables work in Compose?",
              "answer": "Three ways: environment key (hardcoded), env_file (.env file), shell substitution (${VAR}). Priority: shell > env_file > environment. Use .env for local dev, pass vars in production."
            },
            {
              "question": "What is the difference between docker-compose up and docker-compose start?",
              "answer": "up creates and starts containers, networks, volumes. start only starts existing stopped containers. up is typically used, start for restarting after docker-compose stop."
            },
            {
              "question": "How do you scale services in Docker Compose?",
              "answer": "docker-compose up --scale web=3 starts 3 web instances. Remove port mappings (conflicts) or use range (8000-8002:80). Better for stateless services. Load balancer needed for traffic distribution."
            },
            {
              "question": "What is the difference between docker-compose down and docker-compose down -v?",
              "answer": "down stops and removes containers, networks. down -v also removes named volumes, deleting all data. Use -v carefully in development, never in production without backups."
            },
            {
              "question": "How do you override compose file for different environments?",
              "answer": "Use multiple files: docker-compose.yml (base), docker-compose.override.yml (auto-merged), docker-compose.prod.yml (docker-compose -f base.yml -f prod.yml up). Override ports, volumes, env vars."
            },
            {
              "question": "What is the build context in docker-compose?",
              "answer": "build: ./path sets build context. Can specify Dockerfile with dockerfile option, build args with args. Context determines COPY/ADD source paths. Keep context small with .dockerignore."
            },
            {
              "question": "How does networking work in Docker Compose?",
              "answer": "Compose creates default network for all services. Services communicate by service name (DNS). Can define custom networks for isolation. Example: frontend network for web, backend for db."
            },
            {
              "question": "What are healthchecks in Compose and why use them?",
              "answer": "healthcheck tests service health (e.g., HTTP endpoint). Used with depends_on in v3.9+ for true dependency management. Service waits until dependency is healthy before starting. Critical for databases."
            }
          ],
          "exercises": [
            {
              "type": "write",
              "question": "Write docker-compose.yml for nginx and postgres with network",
              "answer": "version: '3.8'\nservices:\n  web:\n    image: nginx\n    ports: ['80:80']\n    networks: [app]\n  db:\n    image: postgres\n    networks: [app]\nnetworks:\n  app:"
            },
            {
              "type": "command",
              "question": "Start all services defined in docker-compose.yml in background",
              "answer": "docker-compose up -d"
            },
            {
              "type": "command",
              "question": "View logs for service named 'api' in real-time",
              "answer": "docker-compose logs -f api"
            },
            {
              "type": "scenario",
              "question": "App depends on database. How to ensure DB starts first?",
              "answer": "Use depends_on: services:\n  app:\n    depends_on:\n      - db\n  db:\n    image: postgres\n\nBetter: add healthcheck to db and use condition: service_healthy"
            },
            {
              "type": "command",
              "question": "Execute bash inside running service named 'backend'",
              "answer": "docker-compose exec backend bash"
            },
            {
              "type": "troubleshoot",
              "question": "docker-compose up fails with 'port already allocated'. How to fix?",
              "answer": "Port conflict. Check with docker ps, netstat, or lsof. Stop conflicting container or change port mapping in compose file: ports: ['8080:80']."
            },
            {
              "type": "command",
              "question": "Stop and remove all containers, networks (keep volumes)",
              "answer": "docker-compose down"
            },
            {
              "type": "scenario",
              "question": "How to rebuild service after Dockerfile changes?",
              "answer": "docker-compose up --build or docker-compose build service-name then docker-compose up"
            },
            {
              "type": "write",
              "question": "Add volume for postgres data persistence in compose file",
              "answer": "services:\n  db:\n    image: postgres\n    volumes:\n      - db-data:/var/lib/postgresql/data\nvolumes:\n  db-data:"
            },
            {
              "type": "command",
              "question": "Scale web service to run 3 instances",
              "answer": "docker-compose up --scale web=3"
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Create compose file for Node app with Redis cache",
              "code": "version: \"3.8\"\nservices:\n  app:\n    build: .\n    ports:\n      - \"3000:3000\"\n    depends_on:\n      - redis\n    environment:\n      REDIS_URL: redis://redis:6379\n  redis:\n    image: redis:alpine",
              "output": "App starts after Redis, can connect to redis via hostname 'redis'"
            },
            {
              "type": "program",
              "question": "Program 2: Full-stack app - frontend, backend, database with networks",
              "code": "version: \"3.8\"\nservices:\n  frontend:\n    build: ./client\n    ports: [\"3000:3000\"]\n    networks: [frontend]\n  backend:\n    build: ./server\n    ports: [\"5000:5000\"]\n    networks: [frontend, backend]\n  db:\n    image: postgres\n    networks: [backend]\nnetworks:\n  frontend:\n  backend:",
              "output": "Frontend can't reach DB (isolated), backend can reach both"
            },
            {
              "type": "program",
              "question": "Program 3: Use env_file for environment variables",
              "code": "# .env file:\nDB_USER=admin\nDB_PASS=secret\n\n# docker-compose.yml:\nservices:\n  db:\n    image: postgres\n    env_file: .env\n\n# docker-compose up -d\n# docker-compose exec db env | grep DB_",
              "output": "Environment variables loaded from .env file into container"
            },
            {
              "type": "program",
              "question": "Program 4: Override compose file for production",
              "code": "# docker-compose.yml (base):\nservices:\n  app:\n    build: .\n    ports: [\"3000:3000\"]\n\n# docker-compose.prod.yml:\nservices:\n  app:\n    restart: always\n    environment:\n      NODE_ENV: production\n\n# Run: docker-compose -f docker-compose.yml -f docker-compose.prod.yml up",
              "output": "Production-specific configs applied (restart policy, env)"
            },
            {
              "type": "program",
              "question": "Program 5: Use healthcheck to ensure database is ready",
              "code": "version: \"3.8\"\nservices:\n  app:\n    build: .\n    depends_on:\n      db:\n        condition: service_healthy\n  db:\n    image: postgres\n    healthcheck:\n      test: [\"CMD\", \"pg_isready\", \"-U\", \"postgres\"]\n      interval: 5s\n      timeout: 3s\n      retries: 5",
              "output": "App waits for DB healthcheck to pass before starting"
            },
            {
              "type": "program",
              "question": "Program 6: Mount local code for development with hot reload",
              "code": "version: \"3.8\"\nservices:\n  app:\n    build: .\n    ports: [\"3000:3000\"]\n    volumes:\n      - ./src:/app/src\n      - /app/node_modules\n    environment:\n      NODE_ENV: development",
              "output": "Code changes on host immediately reflected in container"
            },
            {
              "type": "program",
              "question": "Program 7: Scale web service and verify multiple instances",
              "code": "docker-compose up -d --scale web=3\ndocker-compose ps",
              "output": "Shows 3 instances of web service running"
            },
            {
              "type": "program",
              "question": "Program 8: Use docker-compose exec to run database migration",
              "code": "docker-compose exec db psql -U postgres -c 'CREATE TABLE users (id SERIAL, name TEXT);'\ndocker-compose exec db psql -U postgres -c '\\dt'",
              "output": "Table 'users' created and visible in schema listing"
            },
            {
              "type": "program",
              "question": "Program 9: Override compose config with docker-compose.override.yml",
              "code": "# docker-compose.yml: image: node:18\n# docker-compose.override.yml: ports: ['9229:9229'], command: npm run dev\ndocker-compose config\ndocker-compose up -d",
              "output": "Merged config shows dev ports and command, services start with overrides"
            },
            {
              "type": "program",
              "question": "Program 10: Tear down services, volumes, and orphan containers",
              "code": "docker-compose down -v --remove-orphans\ndocker-compose ps\ndocker volume ls | grep project",
              "output": "All services stopped, volumes removed, no orphan containers remaining"
            }
          ]
        },
        {
          "id": "docker-commands",
          "title": "Docker Commands Reference",
          "category": "Docker Basics",
          "description": "Essential Docker commands for container management and troubleshooting.",
          "explanation": "Mastering Docker CLI commands is essential for effective container management, debugging, and optimization. Beyond the basic run/stop/rm cycle, Docker provides powerful commands for resource monitoring, system maintenance, file operations, and container inspection.\n\nContainer inspection: `docker inspect` returns detailed JSON about any Docker object (container, image, network, volume). Use `--format` with Go templates or pipe to `jq` for specific fields: `docker inspect --format='{{.State.Status}}' mycontainer`.\n\nResource monitoring: `docker stats` shows live CPU/memory/network/IO usage for all running containers. `docker top <container>` lists processes. `docker events` streams real-time events (start, stop, die, destroy, health_status) — great for debugging orchestration issues.\n\nFile operations: `docker cp` copies files between host and container without requiring a volume mount. `docker diff` shows filesystem changes (Added, Changed, Deleted) in a container's writable layer vs its image.\n\nContainer lifecycle: `docker update` changes resource limits (memory, CPU, restart policy) on a running container without recreating it. `docker rename` changes container name. `docker wait` blocks until a container stops and returns exit code.\n\nImage forensics: `docker history <image>` shows each layer with its command, size, and creation time. Useful for understanding large images and debugging cache misses. `docker commit` creates an image from a running container — useful for debugging but NOT for production (prefer Dockerfile).\n\nSystem cleanup: `docker system prune` removes stopped containers, dangling images, unused networks. Add `-a` to also remove all unused images. Add `--volumes` for volumes. `docker system df` shows disk usage breakdown by images, containers, volumes, and build cache.\n\nOutput formatting: `docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'` customizes output. Use `--no-trunc` for full IDs. Combine with `--filter` for powerful queries: `docker ps --filter status=exited --filter ancestor=nginx`.",
          "command": "# Container management\ndocker run -it --rm alpine sh  # Interactive, remove after exit\ndocker attach container-name   # Attach to running container\ndocker cp file.txt container:/path  # Copy files\ndocker export container > backup.tar  # Export container\n\n# System commands\ndocker system df  # Show disk usage\ndocker system prune  # Remove unused data\ndocker system prune -a  # Remove all unused images\n\n# Image management\ndocker history image-name  # Show image layers\ndocker commit container new-image  # Create image from container\n\n# Container stats and monitoring\ndocker stats  # Live resource usage\ndocker top container-name  # Running processes\ndocker port container-name  # Port mappings\ndocker diff container-name # File system changes",
          "example": "# Clean up everything\ndocker system prune -a --volumes\n\n# Run with resource limits\ndocker run -d \\\n  --memory=\"512m\" \\\n  --cpus=\"1.5\" \\\n  --name limited-container \\\n  nginx\n\n# Health check in Dockerfile\nHEALTHCHECK --interval=30s --timeout=3s \\\n  CMD curl -f http://localhost/ || exit 1\n\n# Update container restart policy\ndocker update --restart unless-stopped container-name\n\n# View real-time events\ndocker events\n\n# Format output\ndocker ps --format \"table {{.Names}}\\t{{.Status}}\\t{{.Ports}}\"",
          "useCase": "Troubleshooting, monitoring, resource management, maintenance",
          "interviewQuestions": [
            {
              "question": "What is the difference between docker attach and docker exec?",
              "answer": "docker attach connects to container's main process (PID 1), shares stdin/stdout, exiting kills container. docker exec runs new process in container, can run commands without affecting main process. Use exec for debugging."
            },
            {
              "question": "How do you limit container memory and CPU usage?",
              "answer": "Use --memory and --cpus flags: docker run --memory='512m' --cpus='1.5' image. Also: --memory-swap, --memory-reservation, --cpu-shares. Monitor with docker stats. Prevents resource exhaustion."
            },
            {
              "question": "What does docker system prune do and when to use it?",
              "answer": "Removes unused data: stopped containers, dangling images, unused networks. docker system prune -a removes all unused images (not just dangling). Use regularly to free disk space, especially in CI/CD."
            },
            {
              "question": "How do you copy files between host and container?",
              "answer": "docker cp: host to container: docker cp file.txt container:/path, container to host: docker cp container:/path/file.txt ./. Works with running or stopped containers. No volume needed."
            },
            {
              "question": "What is docker diff and what does it show?",
              "answer": "Shows filesystem changes in container vs image. A=added, D=deleted, C=changed files. Useful for debugging, understanding container state, or deciding what to include in new image."
            },
            {
              "question": "How do you view real-time resource usage for all containers?",
              "answer": "docker stats shows live CPU, memory, network I/O, disk I/O for all running containers. docker stats container-name for specific container. Press Ctrl+C to exit. Useful for performance monitoring."
            },
            {
              "question": "What is docker commit and why is it generally discouraged?",
              "answer": "Creates new image from container's changes. Discouraged because: not reproducible, no version control, can include secrets/temp files, can't leverage caching. Use Dockerfile instead for production."
            },
            {
              "question": "How do you view what ports a container is listening on?",
              "answer": "docker port container-name shows port mappings. docker inspect container --format='{{.NetworkSettings.Ports}}' for detailed info in JSON. Lists container ports and their host mappings."
            },
            {
              "question": "What does docker update do and what can you update?",
              "answer": "Updates container configuration without recreating: --restart policy, --memory, --cpu-shares, --cpus. Example: docker update --restart=always container. Useful for adjusting running containers."
            },
            {
              "question": "How do you monitor Docker events in real-time?",
              "answer": "docker events shows real-time stream of Docker daemon events: start, stop, die, kill, create, destroy, etc. Filter with --filter event=start. Useful for debugging, auditing, automation."
            }
          ],
          "exercises": [
            {
              "type": "command",
              "question": "Show disk usage by Docker (images, containers, volumes)",
              "answer": "docker system df"
            },
            {
              "type": "command",
              "question": "Remove all stopped containers, unused networks, dangling images",
              "answer": "docker system prune"
            },
            {
              "type": "scenario",
              "question": "Run container with memory limit of 256MB and 0.5 CPU cores",
              "answer": "docker run --memory='256m' --cpus='0.5' image-name"
            },
            {
              "type": "command",
              "question": "Copy log file from container to current host directory",
              "answer": "docker cp container-name:/var/log/app.log ./"
            },
            {
              "type": "troubleshoot",
              "question": "Container using 100% CPU. How to investigate?",
              "answer": "docker stats container-name to confirm, docker top container-name to see processes, docker exec -it container sh to enter and investigate. Check application logs."
            },
            {
              "type": "command",
              "question": "View changes made to container filesystem",
              "answer": "docker diff container-name"
            },
            {
              "type": "command",
              "question": "Update restart policy of running container to always restart",
              "answer": "docker update --restart=always container-name"
            },
            {
              "type": "scenario",
              "question": "View all Docker events related to container starts",
              "answer": "docker events --filter event=start"
            },
            {
              "type": "command",
              "question": "Format docker ps output to show only names and status",
              "answer": "docker ps --format \"table {{.Names}}\\t{{.Status}}\""
            },
            {
              "type": "cleanup",
              "question": "Remove all Docker data (containers, images, volumes, networks)",
              "answer": "docker system prune -a --volumes"
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Monitor resource usage of running containers",
              "code": "docker run -d --name web nginx\ndocker run -d --name db postgres\ndocker stats --no-stream",
              "output": "Shows CPU, memory, network, and disk usage for all containers"
            },
            {
              "type": "program",
              "question": "Program 2: Copy file into container, verify it exists",
              "code": "echo 'test content' > test.txt\ndocker run -d --name mycontainer alpine sleep 3600\ndocker cp test.txt mycontainer:/tmp/\ndocker exec mycontainer cat /tmp/test.txt",
              "output": "test content - file successfully copied and read"
            },
            {
              "type": "program",
              "question": "Program 3: Run container with memory limit, trigger OOM",
              "code": "docker run -it --rm --memory='50m' alpine sh -c 'dd if=/dev/zero of=/dev/null bs=1M count=100'",
              "output": "Container killed by OOM when exceeding memory limit"
            },
            {
              "type": "program",
              "question": "Program 4: View container filesystem changes",
              "code": "docker run -d --name test alpine sh -c 'echo hello > /tmp/newfile && sleep 3600'\ndocker diff test",
              "output": "A /tmp/newfile - shows files added to container"
            },
            {
              "type": "program",
              "question": "Program 5: Check disk usage, prune unused data",
              "code": "docker system df\ndocker system prune -f\ndocker system df",
              "output": "Shows disk usage before and after cleanup, space reclaimed"
            },
            {
              "type": "program",
              "question": "Program 6: View running processes inside container",
              "code": "docker run -d --name nginx-test nginx\ndocker top nginx-test",
              "output": "Shows nginx master and worker processes running in container"
            },
            {
              "type": "program",
              "question": "Program 7: Update container restart policy without stopping it",
              "code": "docker run -d --name persistent nginx\ndocker update --restart=always persistent\ndocker inspect persistent --format='{{.HostConfig.RestartPolicy.Name}}'",
              "output": "always - restart policy updated on running container"
            },
            {
              "type": "program",
              "question": "Program 8: Monitor real-time Docker events while running operations",
              "code": "# Terminal 1: docker events --filter type=container --format '{{.Action}} {{.Actor.Attributes.name}}'\n# Terminal 2:\ndocker run -d --name event-test nginx\ndocker stop event-test\ndocker rm event-test",
              "output": "Events stream: create event-test, start event-test, kill event-test, stop event-test, destroy event-test"
            },
            {
              "type": "program",
              "question": "Program 9: Filter containers by status and ancestor image",
              "code": "docker ps -a --filter status=exited --filter ancestor=nginx --format 'table {{.Names}}\t{{.Status}}\t{{.CreatedAt}}'\ndocker ps --filter status=running --format '{{.Names}}' | wc -l",
              "output": "Filtered list of exited nginx containers; count of running containers"
            },
            {
              "type": "program",
              "question": "Program 10: Export container filesystem and inspect contents",
              "code": "docker run -d --name export-test nginx\ndocker export export-test > container.tar\ntar tf container.tar | head -20\ndu -sh container.tar",
              "output": "Container filesystem exported as tar, listing shows /etc, /usr, /var directories"
            }
          ]
        },
        {
          "id": "docker-security",
          "title": "Docker Security Best Practices",
          "category": "Docker Security",
          "description": "Secure containers, images, and Docker environments for production.",
          "explanation": "Container security spans the entire lifecycle: building secure images, running containers with minimal privileges, scanning for vulnerabilities, and securing the Docker daemon. A compromised container with root access and host mounts can escalate to full host compromise.\n\nImage security:\n- Use minimal base images (alpine, distroless, scratch) to reduce attack surface. Fewer packages = fewer CVEs.\n- Pin image tags to specific digests in production: `nginx@sha256:abc123...` not `nginx:latest`. Prevents supply-chain attacks.\n- Scan images with `docker scout`, Trivy, or Snyk. Integrate scanning into CI/CD pipelines. Block deployments with critical CVEs.\n- Never store secrets (API keys, passwords) in images. They persist in layer history even if deleted in later layers. Use multi-stage builds or BuildKit secrets.\n\nRuntime security:\n- Run as non-root: Add `USER 1001` in Dockerfile. In Kubernetes, set `runAsNonRoot: true` in securityContext.\n- Drop all Linux capabilities and add only what's needed: `--cap-drop=ALL --cap-add=NET_BIND_SERVICE`.\n- Use read-only root filesystem: `--read-only`. Mount writable tmpfs only where needed.\n- Limit resources (--memory, --cpus) to prevent denial-of-service from runaway containers.\n- Use `--security-opt=no-new-privileges` to prevent privilege escalation via setuid binaries.\n\nDaemon security:\n- Never expose Docker socket over TCP without TLS. The Docker socket grants root-equivalent access.\n- Use rootless Docker mode (Docker 20.10+) to run the daemon without root privileges.\n- Enable Content Trust (DOCKER_CONTENT_TRUST=1) to verify image signatures before pulling.\n\nNetwork security:\n- Use user-defined networks for isolation. Don't use --network=host in production.\n- Don't expose unnecessary ports. Use internal networks for backend services.\n- Enable encrypted overlay networks for cross-host traffic in Swarm.",
          "command": "# Run as non-root user\ndocker run --user 1001:1001 nginx\n\n# Drop all capabilities, add only needed\ndocker run --cap-drop=ALL --cap-add=NET_BIND_SERVICE nginx\n\n# Read-only filesystem\ndocker run --read-only --tmpfs /tmp nginx\n\n# No new privileges\ndocker run --security-opt=no-new-privileges nginx\n\n# Scan image for vulnerabilities\ndocker scout cves nginx:latest\n\n# Content trust\nexport DOCKER_CONTENT_TRUST=1\ndocker pull nginx\n\n# Resource limits\ndocker run --memory=256m --cpus=0.5 --pids-limit=100 nginx",
          "example": "# Secure Dockerfile\nFROM node:18-alpine AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\nCOPY . .\n\nFROM node:18-alpine\nRUN addgroup -g 1001 app && adduser -D -u 1001 -G app app\nWORKDIR /app\nCOPY --from=builder --chown=app:app /app .\nUSER app\nEXPOSE 3000\nHEALTHCHECK --interval=30s CMD wget -qO- http://localhost:3000/health || exit 1\nCMD [\"node\", \"server.js\"]\n\n# Run with full security options\ndocker run -d \\\n  --name secure-app \\\n  --user 1001:1001 \\\n  --read-only \\\n  --tmpfs /tmp \\\n  --cap-drop=ALL \\\n  --security-opt=no-new-privileges \\\n  --memory=512m \\\n  --cpus=1 \\\n  --pids-limit=100 \\\n  secure-app:latest",
          "useCase": "Production deployments, CI/CD security gates, compliance, hardening",
          "interviewQuestions": [
            {
              "question": "Why should containers run as non-root?",
              "answer": "Root in container = root on host (unless user namespaces enabled). If container is compromised, attacker has root access. Use USER instruction in Dockerfile. In K8s, set runAsNonRoot: true in securityContext. Some images require root (workaround: change file ownership during build)."
            },
            {
              "question": "What are Linux capabilities and how do they relate to Docker security?",
              "answer": "Capabilities split root privileges into granular permissions (NET_BIND_SERVICE, SYS_ADMIN, etc.). Docker drops many by default but keeps some. Best practice: --cap-drop=ALL then --cap-add only what's needed. SYS_ADMIN is especially dangerous (mount filesystems, load kernel modules)."
            },
            {
              "question": "How do you scan Docker images for vulnerabilities?",
              "answer": "Tools: docker scout (built-in), Trivy (open source), Snyk, Anchore, Clair. Scan in CI/CD pipeline before pushing to registry. Block images with critical/high CVEs. Regularly rescan deployed images (new CVEs discovered daily). Use minimal base images to reduce surface area."
            },
            {
              "question": "What is Docker Content Trust and why use it?",
              "answer": "DCT uses digital signatures to verify image publisher identity and integrity. Set DOCKER_CONTENT_TRUST=1. Publishers sign images with private key, consumers verify with public key. Prevents pulling tampered or unauthorized images. Uses Notary under the hood."
            },
            {
              "question": "Explain the risks of mounting the Docker socket in a container.",
              "answer": "Mounting /var/run/docker.sock gives container full Docker daemon access = root on host. Container can create privileged containers, access any volume, read any secret. Only mount when absolutely necessary (CI/CD builders). Use rootless Docker or remote Docker API with TLS instead."
            },
            {
              "question": "What is the difference between ADD and COPY from a security perspective?",
              "answer": "ADD can fetch URLs and extract tar archives automatically. This introduces risk: fetching from untrusted URLs, auto-extracting potentially malicious archives. COPY only copies local files. Always prefer COPY. For downloads, use RUN curl/wget with checksum verification."
            },
            {
              "question": "How do you handle secrets in Docker?",
              "answer": "Never in Dockerfile (visible in image history). Options: runtime env vars (-e), Docker secrets (Swarm), BuildKit secrets (--mount=type=secret for build-time), external secret managers (Vault, AWS SM). In K8s: use Secrets with encryption at rest or External Secrets Operator."
            },
            {
              "question": "What is a distroless image and when to use it?",
              "answer": "Google's distroless images contain only the app runtime (no shell, no package manager, no OS utilities). Minimal attack surface. Cannot exec/shell into container (good for security, hard for debugging). Use for production; use regular images for development."
            },
            {
              "question": "How does --read-only filesystem improve security?",
              "answer": "Prevents attackers from writing malicious files, scripts, or backdoors. Container can only write to mounted volumes and tmpfs. Forces developers to be explicit about writable paths. Use --tmpfs /tmp for temporary files. Combine with --no-new-privileges for defense in depth."
            },
            {
              "question": "What is rootless Docker mode?",
              "answer": "Runs Docker daemon and containers without root privileges. Uses user namespaces to map container root to unprivileged host user. Limitations: no binding to ports <1024, some storage driver restrictions. Available since Docker 20.10. Alternative: Podman (rootless by default)."
            }
          ],
          "exercises": [
            {
              "type": "security",
              "question": "A Dockerfile starts with FROM ubuntu:latest, installs curl, runs as root. List all security issues.",
              "answer": "Issues: (1) latest tag is mutable/unpredictable, (2) ubuntu is large base (use alpine/slim), (3) running as root, (4) no HEALTHCHECK, (5) no .dockerignore possibly. Fix: pin tag, use alpine, add USER, add HEALTHCHECK."
            },
            {
              "type": "command",
              "question": "Run an nginx container with maximum security hardening (non-root, read-only, no capabilities).",
              "answer": "docker run -d --user 1001 --read-only --tmpfs /tmp --tmpfs /var/cache/nginx --cap-drop=ALL --security-opt=no-new-privileges --memory=256m nginx"
            },
            {
              "type": "scenario",
              "question": "You find a container running with --privileged flag. What are the risks and how to fix?",
              "answer": "Risks: Full host access, can load kernel modules, access all devices, mount host filesystem, escape container. Fix: Remove --privileged, use specific --cap-add for needed capabilities, use --device for specific devices."
            },
            {
              "type": "debug",
              "question": "Container fails with 'permission denied' when writing to /app/logs. It runs as USER 1001. Fix it.",
              "answer": "Directory /app/logs is owned by root. Fix in Dockerfile: RUN mkdir -p /app/logs && chown 1001:1001 /app/logs before USER instruction. Or mount a volume at /app/logs."
            },
            {
              "type": "command",
              "question": "Scan an image for vulnerabilities using docker scout and filter critical issues.",
              "answer": "docker scout cves nginx:latest --only-severity critical,high"
            },
            {
              "type": "scenario",
              "question": "Your CI/CD pipeline builds images. How do you prevent deploying images with known CVEs?",
              "answer": "Add image scanning step (Trivy/Snyk) before push. Set policy to fail build on critical CVEs. Use admission controllers (OPA/Kyverno) in K8s to block unscanned images. Pin base image digests and rebuild regularly."
            },
            {
              "type": "write",
              "question": "Write a secure Dockerfile for a Python Flask app that follows all best practices.",
              "answer": "FROM python:3.11-slim AS builder\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nFROM python:3.11-slim\nRUN adduser --disabled-password --uid 1001 appuser\nWORKDIR /app\nCOPY --from=builder /usr/local/lib/python3.11 /usr/local/lib/python3.11\nCOPY --chown=appuser . .\nUSER appuser\nEXPOSE 5000\nHEALTHCHECK CMD curl -f http://localhost:5000/health || exit 1\nCMD [\"python\", \"app.py\"]"
            },
            {
              "type": "explain",
              "question": "What is the PID 1 problem in Docker and how to solve it?",
              "answer": "Container's main process runs as PID 1 but doesn't handle signals (SIGTERM) like init does. Result: container doesn't stop gracefully (docker stop hangs 10s then SIGKILL). Solutions: use tini (--init flag), dumb-init, or handle signals in application code."
            },
            {
              "type": "troubleshoot",
              "question": "docker build fails with 'unable to access .git'. The .git directory shouldn't be in the image.",
              "answer": "Missing .dockerignore file. Create .dockerignore with: .git, node_modules, .env, *.md, tests. This also speeds up build context transfer and reduces image size."
            },
            {
              "type": "security",
              "question": "A developer stored an API key in a Dockerfile ENV instruction and later removed it. Is it safe?",
              "answer": "No. Docker layers are immutable. The ENV instruction created a layer with the key. Even if removed in a later layer, the key exists in image history (docker history). Must rebuild without the key and use runtime env vars or secrets instead."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Run container as non-root, verify user ID",
              "code": "docker run --rm --user 1001:1001 alpine id",
              "output": "uid=1001 gid=1001"
            },
            {
              "type": "program",
              "question": "Program 2: Test read-only filesystem with tmpfs for writable paths",
              "code": "docker run --rm --read-only --tmpfs /tmp alpine sh -c 'echo test > /tmp/ok && echo test > /root/fail'",
              "output": "First write succeeds (tmpfs), second fails (Read-only file system)"
            },
            {
              "type": "program",
              "question": "Program 3: Drop all capabilities, verify none remain",
              "code": "docker run --rm --cap-drop=ALL alpine sh -c 'cat /proc/1/status | grep Cap'",
              "output": "CapEff: 0000000000000000 (no effective capabilities)"
            },
            {
              "type": "program",
              "question": "Program 4: Scan image with Trivy for vulnerabilities",
              "code": "docker run --rm aquasec/trivy image nginx:latest --severity HIGH,CRITICAL --no-progress 2>/dev/null | tail -20",
              "output": "Table of HIGH/CRITICAL CVEs found in nginx image (or 0 if up to date)"
            },
            {
              "type": "program",
              "question": "Program 5: Verify image layer history for leaked secrets",
              "code": "docker history nginx:latest --no-trunc --format '{{.CreatedBy}}' | head -10",
              "output": "Shows all commands used to build each layer (check for ENV with secrets)"
            },
            {
              "type": "program",
              "question": "Program 6: Run with --init flag to solve PID 1 problem",
              "code": "docker run -d --init --name pid1-test alpine sleep 3600\ndocker exec pid1-test ps aux | head -3",
              "output": "PID 1 is tini (init process), PID 2 is sleep (app process handles signals properly)"
            },
            {
              "type": "program",
              "question": "Program 7: Use BuildKit secret to pass npm token during build",
              "code": "echo '//registry.npmjs.org/:_authToken=secret-token' > .npmrc\nDOCKER_BUILDKIT=1 docker build --secret id=npmrc,src=.npmrc -t secure-build .\n# Dockerfile: RUN --mount=type=secret,id=npmrc,target=/root/.npmrc npm ci",
              "output": "Build succeeds using secret, but secret not stored in any image layer"
            },
            {
              "type": "program",
              "question": "Program 8: Compare image sizes: ubuntu vs alpine vs distroless",
              "code": "docker pull ubuntu:22.04\ndocker pull alpine:3.18\ndocker pull gcr.io/distroless/static-debian12\ndocker images --format '{{.Repository}}:{{.Tag}} {{.Size}}' | grep -E 'ubuntu|alpine|distroless'",
              "output": "ubuntu ~77MB, alpine ~7MB, distroless ~2MB"
            },
            {
              "type": "program",
              "question": "Program 9: Test no-new-privileges security option",
              "code": "docker run --rm --security-opt=no-new-privileges alpine sh -c 'cat /proc/1/status | grep NoNewPrivs'",
              "output": "NoNewPrivs: 1 (setuid binaries cannot escalate privileges)"
            },
            {
              "type": "program",
              "question": "Program 10: Limit container PID count to prevent fork bombs",
              "code": "docker run --rm --pids-limit=10 alpine sh -c 'for i in $(seq 1 20); do sleep 100 & done; echo $i'",
              "output": "Resource temporarily unavailable after 10 processes (fork bomb prevented)"
            }
          ]
        },
        {
          "id": "docker-best-practices",
          "title": "Docker Production Best Practices",
          "category": "Docker Security",
          "description": "Production-ready Docker patterns, optimization, and operational best practices.",
          "explanation": "Running Docker in production requires careful attention to image optimization, container orchestration, logging, monitoring, and graceful shutdown patterns. Small mistakes in Dockerfile design can lead to large images, slow deployments, and security vulnerabilities.\n\nImage optimization:\n- Order Dockerfile instructions from least-changing to most-changing. Dependencies (package.json) before source code. This maximizes layer cache hits.\n- Use multi-stage builds to separate build tools from runtime. Go apps: 1.2GB builder → 12MB scratch final. Node apps: remove devDependencies in final stage.\n- Combine RUN commands with && to reduce layers. Clean up in the SAME layer: `RUN apt-get update && apt-get install -y pkg && rm -rf /var/lib/apt/lists/*`.\n- Use .dockerignore to exclude .git, node_modules, tests, docs from build context.\n\nGraceful shutdown (PID 1 problem):\n- Docker sends SIGTERM to PID 1 on `docker stop`. If PID 1 doesn't handle SIGTERM, Docker waits 10 seconds then sends SIGKILL (data loss risk).\n- Shell form CMD (`CMD npm start`) runs under /bin/sh which does NOT forward signals. Use exec form: `CMD [\"node\", \"server.js\"]`.\n- Use --init flag or tini for proper signal handling. In Node.js, handle SIGTERM: `process.on('SIGTERM', () => server.close())`.\n\nLogging:\n- Write logs to stdout/stderr, not files. Docker captures stdout/stderr via logging drivers.\n- Use structured logging (JSON format) for easy parsing by ELK/Loki/CloudWatch.\n- Configure log rotation: `--log-opt max-size=10m --log-opt max-file=3` to prevent disk exhaustion.\n\nHealth checks:\n- Always define HEALTHCHECK in production images. Docker marks unhealthy containers and orchestrators can restart them.\n- HEALTHCHECK should test actual application health, not just process existence. Use HTTP endpoint, database connection, or queue connectivity.\n\nOne process per container:\n- Each container should run one process (or one concern). Separate web server, background worker, and database into different containers.\n- Use docker-compose or orchestrators to manage multi-container applications.\n- Exception: sidecar patterns (log shipper alongside app) are acceptable.",
          "command": "# Check image size breakdown\ndocker images --format '{{.Repository}}:{{.Tag}} {{.Size}}'\ndocker system df -v\n\n# View layer sizes\ndocker history myapp --format 'table {{.Size}}\\t{{.CreatedBy}}' --no-trunc\n\n# Run with logging limits\ndocker run -d --log-opt max-size=10m --log-opt max-file=3 nginx\n\n# Run with init for signal handling\ndocker run -d --init myapp\n\n# Inspect health status\ndocker inspect --format='{{json .State.Health}}' myapp\n\n# Prune everything safely\ndocker system prune -a --volumes --filter 'until=24h'",
          "example": "# Production-ready Dockerfile for Node.js\nFROM node:18-alpine AS deps\nWORKDIR /app\nCOPY package.json package-lock.json ./\nRUN npm ci --only=production\n\nFROM node:18-alpine\nRUN addgroup -g 1001 app && adduser -D -u 1001 -G app app\nWORKDIR /app\nCOPY --from=deps --chown=app:app /app/node_modules ./node_modules\nCOPY --chown=app:app . .\nUSER app\nENV NODE_ENV=production\nEXPOSE 3000\nHEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \\\n  CMD wget -qO- http://localhost:3000/health || exit 1\nCMD [\"node\", \"server.js\"]\n\n# .dockerignore\nnode_modules\n.git\n*.md\ntests\ncoverage\n.env\nDockerfile*\ndocker-compose*",
          "useCase": "Production deployments, CI/CD pipelines, performance optimization, operational excellence",
          "interviewQuestions": [
            {
              "question": "What is the PID 1 problem in Docker and how to solve it?",
              "answer": "Container's PID 1 doesn't get default signal handlers. Shell form CMD runs under /bin/sh which doesn't forward SIGTERM to child process. Solutions: (1) Use exec form CMD [\"node\", \"app.js\"], (2) Use --init flag (tini), (3) Handle SIGTERM in application code. Without this, docker stop kills process after 10s timeout."
            },
            {
              "question": "How do you optimize Docker image size?",
              "answer": "Use minimal base (alpine/slim/distroless), multi-stage builds, combine RUN commands, clean package manager cache in same layer, use .dockerignore, remove dev dependencies, use --no-cache-dir for pip. Example: Node app 900MB → 150MB with alpine + multi-stage."
            },
            {
              "question": "Explain Docker layer caching and how to optimize it.",
              "answer": "Each Dockerfile instruction creates a cached layer. Cache invalidated when instruction or input changes, and ALL subsequent layers rebuild. Optimization: put rarely-changing instructions first (FROM, RUN apt-get), copy dependency files before source code, use --mount=type=cache for package managers."
            },
            {
              "question": "Shell form vs exec form for CMD/ENTRYPOINT — when to use each?",
              "answer": "Exec form: CMD [\"node\", \"app.js\"] — runs directly, receives signals, preferred for production. Shell form: CMD node app.js — runs under /bin/sh, allows variable expansion, doesn't receive signals properly. Always use exec form in production."
            },
            {
              "question": "How should containers handle logging?",
              "answer": "Write to stdout/stderr (not files). Docker captures these via logging drivers (json-file, syslog, fluentd, awslogs). Use structured JSON logging for easy parsing. Set log rotation: --log-opt max-size=10m --log-opt max-file=3. In production, ship to centralized logging (ELK, Loki)."
            },
            {
              "question": "What is the 'one process per container' principle?",
              "answer": "Each container should run one process/concern. Easier to scale independently, simpler health checks, better resource allocation, cleaner logs. Exceptions: sidecar patterns. Anti-pattern: running nginx + app + cron in one container. Use compose/orchestrator for multi-service apps."
            },
            {
              "question": "How do you implement zero-downtime deployments with Docker?",
              "answer": "Use orchestrator (Swarm/K8s) with rolling updates. Health checks ensure new containers are ready before removing old ones. Graceful shutdown: handle SIGTERM, finish in-flight requests, close connections, then exit. Set stop_grace_period appropriately."
            },
            {
              "question": "What is .dockerignore and why is it important?",
              "answer": ".dockerignore excludes files from build context. Reduces context size (faster builds), prevents secrets (.env) from entering image, avoids node_modules conflicts. Similar to .gitignore syntax. Should always exclude: .git, node_modules, .env, tests, docs, Dockerfile."
            },
            {
              "question": "How do you handle environment-specific configuration in Docker?",
              "answer": "Use ENV for defaults, override at runtime with -e or --env-file. Use docker-compose.override.yml for env-specific settings. Never bake environment-specific config into images. Use ConfigMaps/Secrets in Kubernetes. Image should be identical across all environments."
            },
            {
              "question": "Explain the difference between COPY and ADD, and when to use each.",
              "answer": "COPY: copies local files only. Simple, predictable, preferred. ADD: copies files + can extract tar archives + can fetch URLs. ADD's implicit behavior is a risk (auto-extraction, URL fetching). Best practice: always use COPY. For tar extraction: use RUN tar. For URLs: use RUN curl."
            }
          ],
          "exercises": [
            {
              "type": "optimize",
              "question": "This Dockerfile has poor cache hit rate. Fix the layer ordering:\nCOPY . .\nRUN npm install\nEXPOSE 3000\nCMD [\"node\", \"app.js\"]",
              "answer": "COPY package.json package-lock.json ./\nRUN npm install\nCOPY . .\nEXPOSE 3000\nCMD [\"node\", \"app.js\"]\n\nCopy dependency files first, install, then copy source. npm install layer cached until package.json changes."
            },
            {
              "type": "debug",
              "question": "Container takes 10 seconds to stop with docker stop. What's wrong?",
              "answer": "PID 1 isn't handling SIGTERM. Likely using shell form CMD. Fix: use exec form CMD [\"node\", \"app.js\"] or add --init flag. Also add signal handler in app: process.on('SIGTERM', () => server.close(cb))"
            },
            {
              "type": "write",
              "question": "Write a .dockerignore file for a Node.js project.",
              "answer": "node_modules\n.git\n.gitignore\n*.md\n.env\n.env.*\ntests\n__tests__\ncoverage\n.nyc_output\nDockerfile*\ndocker-compose*\n.dockerignore\n.vscode\n.DS_Store"
            },
            {
              "type": "scenario",
              "question": "Image is 1.2GB for a simple Go API. How to get it under 20MB?",
              "answer": "Use multi-stage build. Stage 1: golang:1.21 for build with CGO_ENABLED=0. Stage 2: FROM scratch, COPY binary only. Final image = binary size only (~10-15MB). Add ca-certificates if HTTPS needed."
            },
            {
              "type": "troubleshoot",
              "question": "RUN apt-get update is cached but packages are outdated. Fix it.",
              "answer": "Combine update and install in one RUN: RUN apt-get update && apt-get install -y pkg && rm -rf /var/lib/apt/lists/*. Separate RUN means update layer is cached and never re-runs even when packages change."
            },
            {
              "type": "explain",
              "question": "Why should HEALTHCHECK test application health, not just process existence?",
              "answer": "Process can be alive but deadlocked, out of memory, or unable to serve requests. HEALTHCHECK should verify actual functionality: HTTP 200 from /health endpoint, database connection success, queue consumer active. Docker/orchestrator uses this to restart unhealthy containers."
            },
            {
              "type": "security",
              "question": "A Dockerfile uses ADD to fetch a binary from the internet. What's the risk?",
              "answer": "Risk: MITM attack could replace binary. No integrity verification. URL could change to malicious payload. Fix: use RUN with curl/wget + checksum verification: RUN curl -fsSL https://url -o bin && echo 'sha256hash bin' | sha256sum -c -"
            },
            {
              "type": "scenario",
              "question": "Disk is full on Docker host. Diagnose and fix.",
              "answer": "docker system df (check usage). docker image prune -a (remove unused images). docker container prune (remove stopped containers). docker volume prune (remove unused volumes). docker builder prune (clean build cache). Set up automated cleanup cron job."
            },
            {
              "type": "optimize",
              "question": "Python Dockerfile installs dev dependencies in production image. Fix it.",
              "answer": "Multi-stage: FROM python:3.11-slim AS builder, pip install -r requirements.txt. FROM python:3.11-slim, COPY --from=builder /usr/local/lib/python3.11/site-packages. Or use pip install --no-dev if using pipenv/poetry."
            },
            {
              "type": "command",
              "question": "Configure Docker daemon to limit default container log size to 10MB, max 3 files.",
              "answer": "Edit /etc/docker/daemon.json: {\"log-driver\": \"json-file\", \"log-opts\": {\"max-size\": \"10m\", \"max-file\": \"3\"}}. Restart dockerd. Or per-container: docker run --log-opt max-size=10m --log-opt max-file=3"
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Compare image sizes with different base images",
              "code": "docker build -t app:full -f- . <<'EOF'\nFROM node:18\nWORKDIR /app\nCOPY package.json .\nRUN npm install\nCOPY . .\nCMD [\"node\", \"app.js\"]\nEOF\ndocker build -t app:alpine -f- . <<'EOF'\nFROM node:18-alpine\nWORKDIR /app\nCOPY package.json .\nRUN npm install\nCOPY . .\nCMD [\"node\", \"app.js\"]\nEOF\ndocker images | grep app",
              "output": "app:full ~900MB vs app:alpine ~170MB"
            },
            {
              "type": "program",
              "question": "Program 2: Test graceful shutdown with signal handling",
              "code": "docker run -d --init --name graceful nginx\ntime docker stop graceful\ndocker run -d --name ungraceful nginx\ntime docker stop ungraceful",
              "output": "Graceful stops in <1s, ungraceful may take up to 10s (SIGKILL timeout)"
            },
            {
              "type": "program",
              "question": "Program 3: Verify HEALTHCHECK status transitions",
              "code": "docker run -d --name health-test --health-cmd='curl -f http://localhost/ || exit 1' --health-interval=5s --health-retries=3 nginx\nsleep 2\ndocker inspect health-test --format='{{.State.Health.Status}}'\nsleep 15\ndocker inspect health-test --format='{{.State.Health.Status}}'",
              "output": "starting (first check), then healthy (after passing retries)"
            },
            {
              "type": "program",
              "question": "Program 4: Check build cache usage and efficiency",
              "code": "docker builder prune -f\ndocker build -t cache-test . 2>&1 | grep -E 'CACHED|RUN'\ndocker build -t cache-test . 2>&1 | grep -E 'CACHED|RUN'",
              "output": "First build: no CACHED. Second build: all steps show CACHED (100% cache hit)"
            },
            {
              "type": "program",
              "question": "Program 5: Verify log rotation prevents disk exhaustion",
              "code": "docker run -d --name log-test --log-opt max-size=1k --log-opt max-file=2 alpine sh -c 'while true; do echo $(date) log entry; sleep 0.1; done'\nsleep 5\nls -la /var/lib/docker/containers/$(docker inspect log-test --format='{{.Id}}')/*-json.log*",
              "output": "Only 2 log files, each max 1KB (rotated automatically)"
            },
            {
              "type": "program",
              "question": "Program 6: check disk usage and clean up",
              "code": "docker system df\ndocker system prune -a --volumes -f\ndocker system df",
              "output": "Shows reclaimable space before, 0B reclaimable after cleanup"
            },
            {
              "type": "program",
              "question": "Program 7: Verify .dockerignore excludes files from build context",
              "code": "echo 'node_modules' > .dockerignore\nmkdir -p node_modules && dd if=/dev/zero of=node_modules/big bs=1M count=100\ntime docker build -t ignore-test . 2>&1 | head -3\nrm .dockerignore\ntime docker build -t no-ignore-test . 2>&1 | head -3",
              "output": "With .dockerignore: small context, fast. Without: 100MB+ context sent, slow"
            },
            {
              "type": "program",
              "question": "Program 8: Multi-stage build size comparison",
              "code": "docker build -t go-single --target builder .\ndocker build -t go-multi .\ndocker images --format '{{.Repository}}:{{.Tag}} {{.Size}}' | grep go-",
              "output": "go-single ~1.2GB (includes Go toolchain), go-multi ~12MB (binary only)"
            },
            {
              "type": "program",
              "question": "Program 9: Test exec form vs shell form signal handling",
              "code": "# Shell form (doesn't handle signals properly)\ndocker run -d --name shell-form alpine sh -c 'sleep 3600'\ntime docker stop shell-form\n\n# Exec form (handles signals)\ndocker run -d --name exec-form alpine sleep 3600\ntime docker stop exec-form",
              "output": "shell-form: ~10s (SIGKILL after timeout). exec-form: instant (SIGTERM handled)"
            },
            {
              "type": "program",
              "question": "Program 10: Inspect container resource limits",
              "code": "docker run -d --name limited --memory=256m --cpus=1.5 --pids-limit=50 nginx\ndocker inspect limited --format='Memory={{.HostConfig.Memory}} CPUs={{.HostConfig.NanoCpus}} PIDs={{.HostConfig.PidsLimit}}'",
              "output": "Memory=268435456 CPUs=1500000000 PIDs=50 (limits enforced at runtime)"
            }
          ]
        },
        {
          "id": "docker-registry",
          "title": "Docker Registry & Image Management",
          "category": "Docker Security",
          "description": "Private registries, image lifecycle management, and registry operations.",
          "explanation": "A Docker registry stores and distributes container images. Docker Hub is the default public registry, but production environments typically use private registries for security, compliance, and performance.\n\nRegistry types:\n- Docker Hub: Public/private repos, automated builds, vulnerability scanning. Free tier: 1 private repo.\n- Amazon ECR: Fully managed, IAM integration, image scanning, lifecycle policies.\n- Google Artifact Registry: Multi-format (Docker, npm, Maven), IAM, vulnerability scanning.\n- Azure Container Registry: Geo-replication, content trust, ACR Tasks for building.\n- Self-hosted: Docker Registry (open source), Harbor (enterprise features: replication, signing, scanning, RBAC).\n\nImage tagging strategy:\n- Semantic versioning: myapp:1.2.3, myapp:1.2, myapp:1 (cascading tags).\n- Git SHA: myapp:sha-abc123 (immutable, traceable to exact commit).\n- Branch: myapp:main, myapp:develop (mutable, latest from branch).\n- Never rely on :latest in production — it's mutable and unpredictable.\n- Use image digests for maximum reproducibility: myapp@sha256:abc...\n\nImage lifecycle:\n- Build → Scan → Tag → Push → Deploy → Monitor → Deprecate → Delete.\n- Implement lifecycle policies to auto-delete old images (e.g., keep last 10 tags, delete untagged after 7 days).\n- Use image promotion: dev registry → staging registry → prod registry.\n\nContent Trust & Signing:\n- Docker Content Trust (DCT) uses Notary for image signing.\n- Cosign (Sigstore) is the modern alternative — keyless signing with OIDC identity.\n- Verify signatures before deployment using admission controllers (Kyverno, OPA).\n\nOptimizing pull performance:\n- Place registry close to deployment (same region/network).\n- Use registry mirrors/caches for frequently pulled images.\n- Layer sharing: common base images are pulled once and shared across containers.\n- Use --pull-policy=IfNotPresent in Kubernetes to avoid unnecessary pulls.",
          "command": "# Login to registry\ndocker login\ndocker login registry.example.com\n\n# Tag for private registry\ndocker tag myapp:1.0 registry.example.com/team/myapp:1.0\n\n# Push image\ndocker push registry.example.com/team/myapp:1.0\n\n# Pull image\ndocker pull registry.example.com/team/myapp:1.0\n\n# List tags (Docker Hub API)\ncurl -s https://hub.docker.com/v2/repositories/library/nginx/tags | python3 -m json.tool\n\n# Run local registry\ndocker run -d -p 5000:5000 --name registry registry:2\n\n# Push to local registry\ndocker tag myapp localhost:5000/myapp\ndocker push localhost:5000/myapp\n\n# Pull by digest (immutable)\ndocker pull nginx@sha256:abc123...",
          "example": "# Self-hosted registry with TLS and authentication\ndocker run -d -p 443:5000 \\\n  --name secure-registry \\\n  -v /certs:/certs \\\n  -v /auth:/auth \\\n  -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/fullchain.pem \\\n  -e REGISTRY_HTTP_TLS_KEY=/certs/privkey.pem \\\n  -e REGISTRY_AUTH=htpasswd \\\n  -e REGISTRY_AUTH_HTPASSWD_REALM=Registry \\\n  -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \\\n  registry:2\n\n# CI/CD tagging pattern\nexport SHA=$(git rev-parse --short HEAD)\nexport BRANCH=$(git branch --show-current)\ndocker build -t myapp:$SHA -t myapp:$BRANCH -t myapp:latest .\ndocker push myapp:$SHA\ndocker push myapp:$BRANCH",
          "useCase": "Image distribution, CI/CD pipelines, air-gapped deployments, compliance, image lifecycle",
          "interviewQuestions": [
            {
              "question": "What happens when you docker push an image?",
              "answer": "Docker pushes each layer individually. Registry checks if layer already exists (by digest) — skips existing layers. Only new/changed layers are uploaded. Manifest (metadata linking layers to image) is pushed last. Efficient for incremental updates."
            },
            {
              "question": "How do you set up a private Docker registry?",
              "answer": "Run official registry image: docker run -d -p 5000:5000 registry:2. For production: add TLS certificates, htpasswd/token authentication, persistent volume for storage, configure garbage collection. Alternatives: Harbor (enterprise), ECR, GCR, ACR."
            },
            {
              "question": "What is the difference between image tag and image digest?",
              "answer": "Tag is a mutable pointer (nginx:latest can change). Digest is an immutable SHA256 hash of the image manifest (nginx@sha256:abc...). Tags can be overwritten; digests cannot. Use digests in production for reproducibility. Use tags for human readability."
            },
            {
              "question": "Explain Docker image layer sharing and its benefits.",
              "answer": "Layers are content-addressable and shared across images. If two images use the same base (node:18-alpine), the base layers are stored and pulled only once. Saves disk space, speeds up pulls. This is why consistent base images across teams are important."
            },
            {
              "question": "How do you implement image lifecycle policies?",
              "answer": "Cloud registries (ECR, GCR) have built-in lifecycle policies. Rules: delete untagged images after N days, keep last N tagged images, delete images older than N days. Self-hosted: use registry garbage collection (registry garbage-collect config.yml). Script cleanup for Docker Hub."
            },
            {
              "question": "What is Docker Content Trust and how does it work?",
              "answer": "DCT uses digital signatures (Notary) to verify image integrity and publisher identity. Set DOCKER_CONTENT_TRUST=1. Publishers sign with private key on push. Consumers verify with public key on pull. Prevents pulling tampered images. Modern alternative: Cosign with keyless signing."
            },
            {
              "question": "How do you handle registry credentials securely?",
              "answer": "Docker stores credentials in ~/.docker/config.json (plaintext by default). Use credential helpers: docker-credential-ecr-login (AWS), docker-credential-gcr (GCP), docker-credential-pass (GPG-encrypted). In CI/CD: use short-lived tokens, not persistent passwords. In K8s: imagePullSecrets."
            },
            {
              "question": "What is registry mirroring and when to use it?",
              "answer": "Mirror caches images from upstream registries locally. Reduces external bandwidth, speeds up pulls, works in air-gapped environments. Configure in Docker daemon.json: registry-mirrors. Pull-through cache: registry requests image, caches on first pull, serves from cache on subsequent pulls."
            },
            {
              "question": "How do you migrate images between registries?",
              "answer": "Options: (1) docker pull/tag/push (simple but slow, pulls full image). (2) skopeo copy (doesn't require Docker daemon, preserves digests). (3) crane copy (Google's tool, fast). (4) Registry replication (Harbor supports built-in replication between registries)."
            },
            {
              "question": "Explain multi-architecture images (manifest lists).",
              "answer": "A single tag (nginx:latest) can contain images for multiple CPU architectures (amd64, arm64, etc.). Docker automatically pulls the correct architecture. Created with docker buildx build --platform linux/amd64,linux/arm64. Manifest list is a JSON that maps platform to digest."
            }
          ],
          "exercises": [
            {
              "type": "command",
              "question": "Run a local Docker registry and push an image to it.",
              "answer": "docker run -d -p 5000:5000 registry:2\ndocker tag nginx localhost:5000/nginx\ndocker push localhost:5000/nginx"
            },
            {
              "type": "scenario",
              "question": "Your team uses :latest tag for production deployments. What problems can occur?",
              "answer": "Unpredictable: latest can change without notice. Different environments may run different versions. Can't audit what version is running. Rollback is impossible (tag overwritten). Fix: use immutable tags (semantic version or git SHA)."
            },
            {
              "type": "command",
              "question": "Pull an image by its digest instead of tag for guaranteed immutability.",
              "answer": "docker inspect nginx:latest --format='{{.RepoDigests}}'\ndocker pull nginx@sha256:<digest-from-above>"
            },
            {
              "type": "explain",
              "question": "What is the difference between docker save/load and docker push/pull?",
              "answer": "save/load: exports/imports image as tar file (offline transfer, air-gapped environments). push/pull: transfers via registry protocol (incremental, only changed layers). save includes all layers in tar; push skips existing layers in registry."
            },
            {
              "type": "troubleshoot",
              "question": "docker push fails with 'denied: requested access to the resource is denied'. What to check?",
              "answer": "Check: (1) docker login to correct registry, (2) image tag matches registry path, (3) user has push permissions, (4) repository exists (some registries require creating repo first), (5) token/credentials not expired."
            },
            {
              "type": "scenario",
              "question": "How do you set up Docker authentication in a CI/CD pipeline securely?",
              "answer": "Use CI/CD secret variables for registry password. Login with: echo $REGISTRY_PASSWORD | docker login -u $REGISTRY_USER --password-stdin registry.example.com. For AWS ECR: use IAM role with aws ecr get-login-password. Never hardcode credentials in pipeline files."
            },
            {
              "type": "security",
              "question": "A developer accidentally pushed an image containing secrets to a public registry. What to do?",
              "answer": "Immediately: (1) Delete image/tag from registry, (2) Rotate ALL exposed secrets, (3) Audit access logs for unauthorized pulls, (4) Add image scanning to pipeline to prevent recurrence. Note: deleting from Docker Hub doesn't remove from CDN cache immediately."
            },
            {
              "type": "command",
              "question": "List all tags for an image in Docker Hub using the API.",
              "answer": "curl -s 'https://hub.docker.com/v2/repositories/library/nginx/tags/?page_size=10' | python3 -m json.tool | grep '\"name\"'"
            },
            {
              "type": "optimize",
              "question": "Image pulls in Kubernetes are slow. How to optimize?",
              "answer": "Use imagePullPolicy: IfNotPresent (avoid re-pulling). Use registry mirror/cache in same network. Pre-pull common base images on nodes (DaemonSet). Use smaller images (alpine/distroless). Enable image streaming (GKE) or lazy pulling."
            },
            {
              "type": "write",
              "question": "Write a CI/CD script that builds, tags (SHA + branch + latest), and pushes an image.",
              "answer": "SHA=$(git rev-parse --short HEAD)\nBRANCH=$(git branch --show-current)\nIMAGE=registry.example.com/myapp\ndocker build -t $IMAGE:$SHA -t $IMAGE:$BRANCH -t $IMAGE:latest .\ndocker push $IMAGE:$SHA\ndocker push $IMAGE:$BRANCH\ndocker push $IMAGE:latest"
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Run local registry, tag and push image, pull it back",
              "code": "docker run -d -p 5000:5000 --name local-reg registry:2\ndocker pull alpine\ndocker tag alpine localhost:5000/myalpine:v1\ndocker push localhost:5000/myalpine:v1\ndocker rmi localhost:5000/myalpine:v1\ndocker pull localhost:5000/myalpine:v1\ndocker images | grep myalpine",
              "output": "Image pushed to local registry, pulled back successfully"
            },
            {
              "type": "program",
              "question": "Program 2: List images in local registry via API",
              "code": "curl -s http://localhost:5000/v2/_catalog\ncurl -s http://localhost:5000/v2/myalpine/tags/list",
              "output": "{\"repositories\":[\"myalpine\"]} / {\"name\":\"myalpine\",\"tags\":[\"v1\"]}"
            },
            {
              "type": "program",
              "question": "Program 3: Get image digest for immutable reference",
              "code": "docker inspect nginx:latest --format='{{index .RepoDigests 0}}'",
              "output": "nginx@sha256:abc123... (immutable digest reference)"
            },
            {
              "type": "program",
              "question": "Program 4: Verify layer sharing between images with same base",
              "code": "docker pull node:18-alpine\ndocker pull node:20-alpine\ndocker system df -v | grep -A5 'SHARED SIZE'",
              "output": "Shared size shows common alpine layers reused between both images"
            },
            {
              "type": "program",
              "question": "Program 5: Tag image with git SHA and branch for CI/CD",
              "code": "SHA=$(git rev-parse --short HEAD 2>/dev/null || echo 'abc1234')\ndocker tag nginx myregistry/nginx:$SHA\ndocker tag nginx myregistry/nginx:main\ndocker images | grep myregistry",
              "output": "Same image ID with SHA tag and branch tag, ready for push"
            },
            {
              "type": "program",
              "question": "Program 6: save image to tar for air-gapped transfer",
              "code": "docker save nginx:alpine -o nginx-alpine.tar\nls -lh nginx-alpine.tar\ndocker rmi nginx:alpine\ndocker load -i nginx-alpine.tar\ndocker images | grep nginx",
              "output": "Image saved (~40MB tar), removed, restored from tar file"
            },
            {
              "type": "program",
              "question": "Program 7: Check image manifest for multi-arch support",
              "code": "docker manifest inspect nginx:latest | python3 -c \"import sys,json; m=json.load(sys.stdin); print([p['platform']['architecture'] for p in m.get('manifests',[])])\"",
              "output": "['amd64', 'arm64', 'arm', '386', ...] (supported architectures)"
            },
            {
              "type": "program",
              "question": "Program 8: Login to registry with --password-stdin (secure)",
              "code": "echo 'mypassword' | docker login localhost:5000 -u admin --password-stdin\ncat ~/.docker/config.json | python3 -m json.tool",
              "output": "Login Succeeded. config.json shows auth entry for localhost:5000"
            },
            {
              "type": "program",
              "question": "Program 9: Run registry with persistent volume for data safety",
              "code": "docker volume create reg-data\ndocker run -d -p 5000:5000 -v reg-data:/var/lib/registry --name persistent-reg registry:2\ndocker tag alpine localhost:5000/persist:v1\ndocker push localhost:5000/persist:v1\ndocker rm -f persistent-reg\ndocker run -d -p 5000:5000 -v reg-data:/var/lib/registry --name persistent-reg2 registry:2\ncurl -s http://localhost:5000/v2/_catalog",
              "output": "{\"repositories\":[\"persist\"]} — data survived registry container recreation"
            },
            {
              "type": "program",
              "question": "Program 10: Delete image from local registry via API",
              "code": "DIGEST=$(curl -s -H 'Accept: application/vnd.docker.distribution.manifest.v2+json' http://localhost:5000/v2/myalpine/manifests/v1 -I | grep Docker-Content-Digest | tr -d '\\r' | cut -d' ' -f2)\ncurl -X DELETE http://localhost:5000/v2/myalpine/manifests/$DIGEST\ncurl -s http://localhost:5000/v2/myalpine/tags/list",
              "output": "Tag deleted, tags list shows empty (registry GC needed to reclaim space)"
            }
          ]
        }
      ],
      "quiz": [
        {
          "question": "What is the difference between an image and a container?",
          "options": [
            "An image is a template, a container is a running instance of an image",
            "They are the same thing",
            "Images are faster than containers",
            "Containers can't be modified"
          ],
          "correctAnswer": 0,
          "explanation": "A Docker image is a read-only template with instructions for creating a container. A container is a running instance of an image that can be started, stopped, and modified."
        },
        {
          "question": "What does the FROM instruction in Dockerfile do?",
          "options": [
            "Copies files from host",
            "Specifies the base image to build upon",
            "Sets environment variables",
            "Runs a command"
          ],
          "correctAnswer": 1,
          "explanation": "FROM specifies the base image for your Docker image. Every Dockerfile must start with FROM to establish the foundation upon which you'll build your application."
        },
        {
          "question": "What is a Docker volume used for?",
          "options": [
            "To control sound levels",
            "To create networks",
            "To persist data outside the container's lifecycle",
            "To build images"
          ],
          "correctAnswer": 2,
          "explanation": "Volumes are the preferred mechanism for persisting data generated by and used by Docker containers. They exist outside the container filesystem and persist even when containers are removed."
        },
        {
          "question": "What does 'docker-compose up' do?",
          "options": [
            "Only builds images",
            "Updates Docker",
            "Removes containers",
            "Creates and starts containers defined in docker-compose.yml"
          ],
          "correctAnswer": 3,
          "explanation": "'docker-compose up' builds images if needed, creates services, networks, and volumes defined in docker-compose.yml, and starts the containers."
        },
        {
          "question": "What is the purpose of .dockerignore?",
          "options": [
            "To exclude files from being copied into the image",
            "To hide containers",
            "To ignore errors",
            "To create backups"
          ],
          "correctAnswer": 0,
          "explanation": ".dockerignore works like .gitignore - it excludes files and directories from being copied into your Docker image during build, reducing image size and improving security."
        },
        {
          "question": "What's the difference between CMD and ENTRYPOINT in Dockerfile?",
          "options": [
            "They are identical",
            "ENTRYPOINT sets the main command, CMD provides default arguments that can be overridden",
            "CMD is faster",
            "ENTRYPOINT can't be changed"
          ],
          "correctAnswer": 1,
          "explanation": "ENTRYPOINT defines the executable that will run when the container starts. CMD provides default arguments to ENTRYPOINT (or a default command if no ENTRYPOINT). CMD arguments can be overridden at runtime."
        },
        {
          "question": "What is Docker?",
          "options": [
            "A virtual machine",
            "A programming language",
            "A platform for developing, shipping, and running applications in containers",
            "An operating system"
          ],
          "correctAnswer": 2,
          "explanation": "Docker is a platform that uses OS-level virtualization to deliver software in packages called containers. It packages applications with all dependencies needed to run."
        },
        {
          "question": "What is a Docker container?",
          "options": [
            "A storage box",
            "A database",
            "A VM image",
            "A lightweight, standalone executable package with application and dependencies"
          ],
          "correctAnswer": 3,
          "explanation": "A container is a standard unit of software that packages code and all its dependencies so the application runs quickly and reliably across computing environments."
        },
        {
          "question": "What does 'docker run' do?",
          "options": [
            "Creates and starts a container from an image",
            "Runs a command",
            "Runs Docker daemon",
            "Executes a script"
          ],
          "correctAnswer": 0,
          "explanation": "docker run creates a new container from a specified image and starts it. It combines docker create and docker start in one command."
        },
        {
          "question": "What is the Docker daemon?",
          "options": [
            "An evil spirit",
            "The background service that manages Docker containers",
            "A container type",
            "An image format"
          ],
          "correctAnswer": 1,
          "explanation": "The Docker daemon (dockerd) is a persistent background process that manages Docker containers, images, networks, and volumes on a host system."
        },
        {
          "question": "What does 'docker ps' show?",
          "options": [
            "PostScript files",
            "All images",
            "Currently running containers",
            "Docker processes only"
          ],
          "correctAnswer": 2,
          "explanation": "docker ps lists all currently running containers. Use docker ps -a to see all containers including stopped ones."
        },
        {
          "question": "What does 'docker images' do?",
          "options": [
            "Creates images",
            "Downloads images",
            "Displays pictures",
            "Lists all locally available Docker images"
          ],
          "correctAnswer": 3,
          "explanation": "docker images (or docker image ls) lists all Docker images stored locally on your system with their repository, tag, image ID, creation date, and size."
        },
        {
          "question": "What is a Dockerfile?",
          "options": [
            "A text file with instructions to build a Docker image",
            "A text document",
            "A configuration file",
            "A log file"
          ],
          "correctAnswer": 0,
          "explanation": "A Dockerfile is a text document containing all commands needed to build a Docker image. It automates the image creation process with a series of instructions."
        },
        {
          "question": "What does the COPY instruction do in Dockerfile?",
          "options": [
            "Duplicates containers",
            "Copies files from host to image filesystem",
            "Copies environment variables",
            "Clones repositories"
          ],
          "correctAnswer": 1,
          "explanation": "COPY copies files or directories from the build context (host machine) into the Docker image filesystem at a specified path."
        },
        {
          "question": "What does the ADD instruction do?",
          "options": [
            "Adds containers",
            "Adds environment variables",
            "Copies files and can extract archives and download from URLs",
            "Adds users"
          ],
          "correctAnswer": 2,
          "explanation": "ADD is similar to COPY but has additional features: it can extract tar archives automatically and download files from URLs. COPY is preferred for simple file copying."
        },
        {
          "question": "What does the RUN instruction do in Dockerfile?",
          "options": [
            "Runs the container",
            "Runs tests",
            "Runs at container start",
            "Executes commands during image build"
          ],
          "correctAnswer": 3,
          "explanation": "RUN executes commands during the image build process and commits the results as a new layer. Used for installing packages, creating directories, etc."
        },
        {
          "question": "What does the WORKDIR instruction do?",
          "options": [
            "Sets the working directory for subsequent instructions",
            "Creates a workspace",
            "Defines work hours",
            "Creates workers"
          ],
          "correctAnswer": 0,
          "explanation": "WORKDIR sets the working directory for any RUN, CMD, ENTRYPOINT, COPY, and ADD instructions that follow it. Creates the directory if it doesn't exist."
        },
        {
          "question": "What does the ENV instruction do?",
          "options": [
            "Creates environments",
            "Sets environment variables in the image",
            "Configures envelopes",
            "Defines env files"
          ],
          "correctAnswer": 1,
          "explanation": "ENV sets environment variables that are available during build and at runtime in containers. Format: ENV KEY=value or ENV KEY value."
        },
        {
          "question": "What does the EXPOSE instruction do?",
          "options": [
            "Exposes vulnerabilities",
            "Opens ports automatically",
            "Documents which ports the container listens on",
            "Publishes ports"
          ],
          "correctAnswer": 2,
          "explanation": "EXPOSE documents which network ports the container will listen on at runtime. It's documentation only; use -p flag with docker run to actually publish ports."
        },
        {
          "question": "What is the difference between COPY and ADD?",
          "options": [
            "No difference",
            "COPY is faster",
            "ADD is deprecated",
            "COPY is simpler, ADD can extract tar files and download URLs"
          ],
          "correctAnswer": 3,
          "explanation": "COPY only copies local files/directories. ADD can also extract local tar files and fetch remote URLs. Docker best practices recommend COPY for transparency."
        },
        {
          "question": "What does 'docker build' do?",
          "options": [
            "Creates a Docker image from a Dockerfile",
            "Builds containers",
            "Builds Docker",
            "Compiles code"
          ],
          "correctAnswer": 0,
          "explanation": "docker build reads instructions from a Dockerfile and builds a Docker image. Use -t flag to tag the image with a name."
        },
        {
          "question": "What is a Docker layer?",
          "options": [
            "A coating",
            "A read-only filesystem change in an image",
            "A network layer",
            "A security layer"
          ],
          "correctAnswer": 1,
          "explanation": "Each instruction in a Dockerfile creates a layer. Layers are stacked and each represents a filesystem diff. Docker uses layers for efficient storage and caching."
        },
        {
          "question": "What is image caching in Docker?",
          "options": [
            "Storing images",
            "Memory caching",
            "Reusing unchanged layers to speed up builds",
            "Browser cache"
          ],
          "correctAnswer": 2,
          "explanation": "Docker caches layers during builds. If a layer hasn't changed, Docker reuses the cached layer instead of rebuilding, significantly speeding up subsequent builds."
        },
        {
          "question": "How do you invalidate Docker build cache?",
          "options": [
            "Restart Docker",
            "Clear browser cache",
            "Delete cache folder",
            "Use --no-cache flag with docker build"
          ],
          "correctAnswer": 3,
          "explanation": "Use docker build --no-cache to force rebuild all layers without using cache. Useful when you need to ensure fresh installation of packages."
        },
        {
          "question": "What does 'docker exec' do?",
          "options": [
            "Runs a command in a running container",
            "Executes Docker",
            "Executes image",
            "Starts container"
          ],
          "correctAnswer": 0,
          "explanation": "docker exec runs a new command in a running container. Commonly used as docker exec -it container_name bash to get an interactive shell."
        },
        {
          "question": "What does the -it flag mean in docker run?",
          "options": [
            "Iterate",
            "Interactive terminal (combines -i and -t flags)",
            "Install tools",
            "Immediate termination"
          ],
          "correctAnswer": 1,
          "explanation": "-i keeps STDIN open (interactive), -t allocates a pseudo-TTY (terminal). Together they enable interactive command-line access to containers."
        },
        {
          "question": "What does 'docker stop' do?",
          "options": [
            "Stops Docker daemon",
            "Stops all processes",
            "Gracefully stops a running container",
            "Pauses container"
          ],
          "correctAnswer": 2,
          "explanation": "docker stop sends SIGTERM signal to gracefully stop the main process, then SIGKILL after grace period. Allows cleanup before shutdown."
        },
        {
          "question": "What does 'docker kill' do?",
          "options": [
            "Deletes containers",
            "Removes images",
            "Terminates Docker",
            "Forcefully stops container by sending SIGKILL"
          ],
          "correctAnswer": 3,
          "explanation": "docker kill immediately sends SIGKILL signal to the container's main process, forcing immediate termination without graceful shutdown."
        },
        {
          "question": "What does 'docker rm' do?",
          "options": [
            "Removes one or more stopped containers",
            "Removes images",
            "Removes Docker",
            "Removes volumes"
          ],
          "correctAnswer": 0,
          "explanation": "docker rm removes stopped containers. Use docker rm -f to force remove running containers. Container must be stopped first unless using -f flag."
        },
        {
          "question": "What does 'docker rmi' do?",
          "options": [
            "Removes containers",
            "Removes one or more images",
            "Removes volumes",
            "Removes networks"
          ],
          "correctAnswer": 1,
          "explanation": "docker rmi removes Docker images. Images must not be used by any containers (use docker rm first). Use -f to force removal."
        },
        {
          "question": "What is Docker Hub?",
          "options": [
            "A physical hub",
            "Docker's headquarters",
            "Public registry for Docker images",
            "A network hub"
          ],
          "correctAnswer": 2,
          "explanation": "Docker Hub is the default public registry for Docker images. It hosts millions of images including official ones from software vendors and community images."
        },
        {
          "question": "What does 'docker pull' do?",
          "options": [
            "Pulls code from git",
            "Updates Docker",
            "Pulls containers",
            "Downloads an image from a registry"
          ],
          "correctAnswer": 3,
          "explanation": "docker pull downloads a Docker image from a registry (Docker Hub by default) to your local machine without creating a container."
        },
        {
          "question": "What does 'docker push' do?",
          "options": [
            "Uploads an image to a registry",
            "Pushes code",
            "Pushes containers",
            "Publishes ports"
          ],
          "correctAnswer": 0,
          "explanation": "docker push uploads a Docker image to a registry. You must be logged in (docker login) and the image must be tagged with the registry path."
        },
        {
          "question": "What is a Docker registry?",
          "options": [
            "A list",
            "A storage system for Docker images",
            "A register of containers",
            "A log file"
          ],
          "correctAnswer": 1,
          "explanation": "A Docker registry stores and distributes Docker images. Docker Hub is the default public registry, but you can run private registries for organizational use."
        },
        {
          "question": "What is Docker Compose?",
          "options": [
            "Music composition",
            "Image composer",
            "Tool for defining and running multi-container applications",
            "Container merger"
          ],
          "correctAnswer": 2,
          "explanation": "Docker Compose is a tool for defining and running multi-container Docker applications using a YAML file (docker-compose.yml) to configure services."
        },
        {
          "question": "What file does Docker Compose use?",
          "options": [
            "Dockerfile",
            "config.yaml",
            "compose.json",
            "docker-compose.yml"
          ],
          "correctAnswer": 3,
          "explanation": "Docker Compose uses docker-compose.yml (or .yaml) file to define services, networks, volumes, and other configuration for multi-container applications."
        },
        {
          "question": "What does 'docker-compose down' do?",
          "options": [
            "Stops and removes containers, networks, and volumes",
            "Downloads images",
            "Shuts down Docker",
            "Lowers priority"
          ],
          "correctAnswer": 0,
          "explanation": "docker-compose down stops and removes containers, networks created by up. Use --volumes to also remove volumes. Opposite of docker-compose up."
        },
        {
          "question": "What does 'docker-compose ps' show?",
          "options": [
            "All processes",
            "Status of services defined in docker-compose.yml",
            "System processes",
            "Docker processes"
          ],
          "correctAnswer": 1,
          "explanation": "docker-compose ps lists containers for services defined in the current docker-compose.yml file, showing their state, ports, and other information."
        },
        {
          "question": "What does 'docker-compose logs' do?",
          "options": [
            "Creates logs",
            "Logs in",
            "Displays log output from services",
            "Records events"
          ],
          "correctAnswer": 2,
          "explanation": "docker-compose logs displays log output from services. Use -f to follow log output. Can specify specific service names to filter logs."
        },
        {
          "question": "What is a multi-stage build?",
          "options": [
            "Multiple Dockerfiles",
            "Staged deployment",
            "Building in stages",
            "Using multiple FROM statements to create smaller final images"
          ],
          "correctAnswer": 3,
          "explanation": "Multi-stage builds use multiple FROM statements in one Dockerfile. You can copy artifacts from one stage to another, creating smaller, more secure final images."
        },
        {
          "question": "Why use multi-stage builds?",
          "options": [
            "Reduce final image size by separating build and runtime dependencies",
            "Faster builds",
            "Multiple images",
            "Better security only"
          ],
          "correctAnswer": 0,
          "explanation": "Multi-stage builds reduce image size by keeping only runtime dependencies in the final image, leaving build tools and intermediate files in earlier stages."
        },
        {
          "question": "What is the purpose of ARG in Dockerfile?",
          "options": [
            "Arguments to container",
            "Define build-time variables",
            "Function arguments",
            "Command arguments"
          ],
          "correctAnswer": 1,
          "explanation": "ARG defines build-time variables that can be passed during docker build with --build-arg. Unlike ENV, ARG values aren't available in running containers."
        },
        {
          "question": "What's the difference between ARG and ENV?",
          "options": [
            "No difference",
            "ENV is deprecated",
            "ARG is build-time only, ENV is available at runtime",
            "ARG is faster"
          ],
          "correctAnswer": 2,
          "explanation": "ARG variables are only available during build. ENV variables persist in the built image and are available during runtime. Use ARG for build-time only values."
        },
        {
          "question": "What does VOLUME instruction do in Dockerfile?",
          "options": [
            "Increases volume",
            "Measures capacity",
            "Controls sound",
            "Creates a mount point for external storage"
          ],
          "correctAnswer": 3,
          "explanation": "VOLUME creates a mount point and marks it as holding externally mounted volumes. Used to persist data or share data between host and container."
        },
        {
          "question": "What are the types of Docker volumes?",
          "options": [
            "Named volumes, bind mounts, and tmpfs mounts",
            "Only named volumes",
            "Host volumes only",
            "Virtual volumes"
          ],
          "correctAnswer": 0,
          "explanation": "Docker has three mount types: named volumes (managed by Docker), bind mounts (map host directory), and tmpfs mounts (stored in memory, Linux only)."
        },
        {
          "question": "What is a bind mount?",
          "options": [
            "Binding containers",
            "Mounting a host directory into a container",
            "Network binding",
            "Port binding"
          ],
          "correctAnswer": 1,
          "explanation": "Bind mounts map a host directory or file into a container. Changes in either location are reflected immediately. Specified with -v or --mount."
        },
        {
          "question": "What is the difference between volumes and bind mounts?",
          "options": [
            "No difference",
            "Volumes are faster",
            "Volumes are managed by Docker, bind mounts use host paths directly",
            "Bind mounts are deprecated"
          ],
          "correctAnswer": 2,
          "explanation": "Volumes are managed by Docker in a Docker area. Bind mounts can be anywhere on host filesystem. Volumes are recommended for better portability."
        },
        {
          "question": "What does 'docker volume create' do?",
          "options": [
            "Creates containers",
            "Creates directories",
            "Increases storage",
            "Creates a named volume"
          ],
          "correctAnswer": 3,
          "explanation": "docker volume create creates a named volume that can be used by containers. Volumes persist independently of container lifecycle."
        },
        {
          "question": "What does 'docker volume ls' do?",
          "options": [
            "Lists all Docker volumes",
            "Lists containers",
            "Lists files",
            "Shows volume size"
          ],
          "correctAnswer": 0,
          "explanation": "docker volume ls lists all volumes on the Docker host. Shows volume driver and volume name."
        },
        {
          "question": "What is Docker networking?",
          "options": [
            "Internet connection",
            "System for containers to communicate with each other and outside world",
            "Network cables",
            "Router configuration"
          ],
          "correctAnswer": 1,
          "explanation": "Docker networking enables containers to communicate with each other and external networks. Docker provides several network drivers for different use cases."
        },
        {
          "question": "What are Docker network drivers?",
          "options": [
            "Device drivers",
            "Network cards",
            "bridge, host, overlay, macvlan, none",
            "Ethernet drivers"
          ],
          "correctAnswer": 2,
          "explanation": "Docker network drivers: bridge (default, single host), host (use host network), overlay (multi-host), macvlan (MAC addresses), none (no networking)."
        },
        {
          "question": "What is the bridge network?",
          "options": [
            "Physical bridge",
            "VPN bridge",
            "Network connection",
            "Default network driver creating private internal network on host"
          ],
          "correctAnswer": 3,
          "explanation": "Bridge is the default network driver. Containers on same bridge network can communicate. Bridge network is private to the Docker host."
        },
        {
          "question": "What does 'docker network create' do?",
          "options": [
            "Creates a new Docker network",
            "Creates internet",
            "Creates network cards",
            "Configures router"
          ],
          "correctAnswer": 0,
          "explanation": "docker network create creates a new network. Can specify driver type with --driver. Allows containers to communicate on custom networks."
        },
        {
          "question": "What does 'docker network ls' do?",
          "options": [
            "Lists network cards",
            "Lists all Docker networks",
            "Shows IP addresses",
            "Lists containers"
          ],
          "correctAnswer": 1,
          "explanation": "docker network ls lists all networks on the Docker host, showing network ID, name, driver, and scope."
        },
        {
          "question": "What is overlay network?",
          "options": [
            "Network overlay",
            "Top layer only",
            "Multi-host network for swarm services",
            "Virtual network"
          ],
          "correctAnswer": 2,
          "explanation": "Overlay networks enable communication between containers across multiple Docker daemon hosts. Used in Docker Swarm for service-to-service communication."
        },
        {
          "question": "What is host network mode?",
          "options": [
            "Hosting websites",
            "Network hosting",
            "Host only access",
            "Container uses host's network stack directly"
          ],
          "correctAnswer": 3,
          "explanation": "In host mode, container doesn't get its own IP address and uses host's network directly. No network isolation. Better performance but less secure."
        },
        {
          "question": "What does the -p flag do in docker run?",
          "options": [
            "Publishes container port to host port",
            "Password",
            "Process",
            "Path"
          ],
          "correctAnswer": 0,
          "explanation": "-p (or --publish) maps container port to host port. Format: -p host_port:container_port. Enables external access to containerized services."
        },
        {
          "question": "What does the -d flag do in docker run?",
          "options": [
            "Delete",
            "Runs container in detached mode (background)",
            "Debug mode",
            "Development"
          ],
          "correctAnswer": 1,
          "explanation": "-d (--detach) runs container in background and prints container ID. Container continues running until stopped or exits."
        },
        {
          "question": "What does the --name flag do?",
          "options": [
            "Names images",
            "Renames Docker",
            "Assigns a name to the container",
            "Username"
          ],
          "correctAnswer": 2,
          "explanation": "--name assigns a custom name to container instead of random name. Makes it easier to reference container in commands."
        },
        {
          "question": "What does the --rm flag do in docker run?",
          "options": [
            "Removes images",
            "Removes volumes",
            "Remove flag",
            "Automatically removes container when it exits"
          ],
          "correctAnswer": 3,
          "explanation": "--rm automatically removes the container when it exits. Useful for temporary containers to avoid accumulating stopped containers."
        },
        {
          "question": "What does 'docker logs' show?",
          "options": [
            "Output and logs from a container",
            "System logs",
            "Error logs only",
            "Docker daemon logs"
          ],
          "correctAnswer": 0,
          "explanation": "docker logs fetches logs from a container (stdout and stderr). Use -f to follow log output and --tail to limit number of lines."
        },
        {
          "question": "What does 'docker inspect' do?",
          "options": [
            "Inspects code",
            "Returns detailed information about Docker objects (JSON format)",
            "Visual inspection",
            "Debug tool"
          ],
          "correctAnswer": 1,
          "explanation": "docker inspect returns detailed low-level information about Docker objects (containers, images, volumes, networks) in JSON format. Useful for debugging."
        },
        {
          "question": "What does 'docker stats' show?",
          "options": [
            "Statistics theory",
            "Docker statistics",
            "Real-time resource usage statistics for containers",
            "Build statistics"
          ],
          "correctAnswer": 2,
          "explanation": "docker stats displays live stream of container resource usage statistics including CPU, memory, network I/O, and block I/O."
        },
        {
          "question": "What does 'docker top' show?",
          "options": [
            "Top containers",
            "Top images",
            "Best practices",
            "Running processes inside a container"
          ],
          "correctAnswer": 3,
          "explanation": "docker top displays running processes inside a container, similar to the Unix/Linux top command. Shows PID, user, time, and command."
        },
        {
          "question": "What does 'docker commit' do?",
          "options": [
            "Creates a new image from container's changes",
            "Commits code",
            "Saves changes",
            "Git commit"
          ],
          "correctAnswer": 0,
          "explanation": "docker commit creates a new image from a container's changes. Not recommended for production; use Dockerfile for reproducible builds."
        },
        {
          "question": "What does 'docker tag' do?",
          "options": [
            "Tags files",
            "Creates a tag/alias for an image",
            "Label containers",
            "Version tags"
          ],
          "correctAnswer": 1,
          "explanation": "docker tag creates a new tag (alias) for an existing image. Format: docker tag source_image[:tag] target_image[:tag]. Used for versioning."
        },
        {
          "question": "What is Docker Swarm?",
          "options": [
            "Insect swarm",
            "Container group",
            "Native clustering and orchestration tool for Docker",
            "Network type"
          ],
          "correctAnswer": 2,
          "explanation": "Docker Swarm is Docker's native clustering and orchestration solution. Turns multiple Docker hosts into a single virtual host for container management."
        },
        {
          "question": "What is a Docker service in Swarm?",
          "options": [
            "Service provider",
            "Web service",
            "Background service",
            "Definition of tasks to execute on swarm nodes"
          ],
          "correctAnswer": 3,
          "explanation": "A service is the definition of tasks to execute on worker or manager nodes. It's the central structure of swarm and primary unit of interaction."
        },
        {
          "question": "What does HEALTHCHECK instruction do?",
          "options": [
            "Defines command to check container health status",
            "Health monitoring",
            "Checks Docker health",
            "System diagnostics"
          ],
          "correctAnswer": 0,
          "explanation": "HEALTHCHECK tells Docker how to test if container is working. Docker runs the command periodically and updates container health status."
        },
        {
          "question": "What does 'docker system prune' do?",
          "options": [
            "Prunes trees",
            "Removes unused data (containers, networks, images, cache)",
            "System cleanup",
            "Optimizes Docker"
          ],
          "correctAnswer": 1,
          "explanation": "docker system prune removes all stopped containers, unused networks, dangling images, and build cache. Use -a to also remove unused images."
        },
        {
          "question": "What is a dangling image?",
          "options": [
            "Hanging image",
            "Broken image",
            "Image layer without tag, not referenced by any tagged image",
            "Unused image"
          ],
          "correctAnswer": 2,
          "explanation": "Dangling images are layers that have no relationship to tagged images. Created when rebuilding an image with same tag. Listed with docker images -f dangling=true."
        },
        {
          "question": "What does USER instruction do in Dockerfile?",
          "options": [
            "Creates users",
            "Username configuration",
            "User permissions",
            "Sets the user for running subsequent commands"
          ],
          "correctAnswer": 3,
          "explanation": "USER sets the user (and optionally group) to use when running the image and for any RUN, CMD, ENTRYPOINT instructions that follow."
        },
        {
          "question": "Why should you avoid running containers as root?",
          "options": [
            "Security risk - container escapes could compromise host",
            "Performance issues",
            "Root causes errors",
            "Not compatible"
          ],
          "correctAnswer": 0,
          "explanation": "Running as root is a security risk. If container is compromised, attacker has root privileges. Use USER instruction to run as non-root user."
        },
        {
          "question": "What is the best practice for Dockerfile layers?",
          "options": [
            "Many layers",
            "Minimize layers by combining commands, order by change frequency",
            "One layer only",
            "Layers don't matter"
          ],
          "correctAnswer": 1,
          "explanation": "Minimize layers by combining related commands with &&. Order instructions from least to most frequently changing to maximize cache effectiveness."
        },
        {
          "question": "What does 'docker cp' do?",
          "options": [
            "Copies containers",
            "Copy paste",
            "Copies files between container and host",
            "Creates copies"
          ],
          "correctAnswer": 2,
          "explanation": "docker cp copies files/folders between container and local filesystem. Works with both running and stopped containers."
        },
        {
          "question": "What does 'docker rename' do?",
          "options": [
            "Renames images",
            "Renames Docker",
            "Renames files",
            "Renames a container"
          ],
          "correctAnswer": 3,
          "explanation": "docker rename changes the name of an existing container. Useful when you need a more meaningful name after container creation."
        },
        {
          "question": "What is the difference between docker-compose and Dockerfile?",
          "options": [
            "Dockerfile builds image, docker-compose orchestrates multiple containers",
            "Same thing",
            "Compose is newer",
            "Dockerfile is deprecated"
          ],
          "correctAnswer": 0,
          "explanation": "Dockerfile defines how to build a single image. docker-compose.yml defines how to run multiple containers together, their relationships, and configurations."
        },
        {
          "question": "What does LABEL instruction do in Dockerfile?",
          "options": [
            "Labels containers",
            "Adds metadata to image as key-value pairs",
            "Creates labels",
            "Tags images"
          ],
          "correctAnswer": 1,
          "explanation": "LABEL adds metadata to images as key-value pairs. Used for version, description, maintainer info. Can query with docker inspect."
        },
        {
          "question": "What does MAINTAINER instruction do?",
          "options": [
            "Maintains container",
            "Assigns maintainer",
            "Sets author field of image (deprecated, use LABEL)",
            "Maintenance mode"
          ],
          "correctAnswer": 2,
          "explanation": "MAINTAINER is deprecated. Use LABEL maintainer='name' instead. It sets the author/maintainer information for the image."
        },
        {
          "question": "What does ONBUILD instruction do?",
          "options": [
            "Builds on event",
            "Conditional build",
            "Immediate build",
            "Adds trigger instruction executed when image is used as base"
          ],
          "correctAnswer": 3,
          "explanation": "ONBUILD adds trigger instruction that executes when the image is used as base for another build. Useful for creating base images."
        },
        {
          "question": "What does STOPSIGNAL instruction do?",
          "options": [
            "Sets system call signal to stop container",
            "Stops signals",
            "Signal handler",
            "Stop command"
          ],
          "correctAnswer": 0,
          "explanation": "STOPSIGNAL sets the system call signal that will be sent to container to exit. Default is SIGTERM. Can specify signal number or name."
        },
        {
          "question": "What does SHELL instruction do in Dockerfile?",
          "options": [
            "Creates shell",
            "Overrides default shell for RUN commands",
            "Shell configuration",
            "Command shell"
          ],
          "correctAnswer": 1,
          "explanation": "SHELL allows overriding default shell used for shell form of commands. Default is [\"/bin/sh\", \"-c\"] on Linux. Useful for Windows containers."
        },
        {
          "question": "What is the shell form vs exec form in Dockerfile?",
          "options": [
            "Same thing",
            "Different shells",
            "Shell form runs in shell, exec form runs directly as executable",
            "Form validation"
          ],
          "correctAnswer": 2,
          "explanation": "Shell form (CMD command) runs in shell, enables variable substitution. Exec form (CMD [\"executable\", \"param\"]) runs directly without shell, preferred for ENTRYPOINT."
        },
        {
          "question": "What does 'docker pause' do?",
          "options": [
            "Stops container",
            "Delays execution",
            "Waits",
            "Pauses all processes in container using cgroups"
          ],
          "correctAnswer": 3,
          "explanation": "docker pause suspends all processes in container using cgroup freezer. docker unpause resumes them. Different from stop which terminates processes."
        },
        {
          "question": "What does 'docker wait' do?",
          "options": [
            "Blocks until container stops, then prints exit code",
            "Waits for input",
            "Delays execution",
            "Waits forever"
          ],
          "correctAnswer": 0,
          "explanation": "docker wait blocks until one or more containers stop, then prints their exit codes. Useful in scripts for sequential container operations."
        },
        {
          "question": "What does 'docker export' do?",
          "options": [
            "Exports data",
            "Exports container filesystem as tar archive",
            "Saves images",
            "Exports configuration"
          ],
          "correctAnswer": 1,
          "explanation": "docker export exports container's filesystem as tar archive. Doesn't export volumes or image history. Use docker save for images."
        },
        {
          "question": "What does 'docker import' do?",
          "options": [
            "Imports data",
            "Imports containers",
            "Creates image from tarball",
            "Loads configuration"
          ],
          "correctAnswer": 2,
          "explanation": "docker import creates a new filesystem image from tarball. Often used with docker export. Doesn't preserve image history or metadata."
        },
        {
          "question": "What does 'docker save' do?",
          "options": [
            "Saves containers",
            "Saves configuration",
            "Saves data",
            "Saves one or more images to tar archive with layers and metadata"
          ],
          "correctAnswer": 3,
          "explanation": "docker save saves images to tar archive including all layers, tags, and metadata. Use with docker load to transfer images. Better than export for images."
        },
        {
          "question": "What does 'docker load' do?",
          "options": [
            "Loads images from tar archive",
            "Loads containers",
            "Loads data",
            "Loads configuration"
          ],
          "correctAnswer": 0,
          "explanation": "docker load loads an image from tar archive created by docker save. Preserves all layers, tags, and history. Used for transferring images."
        },
        {
          "question": "What is the least privilege principle in Docker?",
          "options": [
            "Minimum permissions",
            "Run containers with minimum necessary privileges and capabilities",
            "No privileges",
            "Privilege escalation"
          ],
          "correctAnswer": 1,
          "explanation": "Least privilege means running containers with minimum permissions needed. Use non-root users, drop unnecessary capabilities, use read-only filesystems when possible."
        },
        {
          "question": "What does 'docker version' show?",
          "options": [
            "Docker version only",
            "Image versions",
            "Version information of Docker client and server",
            "Container versions"
          ],
          "correctAnswer": 2,
          "explanation": "docker version displays version information for both Docker client and Docker daemon (server), including Go version and architecture."
        },
        {
          "question": "What does 'docker info' show?",
          "options": [
            "Basic info",
            "Image information",
            "Container information",
            "System-wide information about Docker installation"
          ],
          "correctAnswer": 3,
          "explanation": "docker info displays system-wide information including containers count, images, storage driver, network config, swarm status, and more."
        },
        {
          "question": "What are Docker security best practices?",
          "options": [
            "Use official images, run as non-root, scan for vulnerabilities, minimize attack surface",
            "Use defaults",
            "No security needed",
            "Firewall only"
          ],
          "correctAnswer": 0,
          "explanation": "Best practices: use official/trusted images, run as non-root, scan for vulnerabilities, minimize image size, use secrets management, keep Docker updated."
        }
      ],
      "topicCount": 10,
      "quizCount": 93
    },
    {
      "slug": "golang",
      "meta": {
        "title": "Golang Interview Preparation",
        "description": "Prepare for backend interviews with Go fundamentals, concurrency models, data structures, and production practices."
      },
      "topics": [
        {
          "id": "real-world-service-challenges",
          "title": "Real-World Go Service Challenges (100+ Practical Drills)",
          "description": "Production-focused Go practice bank with architecture-level interview questions, practical debugging scenarios, and implementation-heavy program drills.",
          "explanation": "This module is designed for real backend interviews and day-to-day Go service work. It covers concurrency, reliability, data integrity, API contracts, observability, and performance. Use it as a progressive training track: Medium -> Hard -> Very Hard.",
          "implementation": "// Suggested workflow\n// 1) Solve 10 mixed exercises daily (implement/debug/output/scenario)\n// 2) Complete 2-3 programs with full error handling and tests\n// 3) Add benchmarking/profiling notes for each hard problem\n// 4) Explain design trade-offs verbally after every solution",
          "example": "// Example: context-aware repository call\nctx, cancel := context.WithTimeout(r.Context(), 2*time.Second)\ndefer cancel()\nuser, err := repo.GetByID(ctx, id)\nif err != nil {\n  writeErr(w, http.StatusNotFound, \"user not found\")\n  return\n}\nwriteJSON(w, http.StatusOK, user)",
          "useCase": "Backend Go interview prep, service hardening practice, and production-readiness upskilling.",
          "category": "Real-World Service Challenges",
          "interviewQuestions": [
            {
              "question": "Interview Q1: How would you design and defend a http apis decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For http apis, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q2: How would you design and defend a database transactions decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For database transactions, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q3: How would you design and defend a redis caching decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For redis caching, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q4: How would you design and defend a concurrency control decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For concurrency control, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q5: How would you design and defend a message processing decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For message processing, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q6: How would you design and defend a observability decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For observability, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q7: How would you design and defend a resilience decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For resilience, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q8: How would you design and defend a security decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For security, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q9: How would you design and defend a testing decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For testing, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q10: How would you design and defend a performance decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For performance, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q11: How would you design and defend a http apis decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For http apis, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q12: How would you design and defend a database transactions decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For database transactions, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q13: How would you design and defend a redis caching decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For redis caching, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q14: How would you design and defend a concurrency control decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For concurrency control, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q15: How would you design and defend a message processing decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For message processing, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q16: How would you design and defend a observability decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For observability, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q17: How would you design and defend a resilience decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For resilience, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q18: How would you design and defend a security decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For security, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q19: How would you design and defend a testing decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For testing, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q20: How would you design and defend a performance decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For performance, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q21: How would you design and defend a http apis decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For http apis, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q22: How would you design and defend a database transactions decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For database transactions, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q23: How would you design and defend a redis caching decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For redis caching, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q24: How would you design and defend a concurrency control decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For concurrency control, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q25: How would you design and defend a message processing decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For message processing, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q26: How would you design and defend a observability decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For observability, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q27: How would you design and defend a resilience decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For resilience, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q28: How would you design and defend a security decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For security, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q29: How would you design and defend a testing decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For testing, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q30: How would you design and defend a performance decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For performance, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q31: How would you design and defend a http apis decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For http apis, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q32: How would you design and defend a database transactions decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For database transactions, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q33: How would you design and defend a redis caching decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For redis caching, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q34: How would you design and defend a concurrency control decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For concurrency control, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q35: How would you design and defend a message processing decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For message processing, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q36: How would you design and defend a observability decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For observability, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q37: How would you design and defend a resilience decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For resilience, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q38: How would you design and defend a security decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For security, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q39: How would you design and defend a testing decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For testing, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q40: How would you design and defend a performance decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For performance, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q41: How would you design and defend a http apis decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For http apis, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q42: How would you design and defend a database transactions decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For database transactions, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q43: How would you design and defend a redis caching decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For redis caching, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q44: How would you design and defend a concurrency control decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For concurrency control, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q45: How would you design and defend a message processing decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For message processing, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q46: How would you design and defend a observability decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For observability, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q47: How would you design and defend a resilience decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For resilience, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q48: How would you design and defend a security decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For security, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q49: How would you design and defend a testing decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For testing, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            },
            {
              "question": "Interview Q50: How would you design and defend a performance decision in a production Go service?",
              "answer": "Start from failure modes, define clear contracts, add context timeouts, enforce structured errors, and validate with tests/metrics before rollout. For performance, explicitly document trade-offs (latency, consistency, complexity, and operability)."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Exercise 1: Build bounded worker pool with cancellation and backpressure.",
              "topic": "HTTP APIs"
            },
            {
              "type": "debug",
              "question": "Exercise 2: Fix goroutine leak in channel fan-in pipeline.",
              "topic": "Database Transactions",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 3: Predict output/order for defer + panic + recover flow.",
              "topic": "Redis Caching",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 4: Design idempotent payment webhook consumer with retries.",
              "topic": "Concurrency Control"
            },
            {
              "type": "theory",
              "question": "Exercise 5: Explain mutex vs channel trade-offs in shared state updates.",
              "topic": "Message Processing"
            },
            {
              "type": "tricky",
              "question": "Exercise 6: Handle nil-interface bug in typed error wrappers.",
              "topic": "Observability",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 7: Implement request-scoped timeout propagation through repository layer.",
              "topic": "Resilience"
            },
            {
              "type": "debug",
              "question": "Exercise 8: Debug DB pool exhaustion under concurrent API load.",
              "topic": "Security",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 9: Predict race detector findings for shared map write code.",
              "topic": "Testing",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 10: Design cache-aside strategy with stampede protection.",
              "topic": "Performance"
            },
            {
              "type": "theory",
              "question": "Exercise 11: Implement optimistic locking update with version checks.",
              "topic": "HTTP APIs"
            },
            {
              "type": "tricky",
              "question": "Exercise 12: Debug stale cache invalidation after write success.",
              "topic": "Database Transactions",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 13: Predict behavior of append with shared backing slices.",
              "topic": "Redis Caching"
            },
            {
              "type": "debug",
              "question": "Exercise 14: Design graceful shutdown for HTTP server + workers + queue.",
              "topic": "Concurrency Control",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 15: Explain why time.After in loop can leak resources.",
              "topic": "Message Processing",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 16: Implement structured logging middleware with request IDs.",
              "topic": "Observability"
            },
            {
              "type": "theory",
              "question": "Exercise 17: Debug retry storm against unstable dependency.",
              "topic": "Resilience"
            },
            {
              "type": "tricky",
              "question": "Exercise 18: Predict channel close behavior across multiple consumers.",
              "topic": "Security",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 19: Design alerting strategy for high p95 latency endpoint.",
              "topic": "Testing"
            },
            {
              "type": "debug",
              "question": "Exercise 20: Explain consistency trade-offs for outbox/inbox pattern.",
              "topic": "Performance",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 21: Build bounded worker pool with cancellation and backpressure.",
              "topic": "HTTP APIs",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 22: Fix goroutine leak in channel fan-in pipeline.",
              "topic": "Database Transactions"
            },
            {
              "type": "theory",
              "question": "Exercise 23: Predict output/order for defer + panic + recover flow.",
              "topic": "Redis Caching"
            },
            {
              "type": "tricky",
              "question": "Exercise 24: Design idempotent payment webhook consumer with retries.",
              "topic": "Concurrency Control",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 25: Explain mutex vs channel trade-offs in shared state updates.",
              "topic": "Message Processing"
            },
            {
              "type": "debug",
              "question": "Exercise 26: Handle nil-interface bug in typed error wrappers.",
              "topic": "Observability",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 27: Implement request-scoped timeout propagation through repository layer.",
              "topic": "Resilience",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 28: Debug DB pool exhaustion under concurrent API load.",
              "topic": "Security"
            },
            {
              "type": "theory",
              "question": "Exercise 29: Predict race detector findings for shared map write code.",
              "topic": "Testing"
            },
            {
              "type": "tricky",
              "question": "Exercise 30: Design cache-aside strategy with stampede protection.",
              "topic": "Performance",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 31: Implement optimistic locking update with version checks.",
              "topic": "HTTP APIs"
            },
            {
              "type": "debug",
              "question": "Exercise 32: Debug stale cache invalidation after write success.",
              "topic": "Database Transactions",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 33: Predict behavior of append with shared backing slices.",
              "topic": "Redis Caching",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 34: Design graceful shutdown for HTTP server + workers + queue.",
              "topic": "Concurrency Control"
            },
            {
              "type": "theory",
              "question": "Exercise 35: Explain why time.After in loop can leak resources.",
              "topic": "Message Processing"
            },
            {
              "type": "tricky",
              "question": "Exercise 36: Implement structured logging middleware with request IDs.",
              "topic": "Observability",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 37: Debug retry storm against unstable dependency.",
              "topic": "Resilience"
            },
            {
              "type": "debug",
              "question": "Exercise 38: Predict channel close behavior across multiple consumers.",
              "topic": "Security",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 39: Design alerting strategy for high p95 latency endpoint.",
              "topic": "Testing",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 40: Explain consistency trade-offs for outbox/inbox pattern.",
              "topic": "Performance"
            },
            {
              "type": "theory",
              "question": "Exercise 41: Build bounded worker pool with cancellation and backpressure.",
              "topic": "HTTP APIs"
            },
            {
              "type": "tricky",
              "question": "Exercise 42: Fix goroutine leak in channel fan-in pipeline.",
              "topic": "Database Transactions",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 43: Predict output/order for defer + panic + recover flow.",
              "topic": "Redis Caching"
            },
            {
              "type": "debug",
              "question": "Exercise 44: Design idempotent payment webhook consumer with retries.",
              "topic": "Concurrency Control",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 45: Explain mutex vs channel trade-offs in shared state updates.",
              "topic": "Message Processing",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 46: Handle nil-interface bug in typed error wrappers.",
              "topic": "Observability"
            },
            {
              "type": "theory",
              "question": "Exercise 47: Implement request-scoped timeout propagation through repository layer.",
              "topic": "Resilience"
            },
            {
              "type": "tricky",
              "question": "Exercise 48: Debug DB pool exhaustion under concurrent API load.",
              "topic": "Security",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 49: Predict race detector findings for shared map write code.",
              "topic": "Testing"
            },
            {
              "type": "debug",
              "question": "Exercise 50: Design cache-aside strategy with stampede protection.",
              "topic": "Performance",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 51: Implement optimistic locking update with version checks.",
              "topic": "HTTP APIs",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 52: Debug stale cache invalidation after write success.",
              "topic": "Database Transactions"
            },
            {
              "type": "theory",
              "question": "Exercise 53: Predict behavior of append with shared backing slices.",
              "topic": "Redis Caching"
            },
            {
              "type": "tricky",
              "question": "Exercise 54: Design graceful shutdown for HTTP server + workers + queue.",
              "topic": "Concurrency Control",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 55: Explain why time.After in loop can leak resources.",
              "topic": "Message Processing"
            },
            {
              "type": "debug",
              "question": "Exercise 56: Implement structured logging middleware with request IDs.",
              "topic": "Observability",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 57: Debug retry storm against unstable dependency.",
              "topic": "Resilience",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 58: Predict channel close behavior across multiple consumers.",
              "topic": "Security"
            },
            {
              "type": "theory",
              "question": "Exercise 59: Design alerting strategy for high p95 latency endpoint.",
              "topic": "Testing"
            },
            {
              "type": "tricky",
              "question": "Exercise 60: Explain consistency trade-offs for outbox/inbox pattern.",
              "topic": "Performance",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 61: Build bounded worker pool with cancellation and backpressure.",
              "topic": "HTTP APIs"
            },
            {
              "type": "debug",
              "question": "Exercise 62: Fix goroutine leak in channel fan-in pipeline.",
              "topic": "Database Transactions",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 63: Predict output/order for defer + panic + recover flow.",
              "topic": "Redis Caching",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 64: Design idempotent payment webhook consumer with retries.",
              "topic": "Concurrency Control"
            },
            {
              "type": "theory",
              "question": "Exercise 65: Explain mutex vs channel trade-offs in shared state updates.",
              "topic": "Message Processing"
            },
            {
              "type": "tricky",
              "question": "Exercise 66: Handle nil-interface bug in typed error wrappers.",
              "topic": "Observability",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 67: Implement request-scoped timeout propagation through repository layer.",
              "topic": "Resilience"
            },
            {
              "type": "debug",
              "question": "Exercise 68: Debug DB pool exhaustion under concurrent API load.",
              "topic": "Security",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 69: Predict race detector findings for shared map write code.",
              "topic": "Testing",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 70: Design cache-aside strategy with stampede protection.",
              "topic": "Performance"
            },
            {
              "type": "theory",
              "question": "Exercise 71: Implement optimistic locking update with version checks.",
              "topic": "HTTP APIs"
            },
            {
              "type": "tricky",
              "question": "Exercise 72: Debug stale cache invalidation after write success.",
              "topic": "Database Transactions",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 73: Predict behavior of append with shared backing slices.",
              "topic": "Redis Caching"
            },
            {
              "type": "debug",
              "question": "Exercise 74: Design graceful shutdown for HTTP server + workers + queue.",
              "topic": "Concurrency Control",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 75: Explain why time.After in loop can leak resources.",
              "topic": "Message Processing",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 76: Implement structured logging middleware with request IDs.",
              "topic": "Observability"
            },
            {
              "type": "theory",
              "question": "Exercise 77: Debug retry storm against unstable dependency.",
              "topic": "Resilience"
            },
            {
              "type": "tricky",
              "question": "Exercise 78: Predict channel close behavior across multiple consumers.",
              "topic": "Security",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 79: Design alerting strategy for high p95 latency endpoint.",
              "topic": "Testing"
            },
            {
              "type": "debug",
              "question": "Exercise 80: Explain consistency trade-offs for outbox/inbox pattern.",
              "topic": "Performance",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 81: Build bounded worker pool with cancellation and backpressure.",
              "topic": "HTTP APIs",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 82: Fix goroutine leak in channel fan-in pipeline.",
              "topic": "Database Transactions"
            },
            {
              "type": "theory",
              "question": "Exercise 83: Predict output/order for defer + panic + recover flow.",
              "topic": "Redis Caching"
            },
            {
              "type": "tricky",
              "question": "Exercise 84: Design idempotent payment webhook consumer with retries.",
              "topic": "Concurrency Control",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 85: Explain mutex vs channel trade-offs in shared state updates.",
              "topic": "Message Processing"
            },
            {
              "type": "debug",
              "question": "Exercise 86: Handle nil-interface bug in typed error wrappers.",
              "topic": "Observability",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 87: Implement request-scoped timeout propagation through repository layer.",
              "topic": "Resilience",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 88: Debug DB pool exhaustion under concurrent API load.",
              "topic": "Security"
            },
            {
              "type": "theory",
              "question": "Exercise 89: Predict race detector findings for shared map write code.",
              "topic": "Testing"
            },
            {
              "type": "tricky",
              "question": "Exercise 90: Design cache-aside strategy with stampede protection.",
              "topic": "Performance",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 91: Implement optimistic locking update with version checks.",
              "topic": "HTTP APIs"
            },
            {
              "type": "debug",
              "question": "Exercise 92: Debug stale cache invalidation after write success.",
              "topic": "Database Transactions",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 93: Predict behavior of append with shared backing slices.",
              "topic": "Redis Caching",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 94: Design graceful shutdown for HTTP server + workers + queue.",
              "topic": "Concurrency Control"
            },
            {
              "type": "theory",
              "question": "Exercise 95: Explain why time.After in loop can leak resources.",
              "topic": "Message Processing"
            },
            {
              "type": "tricky",
              "question": "Exercise 96: Implement structured logging middleware with request IDs.",
              "topic": "Observability",
              "answer": "Document edge case, failure surface, and mitigation pattern used in production."
            },
            {
              "type": "implement",
              "question": "Exercise 97: Debug retry storm against unstable dependency.",
              "topic": "Resilience"
            },
            {
              "type": "debug",
              "question": "Exercise 98: Predict channel close behavior across multiple consumers.",
              "topic": "Security",
              "hint": "Identify root cause first (leak/race/deadlock), then apply smallest safe fix."
            },
            {
              "type": "output",
              "question": "Exercise 99: Design alerting strategy for high p95 latency endpoint.",
              "topic": "Testing",
              "answer": "Provide exact output and explain synchronization/order guarantees line by line."
            },
            {
              "type": "scenario",
              "question": "Exercise 100: Explain consistency trade-offs for outbox/inbox pattern.",
              "topic": "Performance"
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 1: Implement context-aware HTTP handler with timeout and JSON error envelope",
              "code": "package main\n\nimport (\n  \"context\"\n  \"encoding/json\"\n  \"net/http\"\n  \"time\"\n)\n\nfunc writeJSON(w http.ResponseWriter, code int, v any) {\n  w.Header().Set(\"Content-Type\", \"application/json\")\n  w.WriteHeader(code)\n  _ = json.NewEncoder(w).Encode(v)\n}\n\nfunc main() {\n  http.HandleFunc(\"/health\", func(w http.ResponseWriter, r *http.Request) {\n    ctx, cancel := context.WithTimeout(r.Context(), 500*time.Millisecond)\n    defer cancel()\n    select {\n    case <-ctx.Done():\n      writeJSON(w, http.StatusGatewayTimeout, map[string]string{\"error\": \"timeout\"})\n    default:\n      writeJSON(w, http.StatusOK, map[string]string{\"status\": \"ok\"})\n    }\n  })\n  _ = http.ListenAndServe(\":8080\", nil)\n}",
              "output": "Serves /health with JSON status and timeout-safe context handling."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 2: Build worker pool with bounded queue and cancellation",
              "code": "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n  \"sync\"\n)\n\nfunc main() {\n  ctx, cancel := context.WithCancel(context.Background())\n  defer cancel()\n\n  jobs := make(chan int, 8)\n  var wg sync.WaitGroup\n\n  worker := func(id int) {\n    defer wg.Done()\n    for {\n      select {\n      case <-ctx.Done():\n        return\n      case j, ok := <-jobs:\n        if !ok { return }\n        fmt.Println(\"worker\", id, \"job\", j)\n      }\n    }\n  }\n\n  for i := 0; i < 3; i++ { wg.Add(1); go worker(i) }\n  for j := 1; j <= 6; j++ { jobs <- j }\n  close(jobs)\n  wg.Wait()\n}",
              "output": "Processes queued jobs concurrently without leaking goroutines."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 3: Repository method with sql.ErrNoRows mapping",
              "code": "func (r *UserRepo) GetByID(ctx context.Context, id int64) (User, error) {\n  var u User\n  err := r.db.QueryRowContext(ctx, \"SELECT id,email FROM users WHERE id=$1\", id).Scan(&u.ID, &u.Email)\n  if err == sql.ErrNoRows {\n    return User{}, ErrUserNotFound\n  }\n  if err != nil {\n    return User{}, fmt.Errorf(\"query user: %w\", err)\n  }\n  return u, nil\n}",
              "output": "Returns domain not-found error and wraps infrastructure failures safely."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 4: Implement Redis cache-aside getter with miss fill",
              "code": "func GetUserCached(ctx context.Context, rdb *redis.Client, repo UserRepository, id int64) (User, error) {\n  key := fmt.Sprintf(\"user:%d\", id)\n  raw, err := rdb.Get(ctx, key).Result()\n  if err == nil {\n    var u User\n    if json.Unmarshal([]byte(raw), &u) == nil {\n      return u, nil\n    }\n  }\n\n  u, err := repo.GetByID(ctx, id)\n  if err != nil { return User{}, err }\n\n  b, _ := json.Marshal(u)\n  _ = rdb.Set(ctx, key, b, 5*time.Minute).Err()\n  return u, nil\n}",
              "output": "Reads from cache first and repopulates cache on miss."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 5: Table-driven validator tests with subtests",
              "code": "func TestValidateEmail(t *testing.T) {\n  cases := []struct {\n    name string\n    in   string\n    ok   bool\n  }{\n    {\"valid\", \"a@b.com\", true},\n    {\"missing-at\", \"ab.com\", false},\n    {\"empty\", \"\", false},\n  }\n\n  for _, tc := range cases {\n    tc := tc\n    t.Run(tc.name, func(t *testing.T) {\n      got := ValidateEmail(tc.in)\n      if got != tc.ok {\n        t.Fatalf(\"got=%v want=%v\", got, tc.ok)\n      }\n    })\n  }\n}",
              "output": "Deterministic subtests validating multiple input cases."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 6: Implement context-aware HTTP handler with timeout and JSON error envelope",
              "code": "package main\n\nimport (\n  \"context\"\n  \"encoding/json\"\n  \"net/http\"\n  \"time\"\n)\n\nfunc writeJSON(w http.ResponseWriter, code int, v any) {\n  w.Header().Set(\"Content-Type\", \"application/json\")\n  w.WriteHeader(code)\n  _ = json.NewEncoder(w).Encode(v)\n}\n\nfunc main() {\n  http.HandleFunc(\"/health\", func(w http.ResponseWriter, r *http.Request) {\n    ctx, cancel := context.WithTimeout(r.Context(), 500*time.Millisecond)\n    defer cancel()\n    select {\n    case <-ctx.Done():\n      writeJSON(w, http.StatusGatewayTimeout, map[string]string{\"error\": \"timeout\"})\n    default:\n      writeJSON(w, http.StatusOK, map[string]string{\"status\": \"ok\"})\n    }\n  })\n  _ = http.ListenAndServe(\":8080\", nil)\n}",
              "output": "Serves /health with JSON status and timeout-safe context handling."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 7: Build worker pool with bounded queue and cancellation",
              "code": "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n  \"sync\"\n)\n\nfunc main() {\n  ctx, cancel := context.WithCancel(context.Background())\n  defer cancel()\n\n  jobs := make(chan int, 8)\n  var wg sync.WaitGroup\n\n  worker := func(id int) {\n    defer wg.Done()\n    for {\n      select {\n      case <-ctx.Done():\n        return\n      case j, ok := <-jobs:\n        if !ok { return }\n        fmt.Println(\"worker\", id, \"job\", j)\n      }\n    }\n  }\n\n  for i := 0; i < 3; i++ { wg.Add(1); go worker(i) }\n  for j := 1; j <= 6; j++ { jobs <- j }\n  close(jobs)\n  wg.Wait()\n}",
              "output": "Processes queued jobs concurrently without leaking goroutines."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 8: Repository method with sql.ErrNoRows mapping",
              "code": "func (r *UserRepo) GetByID(ctx context.Context, id int64) (User, error) {\n  var u User\n  err := r.db.QueryRowContext(ctx, \"SELECT id,email FROM users WHERE id=$1\", id).Scan(&u.ID, &u.Email)\n  if err == sql.ErrNoRows {\n    return User{}, ErrUserNotFound\n  }\n  if err != nil {\n    return User{}, fmt.Errorf(\"query user: %w\", err)\n  }\n  return u, nil\n}",
              "output": "Returns domain not-found error and wraps infrastructure failures safely."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 9: Implement Redis cache-aside getter with miss fill",
              "code": "func GetUserCached(ctx context.Context, rdb *redis.Client, repo UserRepository, id int64) (User, error) {\n  key := fmt.Sprintf(\"user:%d\", id)\n  raw, err := rdb.Get(ctx, key).Result()\n  if err == nil {\n    var u User\n    if json.Unmarshal([]byte(raw), &u) == nil {\n      return u, nil\n    }\n  }\n\n  u, err := repo.GetByID(ctx, id)\n  if err != nil { return User{}, err }\n\n  b, _ := json.Marshal(u)\n  _ = rdb.Set(ctx, key, b, 5*time.Minute).Err()\n  return u, nil\n}",
              "output": "Reads from cache first and repopulates cache on miss."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 10: Table-driven validator tests with subtests",
              "code": "func TestValidateEmail(t *testing.T) {\n  cases := []struct {\n    name string\n    in   string\n    ok   bool\n  }{\n    {\"valid\", \"a@b.com\", true},\n    {\"missing-at\", \"ab.com\", false},\n    {\"empty\", \"\", false},\n  }\n\n  for _, tc := range cases {\n    tc := tc\n    t.Run(tc.name, func(t *testing.T) {\n      got := ValidateEmail(tc.in)\n      if got != tc.ok {\n        t.Fatalf(\"got=%v want=%v\", got, tc.ok)\n      }\n    })\n  }\n}",
              "output": "Deterministic subtests validating multiple input cases."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 11: Implement context-aware HTTP handler with timeout and JSON error envelope",
              "code": "package main\n\nimport (\n  \"context\"\n  \"encoding/json\"\n  \"net/http\"\n  \"time\"\n)\n\nfunc writeJSON(w http.ResponseWriter, code int, v any) {\n  w.Header().Set(\"Content-Type\", \"application/json\")\n  w.WriteHeader(code)\n  _ = json.NewEncoder(w).Encode(v)\n}\n\nfunc main() {\n  http.HandleFunc(\"/health\", func(w http.ResponseWriter, r *http.Request) {\n    ctx, cancel := context.WithTimeout(r.Context(), 500*time.Millisecond)\n    defer cancel()\n    select {\n    case <-ctx.Done():\n      writeJSON(w, http.StatusGatewayTimeout, map[string]string{\"error\": \"timeout\"})\n    default:\n      writeJSON(w, http.StatusOK, map[string]string{\"status\": \"ok\"})\n    }\n  })\n  _ = http.ListenAndServe(\":8080\", nil)\n}",
              "output": "Serves /health with JSON status and timeout-safe context handling."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 12: Build worker pool with bounded queue and cancellation",
              "code": "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n  \"sync\"\n)\n\nfunc main() {\n  ctx, cancel := context.WithCancel(context.Background())\n  defer cancel()\n\n  jobs := make(chan int, 8)\n  var wg sync.WaitGroup\n\n  worker := func(id int) {\n    defer wg.Done()\n    for {\n      select {\n      case <-ctx.Done():\n        return\n      case j, ok := <-jobs:\n        if !ok { return }\n        fmt.Println(\"worker\", id, \"job\", j)\n      }\n    }\n  }\n\n  for i := 0; i < 3; i++ { wg.Add(1); go worker(i) }\n  for j := 1; j <= 6; j++ { jobs <- j }\n  close(jobs)\n  wg.Wait()\n}",
              "output": "Processes queued jobs concurrently without leaking goroutines."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 13: Repository method with sql.ErrNoRows mapping",
              "code": "func (r *UserRepo) GetByID(ctx context.Context, id int64) (User, error) {\n  var u User\n  err := r.db.QueryRowContext(ctx, \"SELECT id,email FROM users WHERE id=$1\", id).Scan(&u.ID, &u.Email)\n  if err == sql.ErrNoRows {\n    return User{}, ErrUserNotFound\n  }\n  if err != nil {\n    return User{}, fmt.Errorf(\"query user: %w\", err)\n  }\n  return u, nil\n}",
              "output": "Returns domain not-found error and wraps infrastructure failures safely."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 14: Implement Redis cache-aside getter with miss fill",
              "code": "func GetUserCached(ctx context.Context, rdb *redis.Client, repo UserRepository, id int64) (User, error) {\n  key := fmt.Sprintf(\"user:%d\", id)\n  raw, err := rdb.Get(ctx, key).Result()\n  if err == nil {\n    var u User\n    if json.Unmarshal([]byte(raw), &u) == nil {\n      return u, nil\n    }\n  }\n\n  u, err := repo.GetByID(ctx, id)\n  if err != nil { return User{}, err }\n\n  b, _ := json.Marshal(u)\n  _ = rdb.Set(ctx, key, b, 5*time.Minute).Err()\n  return u, nil\n}",
              "output": "Reads from cache first and repopulates cache on miss."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 15: Table-driven validator tests with subtests",
              "code": "func TestValidateEmail(t *testing.T) {\n  cases := []struct {\n    name string\n    in   string\n    ok   bool\n  }{\n    {\"valid\", \"a@b.com\", true},\n    {\"missing-at\", \"ab.com\", false},\n    {\"empty\", \"\", false},\n  }\n\n  for _, tc := range cases {\n    tc := tc\n    t.Run(tc.name, func(t *testing.T) {\n      got := ValidateEmail(tc.in)\n      if got != tc.ok {\n        t.Fatalf(\"got=%v want=%v\", got, tc.ok)\n      }\n    })\n  }\n}",
              "output": "Deterministic subtests validating multiple input cases."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 16: Implement context-aware HTTP handler with timeout and JSON error envelope",
              "code": "package main\n\nimport (\n  \"context\"\n  \"encoding/json\"\n  \"net/http\"\n  \"time\"\n)\n\nfunc writeJSON(w http.ResponseWriter, code int, v any) {\n  w.Header().Set(\"Content-Type\", \"application/json\")\n  w.WriteHeader(code)\n  _ = json.NewEncoder(w).Encode(v)\n}\n\nfunc main() {\n  http.HandleFunc(\"/health\", func(w http.ResponseWriter, r *http.Request) {\n    ctx, cancel := context.WithTimeout(r.Context(), 500*time.Millisecond)\n    defer cancel()\n    select {\n    case <-ctx.Done():\n      writeJSON(w, http.StatusGatewayTimeout, map[string]string{\"error\": \"timeout\"})\n    default:\n      writeJSON(w, http.StatusOK, map[string]string{\"status\": \"ok\"})\n    }\n  })\n  _ = http.ListenAndServe(\":8080\", nil)\n}",
              "output": "Serves /health with JSON status and timeout-safe context handling."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 17: Build worker pool with bounded queue and cancellation",
              "code": "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n  \"sync\"\n)\n\nfunc main() {\n  ctx, cancel := context.WithCancel(context.Background())\n  defer cancel()\n\n  jobs := make(chan int, 8)\n  var wg sync.WaitGroup\n\n  worker := func(id int) {\n    defer wg.Done()\n    for {\n      select {\n      case <-ctx.Done():\n        return\n      case j, ok := <-jobs:\n        if !ok { return }\n        fmt.Println(\"worker\", id, \"job\", j)\n      }\n    }\n  }\n\n  for i := 0; i < 3; i++ { wg.Add(1); go worker(i) }\n  for j := 1; j <= 6; j++ { jobs <- j }\n  close(jobs)\n  wg.Wait()\n}",
              "output": "Processes queued jobs concurrently without leaking goroutines."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 18: Repository method with sql.ErrNoRows mapping",
              "code": "func (r *UserRepo) GetByID(ctx context.Context, id int64) (User, error) {\n  var u User\n  err := r.db.QueryRowContext(ctx, \"SELECT id,email FROM users WHERE id=$1\", id).Scan(&u.ID, &u.Email)\n  if err == sql.ErrNoRows {\n    return User{}, ErrUserNotFound\n  }\n  if err != nil {\n    return User{}, fmt.Errorf(\"query user: %w\", err)\n  }\n  return u, nil\n}",
              "output": "Returns domain not-found error and wraps infrastructure failures safely."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 19: Implement Redis cache-aside getter with miss fill",
              "code": "func GetUserCached(ctx context.Context, rdb *redis.Client, repo UserRepository, id int64) (User, error) {\n  key := fmt.Sprintf(\"user:%d\", id)\n  raw, err := rdb.Get(ctx, key).Result()\n  if err == nil {\n    var u User\n    if json.Unmarshal([]byte(raw), &u) == nil {\n      return u, nil\n    }\n  }\n\n  u, err := repo.GetByID(ctx, id)\n  if err != nil { return User{}, err }\n\n  b, _ := json.Marshal(u)\n  _ = rdb.Set(ctx, key, b, 5*time.Minute).Err()\n  return u, nil\n}",
              "output": "Reads from cache first and repopulates cache on miss."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 20: Table-driven validator tests with subtests",
              "code": "func TestValidateEmail(t *testing.T) {\n  cases := []struct {\n    name string\n    in   string\n    ok   bool\n  }{\n    {\"valid\", \"a@b.com\", true},\n    {\"missing-at\", \"ab.com\", false},\n    {\"empty\", \"\", false},\n  }\n\n  for _, tc := range cases {\n    tc := tc\n    t.Run(tc.name, func(t *testing.T) {\n      got := ValidateEmail(tc.in)\n      if got != tc.ok {\n        t.Fatalf(\"got=%v want=%v\", got, tc.ok)\n      }\n    })\n  }\n}",
              "output": "Deterministic subtests validating multiple input cases."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 21: Implement context-aware HTTP handler with timeout and JSON error envelope",
              "code": "package main\n\nimport (\n  \"context\"\n  \"encoding/json\"\n  \"net/http\"\n  \"time\"\n)\n\nfunc writeJSON(w http.ResponseWriter, code int, v any) {\n  w.Header().Set(\"Content-Type\", \"application/json\")\n  w.WriteHeader(code)\n  _ = json.NewEncoder(w).Encode(v)\n}\n\nfunc main() {\n  http.HandleFunc(\"/health\", func(w http.ResponseWriter, r *http.Request) {\n    ctx, cancel := context.WithTimeout(r.Context(), 500*time.Millisecond)\n    defer cancel()\n    select {\n    case <-ctx.Done():\n      writeJSON(w, http.StatusGatewayTimeout, map[string]string{\"error\": \"timeout\"})\n    default:\n      writeJSON(w, http.StatusOK, map[string]string{\"status\": \"ok\"})\n    }\n  })\n  _ = http.ListenAndServe(\":8080\", nil)\n}",
              "output": "Serves /health with JSON status and timeout-safe context handling."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 22: Build worker pool with bounded queue and cancellation",
              "code": "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n  \"sync\"\n)\n\nfunc main() {\n  ctx, cancel := context.WithCancel(context.Background())\n  defer cancel()\n\n  jobs := make(chan int, 8)\n  var wg sync.WaitGroup\n\n  worker := func(id int) {\n    defer wg.Done()\n    for {\n      select {\n      case <-ctx.Done():\n        return\n      case j, ok := <-jobs:\n        if !ok { return }\n        fmt.Println(\"worker\", id, \"job\", j)\n      }\n    }\n  }\n\n  for i := 0; i < 3; i++ { wg.Add(1); go worker(i) }\n  for j := 1; j <= 6; j++ { jobs <- j }\n  close(jobs)\n  wg.Wait()\n}",
              "output": "Processes queued jobs concurrently without leaking goroutines."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 23: Repository method with sql.ErrNoRows mapping",
              "code": "func (r *UserRepo) GetByID(ctx context.Context, id int64) (User, error) {\n  var u User\n  err := r.db.QueryRowContext(ctx, \"SELECT id,email FROM users WHERE id=$1\", id).Scan(&u.ID, &u.Email)\n  if err == sql.ErrNoRows {\n    return User{}, ErrUserNotFound\n  }\n  if err != nil {\n    return User{}, fmt.Errorf(\"query user: %w\", err)\n  }\n  return u, nil\n}",
              "output": "Returns domain not-found error and wraps infrastructure failures safely."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 24: Implement Redis cache-aside getter with miss fill",
              "code": "func GetUserCached(ctx context.Context, rdb *redis.Client, repo UserRepository, id int64) (User, error) {\n  key := fmt.Sprintf(\"user:%d\", id)\n  raw, err := rdb.Get(ctx, key).Result()\n  if err == nil {\n    var u User\n    if json.Unmarshal([]byte(raw), &u) == nil {\n      return u, nil\n    }\n  }\n\n  u, err := repo.GetByID(ctx, id)\n  if err != nil { return User{}, err }\n\n  b, _ := json.Marshal(u)\n  _ = rdb.Set(ctx, key, b, 5*time.Minute).Err()\n  return u, nil\n}",
              "output": "Reads from cache first and repopulates cache on miss."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 25: Table-driven validator tests with subtests",
              "code": "func TestValidateEmail(t *testing.T) {\n  cases := []struct {\n    name string\n    in   string\n    ok   bool\n  }{\n    {\"valid\", \"a@b.com\", true},\n    {\"missing-at\", \"ab.com\", false},\n    {\"empty\", \"\", false},\n  }\n\n  for _, tc := range cases {\n    tc := tc\n    t.Run(tc.name, func(t *testing.T) {\n      got := ValidateEmail(tc.in)\n      if got != tc.ok {\n        t.Fatalf(\"got=%v want=%v\", got, tc.ok)\n      }\n    })\n  }\n}",
              "output": "Deterministic subtests validating multiple input cases."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 26: Implement context-aware HTTP handler with timeout and JSON error envelope",
              "code": "package main\n\nimport (\n  \"context\"\n  \"encoding/json\"\n  \"net/http\"\n  \"time\"\n)\n\nfunc writeJSON(w http.ResponseWriter, code int, v any) {\n  w.Header().Set(\"Content-Type\", \"application/json\")\n  w.WriteHeader(code)\n  _ = json.NewEncoder(w).Encode(v)\n}\n\nfunc main() {\n  http.HandleFunc(\"/health\", func(w http.ResponseWriter, r *http.Request) {\n    ctx, cancel := context.WithTimeout(r.Context(), 500*time.Millisecond)\n    defer cancel()\n    select {\n    case <-ctx.Done():\n      writeJSON(w, http.StatusGatewayTimeout, map[string]string{\"error\": \"timeout\"})\n    default:\n      writeJSON(w, http.StatusOK, map[string]string{\"status\": \"ok\"})\n    }\n  })\n  _ = http.ListenAndServe(\":8080\", nil)\n}",
              "output": "Serves /health with JSON status and timeout-safe context handling."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 27: Build worker pool with bounded queue and cancellation",
              "code": "package main\n\nimport (\n  \"context\"\n  \"fmt\"\n  \"sync\"\n)\n\nfunc main() {\n  ctx, cancel := context.WithCancel(context.Background())\n  defer cancel()\n\n  jobs := make(chan int, 8)\n  var wg sync.WaitGroup\n\n  worker := func(id int) {\n    defer wg.Done()\n    for {\n      select {\n      case <-ctx.Done():\n        return\n      case j, ok := <-jobs:\n        if !ok { return }\n        fmt.Println(\"worker\", id, \"job\", j)\n      }\n    }\n  }\n\n  for i := 0; i < 3; i++ { wg.Add(1); go worker(i) }\n  for j := 1; j <= 6; j++ { jobs <- j }\n  close(jobs)\n  wg.Wait()\n}",
              "output": "Processes queued jobs concurrently without leaking goroutines."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 28: Repository method with sql.ErrNoRows mapping",
              "code": "func (r *UserRepo) GetByID(ctx context.Context, id int64) (User, error) {\n  var u User\n  err := r.db.QueryRowContext(ctx, \"SELECT id,email FROM users WHERE id=$1\", id).Scan(&u.ID, &u.Email)\n  if err == sql.ErrNoRows {\n    return User{}, ErrUserNotFound\n  }\n  if err != nil {\n    return User{}, fmt.Errorf(\"query user: %w\", err)\n  }\n  return u, nil\n}",
              "output": "Returns domain not-found error and wraps infrastructure failures safely."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 29: Implement Redis cache-aside getter with miss fill",
              "code": "func GetUserCached(ctx context.Context, rdb *redis.Client, repo UserRepository, id int64) (User, error) {\n  key := fmt.Sprintf(\"user:%d\", id)\n  raw, err := rdb.Get(ctx, key).Result()\n  if err == nil {\n    var u User\n    if json.Unmarshal([]byte(raw), &u) == nil {\n      return u, nil\n    }\n  }\n\n  u, err := repo.GetByID(ctx, id)\n  if err != nil { return User{}, err }\n\n  b, _ := json.Marshal(u)\n  _ = rdb.Set(ctx, key, b, 5*time.Minute).Err()\n  return u, nil\n}",
              "output": "Reads from cache first and repopulates cache on miss."
            },
            {
              "type": "program",
              "level": "Medium",
              "question": "Program 30: Table-driven validator tests with subtests",
              "code": "func TestValidateEmail(t *testing.T) {\n  cases := []struct {\n    name string\n    in   string\n    ok   bool\n  }{\n    {\"valid\", \"a@b.com\", true},\n    {\"missing-at\", \"ab.com\", false},\n    {\"empty\", \"\", false},\n  }\n\n  for _, tc := range cases {\n    tc := tc\n    t.Run(tc.name, func(t *testing.T) {\n      got := ValidateEmail(tc.in)\n      if got != tc.ok {\n        t.Fatalf(\"got=%v want=%v\", got, tc.ok)\n      }\n    })\n  }\n}",
              "output": "Deterministic subtests validating multiple input cases."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 31: Retry with exponential backoff + jitter + context cancel",
              "code": "func Retry(ctx context.Context, max int, fn func(context.Context) error) error {\n  var err error\n  for i := 0; i < max; i++ {\n    if err = fn(ctx); err == nil { return nil }\n\n    d := time.Duration(1<<i) * 50 * time.Millisecond\n    jitter := time.Duration(rand.Intn(40)) * time.Millisecond\n    timer := time.NewTimer(d + jitter)\n\n    select {\n    case <-ctx.Done():\n      timer.Stop()\n      return ctx.Err()\n    case <-timer.C:\n    }\n  }\n  return fmt.Errorf(\"retry exhausted: %w\", err)\n}",
              "output": "Retries failures with bounded exponential backoff and cancel support."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 32: Token bucket rate limiter middleware",
              "code": "type TokenBucket struct {\n  mu       sync.Mutex\n  tokens   float64\n  capacity float64\n  rate     float64\n  last     time.Time\n}\n\nfunc (b *TokenBucket) Allow() bool {\n  b.mu.Lock()\n  defer b.mu.Unlock()\n\n  now := time.Now()\n  elapsed := now.Sub(b.last).Seconds()\n  b.tokens = math.Min(b.capacity, b.tokens+elapsed*b.rate)\n  b.last = now\n\n  if b.tokens < 1 { return false }\n  b.tokens--\n  return true\n}\n\nfunc RateLimit(next http.Handler, bucket *TokenBucket) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    if !bucket.Allow() {\n      http.Error(w, \"rate limited\", http.StatusTooManyRequests)\n      return\n    }\n    next.ServeHTTP(w, r)\n  })\n}",
              "output": "Protects endpoints with deterministic token-based throttling."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 33: Graceful shutdown coordinator for HTTP + workers",
              "code": "func Run(ctx context.Context, srv *http.Server, runWorkers func(context.Context) error) error {\n  g, gctx := errgroup.WithContext(ctx)\n\n  g.Go(func() error { return srv.ListenAndServe() })\n  g.Go(func() error { return runWorkers(gctx) })\n\n  <-gctx.Done()\n\n  shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n  defer cancel()\n  _ = srv.Shutdown(shutdownCtx)\n\n  return g.Wait()\n}",
              "output": "Coordinates service stop and drains inflight work safely."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 34: Outbox publisher transaction skeleton",
              "code": "func CreateOrderWithOutbox(ctx context.Context, db *sql.DB, order Order) error {\n  tx, err := db.BeginTx(ctx, nil)\n  if err != nil { return err }\n  defer tx.Rollback()\n\n  _, err = tx.ExecContext(ctx, \"INSERT INTO orders(id,total) VALUES($1,$2)\", order.ID, order.Total)\n  if err != nil { return err }\n\n  payload, _ := json.Marshal(order)\n  _, err = tx.ExecContext(ctx, \"INSERT INTO outbox(event_type,payload,status) VALUES($1,$2,'pending')\", \"order.created\", payload)\n  if err != nil { return err }\n\n  return tx.Commit()\n}",
              "output": "Writes domain change and outbox event atomically in one transaction."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 35: Channel fan-in with context cancellation and error channel",
              "code": "func FanIn(ctx context.Context, inputs ...<-chan int) (<-chan int, <-chan error) {\n  out := make(chan int)\n  errCh := make(chan error, 1)\n  var wg sync.WaitGroup\n\n  forward := func(ch <-chan int) {\n    defer wg.Done()\n    for {\n      select {\n      case <-ctx.Done():\n        return\n      case v, ok := <-ch:\n        if !ok { return }\n        select {\n        case out <- v:\n        case <-ctx.Done(): return\n        }\n      }\n    }\n  }\n\n  wg.Add(len(inputs))\n  for _, ch := range inputs { go forward(ch) }\n\n  go func() {\n    wg.Wait()\n    close(out)\n    close(errCh)\n  }()\n\n  return out, errCh\n}",
              "output": "Merges multiple streams safely with cancellation-aware forwarding."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 36: Retry with exponential backoff + jitter + context cancel",
              "code": "func Retry(ctx context.Context, max int, fn func(context.Context) error) error {\n  var err error\n  for i := 0; i < max; i++ {\n    if err = fn(ctx); err == nil { return nil }\n\n    d := time.Duration(1<<i) * 50 * time.Millisecond\n    jitter := time.Duration(rand.Intn(40)) * time.Millisecond\n    timer := time.NewTimer(d + jitter)\n\n    select {\n    case <-ctx.Done():\n      timer.Stop()\n      return ctx.Err()\n    case <-timer.C:\n    }\n  }\n  return fmt.Errorf(\"retry exhausted: %w\", err)\n}",
              "output": "Retries failures with bounded exponential backoff and cancel support."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 37: Token bucket rate limiter middleware",
              "code": "type TokenBucket struct {\n  mu       sync.Mutex\n  tokens   float64\n  capacity float64\n  rate     float64\n  last     time.Time\n}\n\nfunc (b *TokenBucket) Allow() bool {\n  b.mu.Lock()\n  defer b.mu.Unlock()\n\n  now := time.Now()\n  elapsed := now.Sub(b.last).Seconds()\n  b.tokens = math.Min(b.capacity, b.tokens+elapsed*b.rate)\n  b.last = now\n\n  if b.tokens < 1 { return false }\n  b.tokens--\n  return true\n}\n\nfunc RateLimit(next http.Handler, bucket *TokenBucket) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    if !bucket.Allow() {\n      http.Error(w, \"rate limited\", http.StatusTooManyRequests)\n      return\n    }\n    next.ServeHTTP(w, r)\n  })\n}",
              "output": "Protects endpoints with deterministic token-based throttling."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 38: Graceful shutdown coordinator for HTTP + workers",
              "code": "func Run(ctx context.Context, srv *http.Server, runWorkers func(context.Context) error) error {\n  g, gctx := errgroup.WithContext(ctx)\n\n  g.Go(func() error { return srv.ListenAndServe() })\n  g.Go(func() error { return runWorkers(gctx) })\n\n  <-gctx.Done()\n\n  shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n  defer cancel()\n  _ = srv.Shutdown(shutdownCtx)\n\n  return g.Wait()\n}",
              "output": "Coordinates service stop and drains inflight work safely."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 39: Outbox publisher transaction skeleton",
              "code": "func CreateOrderWithOutbox(ctx context.Context, db *sql.DB, order Order) error {\n  tx, err := db.BeginTx(ctx, nil)\n  if err != nil { return err }\n  defer tx.Rollback()\n\n  _, err = tx.ExecContext(ctx, \"INSERT INTO orders(id,total) VALUES($1,$2)\", order.ID, order.Total)\n  if err != nil { return err }\n\n  payload, _ := json.Marshal(order)\n  _, err = tx.ExecContext(ctx, \"INSERT INTO outbox(event_type,payload,status) VALUES($1,$2,'pending')\", \"order.created\", payload)\n  if err != nil { return err }\n\n  return tx.Commit()\n}",
              "output": "Writes domain change and outbox event atomically in one transaction."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 40: Channel fan-in with context cancellation and error channel",
              "code": "func FanIn(ctx context.Context, inputs ...<-chan int) (<-chan int, <-chan error) {\n  out := make(chan int)\n  errCh := make(chan error, 1)\n  var wg sync.WaitGroup\n\n  forward := func(ch <-chan int) {\n    defer wg.Done()\n    for {\n      select {\n      case <-ctx.Done():\n        return\n      case v, ok := <-ch:\n        if !ok { return }\n        select {\n        case out <- v:\n        case <-ctx.Done(): return\n        }\n      }\n    }\n  }\n\n  wg.Add(len(inputs))\n  for _, ch := range inputs { go forward(ch) }\n\n  go func() {\n    wg.Wait()\n    close(out)\n    close(errCh)\n  }()\n\n  return out, errCh\n}",
              "output": "Merges multiple streams safely with cancellation-aware forwarding."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 41: Retry with exponential backoff + jitter + context cancel",
              "code": "func Retry(ctx context.Context, max int, fn func(context.Context) error) error {\n  var err error\n  for i := 0; i < max; i++ {\n    if err = fn(ctx); err == nil { return nil }\n\n    d := time.Duration(1<<i) * 50 * time.Millisecond\n    jitter := time.Duration(rand.Intn(40)) * time.Millisecond\n    timer := time.NewTimer(d + jitter)\n\n    select {\n    case <-ctx.Done():\n      timer.Stop()\n      return ctx.Err()\n    case <-timer.C:\n    }\n  }\n  return fmt.Errorf(\"retry exhausted: %w\", err)\n}",
              "output": "Retries failures with bounded exponential backoff and cancel support."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 42: Token bucket rate limiter middleware",
              "code": "type TokenBucket struct {\n  mu       sync.Mutex\n  tokens   float64\n  capacity float64\n  rate     float64\n  last     time.Time\n}\n\nfunc (b *TokenBucket) Allow() bool {\n  b.mu.Lock()\n  defer b.mu.Unlock()\n\n  now := time.Now()\n  elapsed := now.Sub(b.last).Seconds()\n  b.tokens = math.Min(b.capacity, b.tokens+elapsed*b.rate)\n  b.last = now\n\n  if b.tokens < 1 { return false }\n  b.tokens--\n  return true\n}\n\nfunc RateLimit(next http.Handler, bucket *TokenBucket) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    if !bucket.Allow() {\n      http.Error(w, \"rate limited\", http.StatusTooManyRequests)\n      return\n    }\n    next.ServeHTTP(w, r)\n  })\n}",
              "output": "Protects endpoints with deterministic token-based throttling."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 43: Graceful shutdown coordinator for HTTP + workers",
              "code": "func Run(ctx context.Context, srv *http.Server, runWorkers func(context.Context) error) error {\n  g, gctx := errgroup.WithContext(ctx)\n\n  g.Go(func() error { return srv.ListenAndServe() })\n  g.Go(func() error { return runWorkers(gctx) })\n\n  <-gctx.Done()\n\n  shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n  defer cancel()\n  _ = srv.Shutdown(shutdownCtx)\n\n  return g.Wait()\n}",
              "output": "Coordinates service stop and drains inflight work safely."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 44: Outbox publisher transaction skeleton",
              "code": "func CreateOrderWithOutbox(ctx context.Context, db *sql.DB, order Order) error {\n  tx, err := db.BeginTx(ctx, nil)\n  if err != nil { return err }\n  defer tx.Rollback()\n\n  _, err = tx.ExecContext(ctx, \"INSERT INTO orders(id,total) VALUES($1,$2)\", order.ID, order.Total)\n  if err != nil { return err }\n\n  payload, _ := json.Marshal(order)\n  _, err = tx.ExecContext(ctx, \"INSERT INTO outbox(event_type,payload,status) VALUES($1,$2,'pending')\", \"order.created\", payload)\n  if err != nil { return err }\n\n  return tx.Commit()\n}",
              "output": "Writes domain change and outbox event atomically in one transaction."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 45: Channel fan-in with context cancellation and error channel",
              "code": "func FanIn(ctx context.Context, inputs ...<-chan int) (<-chan int, <-chan error) {\n  out := make(chan int)\n  errCh := make(chan error, 1)\n  var wg sync.WaitGroup\n\n  forward := func(ch <-chan int) {\n    defer wg.Done()\n    for {\n      select {\n      case <-ctx.Done():\n        return\n      case v, ok := <-ch:\n        if !ok { return }\n        select {\n        case out <- v:\n        case <-ctx.Done(): return\n        }\n      }\n    }\n  }\n\n  wg.Add(len(inputs))\n  for _, ch := range inputs { go forward(ch) }\n\n  go func() {\n    wg.Wait()\n    close(out)\n    close(errCh)\n  }()\n\n  return out, errCh\n}",
              "output": "Merges multiple streams safely with cancellation-aware forwarding."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 46: Retry with exponential backoff + jitter + context cancel",
              "code": "func Retry(ctx context.Context, max int, fn func(context.Context) error) error {\n  var err error\n  for i := 0; i < max; i++ {\n    if err = fn(ctx); err == nil { return nil }\n\n    d := time.Duration(1<<i) * 50 * time.Millisecond\n    jitter := time.Duration(rand.Intn(40)) * time.Millisecond\n    timer := time.NewTimer(d + jitter)\n\n    select {\n    case <-ctx.Done():\n      timer.Stop()\n      return ctx.Err()\n    case <-timer.C:\n    }\n  }\n  return fmt.Errorf(\"retry exhausted: %w\", err)\n}",
              "output": "Retries failures with bounded exponential backoff and cancel support."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 47: Token bucket rate limiter middleware",
              "code": "type TokenBucket struct {\n  mu       sync.Mutex\n  tokens   float64\n  capacity float64\n  rate     float64\n  last     time.Time\n}\n\nfunc (b *TokenBucket) Allow() bool {\n  b.mu.Lock()\n  defer b.mu.Unlock()\n\n  now := time.Now()\n  elapsed := now.Sub(b.last).Seconds()\n  b.tokens = math.Min(b.capacity, b.tokens+elapsed*b.rate)\n  b.last = now\n\n  if b.tokens < 1 { return false }\n  b.tokens--\n  return true\n}\n\nfunc RateLimit(next http.Handler, bucket *TokenBucket) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    if !bucket.Allow() {\n      http.Error(w, \"rate limited\", http.StatusTooManyRequests)\n      return\n    }\n    next.ServeHTTP(w, r)\n  })\n}",
              "output": "Protects endpoints with deterministic token-based throttling."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 48: Graceful shutdown coordinator for HTTP + workers",
              "code": "func Run(ctx context.Context, srv *http.Server, runWorkers func(context.Context) error) error {\n  g, gctx := errgroup.WithContext(ctx)\n\n  g.Go(func() error { return srv.ListenAndServe() })\n  g.Go(func() error { return runWorkers(gctx) })\n\n  <-gctx.Done()\n\n  shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n  defer cancel()\n  _ = srv.Shutdown(shutdownCtx)\n\n  return g.Wait()\n}",
              "output": "Coordinates service stop and drains inflight work safely."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 49: Outbox publisher transaction skeleton",
              "code": "func CreateOrderWithOutbox(ctx context.Context, db *sql.DB, order Order) error {\n  tx, err := db.BeginTx(ctx, nil)\n  if err != nil { return err }\n  defer tx.Rollback()\n\n  _, err = tx.ExecContext(ctx, \"INSERT INTO orders(id,total) VALUES($1,$2)\", order.ID, order.Total)\n  if err != nil { return err }\n\n  payload, _ := json.Marshal(order)\n  _, err = tx.ExecContext(ctx, \"INSERT INTO outbox(event_type,payload,status) VALUES($1,$2,'pending')\", \"order.created\", payload)\n  if err != nil { return err }\n\n  return tx.Commit()\n}",
              "output": "Writes domain change and outbox event atomically in one transaction."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 50: Channel fan-in with context cancellation and error channel",
              "code": "func FanIn(ctx context.Context, inputs ...<-chan int) (<-chan int, <-chan error) {\n  out := make(chan int)\n  errCh := make(chan error, 1)\n  var wg sync.WaitGroup\n\n  forward := func(ch <-chan int) {\n    defer wg.Done()\n    for {\n      select {\n      case <-ctx.Done():\n        return\n      case v, ok := <-ch:\n        if !ok { return }\n        select {\n        case out <- v:\n        case <-ctx.Done(): return\n        }\n      }\n    }\n  }\n\n  wg.Add(len(inputs))\n  for _, ch := range inputs { go forward(ch) }\n\n  go func() {\n    wg.Wait()\n    close(out)\n    close(errCh)\n  }()\n\n  return out, errCh\n}",
              "output": "Merges multiple streams safely with cancellation-aware forwarding."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 51: Retry with exponential backoff + jitter + context cancel",
              "code": "func Retry(ctx context.Context, max int, fn func(context.Context) error) error {\n  var err error\n  for i := 0; i < max; i++ {\n    if err = fn(ctx); err == nil { return nil }\n\n    d := time.Duration(1<<i) * 50 * time.Millisecond\n    jitter := time.Duration(rand.Intn(40)) * time.Millisecond\n    timer := time.NewTimer(d + jitter)\n\n    select {\n    case <-ctx.Done():\n      timer.Stop()\n      return ctx.Err()\n    case <-timer.C:\n    }\n  }\n  return fmt.Errorf(\"retry exhausted: %w\", err)\n}",
              "output": "Retries failures with bounded exponential backoff and cancel support."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 52: Token bucket rate limiter middleware",
              "code": "type TokenBucket struct {\n  mu       sync.Mutex\n  tokens   float64\n  capacity float64\n  rate     float64\n  last     time.Time\n}\n\nfunc (b *TokenBucket) Allow() bool {\n  b.mu.Lock()\n  defer b.mu.Unlock()\n\n  now := time.Now()\n  elapsed := now.Sub(b.last).Seconds()\n  b.tokens = math.Min(b.capacity, b.tokens+elapsed*b.rate)\n  b.last = now\n\n  if b.tokens < 1 { return false }\n  b.tokens--\n  return true\n}\n\nfunc RateLimit(next http.Handler, bucket *TokenBucket) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    if !bucket.Allow() {\n      http.Error(w, \"rate limited\", http.StatusTooManyRequests)\n      return\n    }\n    next.ServeHTTP(w, r)\n  })\n}",
              "output": "Protects endpoints with deterministic token-based throttling."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 53: Graceful shutdown coordinator for HTTP + workers",
              "code": "func Run(ctx context.Context, srv *http.Server, runWorkers func(context.Context) error) error {\n  g, gctx := errgroup.WithContext(ctx)\n\n  g.Go(func() error { return srv.ListenAndServe() })\n  g.Go(func() error { return runWorkers(gctx) })\n\n  <-gctx.Done()\n\n  shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n  defer cancel()\n  _ = srv.Shutdown(shutdownCtx)\n\n  return g.Wait()\n}",
              "output": "Coordinates service stop and drains inflight work safely."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 54: Outbox publisher transaction skeleton",
              "code": "func CreateOrderWithOutbox(ctx context.Context, db *sql.DB, order Order) error {\n  tx, err := db.BeginTx(ctx, nil)\n  if err != nil { return err }\n  defer tx.Rollback()\n\n  _, err = tx.ExecContext(ctx, \"INSERT INTO orders(id,total) VALUES($1,$2)\", order.ID, order.Total)\n  if err != nil { return err }\n\n  payload, _ := json.Marshal(order)\n  _, err = tx.ExecContext(ctx, \"INSERT INTO outbox(event_type,payload,status) VALUES($1,$2,'pending')\", \"order.created\", payload)\n  if err != nil { return err }\n\n  return tx.Commit()\n}",
              "output": "Writes domain change and outbox event atomically in one transaction."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 55: Channel fan-in with context cancellation and error channel",
              "code": "func FanIn(ctx context.Context, inputs ...<-chan int) (<-chan int, <-chan error) {\n  out := make(chan int)\n  errCh := make(chan error, 1)\n  var wg sync.WaitGroup\n\n  forward := func(ch <-chan int) {\n    defer wg.Done()\n    for {\n      select {\n      case <-ctx.Done():\n        return\n      case v, ok := <-ch:\n        if !ok { return }\n        select {\n        case out <- v:\n        case <-ctx.Done(): return\n        }\n      }\n    }\n  }\n\n  wg.Add(len(inputs))\n  for _, ch := range inputs { go forward(ch) }\n\n  go func() {\n    wg.Wait()\n    close(out)\n    close(errCh)\n  }()\n\n  return out, errCh\n}",
              "output": "Merges multiple streams safely with cancellation-aware forwarding."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 56: Retry with exponential backoff + jitter + context cancel",
              "code": "func Retry(ctx context.Context, max int, fn func(context.Context) error) error {\n  var err error\n  for i := 0; i < max; i++ {\n    if err = fn(ctx); err == nil { return nil }\n\n    d := time.Duration(1<<i) * 50 * time.Millisecond\n    jitter := time.Duration(rand.Intn(40)) * time.Millisecond\n    timer := time.NewTimer(d + jitter)\n\n    select {\n    case <-ctx.Done():\n      timer.Stop()\n      return ctx.Err()\n    case <-timer.C:\n    }\n  }\n  return fmt.Errorf(\"retry exhausted: %w\", err)\n}",
              "output": "Retries failures with bounded exponential backoff and cancel support."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 57: Token bucket rate limiter middleware",
              "code": "type TokenBucket struct {\n  mu       sync.Mutex\n  tokens   float64\n  capacity float64\n  rate     float64\n  last     time.Time\n}\n\nfunc (b *TokenBucket) Allow() bool {\n  b.mu.Lock()\n  defer b.mu.Unlock()\n\n  now := time.Now()\n  elapsed := now.Sub(b.last).Seconds()\n  b.tokens = math.Min(b.capacity, b.tokens+elapsed*b.rate)\n  b.last = now\n\n  if b.tokens < 1 { return false }\n  b.tokens--\n  return true\n}\n\nfunc RateLimit(next http.Handler, bucket *TokenBucket) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    if !bucket.Allow() {\n      http.Error(w, \"rate limited\", http.StatusTooManyRequests)\n      return\n    }\n    next.ServeHTTP(w, r)\n  })\n}",
              "output": "Protects endpoints with deterministic token-based throttling."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 58: Graceful shutdown coordinator for HTTP + workers",
              "code": "func Run(ctx context.Context, srv *http.Server, runWorkers func(context.Context) error) error {\n  g, gctx := errgroup.WithContext(ctx)\n\n  g.Go(func() error { return srv.ListenAndServe() })\n  g.Go(func() error { return runWorkers(gctx) })\n\n  <-gctx.Done()\n\n  shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n  defer cancel()\n  _ = srv.Shutdown(shutdownCtx)\n\n  return g.Wait()\n}",
              "output": "Coordinates service stop and drains inflight work safely."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 59: Outbox publisher transaction skeleton",
              "code": "func CreateOrderWithOutbox(ctx context.Context, db *sql.DB, order Order) error {\n  tx, err := db.BeginTx(ctx, nil)\n  if err != nil { return err }\n  defer tx.Rollback()\n\n  _, err = tx.ExecContext(ctx, \"INSERT INTO orders(id,total) VALUES($1,$2)\", order.ID, order.Total)\n  if err != nil { return err }\n\n  payload, _ := json.Marshal(order)\n  _, err = tx.ExecContext(ctx, \"INSERT INTO outbox(event_type,payload,status) VALUES($1,$2,'pending')\", \"order.created\", payload)\n  if err != nil { return err }\n\n  return tx.Commit()\n}",
              "output": "Writes domain change and outbox event atomically in one transaction."
            },
            {
              "type": "program",
              "level": "Hard",
              "question": "Program 60: Channel fan-in with context cancellation and error channel",
              "code": "func FanIn(ctx context.Context, inputs ...<-chan int) (<-chan int, <-chan error) {\n  out := make(chan int)\n  errCh := make(chan error, 1)\n  var wg sync.WaitGroup\n\n  forward := func(ch <-chan int) {\n    defer wg.Done()\n    for {\n      select {\n      case <-ctx.Done():\n        return\n      case v, ok := <-ch:\n        if !ok { return }\n        select {\n        case out <- v:\n        case <-ctx.Done(): return\n        }\n      }\n    }\n  }\n\n  wg.Add(len(inputs))\n  for _, ch := range inputs { go forward(ch) }\n\n  go func() {\n    wg.Wait()\n    close(out)\n    close(errCh)\n  }()\n\n  return out, errCh\n}",
              "output": "Merges multiple streams safely with cancellation-aware forwarding."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 61: Circuit breaker with closed/open/half-open transitions",
              "code": "type State int\nconst (\n  Closed State = iota\n  Open\n  HalfOpen\n)\n\ntype Breaker struct {\n  mu            sync.Mutex\n  state         State\n  failures      int\n  threshold     int\n  openUntil     time.Time\n  resetInterval time.Duration\n}\n\nfunc (b *Breaker) Execute(fn func() error) error {\n  b.mu.Lock()\n  now := time.Now()\n\n  if b.state == Open && now.Before(b.openUntil) {\n    b.mu.Unlock()\n    return errors.New(\"circuit open\")\n  }\n\n  if b.state == Open && now.After(b.openUntil) {\n    b.state = HalfOpen\n  }\n  b.mu.Unlock()\n\n  err := fn()\n\n  b.mu.Lock()\n  defer b.mu.Unlock()\n\n  if err == nil {\n    b.failures = 0\n    b.state = Closed\n    return nil\n  }\n\n  b.failures++\n  if b.failures >= b.threshold {\n    b.state = Open\n    b.openUntil = time.Now().Add(b.resetInterval)\n  }\n  return err\n}",
              "output": "Prevents cascading failures by short-circuiting unstable dependencies."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 62: Idempotency middleware with request key store",
              "code": "func Idempotency(next http.Handler, store KeyStore) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    key := r.Header.Get(\"Idempotency-Key\")\n    if key == \"\" {\n      http.Error(w, \"missing idempotency key\", http.StatusBadRequest)\n      return\n    }\n\n    if store.Exists(r.Context(), key) {\n      w.WriteHeader(http.StatusConflict)\n      _, _ = w.Write([]byte(\"duplicate request\"))\n      return\n    }\n\n    if err := store.Mark(r.Context(), key, 5*time.Minute); err != nil {\n      http.Error(w, \"store unavailable\", http.StatusServiceUnavailable)\n      return\n    }\n\n    next.ServeHTTP(w, r)\n  })\n}",
              "output": "Rejects duplicate mutation requests safely within TTL window."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 63: Streaming batch processor with bounded parallelism and partial failures",
              "code": "func ProcessBatches[T any](ctx context.Context, in []T, batchSize int, workers int, fn func(context.Context, T) error) []error {\n  jobs := make(chan T)\n  errs := make(chan error, len(in))\n  var wg sync.WaitGroup\n\n  worker := func() {\n    defer wg.Done()\n    for item := range jobs {\n      if err := fn(ctx, item); err != nil {\n        errs <- err\n      }\n    }\n  }\n\n  for i := 0; i < workers; i++ {\n    wg.Add(1)\n    go worker()\n  }\n\n  for _, item := range in {\n    select {\n    case <-ctx.Done():\n      break\n    case jobs <- item:\n    }\n  }\n\n  close(jobs)\n  wg.Wait()\n  close(errs)\n\n  out := make([]error, 0, len(errs))\n  for e := range errs { out = append(out, e) }\n  return out\n}",
              "output": "Processes large inputs concurrently and returns aggregated error set."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 64: Query service with layered cache + stale fallback + singleflight",
              "code": "type Service struct {\n  cache Cache\n  repo  Repo\n  sf    singleflight.Group\n}\n\nfunc (s *Service) GetUser(ctx context.Context, id int64) (User, error) {\n  key := fmt.Sprintf(\"user:%d\", id)\n  if u, ok := s.cache.GetFresh(ctx, key); ok {\n    return u, nil\n  }\n\n  v, err, _ := s.sf.Do(key, func() (any, error) {\n    u, err := s.repo.GetUser(ctx, id)\n    if err != nil {\n      if stale, ok := s.cache.GetStale(ctx, key); ok {\n        return stale, nil\n      }\n      return User{}, err\n    }\n    _ = s.cache.Set(ctx, key, u, 5*time.Minute)\n    return u, nil\n  })\n\n  if err != nil { return User{}, err }\n  return v.(User), nil\n}",
              "output": "Prevents cache stampedes and supports stale fallback on dependency failures."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 65: Service observability bootstrap (logs, metrics, tracing context hooks)",
              "code": "type Logger interface { Info(msg string, fields ...any); Error(msg string, fields ...any) }\n\ntype Metrics interface {\n  IncCounter(name string, labels map[string]string)\n  ObserveHistogram(name string, value float64, labels map[string]string)\n}\n\nfunc Instrument(next http.Handler, log Logger, m Metrics) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    start := time.Now()\n    next.ServeHTTP(w, r)\n    dur := time.Since(start).Seconds()\n\n    labels := map[string]string{\"path\": r.URL.Path, \"method\": r.Method}\n    m.IncCounter(\"http_requests_total\", labels)\n    m.ObserveHistogram(\"http_request_duration_seconds\", dur, labels)\n    log.Info(\"request_complete\", \"path\", r.URL.Path, \"duration_sec\", dur)\n  })\n}",
              "output": "Adds baseline observability for request count/latency and structured logs."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 66: Circuit breaker with closed/open/half-open transitions",
              "code": "type State int\nconst (\n  Closed State = iota\n  Open\n  HalfOpen\n)\n\ntype Breaker struct {\n  mu            sync.Mutex\n  state         State\n  failures      int\n  threshold     int\n  openUntil     time.Time\n  resetInterval time.Duration\n}\n\nfunc (b *Breaker) Execute(fn func() error) error {\n  b.mu.Lock()\n  now := time.Now()\n\n  if b.state == Open && now.Before(b.openUntil) {\n    b.mu.Unlock()\n    return errors.New(\"circuit open\")\n  }\n\n  if b.state == Open && now.After(b.openUntil) {\n    b.state = HalfOpen\n  }\n  b.mu.Unlock()\n\n  err := fn()\n\n  b.mu.Lock()\n  defer b.mu.Unlock()\n\n  if err == nil {\n    b.failures = 0\n    b.state = Closed\n    return nil\n  }\n\n  b.failures++\n  if b.failures >= b.threshold {\n    b.state = Open\n    b.openUntil = time.Now().Add(b.resetInterval)\n  }\n  return err\n}",
              "output": "Prevents cascading failures by short-circuiting unstable dependencies."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 67: Idempotency middleware with request key store",
              "code": "func Idempotency(next http.Handler, store KeyStore) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    key := r.Header.Get(\"Idempotency-Key\")\n    if key == \"\" {\n      http.Error(w, \"missing idempotency key\", http.StatusBadRequest)\n      return\n    }\n\n    if store.Exists(r.Context(), key) {\n      w.WriteHeader(http.StatusConflict)\n      _, _ = w.Write([]byte(\"duplicate request\"))\n      return\n    }\n\n    if err := store.Mark(r.Context(), key, 5*time.Minute); err != nil {\n      http.Error(w, \"store unavailable\", http.StatusServiceUnavailable)\n      return\n    }\n\n    next.ServeHTTP(w, r)\n  })\n}",
              "output": "Rejects duplicate mutation requests safely within TTL window."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 68: Streaming batch processor with bounded parallelism and partial failures",
              "code": "func ProcessBatches[T any](ctx context.Context, in []T, batchSize int, workers int, fn func(context.Context, T) error) []error {\n  jobs := make(chan T)\n  errs := make(chan error, len(in))\n  var wg sync.WaitGroup\n\n  worker := func() {\n    defer wg.Done()\n    for item := range jobs {\n      if err := fn(ctx, item); err != nil {\n        errs <- err\n      }\n    }\n  }\n\n  for i := 0; i < workers; i++ {\n    wg.Add(1)\n    go worker()\n  }\n\n  for _, item := range in {\n    select {\n    case <-ctx.Done():\n      break\n    case jobs <- item:\n    }\n  }\n\n  close(jobs)\n  wg.Wait()\n  close(errs)\n\n  out := make([]error, 0, len(errs))\n  for e := range errs { out = append(out, e) }\n  return out\n}",
              "output": "Processes large inputs concurrently and returns aggregated error set."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 69: Query service with layered cache + stale fallback + singleflight",
              "code": "type Service struct {\n  cache Cache\n  repo  Repo\n  sf    singleflight.Group\n}\n\nfunc (s *Service) GetUser(ctx context.Context, id int64) (User, error) {\n  key := fmt.Sprintf(\"user:%d\", id)\n  if u, ok := s.cache.GetFresh(ctx, key); ok {\n    return u, nil\n  }\n\n  v, err, _ := s.sf.Do(key, func() (any, error) {\n    u, err := s.repo.GetUser(ctx, id)\n    if err != nil {\n      if stale, ok := s.cache.GetStale(ctx, key); ok {\n        return stale, nil\n      }\n      return User{}, err\n    }\n    _ = s.cache.Set(ctx, key, u, 5*time.Minute)\n    return u, nil\n  })\n\n  if err != nil { return User{}, err }\n  return v.(User), nil\n}",
              "output": "Prevents cache stampedes and supports stale fallback on dependency failures."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 70: Service observability bootstrap (logs, metrics, tracing context hooks)",
              "code": "type Logger interface { Info(msg string, fields ...any); Error(msg string, fields ...any) }\n\ntype Metrics interface {\n  IncCounter(name string, labels map[string]string)\n  ObserveHistogram(name string, value float64, labels map[string]string)\n}\n\nfunc Instrument(next http.Handler, log Logger, m Metrics) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    start := time.Now()\n    next.ServeHTTP(w, r)\n    dur := time.Since(start).Seconds()\n\n    labels := map[string]string{\"path\": r.URL.Path, \"method\": r.Method}\n    m.IncCounter(\"http_requests_total\", labels)\n    m.ObserveHistogram(\"http_request_duration_seconds\", dur, labels)\n    log.Info(\"request_complete\", \"path\", r.URL.Path, \"duration_sec\", dur)\n  })\n}",
              "output": "Adds baseline observability for request count/latency and structured logs."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 71: Circuit breaker with closed/open/half-open transitions",
              "code": "type State int\nconst (\n  Closed State = iota\n  Open\n  HalfOpen\n)\n\ntype Breaker struct {\n  mu            sync.Mutex\n  state         State\n  failures      int\n  threshold     int\n  openUntil     time.Time\n  resetInterval time.Duration\n}\n\nfunc (b *Breaker) Execute(fn func() error) error {\n  b.mu.Lock()\n  now := time.Now()\n\n  if b.state == Open && now.Before(b.openUntil) {\n    b.mu.Unlock()\n    return errors.New(\"circuit open\")\n  }\n\n  if b.state == Open && now.After(b.openUntil) {\n    b.state = HalfOpen\n  }\n  b.mu.Unlock()\n\n  err := fn()\n\n  b.mu.Lock()\n  defer b.mu.Unlock()\n\n  if err == nil {\n    b.failures = 0\n    b.state = Closed\n    return nil\n  }\n\n  b.failures++\n  if b.failures >= b.threshold {\n    b.state = Open\n    b.openUntil = time.Now().Add(b.resetInterval)\n  }\n  return err\n}",
              "output": "Prevents cascading failures by short-circuiting unstable dependencies."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 72: Idempotency middleware with request key store",
              "code": "func Idempotency(next http.Handler, store KeyStore) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    key := r.Header.Get(\"Idempotency-Key\")\n    if key == \"\" {\n      http.Error(w, \"missing idempotency key\", http.StatusBadRequest)\n      return\n    }\n\n    if store.Exists(r.Context(), key) {\n      w.WriteHeader(http.StatusConflict)\n      _, _ = w.Write([]byte(\"duplicate request\"))\n      return\n    }\n\n    if err := store.Mark(r.Context(), key, 5*time.Minute); err != nil {\n      http.Error(w, \"store unavailable\", http.StatusServiceUnavailable)\n      return\n    }\n\n    next.ServeHTTP(w, r)\n  })\n}",
              "output": "Rejects duplicate mutation requests safely within TTL window."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 73: Streaming batch processor with bounded parallelism and partial failures",
              "code": "func ProcessBatches[T any](ctx context.Context, in []T, batchSize int, workers int, fn func(context.Context, T) error) []error {\n  jobs := make(chan T)\n  errs := make(chan error, len(in))\n  var wg sync.WaitGroup\n\n  worker := func() {\n    defer wg.Done()\n    for item := range jobs {\n      if err := fn(ctx, item); err != nil {\n        errs <- err\n      }\n    }\n  }\n\n  for i := 0; i < workers; i++ {\n    wg.Add(1)\n    go worker()\n  }\n\n  for _, item := range in {\n    select {\n    case <-ctx.Done():\n      break\n    case jobs <- item:\n    }\n  }\n\n  close(jobs)\n  wg.Wait()\n  close(errs)\n\n  out := make([]error, 0, len(errs))\n  for e := range errs { out = append(out, e) }\n  return out\n}",
              "output": "Processes large inputs concurrently and returns aggregated error set."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 74: Query service with layered cache + stale fallback + singleflight",
              "code": "type Service struct {\n  cache Cache\n  repo  Repo\n  sf    singleflight.Group\n}\n\nfunc (s *Service) GetUser(ctx context.Context, id int64) (User, error) {\n  key := fmt.Sprintf(\"user:%d\", id)\n  if u, ok := s.cache.GetFresh(ctx, key); ok {\n    return u, nil\n  }\n\n  v, err, _ := s.sf.Do(key, func() (any, error) {\n    u, err := s.repo.GetUser(ctx, id)\n    if err != nil {\n      if stale, ok := s.cache.GetStale(ctx, key); ok {\n        return stale, nil\n      }\n      return User{}, err\n    }\n    _ = s.cache.Set(ctx, key, u, 5*time.Minute)\n    return u, nil\n  })\n\n  if err != nil { return User{}, err }\n  return v.(User), nil\n}",
              "output": "Prevents cache stampedes and supports stale fallback on dependency failures."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 75: Service observability bootstrap (logs, metrics, tracing context hooks)",
              "code": "type Logger interface { Info(msg string, fields ...any); Error(msg string, fields ...any) }\n\ntype Metrics interface {\n  IncCounter(name string, labels map[string]string)\n  ObserveHistogram(name string, value float64, labels map[string]string)\n}\n\nfunc Instrument(next http.Handler, log Logger, m Metrics) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    start := time.Now()\n    next.ServeHTTP(w, r)\n    dur := time.Since(start).Seconds()\n\n    labels := map[string]string{\"path\": r.URL.Path, \"method\": r.Method}\n    m.IncCounter(\"http_requests_total\", labels)\n    m.ObserveHistogram(\"http_request_duration_seconds\", dur, labels)\n    log.Info(\"request_complete\", \"path\", r.URL.Path, \"duration_sec\", dur)\n  })\n}",
              "output": "Adds baseline observability for request count/latency and structured logs."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 76: Circuit breaker with closed/open/half-open transitions",
              "code": "type State int\nconst (\n  Closed State = iota\n  Open\n  HalfOpen\n)\n\ntype Breaker struct {\n  mu            sync.Mutex\n  state         State\n  failures      int\n  threshold     int\n  openUntil     time.Time\n  resetInterval time.Duration\n}\n\nfunc (b *Breaker) Execute(fn func() error) error {\n  b.mu.Lock()\n  now := time.Now()\n\n  if b.state == Open && now.Before(b.openUntil) {\n    b.mu.Unlock()\n    return errors.New(\"circuit open\")\n  }\n\n  if b.state == Open && now.After(b.openUntil) {\n    b.state = HalfOpen\n  }\n  b.mu.Unlock()\n\n  err := fn()\n\n  b.mu.Lock()\n  defer b.mu.Unlock()\n\n  if err == nil {\n    b.failures = 0\n    b.state = Closed\n    return nil\n  }\n\n  b.failures++\n  if b.failures >= b.threshold {\n    b.state = Open\n    b.openUntil = time.Now().Add(b.resetInterval)\n  }\n  return err\n}",
              "output": "Prevents cascading failures by short-circuiting unstable dependencies."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 77: Idempotency middleware with request key store",
              "code": "func Idempotency(next http.Handler, store KeyStore) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    key := r.Header.Get(\"Idempotency-Key\")\n    if key == \"\" {\n      http.Error(w, \"missing idempotency key\", http.StatusBadRequest)\n      return\n    }\n\n    if store.Exists(r.Context(), key) {\n      w.WriteHeader(http.StatusConflict)\n      _, _ = w.Write([]byte(\"duplicate request\"))\n      return\n    }\n\n    if err := store.Mark(r.Context(), key, 5*time.Minute); err != nil {\n      http.Error(w, \"store unavailable\", http.StatusServiceUnavailable)\n      return\n    }\n\n    next.ServeHTTP(w, r)\n  })\n}",
              "output": "Rejects duplicate mutation requests safely within TTL window."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 78: Streaming batch processor with bounded parallelism and partial failures",
              "code": "func ProcessBatches[T any](ctx context.Context, in []T, batchSize int, workers int, fn func(context.Context, T) error) []error {\n  jobs := make(chan T)\n  errs := make(chan error, len(in))\n  var wg sync.WaitGroup\n\n  worker := func() {\n    defer wg.Done()\n    for item := range jobs {\n      if err := fn(ctx, item); err != nil {\n        errs <- err\n      }\n    }\n  }\n\n  for i := 0; i < workers; i++ {\n    wg.Add(1)\n    go worker()\n  }\n\n  for _, item := range in {\n    select {\n    case <-ctx.Done():\n      break\n    case jobs <- item:\n    }\n  }\n\n  close(jobs)\n  wg.Wait()\n  close(errs)\n\n  out := make([]error, 0, len(errs))\n  for e := range errs { out = append(out, e) }\n  return out\n}",
              "output": "Processes large inputs concurrently and returns aggregated error set."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 79: Query service with layered cache + stale fallback + singleflight",
              "code": "type Service struct {\n  cache Cache\n  repo  Repo\n  sf    singleflight.Group\n}\n\nfunc (s *Service) GetUser(ctx context.Context, id int64) (User, error) {\n  key := fmt.Sprintf(\"user:%d\", id)\n  if u, ok := s.cache.GetFresh(ctx, key); ok {\n    return u, nil\n  }\n\n  v, err, _ := s.sf.Do(key, func() (any, error) {\n    u, err := s.repo.GetUser(ctx, id)\n    if err != nil {\n      if stale, ok := s.cache.GetStale(ctx, key); ok {\n        return stale, nil\n      }\n      return User{}, err\n    }\n    _ = s.cache.Set(ctx, key, u, 5*time.Minute)\n    return u, nil\n  })\n\n  if err != nil { return User{}, err }\n  return v.(User), nil\n}",
              "output": "Prevents cache stampedes and supports stale fallback on dependency failures."
            },
            {
              "type": "program",
              "level": "Very Hard",
              "question": "Program 80: Service observability bootstrap (logs, metrics, tracing context hooks)",
              "code": "type Logger interface { Info(msg string, fields ...any); Error(msg string, fields ...any) }\n\ntype Metrics interface {\n  IncCounter(name string, labels map[string]string)\n  ObserveHistogram(name string, value float64, labels map[string]string)\n}\n\nfunc Instrument(next http.Handler, log Logger, m Metrics) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    start := time.Now()\n    next.ServeHTTP(w, r)\n    dur := time.Since(start).Seconds()\n\n    labels := map[string]string{\"path\": r.URL.Path, \"method\": r.Method}\n    m.IncCounter(\"http_requests_total\", labels)\n    m.ObserveHistogram(\"http_request_duration_seconds\", dur, labels)\n    log.Info(\"request_complete\", \"path\", r.URL.Path, \"duration_sec\", dur)\n  })\n}",
              "output": "Adds baseline observability for request count/latency and structured logs."
            }
          ]
        },
        {
          "id": "syntax",
          "title": "Basic Syntax & Types",
          "description": "Go's fundamental syntax, variable declarations, and basic types.",
          "code": "package main\n\nimport \"fmt\"\n\nfunc main() {\n    // Variable declarations\n    var name string = \"John\"\n    age := 30 // Short declaration\n    \n    // Basic types\n    var i int = 42\n    var f float64 = 3.14\n    var b bool = true\n    var s string = \"Hello\"\n    \n    // Constants\n    const Pi = 3.14159\n    \n    // Multiple declarations\n    var x, y int = 1, 2\n    a, b := \"hello\", true\n    \n    fmt.Println(name, age, i, f, b, s)\n}",
          "example": "// Type conversion\nvar i int = 42\nvar f float64 = float64(i)\nvar u uint = uint(f)\n\n// Zero values\nvar i int      // 0\nvar f float64  // 0.0\nvar b bool     // false\nvar s string   // \"\"\n\n// Strings\nstr :=\n\n \"Hello, World\"\nmultiline := `Line 1\nLine 2\nLine 3`",
          "useCase": "Basic Go programs, declaring variables, working with types",
          "explanation": "This topic is the foundation for every Go interview round. Focus on declaration styles (`var` vs `:=`), default zero values, explicit type conversion (Go avoids implicit numeric coercion), and constants with `iota`. Interviewers often test whether you understand compile-time type safety and practical implications of zero values in real services.",
          "interviewQuestions": [
            {
              "question": "What is the difference between `var` and `:=` in Go?",
              "answer": "`:=` is short declaration with type inference and can be used only inside functions. `var` works at both package and function scope and optionally allows explicit type."
            },
            {
              "question": "Why does Go avoid implicit type conversions?",
              "answer": "It reduces hidden bugs and forces explicit intent, especially for numeric conversions where precision or sign may change."
            },
            {
              "question": "What are zero values and why are they useful?",
              "answer": "Every declared variable gets a deterministic default (`0`, `false`, `\"\"`, `nil`). This reduces uninitialized-memory bugs and simplifies defensive coding."
            },
            {
              "question": "When would you prefer explicit type declarations over inference?",
              "answer": "When API clarity matters, when literal defaults are ambiguous, or when you want to make contracts obvious for teammates and reviewers."
            },
            {
              "question": "How do constants differ from variables in Go?",
              "answer": "Constants are immutable and can be untyped, enabling flexible compile-time expressions. Variables are runtime values with concrete types."
            }
          ],
          "exercises": [
            {
              "type": "theory",
              "question": "Explain zero value behavior for int, string, bool, slice, map, and pointer."
            },
            {
              "type": "tricky",
              "question": "Why does `var x int = 3.14` fail while `var y float64 = 3.14` works?",
              "answer": "Go does not allow implicit narrowing/precision-loss conversion."
            },
            {
              "type": "implement",
              "question": "Write declarations for the same value using `var` and `:=`, then compare inferred types."
            },
            {
              "type": "output",
              "question": "What prints: `var s string; fmt.Println(len(s), s == \"\")`?",
              "answer": "0 true"
            },
            {
              "type": "debug",
              "question": "Fix a snippet where `:=` is mistakenly used at package scope."
            },
            {
              "type": "scenario",
              "question": "Choose between typed and untyped constants for a reusable math utility package."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Print zero values for key Go types.",
              "code": "var i int\nvar f float64\nvar b bool\nvar s string\nvar sl []int\nfmt.Printf(\"%d %.1f %t %q %v\\n\", i, f, b, s, sl == nil)",
              "output": "0 0.0 false \"\" true"
            },
            {
              "question": "Program 2: Compare `var` and `:=` declarations.",
              "code": "var a int = 10\nb := 10\nfmt.Printf(\"%T %T\\n\", a, b)",
              "output": "int int"
            },
            {
              "question": "Program 3: Explicit conversion demo.",
              "code": "var i int = 42\nvar f float64 = float64(i)\nfmt.Printf(\"%T %.1f\\n\", f, f)",
              "output": "float64 42.0"
            },
            {
              "question": "Program 4: Untyped constant behavior.",
              "code": "const n = 5\nvar x int64 = n\nfmt.Printf(\"%T %d\\n\", x, x)",
              "output": "int64 5"
            },
            {
              "question": "Program 5: Multi-variable declaration and swap.",
              "code": "x, y := 1, 2\nx, y = y, x\nfmt.Println(x, y)",
              "output": "2 1"
            }
          ],
          "category": "Go Basics"
        },
        {
          "id": "functions",
          "title": "Functions",
          "description": "Function declarations, multiple return values, and variadic functions.",
          "code": "package main\n\nimport \"fmt\"\n\n// Basic function\nfunc add(x int, y int) int {\n    return x + y\n}\n\n// Shortened parameter syntax\nfunc multiply(x, y int) int {\n    return x * y\n}\n\n// Multiple return values\nfunc swap(x, y string) (string, string) {\n    return y, x\n}\n\n// Named return values\nfunc split(sum int) (x, y int) {\n    x = sum * 4 / 9\n    y = sum - x\n    return // Naked return\n}\n\n// Variadic function\nfunc sum(nums ...int) int {\n    total := 0\n    for _, num := range nums {\n        total += num\n    }\n    return total\n}\n\nfunc main() {\n    fmt.Println(add(42, 13))\n    a, b := swap(\"hello\", \"world\")\n    fmt.Println(a, b)\n    fmt.Println(sum(1, 2, 3, 4, 5))\n}",
          "example": "// Function as value\nfunc compute(fn func(int, int) int) int {\n    return fn(3, 4)\n}\n\nfunc main() {\n    add := func(a, b int) int {\n        return a + b\n    }\n    fmt.Println(compute(add))\n}\n\n// Closures\nfunc counter() func() int {\n    i := 0\n    return func() int {\n        i++\n        return i\n    }\n}",
          "useCase": "Business logic, utilities, error handling, closures",
          "explanation": "Functions are central in Go interviews because they connect readability, testability, and error handling style. Be strong in multiple returns (`value, err`), variadic signatures, closures, and named return values (and when to avoid naked returns in production for clarity).",
          "interviewQuestions": [
            {
              "question": "Why does Go prefer multiple return values over exceptions?",
              "answer": "It makes error flow explicit and local, so call sites must consciously handle success/failure."
            },
            {
              "question": "When are variadic functions useful?",
              "answer": "For APIs that accept flexible argument counts, such as logging helpers, aggregators, and builders."
            },
            {
              "question": "When should named return values be avoided?",
              "answer": "In long functions where naked returns reduce readability and make control flow harder to follow."
            },
            {
              "question": "How do closures help in interviews and production?",
              "answer": "They capture lexical state, useful for counters, middleware, decorators, and dependency injection patterns."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Write a function returning `(User, error)` and handle error in caller idiomatically."
            },
            {
              "type": "tricky",
              "question": "Why can `sum(nums []int)` and `sum(nums ...int)` have different call ergonomics?",
              "answer": "Variadic function accepts unpacked arguments and slice expansion with `...`."
            },
            {
              "type": "output",
              "question": "Output of closure counter called 3 times?",
              "answer": "1 2 3"
            },
            {
              "type": "debug",
              "question": "Fix a bug where a function ignores returned `err` value."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Value and error return pattern.",
              "code": "func divide(a, b int) (int, error) {\n  if b == 0 { return 0, fmt.Errorf(\"divide by zero\") }\n  return a / b, nil\n}\nv, err := divide(10, 2)\nfmt.Println(v, err == nil)",
              "output": "5 true"
            },
            {
              "question": "Program 2: Variadic sum with slice expansion.",
              "code": "func sum(nums ...int) int { t := 0; for _, n := range nums { t += n }; return t }\narr := []int{1,2,3}\nfmt.Println(sum(arr...))",
              "output": "6"
            },
            {
              "question": "Program 3: Closure counter.",
              "code": "func counter() func() int {\n  i := 0\n  return func() int { i++; return i }\n}\nc := counter()\nfmt.Println(c(), c(), c())",
              "output": "1 2 3"
            }
          ],
          "category": "Go Basics"
        },
        {
          "id": "structs",
          "title": "Structs & Methods",
          "description": "Define custom types with structs and attach methods to them.",
          "code": "package main\n\nimport \"fmt\"\n\n// Define struct\ntype Person struct {\n    Name string\n    Age  int\n}\n\n// Method on struct\nfunc (p Person) Greet() string {\n    return \"Hello, \" + p.Name\n}\n\n// Pointer receiver (can modify)\nfunc (p *Person) HaveBirthday() {\n    p.Age++\n}\n\n// Constructor function\nfunc NewPerson(name string, age int) *Person {\n    return &Person{\n        Name: name,\n        Age:  age,\n    }\n}\n\nfunc main() {\n    p := Person{Name: \"Alice\", Age: 30}\n    fmt.Println(p.Greet())\n    \n    p.HaveBirthday()\n    fmt.Println(p.Age) // 31\n    \n    p2 := NewPerson(\"Bob\", 25)\n    fmt.Println(p2)\n}",
          "example": "// Embedded structs\ntype Address struct {\n    City  string\n    State string\n}\n\ntype Employee struct {\n    Person  // Embedded\n    Address // Embedded\n    Salary  int\n}\n\nemp := Employee{\n    Person:  Person{Name: \"John\", Age: 30},\n    Address: Address{City: \"NYC\", State: \"NY\"},\n    Salary:  100000,\n}\n\n// Access embedded fields\nfmt.Println(emp.Name) // From Person\nfmt.Println(emp.City) // From Address",
          "useCase": "Data modeling, OOP-like patterns, API responses, database models",
          "explanation": "Structs model domain data, while methods provide behavior. Interviews typically test pointer vs value receivers, embedding for composition, and when constructor helpers improve invariants.",
          "interviewQuestions": [
            {
              "question": "When do you use pointer receiver vs value receiver?",
              "answer": "Use pointer receiver when mutating state or avoiding copies on large structs; value receiver for immutable small-value semantics."
            },
            {
              "question": "Is embedding inheritance in Go?",
              "answer": "No, it is composition. Promoted fields/methods provide reuse without classical inheritance hierarchy."
            },
            {
              "question": "Why create constructor-like functions in Go?",
              "answer": "To validate input and ensure required fields/invariants before exposing values to callers."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Create a `BankAccount` struct with deposit/withdraw methods and balance validation."
            },
            {
              "type": "theory",
              "question": "Explain method set differences for type `T` and `*T`."
            },
            {
              "type": "tricky",
              "question": "Why might calling a pointer-receiver method on a value still compile?",
              "answer": "Go may take the address automatically when value is addressable."
            },
            {
              "type": "debug",
              "question": "Fix a bug where a value receiver method tries to mutate struct state but change is lost."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Value vs pointer receiver behavior.",
              "code": "type C struct{ N int }\nfunc (c C) IncV() { c.N++ }\nfunc (c *C) IncP() { c.N++ }\nx := C{N:1}\nx.IncV(); fmt.Println(x.N)\nx.IncP(); fmt.Println(x.N)",
              "output": "1 then 2"
            },
            {
              "question": "Program 2: Embedded struct field promotion.",
              "code": "type A struct{ Name string }\ntype B struct{ A; Role string }\nb := B{A: A{Name:\"go\"}, Role:\"dev\"}\nfmt.Println(b.Name, b.Role)",
              "output": "go dev"
            }
          ],
          "category": "Go Basics"
        },
        {
          "id": "interfaces",
          "title": "Interfaces",
          "description": "Implicit interfaces that define behavior without explicit implementation.",
          "code": "package main\n\nimport (\n    \"fmt\"\n    \"math\"\n)\n\n// Define interface\ntype Shape interface {\n    Area() float64\n    Perimeter() float64\n}\n\n// Rectangle implements Shape\ntype Rectangle struct {\n    Width, Height float64\n}\n\nfunc (r Rectangle) Area() float64 {\n    return r.Width * r.Height\n}\n\nfunc (r Rectangle) Perimeter() float64 {\n    return 2 * (r.Width + r.Height)\n}\n\n// Circle implements Shape\ntype Circle struct {\n    Radius float64\n}\n\nfunc (c Circle) Area() float64 {\n    return math.Pi * c.Radius * c.Radius\n}\n\nfunc (c Circle) Perimeter() float64 {\n    return 2 * math.Pi * c.Radius\n}\n\nfunc printShapeInfo(s Shape) {\n    fmt.Printf(\"Area: %.2f\\n\", s.Area())\n    fmt.Printf(\"Perimeter: %.2f\\n\", s.Perimeter())\n}\n\nfunc main() {\n    r := Rectangle{Width: 10, Height: 5}\n    c := Circle{Radius: 7}\n    \n    printShapeInfo(r)\n    printShapeInfo(c)\n}",
          "example": "// Empty interface (any type)\nfunc printAnything(v interface{}) {\n    fmt.Println(v)\n}\n\n// Type assertion\nvar i interface{} = \"hello\"\ns := i.(string)\ns, ok := i.(string) // Safe type assertion\n\n// Type switch\nfunc describe(i interface{}) {\n    switch v := i.(type) {\n    case int:\n        fmt.Printf(\"Integer: %d\\n\", v)\n    case string:\n        fmt.Printf(\"String: %s\\n\", v)\n    default:\n        fmt.Printf(\"Unknown type\\n\")\n    }\n}",
          "useCase": "Polymorphism, dependency injection, mocking, plugin systems",
          "explanation": "Interfaces in Go are implicit contracts: a type satisfies an interface by implementing required methods. Interviewers often ask about small-interface design, nil-interface pitfalls, and type assertions/switches.",
          "interviewQuestions": [
            {
              "question": "Why are small interfaces preferred in Go?",
              "answer": "Small, focused interfaces are easier to implement, mock, and evolve without breaking many consumers."
            },
            {
              "question": "What is the `nil interface` pitfall?",
              "answer": "An interface can hold a typed nil pointer and still be non-nil because it stores type + value metadata."
            },
            {
              "question": "When should type assertions be used carefully?",
              "answer": "Use two-value assertion (`v, ok := i.(T)`) when dynamic types may vary to avoid panic."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Design a `Notifier` interface and provide email/sms implementations."
            },
            {
              "type": "scenario",
              "question": "Refactor a concrete repository dependency into interface-driven design for testing."
            },
            {
              "type": "tricky",
              "question": "Explain why `var r io.Reader = (*bytes.Buffer)(nil); r != nil`.",
              "answer": "Interface has dynamic type set, so interface value itself is non-nil."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Interface satisfaction example.",
              "code": "type Speaker interface{ Speak() string }\ntype Dog struct{}\nfunc (Dog) Speak() string { return \"woof\" }\nvar s Speaker = Dog{}\nfmt.Println(s.Speak())",
              "output": "woof"
            },
            {
              "question": "Program 2: Type switch handling.",
              "code": "func kind(v any) string {\n  switch v.(type) {\n  case int: return \"int\"\n  case string: return \"string\"\n  default: return \"other\"\n  }\n}\nfmt.Println(kind(10), kind(\"go\"))",
              "output": "int string"
            }
          ],
          "category": "Go Basics"
        },
        {
          "id": "goroutines",
          "title": "Goroutines",
          "description": "Lightweight threads managed by Go runtime. Use 'go' keyword to start concurrent execution.",
          "code": "package main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc say(s string) {\n    for i := 0; i < 5; i++ {\n        time.Sleep(100 * time.Millisecond)\n        fmt.Println(s)\n    }\n}\n\nfunc main() {\n    // Start goroutine\n    go say(\"world\")\n    \n    // Main goroutine\n    say(\"hello\")\n    \n    // Wait for goroutines\n    time.Sleep(time.Second)\n}\n\n// Anonymous goroutine\nfunc main() {\n    go func() {\n        fmt.Println(\"Running in goroutine\")\n    }()\n    \n    time.Sleep(100 * time.Millisecond)\n}",
          "example": "// Multiple goroutines\nfor i := 0; i < 5; i++ {\n    go func(n int) {\n        fmt.Println(\"Goroutine\", n)\n    }(i)\n}\n\n// Wait with sync.WaitGroup\nvar wg sync.WaitGroup\n\nfor i := 0; i < 5; i++ {\n    wg.Add(1)\n    go func(n int) {\n        defer wg.Done()\n        fmt.Println(\"Task\", n)\n    }(i)\n}\n\nwg.Wait()",
          "useCase": "Concurrent tasks, parallel processing, background jobs, async operations",
          "explanation": "Goroutines are lightweight units scheduled by Go runtime, not one-to-one OS threads. Interview depth includes lifecycle management, avoiding goroutine leaks, and synchronization with WaitGroup/context instead of arbitrary sleeps.",
          "interviewQuestions": [
            {
              "question": "Why is `time.Sleep` a weak synchronization strategy?",
              "answer": "It relies on timing assumptions and can be flaky; WaitGroup/channels/context provide deterministic coordination."
            },
            {
              "question": "What is a goroutine leak?",
              "answer": "A goroutine blocked forever due to missing cancellation or channel closure, causing resource growth over time."
            },
            {
              "question": "How do you safely wait for multiple goroutines?",
              "answer": "Use `sync.WaitGroup` and ensure each worker calls `Done()` via `defer`."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Run 5 workers concurrently and wait deterministically for completion."
            },
            {
              "type": "debug",
              "question": "Fix code where loop variable capture causes all goroutines to print same value."
            },
            {
              "type": "scenario",
              "question": "Add cancellation to background goroutine processing HTTP requests."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: WaitGroup synchronization.",
              "code": "var wg sync.WaitGroup\nfor i := 0; i < 3; i++ {\n  wg.Add(1)\n  go func(n int) { defer wg.Done(); fmt.Println(\"job\", n) }(i)\n}\nwg.Wait()\nfmt.Println(\"done\")",
              "output": "prints jobs then done"
            },
            {
              "question": "Program 2: Loop capture fix.",
              "code": "for i := 0; i < 3; i++ {\n  go func(v int) { fmt.Println(v) }(i)\n}",
              "output": "prints 0,1,2 (order not guaranteed)"
            }
          ],
          "category": "Concurrency"
        },
        {
          "id": "channels",
          "title": "Channels",
          "description": "Typed conduits for communication between goroutines. Send and receive values safely.",
          "code": "package main\n\nimport \"fmt\"\n\nfunc sum(nums []int, c chan int) {\n    total := 0\n    for _, num := range nums {\n        total += num\n    }\n    c <- total // Send to channel\n}\n\nfunc main() {\n    nums := []int{1, 2, 3, 4, 5, 6}\n    \n    c := make(chan int)\n    \n    go sum(nums[:len(nums)/2], c)\n    go sum(nums[len(nums)/2:], c)\n    \n    x, y := <-c, <-c // Receive from channel\n    \n    fmt.Println(\"Total:\", x+y)\n}",
          "example": "// Buffered channels\nch := make(chan int, 2)\nch <- 1\nch <- 2\n// ch <- 3 // Would block\n\n// Closing channels\nclose(ch)\n\n// Range over channel\nfor val := range ch {\n    fmt.Println(val)\n}\n\n// Select statement\nselect {\ncase msg1 := <-ch1:\n    fmt.Println(\"Received from ch1:\", msg1)\ncase msg2 := <-ch2:\n    fmt.Println(\"Received from ch2:\", msg2)\ncase <-time.After(time.Second):\n    fmt.Println(\"Timeout\")\ndefault:\n    fmt.Println(\"No data\")\n}",
          "useCase": "Goroutine communication, synchronization, worker pools, pipelines",
          "explanation": "Channels coordinate goroutines through message passing. Interviewers evaluate blocking semantics, buffered vs unbuffered trade-offs, closure behavior, and safe ownership rules for closing channels.",
          "interviewQuestions": [
            {
              "question": "Who should close a channel?",
              "answer": "Typically the sender/producer that knows no more values will be sent."
            },
            {
              "question": "What happens when receiving from a closed channel?",
              "answer": "Receive succeeds with zero value; in two-value receive, `ok` is false."
            },
            {
              "question": "When are buffered channels useful?",
              "answer": "To absorb short bursts and decouple producer/consumer speeds, but not as a substitute for design."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Build worker pool with job and result channels."
            },
            {
              "type": "output",
              "question": "What are values of `v, ok := <-closedCh`?",
              "answer": "zero value of element type, false"
            },
            {
              "type": "debug",
              "question": "Fix panic caused by sending on a closed channel."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Buffered channel basic flow.",
              "code": "ch := make(chan int, 2)\nch <- 10\nch <- 20\nfmt.Println(<-ch, <-ch)",
              "output": "10 20"
            },
            {
              "question": "Program 2: Close and range.",
              "code": "ch := make(chan int, 2)\nch <- 1; ch <- 2; close(ch)\nfor v := range ch { fmt.Println(v) }",
              "output": "1 then 2"
            }
          ],
          "category": "Concurrency"
        },
        {
          "id": "select",
          "title": "Select Statement",
          "description": "Multiplexing goroutine communications. Wait on multiple channel operations.",
          "code": "package main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc main() {\n    c1 := make(chan string)\n    c2 := make(chan string)\n    \n    go func() {\n        time.Sleep(1 * time.Second)\n        c1 <- \"one\"\n    }()\n    \n    go func() {\n        time.Sleep(2 * time.Second)\n        c2 <- \"two\"\n    }()\n    \n    for i := 0; i < 2; i++ {\n        select {\n        case msg1 := <-c1:\n            fmt.Println(\"Received\", msg1)\n        case msg2 := <-c2:\n            fmt.Println(\"Received\", msg2)\n        }\n    }\n}",
          "example": "// Timeout pattern\nselect {\ncase res := <-ch:\n    fmt.Println(res)\ncase <-time.After(1 * time.Second):\n    fmt.Println(\"Timeout\")\n}\n\n// Non-blocking receive\nselect {\ncase msg := <-ch:\n    fmt.Println(\"Received:\", msg)\ndefault:\n    fmt.Println(\"No message\")\n}\n\n// Non-blocking send\nselect {\ncase ch <- value:\n    fmt.Println(\"Sent\")\ndefault:\n    fmt.Println(\"Channel full\")\n}",
          "useCase": "Timeouts, non-blocking operations, multiplexing channels, cancellation",
          "explanation": "Select lets one goroutine wait on multiple channel operations and proceed with whichever is ready. In interviews, show timeout patterns, default branch implications, and cancellation-aware flow.",
          "interviewQuestions": [
            {
              "question": "What does `default` do in select?",
              "answer": "Makes select non-blocking by executing immediately when no channel case is ready."
            },
            {
              "question": "How do you model timeouts in select?",
              "answer": "Use `case <-time.After(d):` or a context Done channel to enforce deadline behavior."
            },
            {
              "question": "Is case selection deterministic when multiple are ready?",
              "answer": "No, Go pseudo-randomly chooses one ready case."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Read from two channels and timeout after 500ms."
            },
            {
              "type": "scenario",
              "question": "Design a fan-in aggregator using select."
            },
            {
              "type": "tricky",
              "question": "What bug can an always-on default case introduce?",
              "answer": "Busy loop/high CPU usage due to no blocking."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Select timeout.",
              "code": "ch := make(chan string)\nselect {\ncase m := <-ch:\n  fmt.Println(m)\ncase <-time.After(50 * time.Millisecond):\n  fmt.Println(\"timeout\")\n}",
              "output": "timeout"
            },
            {
              "question": "Program 2: Non-blocking receive with default.",
              "code": "ch := make(chan int)\nselect {\ncase v := <-ch:\n  fmt.Println(v)\ndefault:\n  fmt.Println(\"no value\")\n}",
              "output": "no value"
            }
          ],
          "category": "Concurrency"
        },
        {
          "id": "sync",
          "title": "Sync Package (Mutex, WaitGroup)",
          "description": "Synchronization primitives for coordinating goroutines.",
          "code": "package main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\ntype SafeCounter struct {\n    mu sync.Mutex\n    v  map[string]int\n}\n\nfunc (c *SafeCounter) Inc(key string) {\n    c.mu.Lock()\n    c.v[key]++\n    c.mu.Unlock()\n}\n\nfunc (c *SafeCounter) Value(key string) int {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    return c.v[key]\n}\n\nfunc main() {\n    c := SafeCounter{v: make(map[string]int)}\n    var wg sync.WaitGroup\n    \n    for i := 0; i < 1000; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            c.Inc(\"key\")\n        }()\n    }\n    \n    wg.Wait()\n    fmt.Println(c.Value(\"key\"))\n}",
          "example": "// RWMutex (reader/writer lock)\nvar rwMu sync.RWMutex\n\n// Read lock (multiple readers allowed)\nrwMu.RLock()\nvalue := data[key]\nrwMu.RUnlock()\n\n// Write lock (exclusive)\nrwMu.Lock()\ndata[key] = newValue\nrwMu.Unlock()\n\n// Once (execute only once)\nvar once sync.Once\nonce.Do(func() {\n    fmt.Println(\"This runs only once\")\n})",
          "useCase": "Protecting shared data, preventing race conditions, one-time initialization",
          "explanation": "Synchronization primitives coordinate shared-memory concurrency. Interviews test mutex correctness, lock granularity, RWMutex trade-offs, WaitGroup lifecycle, and `go test -race` usage.",
          "interviewQuestions": [
            {
              "question": "When is `RWMutex` better than `Mutex`?",
              "answer": "Read-heavy workloads with infrequent writes, though contention patterns must be measured."
            },
            {
              "question": "Why use `defer mu.Unlock()` often?",
              "answer": "It guarantees unlock on all return paths, reducing deadlock risk from missed unlocks."
            },
            {
              "question": "How do you detect data races in Go?",
              "answer": "Run with race detector: `go test -race` or `go run -race`."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Write thread-safe in-memory counter with Mutex and unit test using -race."
            },
            {
              "type": "debug",
              "question": "Fix deadlock due to double lock in nested call path."
            },
            {
              "type": "scenario",
              "question": "Choose atomic increment vs mutex for shared request counter and justify."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Mutex-guarded counter.",
              "code": "type Counter struct { mu sync.Mutex; n int }\nfunc (c *Counter) Inc() { c.mu.Lock(); c.n++; c.mu.Unlock() }\nfunc (c *Counter) Value() int { c.mu.Lock(); defer c.mu.Unlock(); return c.n }",
              "output": "thread-safe methods defined"
            },
            {
              "question": "Program 2: sync.Once initialization.",
              "code": "var once sync.Once\ncount := 0\nfor i := 0; i < 3; i++ { once.Do(func(){ count++ }) }\nfmt.Println(count)",
              "output": "1"
            }
          ],
          "category": "Concurrency"
        },
        {
          "id": "arrays-slices",
          "title": "Arrays & Slices",
          "description": "Fixed-size arrays and dynamic slices. Slices are more commonly used.",
          "code": "package main\n\nimport \"fmt\"\n\nfunc main() {\n    // Array (fixed size)\n    var arr [5]int\n    arr[0] = 1\n    arr[1] = 2\n    \n    // Array literal\n    primes := [6]int{2, 3, 5, 7, 11, 13}\n    \n    // Slice (dynamic)\n    var s []int\n    s = append(s, 1, 2, 3)\n    \n    // Make slice with capacity\n    nums := make([]int, 5)    // len=5, cap=5\n    nums2 := make([]int, 0, 5) // len=0, cap=5\n    \n    // Slice literal\n    foods := []string{\"pizza\", \"burger\", \"pasta\"}\n    \n    // Slicing\n    subSlice := primes[1:4] // [3 5 7]\n    \n    fmt.Println(arr, primes, s, nums, foods, subSlice)\n}",
          "example": "// Append to slice\nnums := []int{1, 2}\nnums = append(nums, 3, 4, 5)\nnums = append(nums, []int{6, 7, 8}...)\n\n// Copy slice\nsrc := []int{1, 2, 3}\ndst := make([]int, len(src))\ncopy(dst, src)\n\n// Iterate\nfor i, v := range nums {\n    fmt.Printf(\"Index: %d, Value: %d\\n\", i, v)\n}\n\n// Length and capacity\nlen(nums) // Number of elements\ncap(nums) // Capacity",
          "useCase": "Collections, lists, dynamic arrays, data processing",
          "explanation": "Arrays are fixed-length values; slices are lightweight descriptors over arrays (pointer, length, capacity). Interviewers often probe append reallocation effects, shared backing array side effects, and copy-based isolation.",
          "interviewQuestions": [
            {
              "question": "Why are slices preferred over arrays in Go APIs?",
              "answer": "Slices are flexible and ergonomic for variable-size data; arrays include length in type and are less convenient to pass around."
            },
            {
              "question": "What does capacity represent for slices?",
              "answer": "Maximum length before reallocation from current starting point in backing array."
            },
            {
              "question": "Why can modifying one slice affect another?",
              "answer": "Different slices may share the same backing array, so writes can be visible across views."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Find len/cap for `s := make([]int, 2, 5)`.",
              "answer": "len=2, cap=5"
            },
            {
              "type": "debug",
              "question": "Fix a bug where helper appends to slice but caller doesn’t see expected updates."
            },
            {
              "type": "implement",
              "question": "Clone a slice defensively before mutation in a function."
            },
            {
              "type": "tricky",
              "question": "Why can append trigger allocation and break shared data assumptions?",
              "answer": "Capacity overflow causes new backing array allocation."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Observe len/cap changes during append.",
              "code": "s := make([]int, 0, 1)\nfor i := 0; i < 4; i++ {\n  s = append(s, i)\n  fmt.Println(len(s), cap(s))\n}",
              "output": "capacity grows as needed"
            },
            {
              "question": "Program 2: Shared backing array side effect.",
              "code": "base := []int{1,2,3,4}\na := base[:2]\nb := base[1:3]\na[1] = 99\nfmt.Println(base, b)",
              "output": "[1 99 3 4] [99 3]"
            },
            {
              "question": "Program 3: Safe clone before mutation.",
              "code": "src := []int{1,2,3}\ndst := append([]int(nil), src...)\ndst[0] = 100\nfmt.Println(src, dst)",
              "output": "[1 2 3] [100 2 3]"
            }
          ],
          "category": "Data Structures"
        },
        {
          "id": "maps",
          "title": "Maps",
          "description": "Key-value pairs (hash tables). Dynamic and unordered.",
          "code": "package main\n\nimport \"fmt\"\n\nfunc main() {\n    // Create map\n    m := make(map[string]int)\n    \n    // Set values\n    m[\"apple\"] = 5\n    m[\"banana\"] = 3\n    \n    // Map literal\n    ages := map[string]int{\n        \"Alice\": 25,\n        \"Bob\":   30,\n    }\n    \n    // Get value\n    age := ages[\"Alice\"]\n    \n    // Check if key exists\n    val, ok := ages[\"Charlie\"]\n    if ok {\n        fmt.Println(\"Found:\", val)\n    } else {\n        fmt.Println(\"Not found\")\n    }\n    \n    // Delete key\n    delete(ages, \"Bob\")\n    \n    // Iterate\n    for key, value := range ages {\n        fmt.Printf(\"%s: %d\\n\", key, value)\n    }\n}",
          "example": "// Map of structs\ntype User struct {\n    Name string\n    Age  int\n}\n\nusers := map[int]User{\n    1: {Name: \"Alice\", Age: 25},\n    2: {Name: \"Bob\", Age: 30},\n}\n\n// Map of slices\ndata := map[string][]int{\n    \"even\": {2, 4, 6, 8},\n    \"odd\":  {1, 3, 5, 7},\n}\n\n// Nested maps\nconfig := map[string]map[string]string{\n    \"database\": {\n        \"host\": \"localhost\",\n        \"port\": \"5432\",\n    },\n}",
          "useCase": "Lookups, caching, counting, grouping, configuration",
          "explanation": "Maps are hash-based key/value containers with O(1)-average lookup semantics. Interviewers usually check map initialization rules, missing-key behavior, iteration non-determinism, and concurrency safety limitations.",
          "interviewQuestions": [
            {
              "question": "What is returned for missing map key access?",
              "answer": "The zero value of value type; use two-value form (`v, ok := m[k]`) to distinguish existence."
            },
            {
              "question": "Is map iteration order stable in Go?",
              "answer": "No, iteration order is intentionally randomized."
            },
            {
              "question": "Can maps be read/written concurrently without locks?",
              "answer": "Concurrent writes or read-write access without synchronization is unsafe and may panic or race."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Build frequency counter for words in a string slice."
            },
            {
              "type": "output",
              "question": "What happens on `delete(m, missing)`?",
              "answer": "Safe no-op"
            },
            {
              "type": "tricky",
              "question": "Why does writing to a nil map panic but reading does not?",
              "answer": "Read can return zero value from absent storage, but write needs allocated hash table."
            },
            {
              "type": "debug",
              "question": "Fix panic from writing to an uninitialized map field in struct."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Frequency map.",
              "code": "words := []string{\"go\",\"go\",\"api\"}\nfreq := make(map[string]int)\nfor _, w := range words { freq[w]++ }\nfmt.Println(freq[\"go\"], freq[\"api\"])",
              "output": "2 1"
            },
            {
              "question": "Program 2: Presence check pattern.",
              "code": "m := map[string]int{\"x\": 1}\nv, ok := m[\"y\"]\nfmt.Println(v, ok)",
              "output": "0 false"
            },
            {
              "question": "Program 3: Grouping values by key.",
              "code": "groups := map[string][]int{}\nfor _, n := range []int{1,2,3,4} {\n  k := \"odd\"; if n%2==0 { k = \"even\" }\n  groups[k] = append(groups[k], n)\n}\nfmt.Println(groups[\"even\"], groups[\"odd\"])",
              "output": "[2 4] [1 3]"
            }
          ],
          "category": "Data Structures"
        },
        {
          "id": "db-connection",
          "title": "Database Connection (database/sql)",
          "description": "Use database/sql with pooled connections, context-aware queries, and safe parameterized SQL.",
          "explanation": "Interview focus: sql.Open vs PingContext, connection pool tuning, transactions, and proper error handling (especially sql.ErrNoRows).",
          "code": "db, err := sql.Open(\"postgres\", dsn)\nif err != nil { return err }\ndefer db.Close()\ndb.SetMaxOpenConns(25)\ndb.SetMaxIdleConns(10)\nctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)\ndefer cancel()\nif err := db.PingContext(ctx); err != nil { return err }",
          "example": "var name string\nerr := db.QueryRowContext(ctx, \"SELECT name FROM users WHERE id=$1\", id).Scan(&name)\nif err == sql.ErrNoRows {\n  return \"\", errors.New(\"not found\")\n}",
          "useCase": "Production APIs with PostgreSQL/MySQL, repository pattern, transactional business logic.",
          "interviewQuestions": [
            {
              "question": "What does database/sql provide?",
              "answer": "A standard abstraction over SQL drivers with pooled connections."
            },
            {
              "question": "Does sql.Open validate connectivity?",
              "answer": "Not fully; use Ping/PingContext for actual connectivity checks."
            },
            {
              "question": "Why pass context to DB calls?",
              "answer": "To enforce deadlines and cancellation under slow or failing infrastructure."
            },
            {
              "question": "How do you prevent SQL injection?",
              "answer": "Use placeholders with query parameters, never string-concatenate user input."
            },
            {
              "question": "When do you use QueryRowContext?",
              "answer": "When expecting a single row result."
            },
            {
              "question": "How do you handle missing rows?",
              "answer": "Check `err == sql.ErrNoRows` and map to domain error."
            },
            {
              "question": "Why close rows from QueryContext?",
              "answer": "To release resources and avoid connection leaks/pool starvation."
            },
            {
              "question": "When should transactions be used?",
              "answer": "When multiple writes must succeed or fail as one atomic unit."
            },
            {
              "question": "Should sql.DB be created per request?",
              "answer": "No. Create once and reuse globally."
            },
            {
              "question": "What pool settings usually matter?",
              "answer": "SetMaxOpenConns, SetMaxIdleConns, SetConnMaxLifetime (and optionally max idle lifetime)."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Implement DB startup health check with 2 second timeout."
            },
            {
              "type": "implement",
              "question": "Write repository GetByID method returning domain not-found error."
            },
            {
              "type": "output",
              "question": "What does Scan return when no row exists?",
              "answer": "sql.ErrNoRows"
            },
            {
              "type": "debug",
              "question": "Rows are never closed in loop. What symptom appears?",
              "answer": "Connection leak and eventual DB pool exhaustion."
            },
            {
              "type": "debug",
              "question": "API hangs under DB load. Which settings do you inspect first?"
            },
            {
              "type": "scenario",
              "question": "Design transaction rollback strategy for money transfer flow."
            },
            {
              "type": "implement",
              "question": "Add parameterized insert with context timeout."
            },
            {
              "type": "scenario",
              "question": "Propagate request context from handler to repository."
            },
            {
              "type": "tricky",
              "question": "Is sql.DB concurrency-safe?",
              "answer": "Yes."
            },
            {
              "type": "tricky",
              "question": "Should you build SQL with fmt.Sprintf(userInput)?",
              "answer": "No."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Ping DB with timeout.",
              "code": "ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)\ndefer cancel()\nfmt.Println(db.PingContext(ctx) == nil)",
              "output": "true (if DB reachable)"
            },
            {
              "type": "program",
              "question": "Program 2: Query one row by id.",
              "code": "var email string\nerr := db.QueryRowContext(ctx, \"SELECT email FROM users WHERE id=$1\", 1).Scan(&email)\nfmt.Println(err == nil)",
              "output": "true (if row exists)"
            },
            {
              "type": "program",
              "question": "Program 3: Insert and rows affected.",
              "code": "res, _ := db.ExecContext(ctx, \"INSERT INTO logs(message) VALUES($1)\", \"hello\")\nn, _ := res.RowsAffected()\nfmt.Println(n)",
              "output": "1"
            },
            {
              "type": "program",
              "question": "Program 4: Handle sql.ErrNoRows branch.",
              "code": "err := db.QueryRowContext(ctx, \"SELECT id FROM users WHERE id=$1\", -1).Scan(new(int64))\nfmt.Println(err == sql.ErrNoRows)",
              "output": "true"
            },
            {
              "type": "program",
              "question": "Program 5: Basic transaction commit/rollback flow.",
              "code": "tx, _ := db.BeginTx(ctx, nil)\n_, err := tx.ExecContext(ctx, \"UPDATE items SET stock=stock-1 WHERE id=$1\", 1)\nif err != nil { _ = tx.Rollback() } else { _ = tx.Commit() }",
              "output": "transaction path executed"
            },
            {
              "type": "program",
              "question": "Program 6: Pool setting and stats snapshot.",
              "code": "db.SetMaxOpenConns(30)\nfmt.Println(db.Stats().MaxOpenConnections)",
              "output": "30"
            },
            {
              "type": "program",
              "question": "Program 7: Iterate rows with defer Close.",
              "code": "rows, _ := db.QueryContext(ctx, \"SELECT id FROM users LIMIT 2\")\ndefer rows.Close()\nfor rows.Next() { var id int; _ = rows.Scan(&id); fmt.Println(id) }",
              "output": "prints ids"
            },
            {
              "type": "program",
              "question": "Program 8: Prepared statement reuse.",
              "code": "stmt, _ := db.PrepareContext(ctx, \"SELECT name FROM users WHERE id=$1\")\ndefer stmt.Close()\nvar name string\n_ = stmt.QueryRowContext(ctx, 1).Scan(&name)\nfmt.Println(name)",
              "output": "prints user name"
            },
            {
              "type": "program",
              "question": "Program 9: Timeout cancellation demo.",
              "code": "ctx, cancel := context.WithTimeout(context.Background(), time.Nanosecond)\ndefer cancel()\nfmt.Println(db.PingContext(ctx) != nil)",
              "output": "true"
            },
            {
              "type": "program",
              "question": "Program 10: Repository interface contract.",
              "code": "type UserRepo interface {\n  GetByID(ctx context.Context, id int64) (User, error)\n}",
              "output": "compiles"
            }
          ],
          "category": "Backend Development"
        },
        {
          "id": "redis-connection",
          "title": "Redis Connection (go-redis)",
          "description": "Connect Go services to Redis for cache, counters, and lightweight coordination.",
          "explanation": "Interview focus: redis.Nil behavior, TTL strategy, cache-aside flow, and timeout/circuit fallback under outages.",
          "code": "rdb := redis.NewClient(&redis.Options{Addr: \"localhost:6379\"})\ndefer rdb.Close()\nif err := rdb.Ping(ctx).Err(); err != nil { return err }",
          "example": "_ = rdb.Set(ctx, \"k\", \"v\", time.Minute).Err()\nv, err := rdb.Get(ctx, \"k\").Result()",
          "useCase": "Caching expensive reads, rate limiting, OTP/session storage.",
          "interviewQuestions": [
            {
              "question": "What does redis.Nil indicate?",
              "answer": "Key miss."
            },
            {
              "question": "Why add TTL to cache keys?",
              "answer": "To avoid stale infinite data and control memory."
            },
            {
              "question": "What is cache-aside?",
              "answer": "Read cache -> miss -> source -> write cache."
            },
            {
              "question": "Set vs SetNX?",
              "answer": "Set writes always, SetNX writes only when absent."
            },
            {
              "question": "Why use context on Redis calls?",
              "answer": "Timeout/cancel support under network failure."
            },
            {
              "question": "What is cache stampede?",
              "answer": "Many concurrent misses recompute same expensive value."
            },
            {
              "question": "How to reduce stampede risk?",
              "answer": "Singleflight lock + jittered TTL + prewarm."
            },
            {
              "question": "When to use Redis pipeline?",
              "answer": "Batch commands to reduce round trips."
            },
            {
              "question": "Can Redis replace SQL database completely?",
              "answer": "Usually no, it complements primary persistence."
            },
            {
              "question": "What happens if expiration is zero?",
              "answer": "Key persists until delete/overwrite."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Implement getOrSet cache helper with loader + TTL."
            },
            {
              "type": "output",
              "question": "Get on missing key returns what error?",
              "answer": "redis.Nil"
            },
            {
              "type": "debug",
              "question": "Stale cache persists forever. What was likely missing?",
              "answer": "TTL/invalidation."
            },
            {
              "type": "scenario",
              "question": "Design login attempt rate limiter using INCR + EXPIRE."
            },
            {
              "type": "implement",
              "question": "Store/retrieve JSON payload in Redis."
            },
            {
              "type": "debug",
              "question": "Requests hang when Redis is down. What to add?",
              "answer": "Timeouts and fallback/circuit strategy."
            },
            {
              "type": "scenario",
              "question": "Invalidate cache key after successful DB update."
            },
            {
              "type": "tricky",
              "question": "Is redis.Nil == nil?",
              "answer": "No."
            },
            {
              "type": "tricky",
              "question": "Is Redis data typed automatically in Go?",
              "answer": "No, values are serialized/deserialized."
            },
            {
              "type": "implement",
              "question": "Use SetNX for short lock key with expiry."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Create client and ping.",
              "code": "rdb := redis.NewClient(&redis.Options{Addr:\"localhost:6379\"})\nfmt.Println(rdb.Ping(ctx).Err() == nil)",
              "output": "true"
            },
            {
              "type": "program",
              "question": "Program 2: Set/get key with TTL.",
              "code": "_ = rdb.Set(ctx, \"k\", \"v\", time.Minute).Err()\nv, _ := rdb.Get(ctx, \"k\").Result()\nfmt.Println(v)",
              "output": "v"
            },
            {
              "type": "program",
              "question": "Program 3: Missing key check.",
              "code": "_, err := rdb.Get(ctx, \"missing\").Result()\nfmt.Println(err == redis.Nil)",
              "output": "true"
            },
            {
              "type": "program",
              "question": "Program 4: Counter increment.",
              "code": "n, _ := rdb.Incr(ctx, \"hits\").Result()\nfmt.Println(n)",
              "output": "1 (or incremented value)"
            },
            {
              "type": "program",
              "question": "Program 5: Conditional set with SetNX.",
              "code": "ok, _ := rdb.SetNX(ctx, \"lock:key\", \"1\", 5*time.Second).Result()\nfmt.Println(ok)",
              "output": "true (if absent)"
            },
            {
              "type": "program",
              "question": "Program 6: Delete and verify miss.",
              "code": "_ = rdb.Del(ctx, \"k\").Err()\nfmt.Println(rdb.Get(ctx, \"k\").Err() == redis.Nil)",
              "output": "true"
            },
            {
              "type": "program",
              "question": "Program 7: Pipeline execution.",
              "code": "pipe := rdb.Pipeline()\npipe.Set(ctx, \"a\", \"1\", 0)\npipe.Incr(ctx, \"a\")\n_, _ = pipe.Exec(ctx)",
              "output": "commands executed"
            },
            {
              "type": "program",
              "question": "Program 8: Store JSON in Redis.",
              "code": "raw, _ := json.Marshal(map[string]string{\"name\":\"go\"})\n_ = rdb.Set(ctx, \"u:1\", raw, time.Minute).Err()",
              "output": "stored"
            },
            {
              "type": "program",
              "question": "Program 9: Read JSON from Redis.",
              "code": "b, _ := rdb.Get(ctx, \"u:1\").Bytes()\nvar m map[string]string\n_ = json.Unmarshal(b, &m)\nfmt.Println(m[\"name\"])",
              "output": "go"
            },
            {
              "type": "program",
              "question": "Program 10: TTL check.",
              "code": "ttl, _ := rdb.TTL(ctx, \"u:1\").Result()\nfmt.Println(ttl > 0)",
              "output": "true"
            }
          ],
          "category": "Backend Development"
        },
        {
          "id": "api-development",
          "title": "API Development (net/http)",
          "description": "Build HTTP JSON APIs with method guards, validation, middleware, and graceful shutdown.",
          "explanation": "Interview focus: thin handlers, status code semantics, consistent error models, and context propagation.",
          "code": "mux := http.NewServeMux()\nmux.HandleFunc(\"/health\", func(w http.ResponseWriter, r *http.Request) {\n  w.Header().Set(\"Content-Type\", \"application/json\")\n  _ = json.NewEncoder(w).Encode(map[string]string{\"status\":\"ok\"})\n})\nlog.Fatal(http.ListenAndServe(\":8080\", mux))",
          "example": "if r.Method != http.MethodPost {\n  http.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n  return\n}",
          "useCase": "Service APIs, webhooks, internal backend endpoints.",
          "interviewQuestions": [
            {
              "question": "Why keep handlers thin?",
              "answer": "Better testability and separation of concerns."
            },
            {
              "question": "Why set Content-Type explicitly?",
              "answer": "Clients and gateways parse response correctly as JSON."
            },
            {
              "question": "When to return 201?",
              "answer": "After successful resource creation."
            },
            {
              "question": "Method guard purpose?",
              "answer": "Return 405 for unsupported methods and enforce contract."
            },
            {
              "question": "How to validate JSON payloads?",
              "answer": "Decode + field validation + proper 400/422 response."
            },
            {
              "question": "Why pass r.Context downstream?",
              "answer": "Timeout and cancellation propagation."
            },
            {
              "question": "What does middleware solve?",
              "answer": "Cross-cutting concerns like logging/auth/recovery."
            },
            {
              "question": "How to protect from oversized payload?",
              "answer": "Use http.MaxBytesReader."
            },
            {
              "question": "How to shut down gracefully?",
              "answer": "Use http.Server.Shutdown(ctx)."
            },
            {
              "question": "Common decode bug?",
              "answer": "Ignoring json decode errors and proceeding."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Implement GET /health returning JSON."
            },
            {
              "type": "implement",
              "question": "Implement POST /users with decode and validation."
            },
            {
              "type": "output",
              "question": "Status code for method not allowed?",
              "answer": "405"
            },
            {
              "type": "debug",
              "question": "API returns text/plain not JSON. What to fix?"
            },
            {
              "type": "scenario",
              "question": "Add logging middleware with duration."
            },
            {
              "type": "implement",
              "question": "Write JSON error helper."
            },
            {
              "type": "debug",
              "question": "Huge payload crashes service. What protection?"
            },
            {
              "type": "scenario",
              "question": "Propagate request timeout to DB layer."
            },
            {
              "type": "tricky",
              "question": "Are net/http handlers concurrent?",
              "answer": "Yes."
            },
            {
              "type": "tricky",
              "question": "Should panic be used for validation errors?",
              "answer": "No."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Minimal health endpoint.",
              "code": "mux := http.NewServeMux()\nmux.HandleFunc(\"/health\", func(w http.ResponseWriter, r *http.Request) {\n  _ = json.NewEncoder(w).Encode(map[string]string{\"status\":\"ok\"})\n})",
              "output": "serves /health"
            },
            {
              "type": "program",
              "question": "Program 2: Method guard block.",
              "code": "if r.Method != http.MethodPost {\n  http.Error(w, \"method not allowed\", http.StatusMethodNotAllowed)\n  return\n}",
              "output": "405 on invalid method"
            },
            {
              "type": "program",
              "question": "Program 3: Decode JSON body.",
              "code": "var body map[string]string\nif err := json.NewDecoder(r.Body).Decode(&body); err != nil {\n  http.Error(w, \"bad request\", http.StatusBadRequest)\n  return\n}",
              "output": "decoded or 400"
            },
            {
              "type": "program",
              "question": "Program 4: writeJSON helper.",
              "code": "func writeJSON(w http.ResponseWriter, code int, v any) {\n  w.Header().Set(\"Content-Type\", \"application/json\")\n  w.WriteHeader(code)\n  _ = json.NewEncoder(w).Encode(v)\n}",
              "output": "helper ready"
            },
            {
              "type": "program",
              "question": "Program 5: writeErr helper.",
              "code": "func writeErr(w http.ResponseWriter, code int, msg string) {\n  writeJSON(w, code, map[string]string{\"error\": msg})\n}",
              "output": "consistent error body"
            },
            {
              "type": "program",
              "question": "Program 6: Logging middleware.",
              "code": "func logging(next http.Handler) http.Handler {\n  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n    start := time.Now()\n    next.ServeHTTP(w, r)\n    log.Println(r.Method, r.URL.Path, time.Since(start))\n  })\n}",
              "output": "logs method/path/duration"
            },
            {
              "type": "program",
              "question": "Program 7: Query param read.",
              "code": "id := r.URL.Query().Get(\"id\")\nfmt.Fprintln(w, \"id:\", id)",
              "output": "prints id"
            },
            {
              "type": "program",
              "question": "Program 8: Limit body size.",
              "code": "r.Body = http.MaxBytesReader(w, r.Body, 1<<20)",
              "output": "max 1MB"
            },
            {
              "type": "program",
              "question": "Program 9: Graceful shutdown skeleton.",
              "code": "srv := &http.Server{Addr: \":8080\", Handler: mux}\ngo srv.ListenAndServe()\nctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\ndefer cancel()\n_ = srv.Shutdown(ctx)",
              "output": "graceful shutdown flow"
            },
            {
              "type": "program",
              "question": "Program 10: Not found fallback check.",
              "code": "if r.URL.Path != \"/\" {\n  http.NotFound(w, r)\n  return\n}",
              "output": "404 for unknown routes"
            }
          ],
          "category": "Backend Development"
        },
        {
          "id": "inbuilt-functions",
          "title": "Inbuilt Functions and Purpose",
          "description": "Core Go built-ins (len, cap, make, new, append, copy, delete) and common stdlib utility functions.",
          "explanation": "Interview focus: make vs new, append semantics, nil map behavior, copy return value, and standard utility packages.",
          "code": "s := make([]int, 0, 4)\ns = append(s, 1, 2)\nfmt.Println(len(s), cap(s))",
          "example": "src := []int{1,2,3}\ndst := make([]int, len(src))\nn := copy(dst, src)\nfmt.Println(n, dst)",
          "useCase": "Coding rounds, utility logic, data transformations.",
          "interviewQuestions": [
            {
              "question": "make vs new?",
              "answer": "make initializes slice/map/channel and returns T; new returns pointer to zeroed T."
            },
            {
              "question": "Why reassign append result?",
              "answer": "append may return a new slice header."
            },
            {
              "question": "copy returns what?",
              "answer": "Number of elements copied."
            },
            {
              "question": "Can you write to nil map?",
              "answer": "No, it panics."
            },
            {
              "question": "len(nilSlice) ?",
              "answer": "0"
            },
            {
              "question": "delete missing key panic?",
              "answer": "No, safe no-op."
            },
            {
              "question": "When to use panic/recover?",
              "answer": "Exceptional boundaries only, not normal control flow."
            },
            {
              "question": "String to int conversion package?",
              "answer": "strconv."
            },
            {
              "question": "Efficient string build in loop?",
              "answer": "strings.Builder."
            },
            {
              "question": "Is copy deep for nested references?",
              "answer": "No, shallow copy of elements."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "len(nilSlice) ?",
              "answer": "0"
            },
            {
              "type": "output",
              "question": "delete(map, missingKey) result?",
              "answer": "safe no-op"
            },
            {
              "type": "implement",
              "question": "Write clone helper for []int using copy."
            },
            {
              "type": "implement",
              "question": "Parse integer from string with validation."
            },
            {
              "type": "debug",
              "question": "append result ignored; what bug appears?"
            },
            {
              "type": "scenario",
              "question": "Choose strings.Builder vs + in loop and justify."
            },
            {
              "type": "implement",
              "question": "Initialize map safely before write."
            },
            {
              "type": "tricky",
              "question": "cap meaning for slice?",
              "answer": "Max elements before reallocation."
            },
            {
              "type": "debug",
              "question": "nil map write panic fix?"
            },
            {
              "type": "implement",
              "question": "Sort integer slice with stdlib."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: make slice len/cap.",
              "code": "s := make([]int, 0, 5)\nfmt.Println(len(s), cap(s))",
              "output": "0 5"
            },
            {
              "type": "program",
              "question": "Program 2: append values.",
              "code": "s := []int{1}\ns = append(s, 2, 3)\nfmt.Println(s)",
              "output": "[1 2 3]"
            },
            {
              "type": "program",
              "question": "Program 3: copy slice.",
              "code": "src := []int{10,20}\ndst := make([]int, len(src))\nn := copy(dst, src)\nfmt.Println(n, dst)",
              "output": "2 [10 20]"
            },
            {
              "type": "program",
              "question": "Program 4: delete map key.",
              "code": "m := map[string]int{\"a\":1,\"b\":2}\ndelete(m, \"b\")\nfmt.Println(m)",
              "output": "map[a:1]"
            },
            {
              "type": "program",
              "question": "Program 5: strconv.Atoi parse.",
              "code": "n, err := strconv.Atoi(\"123\")\nfmt.Println(n, err == nil)",
              "output": "123 true"
            },
            {
              "type": "program",
              "question": "Program 6: strings.Builder usage.",
              "code": "var b strings.Builder\nb.WriteString(\"go\")\nb.WriteString(\"lang\")\nfmt.Println(b.String())",
              "output": "golang"
            },
            {
              "type": "program",
              "question": "Program 7: sort.Ints usage.",
              "code": "nums := []int{3,1,2}\nsort.Ints(nums)\nfmt.Println(nums)",
              "output": "[1 2 3]"
            },
            {
              "type": "program",
              "question": "Program 8: time.Parse and format.",
              "code": "t, _ := time.Parse(\"2006-01-02\", \"2026-02-12\")\nfmt.Println(t.Format(\"02 Jan 2006\"))",
              "output": "12 Feb 2026"
            },
            {
              "type": "program",
              "question": "Program 9: recover demo.",
              "code": "func safe() {\n  defer func() { if recover() != nil { fmt.Println(\"recovered\") } }()\n  panic(\"boom\")\n}\nsafe()",
              "output": "recovered"
            },
            {
              "type": "program",
              "question": "Program 10: cap growth while appending.",
              "code": "s := make([]int, 0, 1)\nfor i := 0; i < 3; i++ {\n  s = append(s, i)\n  fmt.Println(len(s), cap(s))\n}",
              "output": "prints growth sequence"
            }
          ],
          "category": "Backend Development"
        }
      ],
      "quiz": [
        {
          "question": "What is a goroutine in Go?",
          "options": [
            "A type of loop",
            "A lightweight thread managed by the Go runtime",
            "A data structure",
            "A package manager"
          ],
          "correctAnswer": 1,
          "explanation": "A goroutine is a lightweight thread of execution managed by the Go runtime. Goroutines are much cheaper than OS threads and thousands can run concurrently."
        },
        {
          "question": "What is the purpose of channels in Go?",
          "options": [
            "To store data permanently",
            "To enable communication and synchronization between goroutines",
            "To import packages",
            "To handle errors"
          ],
          "correctAnswer": 1,
          "explanation": "Channels are the pipes that connect concurrent goroutines. They allow you to send and receive values between goroutines, providing both communication and synchronization."
        },
        {
          "question": "What does 'defer' keyword do in Go?",
          "options": [
            "Delays execution until the surrounding function returns",
            "Creates a goroutine",
            "Handles errors",
            "Imports a package"
          ],
          "correctAnswer": 0,
          "explanation": "The defer keyword postpones the execution of a function until the surrounding function returns. It's commonly used for cleanup operations like closing files or unlocking mutexes."
        },
        {
          "question": "What's the difference between buffered and unbuffered channels?",
          "options": [
            "Buffered channels can hold values without a receiver, unbuffered require immediate receive",
            "Buffered channels are faster",
            "Unbuffered channels don't work",
            "There is no difference"
          ],
          "correctAnswer": 0,
          "explanation": "Unbuffered channels block the sender until a receiver is ready. Buffered channels allow sending up to N values without blocking, where N is the buffer size."
        },
        {
          "question": "What does the 'select' statement do in Go?",
          "options": [
            "Selects a random number",
            "Waits on multiple channel operations",
            "Filters arrays",
            "Chooses a goroutine"
          ],
          "correctAnswer": 1,
          "explanation": "The select statement lets a goroutine wait on multiple channel operations. It blocks until one of its cases can proceed, enabling powerful concurrent patterns."
        },
        {
          "question": "What is the zero value of a slice in Go?",
          "options": [
            "An empty slice []",
            "nil",
            "0",
            "false"
          ],
          "correctAnswer": 1,
          "explanation": "The zero value of a slice is nil. A nil slice has length and capacity 0 and has no underlying array. However, you can still call len() and cap() on it safely."
        },
        {
          "question": "What are the basic data types in Go?",
          "options": [
            "Only int and string",
            "bool, string, int, float64, complex128",
            "Any type from other languages",
            "Go has no types"
          ],
          "correctAnswer": 1,
          "explanation": "Go has basic types including bool, string, int/int8/int16/int32/int64, uint variants, float32/float64, complex64/complex128, byte, and rune."
        },
        {
          "question": "What is the difference between := and var?",
          "options": [
            "No difference",
            ":= is short declaration only in functions, var works anywhere",
            "var is deprecated",
            ":= is slower"
          ],
          "correctAnswer": 1,
          "explanation": ":= is short variable declaration syntax that only works inside functions and infers type. var can be used at package or function level and allows explicit type declaration."
        },
        {
          "question": "What is a slice in Go?",
          "options": [
            "A fixed-size array",
            "A dynamic-size, flexible view into arrays",
            "A string operation",
            "A goroutine"
          ],
          "correctAnswer": 1,
          "explanation": "A slice is a dynamically-sized, flexible view into the elements of an array. It has a pointer, length, and capacity. Slices are more common than arrays."
        },
        {
          "question": "How do you create a slice with initial capacity?",
          "options": [
            "slice := []int",
            "slice := make([]int, 0, 10)",
            "slice := new([]int)",
            "slice := array[:]"
          ],
          "correctAnswer": 1,
          "explanation": "make([]int, 0, 10) creates a slice with length 0 and capacity 10. The first number is length, second is capacity (optional)."
        },
        {
          "question": "What is the difference between array and slice?",
          "options": [
            "No difference",
            "Arrays have fixed size, slices are dynamic",
            "Arrays are deprecated",
            "Slices are slower"
          ],
          "correctAnswer": 1,
          "explanation": "Arrays have a fixed size that's part of their type. Slices are dynamic, can grow/shrink, and are references to underlying arrays. Slices are more flexible."
        },
        {
          "question": "What does the range keyword do?",
          "options": [
            "Creates a range of numbers",
            "Iterates over elements in arrays, slices, maps, channels",
            "Defines a numeric range",
            "Validates ranges"
          ],
          "correctAnswer": 1,
          "explanation": "range iterates over elements in arrays, slices, strings, maps, or channels. Returns index/key and value for each iteration."
        },
        {
          "question": "What is a map in Go?",
          "options": [
            "Geographic map",
            "Hash table that maps keys to values",
            "Array index",
            "Function mapper"
          ],
          "correctAnswer": 1,
          "explanation": "A map is Go's built-in hash table/dictionary type that maps keys of one type to values of another type. Created with make(map[KeyType]ValueType)."
        },
        {
          "question": "What is the zero value of a map?",
          "options": [
            "Empty map {}",
            "nil",
            "0",
            "false"
          ],
          "correctAnswer": 1,
          "explanation": "The zero value of a map is nil. A nil map has no keys and can't have keys added. Use make() to create a usable map."
        },
        {
          "question": "How do you check if a key exists in a map?",
          "options": [
            "map.has(key)",
            "value, ok := map[key]",
            "map.contains(key)",
            "key in map"
          ],
          "correctAnswer": 1,
          "explanation": "Use the two-value assignment: value, ok := map[key]. If key exists, ok is true and value is the map value. Otherwise, ok is false and value is zero value."
        },
        {
          "question": "What is a struct in Go?",
          "options": [
            "A class",
            "A collection of fields/properties grouped together",
            "A function",
            "An interface"
          ],
          "correctAnswer": 1,
          "explanation": "A struct is a composite data type that groups together zero or more named fields of arbitrary types under a single name. Similar to classes but without inheritance."
        },
        {
          "question": "How do you define a method on a struct?",
          "options": [
            "func (s Struct) method() {}",
            "Struct.method = func() {}",
            "method Struct() {}",
            "def method(self)"
          ],
          "correctAnswer": 0,
          "explanation": "Methods are functions with a receiver argument between func keyword and function name: func (s Struct) method() {}. The receiver can be value or pointer type."
        },
        {
          "question": "What's the difference between value and pointer receivers?",
          "options": [
            "No difference",
            "Pointer receivers can modify the receiver, value receivers can't",
            "Value receivers are faster",
            "Pointer receivers are deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "Pointer receivers (*T) can modify the receiver and avoid copying large structs. Value receivers (T) operate on a copy and can't modify the original."
        },
        {
          "question": "What is an interface in Go?",
          "options": [
            "A class",
            "A set of method signatures that a type can implement",
            "A network interface",
            "A user interface"
          ],
          "correctAnswer": 1,
          "explanation": "An interface is a type that specifies a set of method signatures. A type implements an interface by implementing its methods (implicitly, no 'implements' keyword)."
        },
        {
          "question": "What is the empty interface interface{}?",
          "options": [
            "A broken interface",
            "Can hold values of any type",
            "An error",
            "A null interface"
          ],
          "correctAnswer": 1,
          "explanation": "The empty interface interface{} has no methods, so all types implement it. It can hold values of any type. Similar to 'any' in other languages (Go 1.18+ has 'any' alias)."
        },
        {
          "question": "How do you check the type of an interface value?",
          "options": [
            "typeof(value)",
            "value.(Type) and type assertion or type switch",
            "value.type()",
            "getType(value)"
          ],
          "correctAnswer": 1,
          "explanation": "Use type assertion: value.(Type) or type switch: switch v := i.(type). Type assertion returns value and boolean indicating success."
        },
        {
          "question": "What is a pointer in Go?",
          "options": [
            "A cursor",
            "A variable that stores memory address of another variable",
            "An array index",
            "A reference"
          ],
          "correctAnswer": 1,
          "explanation": "A pointer holds the memory address of a value. Use & to get pointer to value and * to dereference pointer. Go has pointers but no pointer arithmetic."
        },
        {
          "question": "What does the & operator do?",
          "options": [
            "Bitwise AND",
            "Gets the memory address (pointer) of a variable",
            "Logical AND",
            "Concatenation"
          ],
          "correctAnswer": 1,
          "explanation": "The & operator generates a pointer to its operand. &x gives you the memory address of x, creating a pointer to x."
        },
        {
          "question": "What does the * operator do with pointers?",
          "options": [
            "Multiplication",
            "Dereferences pointer to access the value it points to",
            "Creates pointer",
            "Pointer arithmetic"
          ],
          "correctAnswer": 1,
          "explanation": "The * operator dereferences a pointer, giving access to the value at that address. *p accesses the value pointed to by pointer p."
        },
        {
          "question": "What is error handling in Go?",
          "options": [
            "Try-catch blocks",
            "Functions return error as last return value",
            "Exceptions",
            "No error handling"
          ],
          "correctAnswer": 1,
          "explanation": "Go uses explicit error handling. Functions return error as the last return value. Caller checks if error is nil to determine success or failure."
        },
        {
          "question": "What is the error interface?",
          "options": [
            "A bug",
            "An interface with Error() string method",
            "An exception type",
            "A logging mechanism"
          ],
          "correctAnswer": 1,
          "explanation": "The error interface is a built-in interface with a single method: Error() string. Any type implementing this method satisfies the error interface."
        },
        {
          "question": "How do you create a custom error?",
          "options": [
            "throw new Error()",
            "errors.New('message') or fmt.Errorf()",
            "error('message')",
            "raise Exception"
          ],
          "correctAnswer": 1,
          "explanation": "Use errors.New('message') for simple errors or fmt.Errorf('format %v', value) for formatted errors. Can also create custom error types."
        },
        {
          "question": "What does panic do in Go?",
          "options": [
            "Logs a warning",
            "Stops normal execution and begins panicking",
            "Creates an error",
            "Exits gracefully"
          ],
          "correctAnswer": 1,
          "explanation": "panic stops normal execution of current goroutine and begins panicking. Deferred functions run, then program crashes. Use for unrecoverable errors."
        },
        {
          "question": "What does recover do?",
          "options": [
            "Recovers memory",
            "Regains control of panicking goroutine when called in defer",
            "Restores data",
            "Fixes errors"
          ],
          "correctAnswer": 1,
          "explanation": "recover regains control of a panicking goroutine. Must be called inside a deferred function. Returns the value passed to panic or nil if not panicking."
        },
        {
          "question": "What is the defer, panic, recover pattern?",
          "options": [
            "Design pattern",
            "Error handling mechanism similar to try-catch-finally",
            "Concurrency pattern",
            "Testing pattern"
          ],
          "correctAnswer": 1,
          "explanation": "defer/panic/recover is Go's mechanism similar to try-catch-finally. defer runs cleanup, panic raises errors, recover catches panics in deferred functions."
        },
        {
          "question": "What is a package in Go?",
          "options": [
            "A zip file",
            "A way to organize and reuse code",
            "A container",
            "A module"
          ],
          "correctAnswer": 1,
          "explanation": "A package is a collection of Go source files in the same directory. Packages are Go's way of organizing and reusing code. Every Go file belongs to a package."
        },
        {
          "question": "What is the init function?",
          "options": [
            "Constructor",
            "Special function that runs automatically when package is imported",
            "Initializer method",
            "Setup function"
          ],
          "correctAnswer": 1,
          "explanation": "init() is a special function that runs automatically when the package is imported, before main(). Used for initialization. Multiple init() functions can exist."
        },
        {
          "question": "What is the main package?",
          "options": [
            "Most important package",
            "Entry point package that defines executable program",
            "Main library",
            "Root package"
          ],
          "correctAnswer": 1,
          "explanation": "The main package defines an executable program (not a library). Must have a main() function which is the entry point of the program."
        },
        {
          "question": "How do you export identifiers from a package?",
          "options": [
            "export keyword",
            "Capitalize the first letter",
            "public keyword",
            "Use exports object"
          ],
          "correctAnswer": 1,
          "explanation": "In Go, identifiers are exported by capitalizing the first letter. Lowercase identifiers are private to the package. No explicit export keyword needed."
        },
        {
          "question": "What are Go modules?",
          "options": [
            "Code modules",
            "Dependency management system for Go projects",
            "Import statements",
            "Package managers"
          ],
          "correctAnswer": 1,
          "explanation": "Go modules is the official dependency management system. go.mod file defines module path and dependencies. Introduced in Go 1.11, standard since 1.13."
        },
        {
          "question": "What does go mod init do?",
          "options": [
            "Initializes variables",
            "Creates a new go.mod file for a module",
            "Installs modules",
            "Imports modules"
          ],
          "correctAnswer": 1,
          "explanation": "go mod init <module-path> creates a new go.mod file, initializing a new module. The module path is typically the repository path where code will be published."
        },
        {
          "question": "What does go mod tidy do?",
          "options": [
            "Cleans code",
            "Adds missing and removes unused module dependencies",
            "Formats code",
            "Organizes imports"
          ],
          "correctAnswer": 1,
          "explanation": "go mod tidy adds missing module dependencies and removes unused ones from go.mod and go.sum. It ensures dependencies match the source code."
        },
        {
          "question": "What is go.sum file?",
          "options": [
            "Summary file",
            "Contains cryptographic checksums of module dependencies",
            "Sum calculations",
            "Build output"
          ],
          "correctAnswer": 1,
          "explanation": "go.sum contains cryptographic checksums of specific module versions. It ensures that future downloads produce the same bits, providing security and reproducibility."
        },
        {
          "question": "What is a WaitGroup?",
          "options": [
            "A waiting room",
            "Sync primitive to wait for collection of goroutines to finish",
            "A time delay",
            "A channel type"
          ],
          "correctAnswer": 1,
          "explanation": "sync.WaitGroup waits for a collection of goroutines to finish. Add() increments counter, Done() decrements, Wait() blocks until counter is zero."
        },
        {
          "question": "What is a Mutex?",
          "options": [
            "Musical term",
            "Mutual exclusion lock for protecting shared data",
            "Multiple execution",
            "A channel"
          ],
          "correctAnswer": 1,
          "explanation": "sync.Mutex (mutual exclusion) provides a locking mechanism to protect shared data from concurrent access. Lock() acquires, Unlock() releases the lock."
        },
        {
          "question": "What's the difference between Mutex and RWMutex?",
          "options": [
            "No difference",
            "RWMutex allows multiple readers or one writer, Mutex allows only one",
            "RWMutex is deprecated",
            "Mutex is faster"
          ],
          "correctAnswer": 1,
          "explanation": "sync.RWMutex allows multiple concurrent readers or a single writer. sync.Mutex allows only one goroutine at a time. RWMutex is better when reads are more frequent."
        },
        {
          "question": "What does close() do with channels?",
          "options": [
            "Deletes channel",
            "Closes channel indicating no more values will be sent",
            "Stops goroutine",
            "Blocks channel"
          ],
          "correctAnswer": 1,
          "explanation": "close(ch) closes a channel, indicating no more values will be sent. Receivers can detect closure with v, ok := <-ch. Only sender should close, never receiver."
        },
        {
          "question": "What happens when you receive from a closed channel?",
          "options": [
            "Error",
            "Returns zero value and false for ok",
            "Blocks forever",
            "Panics"
          ],
          "correctAnswer": 1,
          "explanation": "Receiving from a closed channel immediately returns the zero value of the channel's type and false for the second ok value. Never panics on receive."
        },
        {
          "question": "What happens when you send to a closed channel?",
          "options": [
            "Nothing",
            "Panics",
            "Returns error",
            "Blocks"
          ],
          "correctAnswer": 1,
          "explanation": "Sending to a closed channel causes a panic. This is why only the sender should close channels, and only when absolutely necessary."
        },
        {
          "question": "What is the context package used for?",
          "options": [
            "Text context",
            "Carries deadlines, cancellation signals, and request-scoped values",
            "Application context",
            "Background jobs"
          ],
          "correctAnswer": 1,
          "explanation": "context package carries deadlines, cancellation signals, and request-scoped values across API boundaries and between goroutines. Essential for managing goroutine lifecycles."
        },
        {
          "question": "What does context.Background() return?",
          "options": [
            "Background color",
            "An empty, non-nil context used as root context",
            "A goroutine",
            "Background process"
          ],
          "correctAnswer": 1,
          "explanation": "context.Background() returns non-nil, empty Context. Used as root context for main function, initialization, and tests. Never canceled, has no values or deadline."
        },
        {
          "question": "What does context.WithTimeout do?",
          "options": [
            "Sets timeout",
            "Returns context that automatically cancels after specified duration",
            "Delays execution",
            "Waits for duration"
          ],
          "correctAnswer": 1,
          "explanation": "context.WithTimeout returns a context and cancel function. The context automatically cancels after the specified duration, useful for limiting operation time."
        },
        {
          "question": "What does context.WithCancel return?",
          "options": [
            "Cancel button",
            "A context and cancel function to manually cancel context",
            "Cancellation token",
            "Stop signal"
          ],
          "correctAnswer": 1,
          "explanation": "context.WithCancel returns a copy of parent context and a cancel function. Calling cancel closes Done channel, signaling operations to stop."
        },
        {
          "question": "How do you test if a channel is closed?",
          "options": [
            "ch.closed()",
            "value, ok := <-ch; ok is false if closed",
            "isClosed(ch)",
            "ch == nil"
          ],
          "correctAnswer": 1,
          "explanation": "Use two-value receive: value, ok := <-ch. If ok is false, channel is closed and value is zero value. This is the idiomatic way to detect closure."
        },
        {
          "question": "What is the blank identifier _?",
          "options": [
            "Space character",
            "Used to ignore values you don't need",
            "Empty string",
            "Null value"
          ],
          "correctAnswer": 1,
          "explanation": "The blank identifier _ is a special identifier that ignores values. Used when syntax requires a variable but you don't need the value (e.g., for _, v := range slice)."
        },
        {
          "question": "What does := operator do?",
          "options": [
            "Assignment only",
            "Short variable declaration with type inference",
            "Comparison",
            "Equality check"
          ],
          "correctAnswer": 1,
          "explanation": ":= is short variable declaration that declares and initializes variables with type inference. Only works inside functions, not at package level."
        },
        {
          "question": "What is the difference between = and :=?",
          "options": [
            "No difference",
            "= assigns to existing variables, := declares and assigns new variables",
            "= is older syntax",
            ":= is slower"
          ],
          "correctAnswer": 1,
          "explanation": "= is simple assignment to existing variables. := declares new variables and assigns values (type inferred). Can't use := at package level."
        },
        {
          "question": "What is a variadic function?",
          "options": [
            "Variable function",
            "Function that accepts variable number of arguments",
            "Varying return types",
            "Multiple functions"
          ],
          "correctAnswer": 1,
          "explanation": "Variadic function accepts variable number of arguments using ...Type syntax. Example: func sum(nums ...int). Arguments are received as a slice."
        },
        {
          "question": "How do you pass a slice to a variadic function?",
          "options": [
            "Just pass the slice",
            "Use ... operator: function(slice...)",
            "Convert to array",
            "Loop and pass elements"
          ],
          "correctAnswer": 1,
          "explanation": "Use ... operator after slice name: function(slice...). This unpacks the slice elements as individual arguments to the variadic function."
        },
        {
          "question": "What is type alias in Go?",
          "options": [
            "Alternate name",
            "An alternative name for an existing type using =",
            "New type",
            "Type conversion"
          ],
          "correctAnswer": 1,
          "explanation": "Type alias creates an alternative name for existing type: type MyInt = int. It's identical to the original type, not a new type."
        },
        {
          "question": "What is a type definition versus type alias?",
          "options": [
            "Same thing",
            "Type definition creates new type, alias is just another name",
            "No difference",
            "Alias is deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "type MyInt int creates a new type (requires conversion). type MyInt = int creates an alias (same type). Definitions give type safety, aliases don't."
        },
        {
          "question": "What does make() do?",
          "options": [
            "Makes variables",
            "Allocates and initializes slices, maps, and channels",
            "Makes structs",
            "Compiles code"
          ],
          "correctAnswer": 1,
          "explanation": "make() allocates and initializes slices, maps, and channels. Unlike new(), make returns initialized (not zeroed) value of type T, not *T."
        },
        {
          "question": "What does new() do?",
          "options": [
            "Creates new variables",
            "Allocates zeroed memory and returns pointer",
            "Makes slices",
            "Initializes structs"
          ],
          "correctAnswer": 1,
          "explanation": "new(T) allocates zeroed storage for a new item of type T and returns its address, a value of type *T. The value is zeroed but not initialized."
        },
        {
          "question": "What's the difference between make and new?",
          "options": [
            "No difference",
            "make initializes slices/maps/channels and returns type T, new zeros memory and returns *T",
            "new is deprecated",
            "make is faster"
          ],
          "correctAnswer": 1,
          "explanation": "make() is for slices, maps, channels and returns initialized value of type T. new() works with any type, returns pointer to zeroed memory *T."
        },
        {
          "question": "What is embedding in Go?",
          "options": [
            "Nested loops",
            "Including one struct/interface in another for composition",
            "Inheritance",
            "Import statements"
          ],
          "correctAnswer": 1,
          "explanation": "Embedding is Go's composition mechanism. An embedded type's methods are promoted to the outer type. It's composition without inheritance."
        },
        {
          "question": "What is the len() function?",
          "options": [
            "Length of string only",
            "Returns length of arrays, slices, maps, strings, channels",
            "Line count",
            "Loop length"
          ],
          "correctAnswer": 1,
          "explanation": "len() returns the number of elements in arrays, slices, maps, strings, or buffered elements in channels. Built-in function that works with various types."
        },
        {
          "question": "What is the cap() function?",
          "options": [
            "Capacity of strings",
            "Returns capacity of slices and channels",
            "Capital letters",
            "Maximum value"
          ],
          "correctAnswer": 1,
          "explanation": "cap() returns capacity (maximum size without reallocation) of slices, arrays, and channels. For slices, it's the size of the underlying array."
        },
        {
          "question": "What is the append() function?",
          "options": [
            "Adds to strings",
            "Adds elements to slice end, returns new slice",
            "Appends files",
            "Concatenates arrays"
          ],
          "correctAnswer": 1,
          "explanation": "append() adds elements to the end of a slice. Returns a new slice. If capacity exceeded, a new underlying array is allocated with larger capacity."
        },
        {
          "question": "What is copy() function for?",
          "options": [
            "Duplicates variables",
            "Copies elements from source slice to destination slice",
            "Copies files",
            "Clones objects"
          ],
          "correctAnswer": 1,
          "explanation": "copy(dst, src) copies elements from source slice to destination slice. Returns number of elements copied (minimum of len(dst) and len(src))."
        },
        {
          "question": "What is testing package used for?",
          "options": [
            "Production tests",
            "Writing unit tests and benchmarks",
            "Test data",
            "Testing environments"
          ],
          "correctAnswer": 1,
          "explanation": "testing package provides support for automated testing. Test files end with _test.go. Test functions start with Test, benchmarks with Benchmark."
        },
        {
          "question": "How do you run tests in Go?",
          "options": [
            "test run",
            "go test",
            "run tests",
            "go check"
          ],
          "correctAnswer": 1,
          "explanation": "go test runs all tests in the current package. Use go test ./... to test all packages recursively. Tests must be in *_test.go files."
        },
        {
          "question": "What is t.Run() in tests?",
          "options": [
            "Runs tests",
            "Defines a subtest with a name",
            "Runs goroutines",
            "Executes functions"
          ],
          "correctAnswer": 1,
          "explanation": "t.Run() runs a subtest with a given name. Useful for table-driven tests where you can group related test cases and run them individually."
        },
        {
          "question": "What does t.Error() do in tests?",
          "options": [
            "Creates errors",
            "Reports error but continues test execution",
            "Stops test",
            "Throws exception"
          ],
          "correctAnswer": 1,
          "explanation": "t.Error() marks test as failed and logs message but continues executing the test. Use t.Fatal() to stop test immediately after failure."
        },
        {
          "question": "What's the difference between t.Error() and t.Fatal()?",
          "options": [
            "No difference",
            "t.Error() continues execution, t.Fatal() stops immediately",
            "t.Fatal() is deprecated",
            "t.Error() is for errors only"
          ],
          "correctAnswer": 1,
          "explanation": "t.Error() marks failure but continues test. t.Fatal() marks failure and stops test immediately. Use Fatal for critical failures where continuing is pointless."
        },
        {
          "question": "What is table-driven testing?",
          "options": [
            "Database testing",
            "Using slice of test cases with input/expected output pairs",
            "Testing tables",
            "Excel testing"
          ],
          "correctAnswer": 1,
          "explanation": "Table-driven testing uses a slice of structs containing test inputs and expected outputs. Iterate and run each case, making tests more maintainable."
        },
        {
          "question": "What is reflection in Go?",
          "options": [
            "Mirror image",
            "Runtime inspection of types and values using reflect package",
            "Code reflection",
            "Self-documentation"
          ],
          "correctAnswer": 1,
          "explanation": "Reflection allows runtime inspection and manipulation of types and values. reflect package provides TypeOf() and ValueOf() for examining interface values."
        },
        {
          "question": "What is the reflect.TypeOf() function?",
          "options": [
            "Type conversion",
            "Returns the reflection Type of the value",
            "Type checking",
            "Type definition"
          ],
          "correctAnswer": 1,
          "explanation": "reflect.TypeOf() returns the reflection Type that represents the dynamic type of the interface value. Used for runtime type inspection."
        },
        {
          "question": "What is the reflect.ValueOf() function?",
          "options": [
            "Value conversion",
            "Returns the reflection Value of the interface value",
            "Gets value",
            "Value checking"
          ],
          "correctAnswer": 1,
          "explanation": "reflect.ValueOf() returns a new reflect.Value initialized to the concrete value stored in the interface. Allows inspection and manipulation of values."
        },
        {
          "question": "What is the go keyword?",
          "options": [
            "Go language",
            "Starts a new goroutine",
            "Goto statement",
            "Go function"
          ],
          "correctAnswer": 1,
          "explanation": "The go keyword starts a new goroutine. go function() executes function concurrently in a new lightweight thread managed by Go runtime."
        },
        {
          "question": "What is a buffered channel created with?",
          "options": [
            "make(chan Type)",
            "make(chan Type, capacity)",
            "new(chan Type)",
            "chan Type{size}"
          ],
          "correctAnswer": 1,
          "explanation": "Buffered channels are created with make(chan Type, capacity). The capacity is buffer size. make(chan Type) or make(chan Type, 0) creates unbuffered channel."
        },
        {
          "question": "What happens when a goroutine tries to send on a full buffered channel?",
          "options": [
            "Message is dropped",
            "Goroutine blocks until space is available",
            "Creates larger buffer",
            "Returns error"
          ],
          "correctAnswer": 1,
          "explanation": "When a buffered channel is full, sending goroutine blocks until another goroutine receives from channel, making space available in the buffer."
        },
        {
          "question": "What is a deadlock in Go?",
          "options": [
            "Locked code",
            "All goroutines are blocked waiting, program can't proceed",
            "Security lock",
            "Mutex lock"
          ],
          "correctAnswer": 1,
          "explanation": "Deadlock occurs when all goroutines are blocked waiting for something that will never happen. Go runtime detects deadlocks and panics with 'fatal error: all goroutines are asleep'."
        },
        {
          "question": "What is the select default case?",
          "options": [
            "Default channel",
            "Executed when no other case is ready, prevents blocking",
            "Default value",
            "Fallback option"
          ],
          "correctAnswer": 1,
          "explanation": "The default case in select is executed when no other case is ready. Makes select non-blocking. Useful for polling or implementing timeouts."
        },
        {
          "question": "What does time.After() return?",
          "options": [
            "Time value",
            "A channel that sends time after duration",
            "Timer object",
            "Delay function"
          ],
          "correctAnswer": 1,
          "explanation": "time.After(duration) returns a channel that sends the current time after the specified duration. Commonly used in select for timeouts."
        },
        {
          "question": "What is the difference between time.Sleep() and time.After()?",
          "options": [
            "No difference",
            "Sleep blocks goroutine, After returns channel for select",
            "After is deprecated",
            "Sleep is faster"
          ],
          "correctAnswer": 1,
          "explanation": "time.Sleep() blocks the current goroutine. time.After() returns a channel for use in select, allowing timeout patterns without blocking."
        },
        {
          "question": "What is a race condition?",
          "options": [
            "Racing goroutines",
            "Multiple goroutines access shared data concurrently without synchronization",
            "Speed competition",
            "Timing issue"
          ],
          "correctAnswer": 1,
          "explanation": "Race condition occurs when multiple goroutines access shared data concurrently and at least one modifies it, without proper synchronization. Results are unpredictable."
        },
        {
          "question": "How do you detect race conditions?",
          "options": [
            "Visual inspection",
            "Run tests with -race flag: go test -race",
            "Use debugger",
            "Log everything"
          ],
          "correctAnswer": 1,
          "explanation": "Go's race detector finds race conditions at runtime. Run with -race flag: go run -race or go test -race. Reports concurrent conflicting accesses."
        },
        {
          "question": "What is the sync.Once type?",
          "options": [
            "One-time variable",
            "Ensures action is performed exactly once across multiple goroutines",
            "Single goroutine",
            "One channel"
          ],
          "correctAnswer": 1,
          "explanation": "sync.Once ensures a function is executed exactly once, even when called from multiple goroutines. Useful for one-time initialization."
        },
        {
          "question": "What is the sync.Pool type?",
          "options": [
            "Connection pool",
            "Cache for reusing objects to reduce memory allocations",
            "Thread pool",
            "Goroutine pool"
          ],
          "correctAnswer": 1,
          "explanation": "sync.Pool is a cache for temporary objects that can be reused. Reduces memory allocations and garbage collection pressure. Objects may be removed automatically."
        },
        {
          "question": "What is the atomic package for?",
          "options": [
            "Physics calculations",
            "Atomic operations on primitive types for lock-free synchronization",
            "Small operations",
            "Molecular operations"
          ],
          "correctAnswer": 1,
          "explanation": "sync/atomic provides low-level atomic memory operations for primitive types. Useful for lock-free data structures and counters without mutexes."
        },
        {
          "question": "What is a channel direction?",
          "options": [
            "Data flow direction",
            "Restricting channel to send-only or receive-only",
            "Channel orientation",
            "Message direction"
          ],
          "correctAnswer": 1,
          "explanation": "Channel direction restricts channel use. chan<- T is send-only, <-chan T is receive-only. Used in function signatures to enforce correct usage and prevent mistakes."
        },
        {
          "question": "What does struct{}{} represent?",
          "options": [
            "Empty struct value",
            "Zero-size empty struct value, uses no memory",
            "Null struct",
            "Broken syntax"
          ],
          "correctAnswer": 1,
          "explanation": "struct{}{} is the value of empty struct type. Takes zero bytes of storage. Useful for signaling in channels when no data needs to be sent."
        },
        {
          "question": "What is the iota identifier?",
          "options": [
            "Iterator variable",
            "Constant generator that increments in const blocks",
            "Index variable",
            "Interface identifier"
          ],
          "correctAnswer": 1,
          "explanation": "iota is a predeclared identifier used in const declarations. Represents successive untyped integer constants starting from 0, incrementing by 1 each line."
        },
        {
          "question": "What is Go's convention for package naming?",
          "options": [
            "CamelCase",
            "Short, lowercase, single-word names",
            "snake_case",
            "kebab-case"
          ],
          "correctAnswer": 1,
          "explanation": "Package names should be short, concise, lowercase, single-word names without underscores or mixed caps. Should be evocative and clear about purpose."
        },
        {
          "question": "What is the purpose of go fmt?",
          "options": [
            "Format strings",
            "Automatically formats Go source code to standard style",
            "Format output",
            "File formatting"
          ],
          "correctAnswer": 1,
          "explanation": "go fmt formats Go source code according to standard style. Ensures consistent code formatting across projects. gofmt is the underlying tool."
        },
        {
          "question": "What does go vet do?",
          "options": [
            "Veterinary checks",
            "Examines code for suspicious constructs and potential bugs",
            "Version check",
            "Validates syntax"
          ],
          "correctAnswer": 1,
          "explanation": "go vet examines Go source code and reports suspicious constructs like unreachable code, incorrect function signatures, or common mistakes. Static analysis tool."
        },
        {
          "question": "Output: What is printed by `fmt.Println(len(make([]int, 2, 5)), cap(make([]int, 2, 5)))`?",
          "options": [
            "2 2",
            "2 5",
            "5 5",
            "0 5"
          ],
          "correctAnswer": 1,
          "explanation": "Length is initialized as 2 while capacity is 5."
        },
        {
          "question": "Output: `m := map[string]int{\"a\":1}; v, ok := m[\"b\"];` what are `v` and `ok`?",
          "options": [
            "1 true",
            "0 false",
            "0 true",
            "panic"
          ],
          "correctAnswer": 1,
          "explanation": "Missing key returns zero value and `ok=false`."
        },
        {
          "question": "Tricky: Which statement about interfaces is correct?",
          "options": [
            "Types must explicitly declare implemented interfaces",
            "Interface implementation is implicit in Go",
            "Only structs can implement interfaces",
            "Interfaces cannot be composed"
          ],
          "correctAnswer": 1,
          "explanation": "Go uses structural typing with implicit interface satisfaction."
        },
        {
          "question": "Tricky: What usually causes goroutine leaks?",
          "options": [
            "Using WaitGroup",
            "Blocked sends/receives with no cancellation path",
            "Using buffered channels",
            "Using select statement"
          ],
          "correctAnswer": 1,
          "explanation": "Leaks happen when goroutines block forever due to missing receiver/sender or no cancellation."
        },
        {
          "question": "Which is idiomatic for operation timeout in Go services?",
          "options": [
            "Infinite retry loop",
            "context.WithTimeout + select/propagation",
            "Thread sleep in loop",
            "panic and recover"
          ],
          "correctAnswer": 1,
          "explanation": "Context-based deadlines are idiomatic for cancellable operations across call boundaries."
        },
        {
          "question": "Output: What prints? `s := []int{1,2}; t := s; t[0]=9; fmt.Println(s[0])`",
          "options": [
            "1",
            "9",
            "0",
            "panic"
          ],
          "correctAnswer": 1,
          "explanation": "Slices share backing arrays, so mutation through one view is visible in the other."
        },
        {
          "question": "Which map operation is concurrency-safe without locking?",
          "options": [
            "Concurrent writes",
            "Concurrent read and write",
            "Only read-only concurrent access",
            "None, not even reads"
          ],
          "correctAnswer": 2,
          "explanation": "Read-only concurrent access is safe; writes require synchronization."
        },
        {
          "question": "Output: What prints? `x := 1; defer fmt.Println(x); x = 2`",
          "options": [
            "1",
            "2",
            "panic",
            "depends"
          ],
          "correctAnswer": 0,
          "explanation": "Deferred call arguments are evaluated at defer time, so it prints original value 1."
        },
        {
          "question": "Which package is standard for SQL abstraction in Go?",
          "options": [
            "database/core",
            "database/sql",
            "sql/go",
            "db/stdlib"
          ],
          "correctAnswer": 1,
          "explanation": "database/sql is the standard SQL abstraction package."
        },
        {
          "question": "sql.Open verifies connectivity immediately?",
          "options": [
            "Yes",
            "No, use Ping/PingContext",
            "Only for postgres",
            "Only after first query"
          ],
          "correctAnswer": 1,
          "explanation": "Use Ping for connectivity check."
        },
        {
          "question": "redis.Nil usually means:",
          "options": [
            "Redis down",
            "Auth failed",
            "Missing key",
            "Timeout"
          ],
          "correctAnswer": 2,
          "explanation": "redis.Nil indicates key not found."
        },
        {
          "question": "Status code for successful creation is:",
          "options": [
            "200",
            "201",
            "204",
            "400"
          ],
          "correctAnswer": 1,
          "explanation": "Use 201 Created."
        },
        {
          "question": "Which built-in may require reassignment of result?",
          "options": [
            "len",
            "cap",
            "append",
            "delete"
          ],
          "correctAnswer": 2,
          "explanation": "append can return a new slice header/backing array."
        },
        {
          "question": "Writing to nil map causes:",
          "options": [
            "No-op",
            "Compile error",
            "Runtime panic",
            "Deadlock"
          ],
          "correctAnswer": 2,
          "explanation": "Nil map write panics."
        },
        {
          "question": "db.QueryRowContext missing row should be checked against:",
          "options": [
            "io.EOF",
            "sql.ErrNoRows",
            "redis.Nil",
            "nil"
          ],
          "correctAnswer": 1,
          "explanation": "Missing SQL row returns sql.ErrNoRows."
        },
        {
          "question": "SetNX behavior in Redis is:",
          "options": [
            "Always overwrite",
            "Set only when key absent",
            "Delete if exists",
            "Set without expiry only"
          ],
          "correctAnswer": 1,
          "explanation": "SetNX writes only if key does not already exist."
        },
        {
          "question": "Malformed JSON request body should usually return:",
          "options": [
            "200",
            "201",
            "400",
            "500"
          ],
          "correctAnswer": 2,
          "explanation": "Malformed body is a client error: 400 Bad Request."
        },
        {
          "question": "Output-oriented: len(make([]int, 0, 5)) equals:",
          "options": [
            "0",
            "5",
            "1",
            "panic"
          ],
          "correctAnswer": 0,
          "explanation": "Length is 0, capacity is 5."
        },
        {
          "question": "Output-oriented: cap(make([]int, 0, 5)) equals:",
          "options": [
            "0",
            "5",
            "1",
            "panic"
          ],
          "correctAnswer": 1,
          "explanation": "Capacity is 5."
        },
        {
          "question": "delete(map, missingKey) behavior is:",
          "options": [
            "panic",
            "no-op",
            "error returned",
            "deletes all keys"
          ],
          "correctAnswer": 1,
          "explanation": "Delete on missing key is safe."
        },
        {
          "question": "Why pass r.Context() to repository layer?",
          "options": [
            "For syntax",
            "For timeout/cancel propagation",
            "For static typing",
            "For panic recovery"
          ],
          "correctAnswer": 1,
          "explanation": "Request context carries deadlines and cancellation."
        }
      ],
      "topicCount": 15,
      "quizCount": 112
    },
    {
      "slug": "javascript",
      "meta": {
        "title": "JavaScript Fundamentals",
        "description": "Master core JavaScript concepts including debouncing, throttling, currying, and async programming with detailed explanations and code implementations"
      },
      "topics": [
        {
          "id": "javascript-practice-150",
          "title": "JavaScript Practice Hub (150+ Exercises)",
          "description": "A cross-topic JavaScript practice bank with output prediction, implementation, and debugging exercises spanning closures, async, prototypes, coercion, and more.",
          "explanation": "This section combines exercises from multiple JavaScript topics into a mixed practice format. Unlike individual topic pages that focus on one concept, these exercises require you to identify which concept is being tested and apply the right knowledge. This simulates real interview conditions where questions jump between topics.\n\nRecommended workflow:\n1. Pick 10 exercises at random\n2. Time yourself (3-5 min per exercise)\n3. Explain your reasoning out loud (interview practice)\n4. Review wrong answers by visiting the relevant topic page\n5. Re-attempt after 24 hours for spaced repetition",
          "implementation": "// Suggested workflow\n// 1) Pick 10 exercises by mixed types\n// 2) Solve with time limit (5-10 min each)\n// 3) Re-solve missed ones without notes\n// 4) Convert best solutions to reusable utilities",
          "example": "// Quick warm-up\nconst arr = [1, 2, 3, 4, 5];\nconst evens = arr.filter(n => n % 2 === 0);\nconst doubled = evens.map(n => n * 2);\nconsole.log(doubled); // [4, 8]",
          "useCase": "Interview preparation, frontend screening rounds, DSA-lite JavaScript practice, and core language mastery.",
          "category": "Complete Practice Guide",
          "interviewQuestions": [
            {
              "question": "How do you choose between map, filter, and reduce?",
              "answer": "Map transforms one-to-one, filter selects subset, reduce accumulates to a single value/structure."
            },
            {
              "question": "What causes most async JavaScript bugs in interviews?",
              "answer": "Not understanding event-loop ordering, missing await, and uncaught promise rejections."
            },
            {
              "question": "When is mutation acceptable in JavaScript code?",
              "answer": "When intentional and localized for performance-critical paths, but immutable style is safer by default."
            },
            {
              "question": "How do you debug closure-related issues?",
              "answer": "Trace lexical scope and captured variables, especially inside loops, timers, and listeners."
            },
            {
              "question": "What is a practical strategy for output prediction questions?",
              "answer": "Evaluate synchronous phase first, then microtasks, then macrotasks."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "What is the output?\nfor (var i = 0; i < 3; i++) {\n  setTimeout(() => console.log(i), 0);\n}",
              "answer": "3, 3, 3 â€” var is function-scoped, all callbacks share the same i which is 3 after the loop"
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(typeof null);\nconsole.log(typeof undefined);\nconsole.log(null == undefined);\nconsole.log(null === undefined);",
              "answer": "object, undefined, true, false â€” typeof null is a historical bug. null loosely equals undefined."
            },
            {
              "type": "output",
              "question": "What is the output?\nconst a = { x: 1 };\nconst b = { x: 1 };\nconsole.log(a === b);\nconsole.log(a == b);",
              "answer": "false, false â€” Objects are compared by reference, not by value. a and b are different objects."
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(1 + '2' + 3);\nconsole.log(1 + 2 + '3');",
              "answer": "'123', '33' â€” First: 1+'2'='12', '12'+3='123'. Second: 1+2=3, 3+'3'='33'."
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction foo() {\n  console.log(this);\n}\nconst obj = { foo };\nobj.foo();\nconst fn = obj.foo;\nfn();",
              "answer": "obj (implicit binding), then undefined in strict mode / window in non-strict (lost binding when assigned to variable)"
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log('start');\nsetTimeout(() => console.log('timeout'), 0);\nPromise.resolve().then(() => console.log('promise'));\nconsole.log('end');",
              "answer": "start, end, promise, timeout â€” Sync first, then microtasks (promise), then macrotasks (setTimeout)"
            },
            {
              "type": "output",
              "question": "What is the output?\nconst arr = [1, 2, 3];\narr[10] = 11;\nconsole.log(arr.length);\nconsole.log(arr.filter(x => x).length);",
              "answer": "11, 4 â€” Array length is 11 (sparse). filter skips empty slots, so only 4 elements: 1,2,3,11"
            },
            {
              "type": "output",
              "question": "What is the output?\nlet x = 10;\nlet y = x;\nx = 20;\nconsole.log(x, y);",
              "answer": "20, 10 â€” Primitives are copied by value. Changing x doesn't affect y."
            },
            {
              "type": "output",
              "question": "What is the output?\nconst obj = { a: 1, b: 2 };\nconst { a: x, b: y } = obj;\nconsole.log(x, y);",
              "answer": "1, 2 â€” Destructuring with renaming: a is renamed to x, b to y."
            },
            {
              "type": "output",
              "question": "What is the output?\n[] + [];\n[] + {};\n{} + [];",
              "answer": "'' (empty string), '[object Object]', '[object Object]' â€” Arrays/objects convert via toString for + operator"
            },
            {
              "type": "output",
              "question": "What is the output?\nconst promise = new Promise((resolve) => {\n  console.log('A');\n  resolve();\n  console.log('B');\n});\npromise.then(() => console.log('C'));\nconsole.log('D');",
              "answer": "A, B, D, C â€” Promise executor runs synchronously. resolve() doesn't stop execution. .then is a microtask."
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction createCounter() {\n  let count = 0;\n  return {\n    inc: () => ++count,\n    get: () => count\n  };\n}\nconst c = createCounter();\nc.inc(); c.inc(); c.inc();\nconsole.log(c.get());",
              "answer": "3 â€” Closure captures count by reference. Three inc() calls increment to 3."
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(0.1 + 0.2 === 0.3);\nconsole.log(0.1 + 0.2);",
              "answer": "false, 0.30000000000000004 â€” IEEE 754 floating point precision issue"
            },
            {
              "type": "output",
              "question": "What is the output?\nconst arr = [1, 2, 3, 4, 5];\nconst [a, , b, ...rest] = arr;\nconsole.log(a, b, rest);",
              "answer": "1, 3, [4, 5] â€” Destructuring: a=1, skip 2, b=3, rest collects remaining"
            },
            {
              "type": "output",
              "question": "What is the output?\nasync function test() {\n  return 1;\n}\nconsole.log(test());\nconsole.log(await test());",
              "answer": "Promise { 1 }, then 1 â€” async always returns Promise. await unwraps it."
            },
            {
              "type": "output",
              "question": "What is the output?\nclass Animal {\n  constructor(name) { this.name = name; }\n  speak() { return `${this.name} speaks`; }\n}\nclass Dog extends Animal {\n  speak() { return `${this.name} barks`; }\n}\nconsole.log(new Dog('Rex').speak());\nconsole.log(new Dog('Rex') instanceof Animal);",
              "answer": "Rex barks, true â€” Dog overrides speak(). instanceof checks prototype chain."
            },
            {
              "type": "output",
              "question": "What is the output?\nconst s = new Set([1, 2, 3, 1, 2]);\nconsole.log(s.size);\ns.add(1);\nconsole.log(s.size);",
              "answer": "3, 3 â€” Set removes duplicates. Adding existing value has no effect."
            },
            {
              "type": "output",
              "question": "What is the output?\nconst m = new Map();\nm.set({}, 'a');\nm.set({}, 'b');\nconsole.log(m.size);",
              "answer": "2 â€” Each {} creates a new object reference, so they're different keys."
            },
            {
              "type": "output",
              "question": "What is the output?\ntry {\n  throw new Error('oops');\n} catch (e) {\n  console.log(e.message);\n} finally {\n  console.log('done');\n}",
              "answer": "oops, done â€” catch handles the error, finally always runs"
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(Boolean(''));\nconsole.log(Boolean('0'));\nconsole.log(Boolean(0));\nconsole.log(Boolean([]));\nconsole.log(Boolean({}));",
              "answer": "false, true, false, true, true â€” '' and 0 are falsy. '0', [], {} are truthy."
            },
            {
              "type": "implement",
              "question": "Implement a debounce function that delays execution until N ms after the last call.",
              "answer": "function debounce(fn, ms) { let timer; return (...args) => { clearTimeout(timer); timer = setTimeout(() => fn(...args), ms); }; }"
            },
            {
              "type": "implement",
              "question": "Implement a function that deep clones an object (handle objects, arrays, dates).",
              "answer": "function deepClone(obj) { if (obj === null || typeof obj !== 'object') return obj; if (obj instanceof Date) return new Date(obj); if (Array.isArray(obj)) return obj.map(deepClone); return Object.fromEntries(Object.entries(obj).map(([k, v]) => [k, deepClone(v)])); }"
            },
            {
              "type": "implement",
              "question": "Implement Array.prototype.myMap without using the built-in map.",
              "answer": "Array.prototype.myMap = function(cb) { const result = []; for (let i = 0; i < this.length; i++) { if (i in this) result[i] = cb(this[i], i, this); } return result; }"
            },
            {
              "type": "implement",
              "question": "Implement a pipe function: pipe(fn1, fn2, fn3)(value) applies functions left to right.",
              "answer": "const pipe = (...fns) => (x) => fns.reduce((v, fn) => fn(v), x);"
            },
            {
              "type": "implement",
              "question": "Implement a function that flattens a nested array to any depth.",
              "answer": "function flatten(arr, depth = Infinity) { return depth > 0 ? arr.reduce((acc, val) => acc.concat(Array.isArray(val) ? flatten(val, depth - 1) : val), []) : arr.slice(); }"
            },
            {
              "type": "debug",
              "question": "Bug: ['1','2','3'].map(parseInt) returns [1, NaN, NaN] instead of [1, 2, 3]. Why and how to fix?",
              "answer": "parseInt receives (element, index) as arguments: parseInt('2', 1) is NaN (base 1 invalid). Fix: .map(s => parseInt(s, 10)) or .map(Number)"
            },
            {
              "type": "debug",
              "question": "Bug: const obj = {a: 1}; const copy = {...obj}; copy.nested = obj.nested; â€” copy.nested changes when obj.nested changes. Why?",
              "answer": "Spread is a shallow copy. Nested objects share references. Fix: use structuredClone(obj) or JSON parse/stringify for deep copy."
            },
            {
              "type": "debug",
              "question": "Bug: async function fetchAll(urls) { urls.forEach(async url => { await fetch(url); }); console.log('done'); } â€” 'done' logs before fetches complete. Why?",
              "answer": "forEach doesn't await async callbacks â€” it fires all and returns immediately. Fix: use for...of loop or await Promise.all(urls.map(url => fetch(url)))."
            },
            {
              "type": "concept",
              "question": "Explain the difference between == and === with examples.",
              "answer": "=== (strict equality) checks type and value without conversion. == (loose equality) coerces types first. Examples: '5' == 5 is true (string coerced to number), '5' === 5 is false (different types). Best practice: always use === unless checking null/undefined (x == null)."
            },
            {
              "type": "concept",
              "question": "What is the event loop and how does it process tasks?",
              "answer": "The event loop checks: 1) Call stack (synchronous code runs first), 2) Microtask queue (Promise.then, queueMicrotask â€” processed after each task, before rendering), 3) Macrotask queue (setTimeout, setInterval â€” one per tick). Microtasks have higher priority than macrotasks."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Implement `promiseAllSettledLimit` with concurrency control.",
              "code": "async function promiseAllSettledLimit(taskFns, limit = 3) {\n  const results = new Array(taskFns.length);\n  let idx = 0;\n\n  async function worker() {\n    while (idx < taskFns.length) {\n      const i = idx++;\n      try {\n        const value = await taskFns[i]();\n        results[i] = { status: 'fulfilled', value };\n      } catch (error) {\n        results[i] = { status: 'rejected', reason: error.message };\n      }\n    }\n  }\n\n  await Promise.all(Array.from({ length: Math.min(limit, taskFns.length) }, worker));\n  return results;\n}\n\nconst wait = (v, ms, fail = false) => () => new Promise((res, rej) => setTimeout(() => fail ? rej(new Error(v)) : res(v), ms));\n(async () => {\n  const out = await promiseAllSettledLimit([wait('A', 30), wait('B', 10, true), wait('C', 5)], 2);\n  console.log(out.map(x => x.status));\n})();",
              "output": "[ 'fulfilled', 'rejected', 'fulfilled' ]",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Build deep equality check supporting objects, arrays, and dates.",
              "code": "function deepEqual(a, b) {\n  if (Object.is(a, b)) return true;\n  if (a instanceof Date && b instanceof Date) return a.getTime() === b.getTime();\n  if (typeof a !== 'object' || typeof b !== 'object' || a === null || b === null) return false;\n  if (Array.isArray(a) !== Array.isArray(b)) return false;\n\n  const keysA = Object.keys(a);\n  const keysB = Object.keys(b);\n  if (keysA.length !== keysB.length) return false;\n\n  for (const k of keysA) {\n    if (!keysB.includes(k)) return false;\n    if (!deepEqual(a[k], b[k])) return false;\n  }\n  return true;\n}\n\nconsole.log(\n  deepEqual({ x: [1, { y: 2 }], d: new Date('2026-01-01') }, { x: [1, { y: 2 }], d: new Date('2026-01-01') })\n);",
              "output": "true",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Implement object diff utility (added/removed/changed keys).",
              "code": "function objectDiff(oldObj, newObj) {\n  const added = [];\n  const removed = [];\n  const changed = [];\n\n  for (const k of Object.keys(oldObj)) {\n    if (!(k in newObj)) removed.push(k);\n    else if (JSON.stringify(oldObj[k]) !== JSON.stringify(newObj[k])) changed.push(k);\n  }\n  for (const k of Object.keys(newObj)) {\n    if (!(k in oldObj)) added.push(k);\n  }\n  return { added, removed, changed };\n}\n\nconsole.log(objectDiff(\n  { a: 1, b: 2, c: { x: 1 } },\n  { a: 1, b: 3, d: true, c: { x: 2 } }\n));",
              "output": "{ added: [ 'd' ], removed: [], changed: [ 'b', 'c' ] }",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Build immutable deep update by path (`setIn`).",
              "code": "function setIn(obj, path, value) {\n  const keys = path.split('.');\n  const out = Array.isArray(obj) ? [...obj] : { ...obj };\n  let cur = out;\n  let src = obj;\n\n  for (let i = 0; i < keys.length - 1; i++) {\n    const k = keys[i];\n    const next = src?.[k];\n    cur[k] = Array.isArray(next) ? [...next] : { ...(next || {}) };\n    cur = cur[k];\n    src = next;\n  }\n  cur[keys[keys.length - 1]] = value;\n  return out;\n}\n\nconst state = { user: { profile: { city: 'Austin' } } };\nconst next = setIn(state, 'user.profile.city', 'Dallas');\nconsole.log(state.user.profile.city, next.user.profile.city, state !== next);",
              "output": "Austin Dallas true",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Implement `groupBy` + aggregate pipeline for sales analytics.",
              "code": "function groupBy(arr, keyFn) {\n  return arr.reduce((m, item) => {\n    const k = keyFn(item);\n    if (!m[k]) m[k] = [];\n    m[k].push(item);\n    return m;\n  }, {});\n}\n\nconst sales = [\n  { region: 'US', amount: 120 },\n  { region: 'EU', amount: 80 },\n  { region: 'US', amount: 30 }\n];\n\nconst grouped = groupBy(sales, x => x.region);\nconst totals = Object.fromEntries(Object.entries(grouped).map(([k, v]) => [k, v.reduce((s, x) => s + x.amount, 0)]));\nconsole.log(totals);",
              "output": "{ US: 150, EU: 80 }",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Write robust CSV parser for quoted fields.",
              "code": "function parseCSVLine(line) {\n  const out = [];\n  let cur = '';\n  let inQuotes = false;\n\n  for (let i = 0; i < line.length; i++) {\n    const ch = line[i];\n    if (ch === '\"') {\n      if (inQuotes && line[i + 1] === '\"') {\n        cur += '\"';\n        i++;\n      } else {\n        inQuotes = !inQuotes;\n      }\n    } else if (ch === ',' && !inQuotes) {\n      out.push(cur);\n      cur = '';\n    } else {\n      cur += ch;\n    }\n  }\n  out.push(cur);\n  return out;\n}\n\nconsole.log(parseCSVLine('1,\"Ada, Lovelace\",Engineer'));",
              "output": "[ '1', 'Ada, Lovelace', 'Engineer' ]",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Build mini template engine with `{{key}}` placeholders.",
              "code": "function renderTemplate(template, data) {\n  return template.replace(/{{s*([w.]+)s*}}/g, (_, path) => {\n    const value = path.split('.').reduce((acc, k) => acc?.[k], data);\n    return value == null ? '' : String(value);\n  });\n}\n\nconst t = 'Hello {{user.name}}, order {{order.id}} is {{order.status}}.';\nconsole.log(renderTemplate(t, { user: { name: 'Alice' }, order: { id: 101, status: 'shipped' } }));",
              "output": "Hello Alice, order 101 is shipped.",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Implement topological sort for dependency graph.",
              "code": "function topoSort(graph) {\n  const indeg = new Map();\n  for (const n of Object.keys(graph)) indeg.set(n, 0);\n  for (const deps of Object.values(graph)) for (const d of deps) indeg.set(d, (indeg.get(d) || 0) + 1);\n\n  const q = [...[...indeg.entries()].filter(([, v]) => v === 0).map(([k]) => k)];\n  const out = [];\n\n  while (q.length) {\n    const n = q.shift();\n    out.push(n);\n    for (const d of graph[n] || []) {\n      indeg.set(d, indeg.get(d) - 1);\n      if (indeg.get(d) === 0) q.push(d);\n    }\n  }\n  return out.length === indeg.size ? out : null;\n}\n\nconsole.log(topoSort({ build: ['test'], test: ['lint'], lint: [] }));",
              "output": "[ 'build', 'test', 'lint' ]",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Implement token bucket rate limiter.",
              "code": "class TokenBucket {\n  constructor(capacity, refillPerSec) {\n    this.capacity = capacity;\n    this.tokens = capacity;\n    this.refillPerSec = refillPerSec;\n    this.last = Date.now();\n  }\n  allow(cost = 1) {\n    const now = Date.now();\n    const elapsed = (now - this.last) / 1000;\n    this.tokens = Math.min(this.capacity, this.tokens + elapsed * this.refillPerSec);\n    this.last = now;\n    if (this.tokens >= cost) {\n      this.tokens -= cost;\n      return true;\n    }\n    return false;\n  }\n}\n\nconst bucket = new TokenBucket(2, 1);\nconsole.log(bucket.allow(), bucket.allow(), bucket.allow());",
              "output": "true true false",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Build Trie with insert/search/prefix methods.",
              "code": "class TrieNode {\n  constructor() { this.next = new Map(); this.end = false; }\n}\nclass Trie {\n  constructor() { this.root = new TrieNode(); }\n  insert(word) {\n    let cur = this.root;\n    for (const ch of word) {\n      if (!cur.next.has(ch)) cur.next.set(ch, new TrieNode());\n      cur = cur.next.get(ch);\n    }\n    cur.end = true;\n  }\n  search(word) {\n    let cur = this.root;\n    for (const ch of word) {\n      if (!cur.next.has(ch)) return false;\n      cur = cur.next.get(ch);\n    }\n    return cur.end;\n  }\n  startsWith(prefix) {\n    let cur = this.root;\n    for (const ch of prefix) {\n      if (!cur.next.has(ch)) return false;\n      cur = cur.next.get(ch);\n    }\n    return true;\n  }\n}\n\nconst t = new Trie();\nt.insert('code'); t.insert('coder');\nconsole.log(t.search('code'), t.search('cod'), t.startsWith('cod'));",
              "output": "true false true",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Build undo/redo state manager (command stack).",
              "code": "class HistoryState {\n  constructor(initial) {\n    this.past = [];\n    this.present = initial;\n    this.future = [];\n  }\n  set(next) {\n    this.past.push(this.present);\n    this.present = next;\n    this.future = [];\n  }\n  undo() {\n    if (!this.past.length) return;\n    this.future.push(this.present);\n    this.present = this.past.pop();\n  }\n  redo() {\n    if (!this.future.length) return;\n    this.past.push(this.present);\n    this.present = this.future.pop();\n  }\n}\n\nconst h = new HistoryState(1);\nh.set(2); h.set(3); h.undo(); h.undo(); h.redo();\nconsole.log(h.present);",
              "output": "2",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Implement async queue with pause/resume and worker.",
              "code": "class AsyncQueue {\n  constructor(worker) {\n    this.worker = worker;\n    this.q = [];\n    this.running = false;\n    this.paused = false;\n  }\n  push(item) {\n    this.q.push(item);\n    this.drain();\n  }\n  pause() { this.paused = true; }\n  resume() { this.paused = false; this.drain(); }\n  async drain() {\n    if (this.running || this.paused) return;\n    this.running = true;\n    while (this.q.length && !this.paused) {\n      const item = this.q.shift();\n      await this.worker(item);\n    }\n    this.running = false;\n  }\n}\n\nconst out = [];\nconst aq = new AsyncQueue(async x => { out.push(x * 2); });\naq.push(1); aq.push(2); aq.push(3);\nsetTimeout(() => console.log(out), 10);",
              "output": "[ 2, 4, 6 ]",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Implement paginated fetch iterator over async source.",
              "code": "async function* paginate(fetchPage) {\n  let page = 1;\n  while (true) {\n    const { items, hasNext } = await fetchPage(page);\n    for (const item of items) yield item;\n    if (!hasNext) break;\n    page++;\n  }\n}\n\n(async () => {\n  const source = {\n    1: { items: [1, 2], hasNext: true },\n    2: { items: [3, 4], hasNext: false }\n  };\n  const out = [];\n  for await (const v of paginate(async p => source[p])) out.push(v);\n  console.log(out);\n})();",
              "output": "[ 1, 2, 3, 4 ]",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Build safe JSON parser with validation and defaults.",
              "code": "function parseConfig(input, schema) {\n  let raw;\n  try { raw = JSON.parse(input); } catch { raw = {}; }\n  const out = {};\n  for (const [k, rule] of Object.entries(schema)) {\n    const v = raw[k];\n    if (v == null) out[k] = rule.default;\n    else if (typeof v === rule.type) out[k] = v;\n    else out[k] = rule.default;\n  }\n  return out;\n}\n\nconst schema = { retries: { type: 'number', default: 3 }, mode: { type: 'string', default: 'safe' } };\nconsole.log(parseConfig('{\"retries\":5,\"mode\":\"fast\"}', schema));",
              "output": "{ retries: 5, mode: 'fast' }",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Build binary search over sorted array of objects by key.",
              "code": "function binarySearchBy(arr, key, target) {\n  let l = 0, r = arr.length - 1;\n  while (l <= r) {\n    const m = (l + r) >> 1;\n    if (arr[m][key] === target) return m;\n    if (arr[m][key] < target) l = m + 1;\n    else r = m - 1;\n  }\n  return -1;\n}\n\nconst users = [{ id: 10 }, { id: 20 }, { id: 30 }, { id: 40 }];\nconsole.log(binarySearchBy(users, 'id', 30));",
              "output": "2",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Implement interval scheduler for maximum non-overlap jobs.",
              "code": "function maxNonOverlapping(intervals) {\n  intervals.sort((a, b) => a[1] - b[1]);\n  const selected = [];\n  let end = -Infinity;\n  for (const [s, e] of intervals) {\n    if (s >= end) {\n      selected.push([s, e]);\n      end = e;\n    }\n  }\n  return selected;\n}\n\nconsole.log(maxNonOverlapping([[1,3],[2,5],[4,6],[6,7]]));",
              "output": "[ [ 1, 3 ], [ 4, 6 ], [ 6, 7 ] ]",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Build path matcher with params (`/users/:id/orders/:oid`).",
              "code": "function matchRoute(pattern, path) {\n  const p1 = pattern.split('/').filter(Boolean);\n  const p2 = path.split('/').filter(Boolean);\n  if (p1.length !== p2.length) return null;\n  const params = {};\n  for (let i = 0; i < p1.length; i++) {\n    if (p1[i].startsWith(':')) params[p1[i].slice(1)] = p2[i];\n    else if (p1[i] !== p2[i]) return null;\n  }\n  return params;\n}\n\nconsole.log(matchRoute('/users/:id/orders/:oid', '/users/42/orders/900'));",
              "output": "{ id: '42', oid: '900' }",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Implement custom `Promise.any` polyfill.",
              "code": "function promiseAny(promises) {\n  return new Promise((resolve, reject) => {\n    let rejected = 0;\n    const errs = [];\n    promises.forEach((p, i) => {\n      Promise.resolve(p)\n        .then(resolve)\n        .catch(e => {\n          errs[i] = e;\n          rejected++;\n          if (rejected === promises.length) reject(new AggregateError(errs, 'All promises were rejected'));\n        });\n    });\n  });\n}\n\npromiseAny([Promise.reject('x'), Promise.resolve('ok'), Promise.reject('y')]).then(console.log);",
              "output": "ok",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Build LCS (longest common subsequence) dynamic programming.",
              "code": "function lcs(a, b) {\n  const dp = Array.from({ length: a.length + 1 }, () => Array(b.length + 1).fill(0));\n  for (let i = 1; i <= a.length; i++) {\n    for (let j = 1; j <= b.length; j++) {\n      if (a[i - 1] === b[j - 1]) dp[i][j] = dp[i - 1][j - 1] + 1;\n      else dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);\n    }\n  }\n  return dp[a.length][b.length];\n}\n\nconsole.log(lcs('ABCBDAB', 'BDCAB'));",
              "output": "4",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Implement rolling logger with max size and severity filter.",
              "code": "class RollingLogger {\n  constructor(max = 5) {\n    this.max = max;\n    this.rows = [];\n  }\n  log(level, msg) {\n    this.rows.push({ level, msg });\n    if (this.rows.length > this.max) this.rows.shift();\n  }\n  get(minLevel = 'debug') {\n    const order = { debug: 1, info: 2, warn: 3, error: 4 };\n    return this.rows.filter(r => order[r.level] >= order[minLevel]);\n  }\n}\n\nconst lg = new RollingLogger(3);\nlg.log('info', 'a'); lg.log('warn', 'b'); lg.log('error', 'c'); lg.log('debug', 'd');\nconsole.log(lg.get('warn'));",
              "output": "[ { level: 'warn', msg: 'b' }, { level: 'error', msg: 'c' } ]",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Implement `promiseAllSettledLimit` with concurrency control.",
              "code": "async function promiseAllSettledLimit(taskFns, limit = 3) {\n  const results = new Array(taskFns.length);\n  let idx = 0;\n\n  async function worker() {\n    while (idx < taskFns.length) {\n      const i = idx++;\n      try {\n        const value = await taskFns[i]();\n        results[i] = { status: 'fulfilled', value };\n      } catch (error) {\n        results[i] = { status: 'rejected', reason: error.message };\n      }\n    }\n  }\n\n  await Promise.all(Array.from({ length: Math.min(limit, taskFns.length) }, worker));\n  return results;\n}\n\nconst wait = (v, ms, fail = false) => () => new Promise((res, rej) => setTimeout(() => fail ? rej(new Error(v)) : res(v), ms));\n(async () => {\n  const out = await promiseAllSettledLimit([wait('A', 30), wait('B', 10, true), wait('C', 5)], 2);\n  console.log(out.map(x => x.status));\n})();",
              "output": "[ 'fulfilled', 'rejected', 'fulfilled' ]",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Build deep equality check supporting objects, arrays, and dates.",
              "code": "function deepEqual(a, b) {\n  if (Object.is(a, b)) return true;\n  if (a instanceof Date && b instanceof Date) return a.getTime() === b.getTime();\n  if (typeof a !== 'object' || typeof b !== 'object' || a === null || b === null) return false;\n  if (Array.isArray(a) !== Array.isArray(b)) return false;\n\n  const keysA = Object.keys(a);\n  const keysB = Object.keys(b);\n  if (keysA.length !== keysB.length) return false;\n\n  for (const k of keysA) {\n    if (!keysB.includes(k)) return false;\n    if (!deepEqual(a[k], b[k])) return false;\n  }\n  return true;\n}\n\nconsole.log(\n  deepEqual({ x: [1, { y: 2 }], d: new Date('2026-01-01') }, { x: [1, { y: 2 }], d: new Date('2026-01-01') })\n);",
              "output": "true",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Implement object diff utility (added/removed/changed keys).",
              "code": "function objectDiff(oldObj, newObj) {\n  const added = [];\n  const removed = [];\n  const changed = [];\n\n  for (const k of Object.keys(oldObj)) {\n    if (!(k in newObj)) removed.push(k);\n    else if (JSON.stringify(oldObj[k]) !== JSON.stringify(newObj[k])) changed.push(k);\n  }\n  for (const k of Object.keys(newObj)) {\n    if (!(k in oldObj)) added.push(k);\n  }\n  return { added, removed, changed };\n}\n\nconsole.log(objectDiff(\n  { a: 1, b: 2, c: { x: 1 } },\n  { a: 1, b: 3, d: true, c: { x: 2 } }\n));",
              "output": "{ added: [ 'd' ], removed: [], changed: [ 'b', 'c' ] }",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Build immutable deep update by path (`setIn`).",
              "code": "function setIn(obj, path, value) {\n  const keys = path.split('.');\n  const out = Array.isArray(obj) ? [...obj] : { ...obj };\n  let cur = out;\n  let src = obj;\n\n  for (let i = 0; i < keys.length - 1; i++) {\n    const k = keys[i];\n    const next = src?.[k];\n    cur[k] = Array.isArray(next) ? [...next] : { ...(next || {}) };\n    cur = cur[k];\n    src = next;\n  }\n  cur[keys[keys.length - 1]] = value;\n  return out;\n}\n\nconst state = { user: { profile: { city: 'Austin' } } };\nconst next = setIn(state, 'user.profile.city', 'Dallas');\nconsole.log(state.user.profile.city, next.user.profile.city, state !== next);",
              "output": "Austin Dallas true",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Implement `groupBy` + aggregate pipeline for sales analytics.",
              "code": "function groupBy(arr, keyFn) {\n  return arr.reduce((m, item) => {\n    const k = keyFn(item);\n    if (!m[k]) m[k] = [];\n    m[k].push(item);\n    return m;\n  }, {});\n}\n\nconst sales = [\n  { region: 'US', amount: 120 },\n  { region: 'EU', amount: 80 },\n  { region: 'US', amount: 30 }\n];\n\nconst grouped = groupBy(sales, x => x.region);\nconst totals = Object.fromEntries(Object.entries(grouped).map(([k, v]) => [k, v.reduce((s, x) => s + x.amount, 0)]));\nconsole.log(totals);",
              "output": "{ US: 150, EU: 80 }",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Write robust CSV parser for quoted fields.",
              "code": "function parseCSVLine(line) {\n  const out = [];\n  let cur = '';\n  let inQuotes = false;\n\n  for (let i = 0; i < line.length; i++) {\n    const ch = line[i];\n    if (ch === '\"') {\n      if (inQuotes && line[i + 1] === '\"') {\n        cur += '\"';\n        i++;\n      } else {\n        inQuotes = !inQuotes;\n      }\n    } else if (ch === ',' && !inQuotes) {\n      out.push(cur);\n      cur = '';\n    } else {\n      cur += ch;\n    }\n  }\n  out.push(cur);\n  return out;\n}\n\nconsole.log(parseCSVLine('1,\"Ada, Lovelace\",Engineer'));",
              "output": "[ '1', 'Ada, Lovelace', 'Engineer' ]",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Build mini template engine with `{{key}}` placeholders.",
              "code": "function renderTemplate(template, data) {\n  return template.replace(/{{s*([w.]+)s*}}/g, (_, path) => {\n    const value = path.split('.').reduce((acc, k) => acc?.[k], data);\n    return value == null ? '' : String(value);\n  });\n}\n\nconst t = 'Hello {{user.name}}, order {{order.id}} is {{order.status}}.';\nconsole.log(renderTemplate(t, { user: { name: 'Alice' }, order: { id: 101, status: 'shipped' } }));",
              "output": "Hello Alice, order 101 is shipped.",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Implement topological sort for dependency graph.",
              "code": "function topoSort(graph) {\n  const indeg = new Map();\n  for (const n of Object.keys(graph)) indeg.set(n, 0);\n  for (const deps of Object.values(graph)) for (const d of deps) indeg.set(d, (indeg.get(d) || 0) + 1);\n\n  const q = [...[...indeg.entries()].filter(([, v]) => v === 0).map(([k]) => k)];\n  const out = [];\n\n  while (q.length) {\n    const n = q.shift();\n    out.push(n);\n    for (const d of graph[n] || []) {\n      indeg.set(d, indeg.get(d) - 1);\n      if (indeg.get(d) === 0) q.push(d);\n    }\n  }\n  return out.length === indeg.size ? out : null;\n}\n\nconsole.log(topoSort({ build: ['test'], test: ['lint'], lint: [] }));",
              "output": "[ 'build', 'test', 'lint' ]",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Implement token bucket rate limiter.",
              "code": "class TokenBucket {\n  constructor(capacity, refillPerSec) {\n    this.capacity = capacity;\n    this.tokens = capacity;\n    this.refillPerSec = refillPerSec;\n    this.last = Date.now();\n  }\n  allow(cost = 1) {\n    const now = Date.now();\n    const elapsed = (now - this.last) / 1000;\n    this.tokens = Math.min(this.capacity, this.tokens + elapsed * this.refillPerSec);\n    this.last = now;\n    if (this.tokens >= cost) {\n      this.tokens -= cost;\n      return true;\n    }\n    return false;\n  }\n}\n\nconst bucket = new TokenBucket(2, 1);\nconsole.log(bucket.allow(), bucket.allow(), bucket.allow());",
              "output": "true true false",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Build Trie with insert/search/prefix methods.",
              "code": "class TrieNode {\n  constructor() { this.next = new Map(); this.end = false; }\n}\nclass Trie {\n  constructor() { this.root = new TrieNode(); }\n  insert(word) {\n    let cur = this.root;\n    for (const ch of word) {\n      if (!cur.next.has(ch)) cur.next.set(ch, new TrieNode());\n      cur = cur.next.get(ch);\n    }\n    cur.end = true;\n  }\n  search(word) {\n    let cur = this.root;\n    for (const ch of word) {\n      if (!cur.next.has(ch)) return false;\n      cur = cur.next.get(ch);\n    }\n    return cur.end;\n  }\n  startsWith(prefix) {\n    let cur = this.root;\n    for (const ch of prefix) {\n      if (!cur.next.has(ch)) return false;\n      cur = cur.next.get(ch);\n    }\n    return true;\n  }\n}\n\nconst t = new Trie();\nt.insert('code'); t.insert('coder');\nconsole.log(t.search('code'), t.search('cod'), t.startsWith('cod'));",
              "output": "true false true",
              "level": "Medium"
            },
            {
              "type": "program",
              "question": "Edge-safe Build undo/redo state manager (command stack).",
              "code": "class HistoryState {\n  constructor(initial) {\n    this.past = [];\n    this.present = initial;\n    this.future = [];\n  }\n  set(next) {\n    this.past.push(this.present);\n    this.present = next;\n    this.future = [];\n  }\n  undo() {\n    if (!this.past.length) return;\n    this.future.push(this.present);\n    this.present = this.past.pop();\n  }\n  redo() {\n    if (!this.future.length) return;\n    this.past.push(this.present);\n    this.present = this.future.pop();\n  }\n}\n\nconst h = new HistoryState(1);\nh.set(2); h.set(3); h.undo(); h.undo(); h.redo();\nconsole.log(h.present);",
              "output": "2",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Production-ready Implement async queue with pause/resume and worker.",
              "code": "class AsyncQueue {\n  constructor(worker) {\n    this.worker = worker;\n    this.q = [];\n    this.running = false;\n    this.paused = false;\n  }\n  push(item) {\n    this.q.push(item);\n    this.drain();\n  }\n  pause() { this.paused = true; }\n  resume() { this.paused = false; this.drain(); }\n  async drain() {\n    if (this.running || this.paused) return;\n    this.running = true;\n    while (this.q.length && !this.paused) {\n      const item = this.q.shift();\n      await this.worker(item);\n    }\n    this.running = false;\n  }\n}\n\nconst out = [];\nconst aq = new AsyncQueue(async x => { out.push(x * 2); });\naq.push(1); aq.push(2); aq.push(3);\nsetTimeout(() => console.log(out), 10);",
              "output": "[ 2, 4, 6 ]",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Optimized Implement paginated fetch iterator over async source.",
              "code": "async function* paginate(fetchPage) {\n  let page = 1;\n  while (true) {\n    const { items, hasNext } = await fetchPage(page);\n    for (const item of items) yield item;\n    if (!hasNext) break;\n    page++;\n  }\n}\n\n(async () => {\n  const source = {\n    1: { items: [1, 2], hasNext: true },\n    2: { items: [3, 4], hasNext: false }\n  };\n  const out = [];\n  for await (const v of paginate(async p => source[p])) out.push(v);\n  console.log(out);\n})();",
              "output": "[ 1, 2, 3, 4 ]",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Concurrency-aware Build safe JSON parser with validation and defaults.",
              "code": "function parseConfig(input, schema) {\n  let raw;\n  try { raw = JSON.parse(input); } catch { raw = {}; }\n  const out = {};\n  for (const [k, rule] of Object.entries(schema)) {\n    const v = raw[k];\n    if (v == null) out[k] = rule.default;\n    else if (typeof v === rule.type) out[k] = v;\n    else out[k] = rule.default;\n  }\n  return out;\n}\n\nconst schema = { retries: { type: 'number', default: 3 }, mode: { type: 'string', default: 'safe' } };\nconsole.log(parseConfig('{\"retries\":5,\"mode\":\"fast\"}', schema));",
              "output": "{ retries: 5, mode: 'fast' }",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Fault-tolerant Build binary search over sorted array of objects by key.",
              "code": "function binarySearchBy(arr, key, target) {\n  let l = 0, r = arr.length - 1;\n  while (l <= r) {\n    const m = (l + r) >> 1;\n    if (arr[m][key] === target) return m;\n    if (arr[m][key] < target) l = m + 1;\n    else r = m - 1;\n  }\n  return -1;\n}\n\nconst users = [{ id: 10 }, { id: 20 }, { id: 30 }, { id: 40 }];\nconsole.log(binarySearchBy(users, 'id', 30));",
              "output": "2",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Edge-safe Implement interval scheduler for maximum non-overlap jobs.",
              "code": "function maxNonOverlapping(intervals) {\n  intervals.sort((a, b) => a[1] - b[1]);\n  const selected = [];\n  let end = -Infinity;\n  for (const [s, e] of intervals) {\n    if (s >= end) {\n      selected.push([s, e]);\n      end = e;\n    }\n  }\n  return selected;\n}\n\nconsole.log(maxNonOverlapping([[1,3],[2,5],[4,6],[6,7]]));",
              "output": "[ [ 1, 3 ], [ 4, 6 ], [ 6, 7 ] ]",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Production-ready Build path matcher with params (`/users/:id/orders/:oid`).",
              "code": "function matchRoute(pattern, path) {\n  const p1 = pattern.split('/').filter(Boolean);\n  const p2 = path.split('/').filter(Boolean);\n  if (p1.length !== p2.length) return null;\n  const params = {};\n  for (let i = 0; i < p1.length; i++) {\n    if (p1[i].startsWith(':')) params[p1[i].slice(1)] = p2[i];\n    else if (p1[i] !== p2[i]) return null;\n  }\n  return params;\n}\n\nconsole.log(matchRoute('/users/:id/orders/:oid', '/users/42/orders/900'));",
              "output": "{ id: '42', oid: '900' }",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Optimized Implement custom `Promise.any` polyfill.",
              "code": "function promiseAny(promises) {\n  return new Promise((resolve, reject) => {\n    let rejected = 0;\n    const errs = [];\n    promises.forEach((p, i) => {\n      Promise.resolve(p)\n        .then(resolve)\n        .catch(e => {\n          errs[i] = e;\n          rejected++;\n          if (rejected === promises.length) reject(new AggregateError(errs, 'All promises were rejected'));\n        });\n    });\n  });\n}\n\npromiseAny([Promise.reject('x'), Promise.resolve('ok'), Promise.reject('y')]).then(console.log);",
              "output": "ok",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Concurrency-aware Build LCS (longest common subsequence) dynamic programming.",
              "code": "function lcs(a, b) {\n  const dp = Array.from({ length: a.length + 1 }, () => Array(b.length + 1).fill(0));\n  for (let i = 1; i <= a.length; i++) {\n    for (let j = 1; j <= b.length; j++) {\n      if (a[i - 1] === b[j - 1]) dp[i][j] = dp[i - 1][j - 1] + 1;\n      else dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);\n    }\n  }\n  return dp[a.length][b.length];\n}\n\nconsole.log(lcs('ABCBDAB', 'BDCAB'));",
              "output": "4",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Fault-tolerant Implement rolling logger with max size and severity filter.",
              "code": "class RollingLogger {\n  constructor(max = 5) {\n    this.max = max;\n    this.rows = [];\n  }\n  log(level, msg) {\n    this.rows.push({ level, msg });\n    if (this.rows.length > this.max) this.rows.shift();\n  }\n  get(minLevel = 'debug') {\n    const order = { debug: 1, info: 2, warn: 3, error: 4 };\n    return this.rows.filter(r => order[r.level] >= order[minLevel]);\n  }\n}\n\nconst lg = new RollingLogger(3);\nlg.log('info', 'a'); lg.log('warn', 'b'); lg.log('error', 'c'); lg.log('debug', 'd');\nconsole.log(lg.get('warn'));",
              "output": "[ { level: 'warn', msg: 'b' }, { level: 'error', msg: 'c' } ]",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Edge-safe Implement `promiseAllSettledLimit` with concurrency control.",
              "code": "async function promiseAllSettledLimit(taskFns, limit = 3) {\n  const results = new Array(taskFns.length);\n  let idx = 0;\n\n  async function worker() {\n    while (idx < taskFns.length) {\n      const i = idx++;\n      try {\n        const value = await taskFns[i]();\n        results[i] = { status: 'fulfilled', value };\n      } catch (error) {\n        results[i] = { status: 'rejected', reason: error.message };\n      }\n    }\n  }\n\n  await Promise.all(Array.from({ length: Math.min(limit, taskFns.length) }, worker));\n  return results;\n}\n\nconst wait = (v, ms, fail = false) => () => new Promise((res, rej) => setTimeout(() => fail ? rej(new Error(v)) : res(v), ms));\n(async () => {\n  const out = await promiseAllSettledLimit([wait('A', 30), wait('B', 10, true), wait('C', 5)], 2);\n  console.log(out.map(x => x.status));\n})();",
              "output": "[ 'fulfilled', 'rejected', 'fulfilled' ]",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Production-ready Build deep equality check supporting objects, arrays, and dates.",
              "code": "function deepEqual(a, b) {\n  if (Object.is(a, b)) return true;\n  if (a instanceof Date && b instanceof Date) return a.getTime() === b.getTime();\n  if (typeof a !== 'object' || typeof b !== 'object' || a === null || b === null) return false;\n  if (Array.isArray(a) !== Array.isArray(b)) return false;\n\n  const keysA = Object.keys(a);\n  const keysB = Object.keys(b);\n  if (keysA.length !== keysB.length) return false;\n\n  for (const k of keysA) {\n    if (!keysB.includes(k)) return false;\n    if (!deepEqual(a[k], b[k])) return false;\n  }\n  return true;\n}\n\nconsole.log(\n  deepEqual({ x: [1, { y: 2 }], d: new Date('2026-01-01') }, { x: [1, { y: 2 }], d: new Date('2026-01-01') })\n);",
              "output": "true",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Optimized Implement object diff utility (added/removed/changed keys).",
              "code": "function objectDiff(oldObj, newObj) {\n  const added = [];\n  const removed = [];\n  const changed = [];\n\n  for (const k of Object.keys(oldObj)) {\n    if (!(k in newObj)) removed.push(k);\n    else if (JSON.stringify(oldObj[k]) !== JSON.stringify(newObj[k])) changed.push(k);\n  }\n  for (const k of Object.keys(newObj)) {\n    if (!(k in oldObj)) added.push(k);\n  }\n  return { added, removed, changed };\n}\n\nconsole.log(objectDiff(\n  { a: 1, b: 2, c: { x: 1 } },\n  { a: 1, b: 3, d: true, c: { x: 2 } }\n));",
              "output": "{ added: [ 'd' ], removed: [], changed: [ 'b', 'c' ] }",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Concurrency-aware Build immutable deep update by path (`setIn`).",
              "code": "function setIn(obj, path, value) {\n  const keys = path.split('.');\n  const out = Array.isArray(obj) ? [...obj] : { ...obj };\n  let cur = out;\n  let src = obj;\n\n  for (let i = 0; i < keys.length - 1; i++) {\n    const k = keys[i];\n    const next = src?.[k];\n    cur[k] = Array.isArray(next) ? [...next] : { ...(next || {}) };\n    cur = cur[k];\n    src = next;\n  }\n  cur[keys[keys.length - 1]] = value;\n  return out;\n}\n\nconst state = { user: { profile: { city: 'Austin' } } };\nconst next = setIn(state, 'user.profile.city', 'Dallas');\nconsole.log(state.user.profile.city, next.user.profile.city, state !== next);",
              "output": "Austin Dallas true",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Fault-tolerant Implement `groupBy` + aggregate pipeline for sales analytics.",
              "code": "function groupBy(arr, keyFn) {\n  return arr.reduce((m, item) => {\n    const k = keyFn(item);\n    if (!m[k]) m[k] = [];\n    m[k].push(item);\n    return m;\n  }, {});\n}\n\nconst sales = [\n  { region: 'US', amount: 120 },\n  { region: 'EU', amount: 80 },\n  { region: 'US', amount: 30 }\n];\n\nconst grouped = groupBy(sales, x => x.region);\nconst totals = Object.fromEntries(Object.entries(grouped).map(([k, v]) => [k, v.reduce((s, x) => s + x.amount, 0)]));\nconsole.log(totals);",
              "output": "{ US: 150, EU: 80 }",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Edge-safe Write robust CSV parser for quoted fields.",
              "code": "function parseCSVLine(line) {\n  const out = [];\n  let cur = '';\n  let inQuotes = false;\n\n  for (let i = 0; i < line.length; i++) {\n    const ch = line[i];\n    if (ch === '\"') {\n      if (inQuotes && line[i + 1] === '\"') {\n        cur += '\"';\n        i++;\n      } else {\n        inQuotes = !inQuotes;\n      }\n    } else if (ch === ',' && !inQuotes) {\n      out.push(cur);\n      cur = '';\n    } else {\n      cur += ch;\n    }\n  }\n  out.push(cur);\n  return out;\n}\n\nconsole.log(parseCSVLine('1,\"Ada, Lovelace\",Engineer'));",
              "output": "[ '1', 'Ada, Lovelace', 'Engineer' ]",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Production-ready Build mini template engine with `{{key}}` placeholders.",
              "code": "function renderTemplate(template, data) {\n  return template.replace(/{{s*([w.]+)s*}}/g, (_, path) => {\n    const value = path.split('.').reduce((acc, k) => acc?.[k], data);\n    return value == null ? '' : String(value);\n  });\n}\n\nconst t = 'Hello {{user.name}}, order {{order.id}} is {{order.status}}.';\nconsole.log(renderTemplate(t, { user: { name: 'Alice' }, order: { id: 101, status: 'shipped' } }));",
              "output": "Hello Alice, order 101 is shipped.",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Optimized Implement topological sort for dependency graph.",
              "code": "function topoSort(graph) {\n  const indeg = new Map();\n  for (const n of Object.keys(graph)) indeg.set(n, 0);\n  for (const deps of Object.values(graph)) for (const d of deps) indeg.set(d, (indeg.get(d) || 0) + 1);\n\n  const q = [...[...indeg.entries()].filter(([, v]) => v === 0).map(([k]) => k)];\n  const out = [];\n\n  while (q.length) {\n    const n = q.shift();\n    out.push(n);\n    for (const d of graph[n] || []) {\n      indeg.set(d, indeg.get(d) - 1);\n      if (indeg.get(d) === 0) q.push(d);\n    }\n  }\n  return out.length === indeg.size ? out : null;\n}\n\nconsole.log(topoSort({ build: ['test'], test: ['lint'], lint: [] }));",
              "output": "[ 'build', 'test', 'lint' ]",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Concurrency-aware Implement token bucket rate limiter.",
              "code": "class TokenBucket {\n  constructor(capacity, refillPerSec) {\n    this.capacity = capacity;\n    this.tokens = capacity;\n    this.refillPerSec = refillPerSec;\n    this.last = Date.now();\n  }\n  allow(cost = 1) {\n    const now = Date.now();\n    const elapsed = (now - this.last) / 1000;\n    this.tokens = Math.min(this.capacity, this.tokens + elapsed * this.refillPerSec);\n    this.last = now;\n    if (this.tokens >= cost) {\n      this.tokens -= cost;\n      return true;\n    }\n    return false;\n  }\n}\n\nconst bucket = new TokenBucket(2, 1);\nconsole.log(bucket.allow(), bucket.allow(), bucket.allow());",
              "output": "true true false",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Fault-tolerant Build Trie with insert/search/prefix methods.",
              "code": "class TrieNode {\n  constructor() { this.next = new Map(); this.end = false; }\n}\nclass Trie {\n  constructor() { this.root = new TrieNode(); }\n  insert(word) {\n    let cur = this.root;\n    for (const ch of word) {\n      if (!cur.next.has(ch)) cur.next.set(ch, new TrieNode());\n      cur = cur.next.get(ch);\n    }\n    cur.end = true;\n  }\n  search(word) {\n    let cur = this.root;\n    for (const ch of word) {\n      if (!cur.next.has(ch)) return false;\n      cur = cur.next.get(ch);\n    }\n    return cur.end;\n  }\n  startsWith(prefix) {\n    let cur = this.root;\n    for (const ch of prefix) {\n      if (!cur.next.has(ch)) return false;\n      cur = cur.next.get(ch);\n    }\n    return true;\n  }\n}\n\nconst t = new Trie();\nt.insert('code'); t.insert('coder');\nconsole.log(t.search('code'), t.search('cod'), t.startsWith('cod'));",
              "output": "true false true",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Edge-safe Build undo/redo state manager (command stack).",
              "code": "class HistoryState {\n  constructor(initial) {\n    this.past = [];\n    this.present = initial;\n    this.future = [];\n  }\n  set(next) {\n    this.past.push(this.present);\n    this.present = next;\n    this.future = [];\n  }\n  undo() {\n    if (!this.past.length) return;\n    this.future.push(this.present);\n    this.present = this.past.pop();\n  }\n  redo() {\n    if (!this.future.length) return;\n    this.past.push(this.present);\n    this.present = this.future.pop();\n  }\n}\n\nconst h = new HistoryState(1);\nh.set(2); h.set(3); h.undo(); h.undo(); h.redo();\nconsole.log(h.present);",
              "output": "2",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Production-ready Implement async queue with pause/resume and worker.",
              "code": "class AsyncQueue {\n  constructor(worker) {\n    this.worker = worker;\n    this.q = [];\n    this.running = false;\n    this.paused = false;\n  }\n  push(item) {\n    this.q.push(item);\n    this.drain();\n  }\n  pause() { this.paused = true; }\n  resume() { this.paused = false; this.drain(); }\n  async drain() {\n    if (this.running || this.paused) return;\n    this.running = true;\n    while (this.q.length && !this.paused) {\n      const item = this.q.shift();\n      await this.worker(item);\n    }\n    this.running = false;\n  }\n}\n\nconst out = [];\nconst aq = new AsyncQueue(async x => { out.push(x * 2); });\naq.push(1); aq.push(2); aq.push(3);\nsetTimeout(() => console.log(out), 10);",
              "output": "[ 2, 4, 6 ]",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Optimized Implement paginated fetch iterator over async source.",
              "code": "async function* paginate(fetchPage) {\n  let page = 1;\n  while (true) {\n    const { items, hasNext } = await fetchPage(page);\n    for (const item of items) yield item;\n    if (!hasNext) break;\n    page++;\n  }\n}\n\n(async () => {\n  const source = {\n    1: { items: [1, 2], hasNext: true },\n    2: { items: [3, 4], hasNext: false }\n  };\n  const out = [];\n  for await (const v of paginate(async p => source[p])) out.push(v);\n  console.log(out);\n})();",
              "output": "[ 1, 2, 3, 4 ]",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Concurrency-aware Build safe JSON parser with validation and defaults.",
              "code": "function parseConfig(input, schema) {\n  let raw;\n  try { raw = JSON.parse(input); } catch { raw = {}; }\n  const out = {};\n  for (const [k, rule] of Object.entries(schema)) {\n    const v = raw[k];\n    if (v == null) out[k] = rule.default;\n    else if (typeof v === rule.type) out[k] = v;\n    else out[k] = rule.default;\n  }\n  return out;\n}\n\nconst schema = { retries: { type: 'number', default: 3 }, mode: { type: 'string', default: 'safe' } };\nconsole.log(parseConfig('{\"retries\":5,\"mode\":\"fast\"}', schema));",
              "output": "{ retries: 5, mode: 'fast' }",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Fault-tolerant Build binary search over sorted array of objects by key.",
              "code": "function binarySearchBy(arr, key, target) {\n  let l = 0, r = arr.length - 1;\n  while (l <= r) {\n    const m = (l + r) >> 1;\n    if (arr[m][key] === target) return m;\n    if (arr[m][key] < target) l = m + 1;\n    else r = m - 1;\n  }\n  return -1;\n}\n\nconst users = [{ id: 10 }, { id: 20 }, { id: 30 }, { id: 40 }];\nconsole.log(binarySearchBy(users, 'id', 30));",
              "output": "2",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Edge-safe Implement interval scheduler for maximum non-overlap jobs.",
              "code": "function maxNonOverlapping(intervals) {\n  intervals.sort((a, b) => a[1] - b[1]);\n  const selected = [];\n  let end = -Infinity;\n  for (const [s, e] of intervals) {\n    if (s >= end) {\n      selected.push([s, e]);\n      end = e;\n    }\n  }\n  return selected;\n}\n\nconsole.log(maxNonOverlapping([[1,3],[2,5],[4,6],[6,7]]));",
              "output": "[ [ 1, 3 ], [ 4, 6 ], [ 6, 7 ] ]",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Production-ready Build path matcher with params (`/users/:id/orders/:oid`).",
              "code": "function matchRoute(pattern, path) {\n  const p1 = pattern.split('/').filter(Boolean);\n  const p2 = path.split('/').filter(Boolean);\n  if (p1.length !== p2.length) return null;\n  const params = {};\n  for (let i = 0; i < p1.length; i++) {\n    if (p1[i].startsWith(':')) params[p1[i].slice(1)] = p2[i];\n    else if (p1[i] !== p2[i]) return null;\n  }\n  return params;\n}\n\nconsole.log(matchRoute('/users/:id/orders/:oid', '/users/42/orders/900'));",
              "output": "{ id: '42', oid: '900' }",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Optimized Implement custom `Promise.any` polyfill.",
              "code": "function promiseAny(promises) {\n  return new Promise((resolve, reject) => {\n    let rejected = 0;\n    const errs = [];\n    promises.forEach((p, i) => {\n      Promise.resolve(p)\n        .then(resolve)\n        .catch(e => {\n          errs[i] = e;\n          rejected++;\n          if (rejected === promises.length) reject(new AggregateError(errs, 'All promises were rejected'));\n        });\n    });\n  });\n}\n\npromiseAny([Promise.reject('x'), Promise.resolve('ok'), Promise.reject('y')]).then(console.log);",
              "output": "ok",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Concurrency-aware Build LCS (longest common subsequence) dynamic programming.",
              "code": "function lcs(a, b) {\n  const dp = Array.from({ length: a.length + 1 }, () => Array(b.length + 1).fill(0));\n  for (let i = 1; i <= a.length; i++) {\n    for (let j = 1; j <= b.length; j++) {\n      if (a[i - 1] === b[j - 1]) dp[i][j] = dp[i - 1][j - 1] + 1;\n      else dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);\n    }\n  }\n  return dp[a.length][b.length];\n}\n\nconsole.log(lcs('ABCBDAB', 'BDCAB'));",
              "output": "4",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "Fault-tolerant Implement rolling logger with max size and severity filter.",
              "code": "class RollingLogger {\n  constructor(max = 5) {\n    this.max = max;\n    this.rows = [];\n  }\n  log(level, msg) {\n    this.rows.push({ level, msg });\n    if (this.rows.length > this.max) this.rows.shift();\n  }\n  get(minLevel = 'debug') {\n    const order = { debug: 1, info: 2, warn: 3, error: 4 };\n    return this.rows.filter(r => order[r.level] >= order[minLevel]);\n  }\n}\n\nconst lg = new RollingLogger(3);\nlg.log('info', 'a'); lg.log('warn', 'b'); lg.log('error', 'c'); lg.log('debug', 'd');\nconsole.log(lg.get('warn'));",
              "output": "[ { level: 'warn', msg: 'b' }, { level: 'error', msg: 'c' } ]",
              "level": "Hard"
            },
            {
              "type": "program",
              "question": "System-level Implement `promiseAllSettledLimit` with concurrency control.",
              "code": "async function promiseAllSettledLimit(taskFns, limit = 3) {\n  const results = new Array(taskFns.length);\n  let idx = 0;\n\n  async function worker() {\n    while (idx < taskFns.length) {\n      const i = idx++;\n      try {\n        const value = await taskFns[i]();\n        results[i] = { status: 'fulfilled', value };\n      } catch (error) {\n        results[i] = { status: 'rejected', reason: error.message };\n      }\n    }\n  }\n\n  await Promise.all(Array.from({ length: Math.min(limit, taskFns.length) }, worker));\n  return results;\n}\n\nconst wait = (v, ms, fail = false) => () => new Promise((res, rej) => setTimeout(() => fail ? rej(new Error(v)) : res(v), ms));\n(async () => {\n  const out = await promiseAllSettledLimit([wait('A', 30), wait('B', 10, true), wait('C', 5)], 2);\n  console.log(out.map(x => x.status));\n})();",
              "output": "[ 'fulfilled', 'rejected', 'fulfilled' ]",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "Scalable Build deep equality check supporting objects, arrays, and dates.",
              "code": "function deepEqual(a, b) {\n  if (Object.is(a, b)) return true;\n  if (a instanceof Date && b instanceof Date) return a.getTime() === b.getTime();\n  if (typeof a !== 'object' || typeof b !== 'object' || a === null || b === null) return false;\n  if (Array.isArray(a) !== Array.isArray(b)) return false;\n\n  const keysA = Object.keys(a);\n  const keysB = Object.keys(b);\n  if (keysA.length !== keysB.length) return false;\n\n  for (const k of keysA) {\n    if (!keysB.includes(k)) return false;\n    if (!deepEqual(a[k], b[k])) return false;\n  }\n  return true;\n}\n\nconsole.log(\n  deepEqual({ x: [1, { y: 2 }], d: new Date('2026-01-01') }, { x: [1, { y: 2 }], d: new Date('2026-01-01') })\n);",
              "output": "true",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "Interview-hard Implement object diff utility (added/removed/changed keys).",
              "code": "function objectDiff(oldObj, newObj) {\n  const added = [];\n  const removed = [];\n  const changed = [];\n\n  for (const k of Object.keys(oldObj)) {\n    if (!(k in newObj)) removed.push(k);\n    else if (JSON.stringify(oldObj[k]) !== JSON.stringify(newObj[k])) changed.push(k);\n  }\n  for (const k of Object.keys(newObj)) {\n    if (!(k in oldObj)) added.push(k);\n  }\n  return { added, removed, changed };\n}\n\nconsole.log(objectDiff(\n  { a: 1, b: 2, c: { x: 1 } },\n  { a: 1, b: 3, d: true, c: { x: 2 } }\n));",
              "output": "{ added: [ 'd' ], removed: [], changed: [ 'b', 'c' ] }",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "Architecture-grade Build immutable deep update by path (`setIn`).",
              "code": "function setIn(obj, path, value) {\n  const keys = path.split('.');\n  const out = Array.isArray(obj) ? [...obj] : { ...obj };\n  let cur = out;\n  let src = obj;\n\n  for (let i = 0; i < keys.length - 1; i++) {\n    const k = keys[i];\n    const next = src?.[k];\n    cur[k] = Array.isArray(next) ? [...next] : { ...(next || {}) };\n    cur = cur[k];\n    src = next;\n  }\n  cur[keys[keys.length - 1]] = value;\n  return out;\n}\n\nconst state = { user: { profile: { city: 'Austin' } } };\nconst next = setIn(state, 'user.profile.city', 'Dallas');\nconsole.log(state.user.profile.city, next.user.profile.city, state !== next);",
              "output": "Austin Dallas true",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "High-complexity Implement `groupBy` + aggregate pipeline for sales analytics.",
              "code": "function groupBy(arr, keyFn) {\n  return arr.reduce((m, item) => {\n    const k = keyFn(item);\n    if (!m[k]) m[k] = [];\n    m[k].push(item);\n    return m;\n  }, {});\n}\n\nconst sales = [\n  { region: 'US', amount: 120 },\n  { region: 'EU', amount: 80 },\n  { region: 'US', amount: 30 }\n];\n\nconst grouped = groupBy(sales, x => x.region);\nconst totals = Object.fromEntries(Object.entries(grouped).map(([k, v]) => [k, v.reduce((s, x) => s + x.amount, 0)]));\nconsole.log(totals);",
              "output": "{ US: 150, EU: 80 }",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "System-level Write robust CSV parser for quoted fields.",
              "code": "function parseCSVLine(line) {\n  const out = [];\n  let cur = '';\n  let inQuotes = false;\n\n  for (let i = 0; i < line.length; i++) {\n    const ch = line[i];\n    if (ch === '\"') {\n      if (inQuotes && line[i + 1] === '\"') {\n        cur += '\"';\n        i++;\n      } else {\n        inQuotes = !inQuotes;\n      }\n    } else if (ch === ',' && !inQuotes) {\n      out.push(cur);\n      cur = '';\n    } else {\n      cur += ch;\n    }\n  }\n  out.push(cur);\n  return out;\n}\n\nconsole.log(parseCSVLine('1,\"Ada, Lovelace\",Engineer'));",
              "output": "[ '1', 'Ada, Lovelace', 'Engineer' ]",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "Scalable Build mini template engine with `{{key}}` placeholders.",
              "code": "function renderTemplate(template, data) {\n  return template.replace(/{{s*([w.]+)s*}}/g, (_, path) => {\n    const value = path.split('.').reduce((acc, k) => acc?.[k], data);\n    return value == null ? '' : String(value);\n  });\n}\n\nconst t = 'Hello {{user.name}}, order {{order.id}} is {{order.status}}.';\nconsole.log(renderTemplate(t, { user: { name: 'Alice' }, order: { id: 101, status: 'shipped' } }));",
              "output": "Hello Alice, order 101 is shipped.",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "Interview-hard Implement topological sort for dependency graph.",
              "code": "function topoSort(graph) {\n  const indeg = new Map();\n  for (const n of Object.keys(graph)) indeg.set(n, 0);\n  for (const deps of Object.values(graph)) for (const d of deps) indeg.set(d, (indeg.get(d) || 0) + 1);\n\n  const q = [...[...indeg.entries()].filter(([, v]) => v === 0).map(([k]) => k)];\n  const out = [];\n\n  while (q.length) {\n    const n = q.shift();\n    out.push(n);\n    for (const d of graph[n] || []) {\n      indeg.set(d, indeg.get(d) - 1);\n      if (indeg.get(d) === 0) q.push(d);\n    }\n  }\n  return out.length === indeg.size ? out : null;\n}\n\nconsole.log(topoSort({ build: ['test'], test: ['lint'], lint: [] }));",
              "output": "[ 'build', 'test', 'lint' ]",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "Architecture-grade Implement token bucket rate limiter.",
              "code": "class TokenBucket {\n  constructor(capacity, refillPerSec) {\n    this.capacity = capacity;\n    this.tokens = capacity;\n    this.refillPerSec = refillPerSec;\n    this.last = Date.now();\n  }\n  allow(cost = 1) {\n    const now = Date.now();\n    const elapsed = (now - this.last) / 1000;\n    this.tokens = Math.min(this.capacity, this.tokens + elapsed * this.refillPerSec);\n    this.last = now;\n    if (this.tokens >= cost) {\n      this.tokens -= cost;\n      return true;\n    }\n    return false;\n  }\n}\n\nconst bucket = new TokenBucket(2, 1);\nconsole.log(bucket.allow(), bucket.allow(), bucket.allow());",
              "output": "true true false",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "High-complexity Build Trie with insert/search/prefix methods.",
              "code": "class TrieNode {\n  constructor() { this.next = new Map(); this.end = false; }\n}\nclass Trie {\n  constructor() { this.root = new TrieNode(); }\n  insert(word) {\n    let cur = this.root;\n    for (const ch of word) {\n      if (!cur.next.has(ch)) cur.next.set(ch, new TrieNode());\n      cur = cur.next.get(ch);\n    }\n    cur.end = true;\n  }\n  search(word) {\n    let cur = this.root;\n    for (const ch of word) {\n      if (!cur.next.has(ch)) return false;\n      cur = cur.next.get(ch);\n    }\n    return cur.end;\n  }\n  startsWith(prefix) {\n    let cur = this.root;\n    for (const ch of prefix) {\n      if (!cur.next.has(ch)) return false;\n      cur = cur.next.get(ch);\n    }\n    return true;\n  }\n}\n\nconst t = new Trie();\nt.insert('code'); t.insert('coder');\nconsole.log(t.search('code'), t.search('cod'), t.startsWith('cod'));",
              "output": "true false true",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "System-level Build undo/redo state manager (command stack).",
              "code": "class HistoryState {\n  constructor(initial) {\n    this.past = [];\n    this.present = initial;\n    this.future = [];\n  }\n  set(next) {\n    this.past.push(this.present);\n    this.present = next;\n    this.future = [];\n  }\n  undo() {\n    if (!this.past.length) return;\n    this.future.push(this.present);\n    this.present = this.past.pop();\n  }\n  redo() {\n    if (!this.future.length) return;\n    this.past.push(this.present);\n    this.present = this.future.pop();\n  }\n}\n\nconst h = new HistoryState(1);\nh.set(2); h.set(3); h.undo(); h.undo(); h.redo();\nconsole.log(h.present);",
              "output": "2",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "Scalable Implement async queue with pause/resume and worker.",
              "code": "class AsyncQueue {\n  constructor(worker) {\n    this.worker = worker;\n    this.q = [];\n    this.running = false;\n    this.paused = false;\n  }\n  push(item) {\n    this.q.push(item);\n    this.drain();\n  }\n  pause() { this.paused = true; }\n  resume() { this.paused = false; this.drain(); }\n  async drain() {\n    if (this.running || this.paused) return;\n    this.running = true;\n    while (this.q.length && !this.paused) {\n      const item = this.q.shift();\n      await this.worker(item);\n    }\n    this.running = false;\n  }\n}\n\nconst out = [];\nconst aq = new AsyncQueue(async x => { out.push(x * 2); });\naq.push(1); aq.push(2); aq.push(3);\nsetTimeout(() => console.log(out), 10);",
              "output": "[ 2, 4, 6 ]",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "Interview-hard Implement paginated fetch iterator over async source.",
              "code": "async function* paginate(fetchPage) {\n  let page = 1;\n  while (true) {\n    const { items, hasNext } = await fetchPage(page);\n    for (const item of items) yield item;\n    if (!hasNext) break;\n    page++;\n  }\n}\n\n(async () => {\n  const source = {\n    1: { items: [1, 2], hasNext: true },\n    2: { items: [3, 4], hasNext: false }\n  };\n  const out = [];\n  for await (const v of paginate(async p => source[p])) out.push(v);\n  console.log(out);\n})();",
              "output": "[ 1, 2, 3, 4 ]",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "Architecture-grade Build safe JSON parser with validation and defaults.",
              "code": "function parseConfig(input, schema) {\n  let raw;\n  try { raw = JSON.parse(input); } catch { raw = {}; }\n  const out = {};\n  for (const [k, rule] of Object.entries(schema)) {\n    const v = raw[k];\n    if (v == null) out[k] = rule.default;\n    else if (typeof v === rule.type) out[k] = v;\n    else out[k] = rule.default;\n  }\n  return out;\n}\n\nconst schema = { retries: { type: 'number', default: 3 }, mode: { type: 'string', default: 'safe' } };\nconsole.log(parseConfig('{\"retries\":5,\"mode\":\"fast\"}', schema));",
              "output": "{ retries: 5, mode: 'fast' }",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "High-complexity Build binary search over sorted array of objects by key.",
              "code": "function binarySearchBy(arr, key, target) {\n  let l = 0, r = arr.length - 1;\n  while (l <= r) {\n    const m = (l + r) >> 1;\n    if (arr[m][key] === target) return m;\n    if (arr[m][key] < target) l = m + 1;\n    else r = m - 1;\n  }\n  return -1;\n}\n\nconst users = [{ id: 10 }, { id: 20 }, { id: 30 }, { id: 40 }];\nconsole.log(binarySearchBy(users, 'id', 30));",
              "output": "2",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "System-level Implement interval scheduler for maximum non-overlap jobs.",
              "code": "function maxNonOverlapping(intervals) {\n  intervals.sort((a, b) => a[1] - b[1]);\n  const selected = [];\n  let end = -Infinity;\n  for (const [s, e] of intervals) {\n    if (s >= end) {\n      selected.push([s, e]);\n      end = e;\n    }\n  }\n  return selected;\n}\n\nconsole.log(maxNonOverlapping([[1,3],[2,5],[4,6],[6,7]]));",
              "output": "[ [ 1, 3 ], [ 4, 6 ], [ 6, 7 ] ]",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "Scalable Build path matcher with params (`/users/:id/orders/:oid`).",
              "code": "function matchRoute(pattern, path) {\n  const p1 = pattern.split('/').filter(Boolean);\n  const p2 = path.split('/').filter(Boolean);\n  if (p1.length !== p2.length) return null;\n  const params = {};\n  for (let i = 0; i < p1.length; i++) {\n    if (p1[i].startsWith(':')) params[p1[i].slice(1)] = p2[i];\n    else if (p1[i] !== p2[i]) return null;\n  }\n  return params;\n}\n\nconsole.log(matchRoute('/users/:id/orders/:oid', '/users/42/orders/900'));",
              "output": "{ id: '42', oid: '900' }",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "Interview-hard Implement custom `Promise.any` polyfill.",
              "code": "function promiseAny(promises) {\n  return new Promise((resolve, reject) => {\n    let rejected = 0;\n    const errs = [];\n    promises.forEach((p, i) => {\n      Promise.resolve(p)\n        .then(resolve)\n        .catch(e => {\n          errs[i] = e;\n          rejected++;\n          if (rejected === promises.length) reject(new AggregateError(errs, 'All promises were rejected'));\n        });\n    });\n  });\n}\n\npromiseAny([Promise.reject('x'), Promise.resolve('ok'), Promise.reject('y')]).then(console.log);",
              "output": "ok",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "Architecture-grade Build LCS (longest common subsequence) dynamic programming.",
              "code": "function lcs(a, b) {\n  const dp = Array.from({ length: a.length + 1 }, () => Array(b.length + 1).fill(0));\n  for (let i = 1; i <= a.length; i++) {\n    for (let j = 1; j <= b.length; j++) {\n      if (a[i - 1] === b[j - 1]) dp[i][j] = dp[i - 1][j - 1] + 1;\n      else dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);\n    }\n  }\n  return dp[a.length][b.length];\n}\n\nconsole.log(lcs('ABCBDAB', 'BDCAB'));",
              "output": "4",
              "level": "Very Hard"
            },
            {
              "type": "program",
              "question": "High-complexity Implement rolling logger with max size and severity filter.",
              "code": "class RollingLogger {\n  constructor(max = 5) {\n    this.max = max;\n    this.rows = [];\n  }\n  log(level, msg) {\n    this.rows.push({ level, msg });\n    if (this.rows.length > this.max) this.rows.shift();\n  }\n  get(minLevel = 'debug') {\n    const order = { debug: 1, info: 2, warn: 3, error: 4 };\n    return this.rows.filter(r => order[r.level] >= order[minLevel]);\n  }\n}\n\nconst lg = new RollingLogger(3);\nlg.log('info', 'a'); lg.log('warn', 'b'); lg.log('error', 'c'); lg.log('debug', 'd');\nconsole.log(lg.get('warn'));",
              "output": "[ { level: 'warn', msg: 'b' }, { level: 'error', msg: 'c' } ]",
              "level": "Very Hard"
            }
          ]
        },
        {
          "id": "destructuring",
          "title": "Object Destructuring",
          "category": "Object Operations",
          "description": "Extracts properties from objects into distinct variables.",
          "explanation": "Extracts properties from objects into distinct variables.\n\nInterview focus:\n- Core definition and mental model\n- Trade-offs and edge cases\n- Practical implementation and debugging patterns\n- Real production use cases",
          "implementation": "const user = {name: 'John', age: 30, email: 'john@example.com'};\nconst {name, age} = user;\n\n// With renaming\nconst {name: userName, age: userAge} = user;\n\n// With default values\nconst {name, country = 'USA'} = user;",
          "example": "function greet({name, age}) {\n  console.log(`Hello ${name}, you are ${age} years old`);\n}\ngreet({name: 'John', age: 30});",
          "useCase": "Function parameters, importing specific exports, extracting API response data",
          "interviewQuestions": [
            {
              "question": "What is object destructuring and why is it useful?",
              "answer": "Object destructuring extracts object properties into local variables with concise syntax, reducing repetitive property access and improving readability."
            },
            {
              "question": "How do you rename a destructured property?",
              "answer": "Use alias syntax: const { name: userName } = user; this keeps source key as name and local variable as userName."
            },
            {
              "question": "How do default values work in destructuring?",
              "answer": "Defaults are used only when extracted value is undefined, not when it is null, false, or 0."
            },
            {
              "question": "What is a common bug with nested destructuring?",
              "answer": "Destructuring nested keys without guarding can throw if parent object is undefined. Use defaults or optional chaining before destructuring deeply."
            },
            {
              "question": "How would you destructure function parameters safely?",
              "answer": "Use function signature defaults, e.g. function f({a} = {}) so call sites without argument do not crash."
            },
            {
              "question": "How do you destructure nested objects?",
              "answer": "Use nested pattern syntax, e.g. const { profile: { email } } = user, and guard missing parents with defaults."
            },
            {
              "question": "Can destructuring be used with arrays and objects together?",
              "answer": "Yes. You can destructure arrays by position and objects by key in the same statement."
            },
            {
              "question": "What happens when you destructure a missing property?",
              "answer": "The value becomes undefined unless a default value is provided in the pattern."
            },
            {
              "question": "How do you skip elements in array destructuring?",
              "answer": "Use commas as placeholders, e.g. const [first, , third] = arr."
            },
            {
              "question": "Why is destructuring useful in API response handling?",
              "answer": "It extracts needed fields directly and keeps transformation code concise and readable."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Predict output: const [a,,c=9] = [1,2]; console.log(a,c);",
              "answer": "1 9",
              "code": "const [a,,c=9] = [1,2];\nconsole.log(a,c);",
              "output": "1 9"
            },
            {
              "type": "output",
              "question": "Predict output: const {x:{y}= {y:7}} = {}; console.log(y);",
              "answer": "7",
              "code": "const {x:{y}= {y:7}} = {};\nconsole.log(y);",
              "output": "7"
            },
            {
              "type": "implement",
              "question": "Write swap([a,b]) returning [b,a] using destructuring assignment.",
              "answer": "Use temporary-less swap with [a,b] = [b,a]."
            },
            {
              "type": "implement",
              "question": "Build function getConfig({host=\"localhost\", port=3000}={}) returning normalized config."
            },
            {
              "type": "debug",
              "question": "Fix crash: function f({x}) { return x; } called as f().",
              "answer": "Use function f({x} = {}) { return x; }."
            },
            {
              "type": "debug",
              "question": "Fix invalid syntax: const {a:b:c} = obj;",
              "answer": "Use const { a: b } = obj; then use b."
            },
            {
              "type": "refactor",
              "question": "Refactor repeated user.name and user.email reads into concise syntax.",
              "answer": "Use const { name, email } = user once."
            },
            {
              "type": "scenario",
              "question": "Given API payload {data:{items,meta}}, extract items and page in one line with defaults."
            },
            {
              "type": "scenario",
              "question": "How will you destructure optional function param to avoid runtime error?",
              "answer": "Provide default empty object in parameter signature."
            },
            {
              "type": "tricky",
              "question": "Does default value apply when source value is null?",
              "answer": "No. Defaults only apply for undefined."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Swap two numbers without temp variable using array destructuring.",
              "answer": "Use [a, b] = [b, a].",
              "code": "let a = 10;\nlet b = 25;\n[a, b] = [b, a];\nconsole.log(a, b);",
              "output": "25 10"
            },
            {
              "type": "program",
              "question": "Program 2: Extract name and city from user object with defaults.",
              "code": "const user = { name: \"Jitender\" };\nconst { name, city = \"Unknown\" } = user;\nconsole.log(name, city);",
              "output": "Jitender Unknown"
            },
            {
              "type": "program",
              "question": "Program 3: Destructure nested API response to read first product title safely.",
              "code": "const response = { data: { products: [{ title: \"Laptop\" }] } };\nconst { data: { products: [{ title } = {}] = [] } = {} } = response;\nconsole.log(title);",
              "output": "Laptop"
            },
            {
              "type": "program",
              "question": "Program 4: Build function that returns {id, email} from input object parameter using destructuring.",
              "code": "function pickIdEmail({ id, email }) {\n  return { id, email };\n}\nconsole.log(pickIdEmail({ id: 7, email: \"a@b.com\", role: \"admin\" }));",
              "output": "{ id: 7, email: \"a@b.com\" }"
            },
            {
              "type": "program",
              "question": "Program 5: Convert array [first, second, third] into object using destructuring.",
              "code": "const arr = [\"red\", \"green\", \"blue\"];\nconst [first, second, third] = arr;\nconst result = { first, second, third };\nconsole.log(result);",
              "output": "{ first: \"red\", second: \"green\", third: \"blue\" }"
            },
            {
              "type": "program",
              "question": "Program 6: Skip middle values and print first and last using destructuring.",
              "code": "const nums = [10, 20, 30, 40, 50];\nconst [first, , , , last] = nums;\nconsole.log(first, last);",
              "output": "10 50"
            },
            {
              "type": "program",
              "question": "Program 7: Destructure object key and rename variable (name -> fullName).",
              "code": "const profile = { name: \"Ravi\", exp: 3 };\nconst { name: fullName, exp } = profile;\nconsole.log(fullName, exp);",
              "output": "Ravi 3"
            },
            {
              "type": "program",
              "question": "Program 8: Write function with safe default parameter destructuring.",
              "code": "function connect({ host = \"localhost\", port = 5432 } = {}) {\n  return `${host}:${port}`;\n}\nconsole.log(connect());\nconsole.log(connect({ host: \"db.local\" }));",
              "output": "localhost:5432\ndb.local:5432"
            },
            {
              "type": "program",
              "question": "Program 9: Destructure top 2 elements and store rest in a new array.",
              "code": "const scores = [98, 91, 88, 80, 75];\nconst [top1, top2, ...others] = scores;\nconsole.log(top1, top2, others);",
              "output": "98 91 [ 88, 80, 75 ]"
            },
            {
              "type": "program",
              "question": "Program 10: Extract date parts from \"YYYY-MM-DD\" string using destructuring.",
              "code": "const date = \"2026-02-12\";\nconst [year, month, day] = date.split(\"-\");\nconsole.log(year, month, day);",
              "output": "2026 02 12"
            }
          ]
        },
        {
          "id": "spread-rest",
          "title": "Spread & Rest Operators",
          "category": "Object Operations",
          "description": "Spread (...) expands arrays/objects. Rest (...) collects multiple elements.",
          "explanation": "The ... syntax serves two purposes in JavaScript depending on context:\n\nSpread (...) — expands/unpacks:\n- Arrays: [...arr1, ...arr2] merges arrays\n- Objects: {...obj1, ...obj2} merges objects (last wins for duplicate keys)\n- Function calls: fn(...args) passes array elements as arguments\n\nRest (...) — collects/packs:\n- Function params: function(...args) collects arguments into an array\n- Destructuring: const [first, ...rest] = arr collects remaining elements\n- Object destructuring: const { id, ...rest } = obj collects remaining properties\n\nKey rules:\n- Rest must be the LAST element in function params or destructuring\n- Spread creates SHALLOW copies (nested objects share references!)\n- Object spread copies own enumerable properties only\n- Spread on objects is NOT the same as Object.assign() — spread can't call setters on the target\n\nCommon patterns:\n- Clone array: const copy = [...arr]\n- Shallow clone object: const copy = {...obj}\n- Remove property immutably: const { password, ...safeUser } = user\n- Merge with override: const config = { ...defaults, ...userConfig }\n- Convert iterable to array: [...'hello'] → ['h','e','l','l','o']\n\nSpread vs Object.assign():\n- Both do shallow copy\n- Spread is more readable and creates a new object\n- Object.assign mutates the first argument\n- Object.assign triggers setters, spread does not",
          "implementation": "// Spread\nconst arr1 = [1, 2, 3];\nconst arr2 = [...arr1, 4, 5]; // [1,2,3,4,5]\n\nconst obj1 = {a: 1, b: 2};\nconst obj2 = {...obj1, c: 3}; // {a:1, b:2, c:3}\n\n// Rest\nfunction sum(...numbers) {\n  return numbers.reduce((a, b) => a + b, 0);\n}",
          "example": "// Merging arrays\nconst combined = [...array1, ...array2];\n\n// Copying objects\nconst copy = {...original};\n\n// Function with any number of args\nconst max = Math.max(...numbers);",
          "useCase": "Cloning objects/arrays, merging data, function arguments",
          "interviewQuestions": [
            {
              "question": "What is the difference between spread and rest operators?",
              "answer": "Spread expands an iterable/object into individual elements. Rest collects remaining elements into an array/object."
            },
            {
              "question": "Is object spread a deep copy?",
              "answer": "No. It is a shallow copy. Nested objects keep shared references unless cloned separately."
            },
            {
              "question": "When should you use rest parameters in functions?",
              "answer": "When function arity is variable or you want to pass any number of args without arguments object."
            },
            {
              "question": "How does spread help immutable updates?",
              "answer": "It creates new arrays/objects while keeping unchanged references for unaffected branches."
            },
            {
              "question": "What is a common interview trap with spread on arrays of objects?",
              "answer": "Copying array with [...arr] still shares inner object references, so nested mutations affect original objects."
            },
            {
              "question": "How does spread behave with function arguments?",
              "answer": "It expands iterable items as separate arguments, e.g. fn(...arr)."
            },
            {
              "question": "Can rest be used in object destructuring?",
              "answer": "Yes. const { id, ...rest } = obj collects remaining own enumerable props into rest."
            },
            {
              "question": "What is parameter order rule for rest?",
              "answer": "Rest must be the last parameter in function signature or pattern."
            },
            {
              "question": "How do you immutably remove one key from object?",
              "answer": "Use destructuring + rest: const { removeKey, ...next } = obj."
            },
            {
              "question": "What is a common bug with nested state and spread?",
              "answer": "Only top-level copy is made; nested structures still share references."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Predict output: const o={a:1,b:2}; const p={...o,b:9}; console.log(p.b);",
              "answer": "9",
              "code": "const o={a:1,b:2};\nconst p={...o,b:9};\nconsole.log(p.b);",
              "output": "9"
            },
            {
              "type": "output",
              "question": "Predict output: function f(a,...r){console.log(r.length)}; f(1,2,3,4);",
              "answer": "3",
              "code": "function f(a,...r){console.log(r.length)}\nf(1,2,3,4);",
              "output": "3"
            },
            {
              "type": "implement",
              "question": "Implement mergeOptions(defaults, overrides) immutably.",
              "answer": "Return { ...defaults, ...overrides }."
            },
            {
              "type": "implement",
              "question": "Implement omit(obj, keys) returning object without selected keys."
            },
            {
              "type": "debug",
              "question": "A copied array of objects mutates original. Why?",
              "answer": "Spread makes shallow copy only."
            },
            {
              "type": "debug",
              "question": "Why does nested object in spread still change original after mutation?",
              "answer": "Nested refs are shared unless explicitly cloned."
            },
            {
              "type": "refactor",
              "question": "Refactor reducer update to immutable spread style."
            },
            {
              "type": "scenario",
              "question": "You need variable args sum(...nums). Implement with rest."
            },
            {
              "type": "tricky",
              "question": "Can rest parameter be anywhere in function arguments?",
              "answer": "No, it must be last."
            },
            {
              "type": "tricky",
              "question": "Is object spread a deep clone?",
              "answer": "No, shallow clone only."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Merge two arrays and remove duplicates using spread + Set.",
              "code": "const a = [1, 2, 3];\nconst b = [3, 4, 5];\nconst merged = [...new Set([...a, ...b])];\nconsole.log(merged);",
              "output": "[ 1, 2, 3, 4, 5 ]"
            },
            {
              "type": "program",
              "question": "Program 2: Clone object and override one property without mutation.",
              "code": "const user = { name: \"Sam\", role: \"user\" };\nconst updated = { ...user, role: \"admin\" };\nconsole.log(user.role, updated.role);",
              "output": "user admin"
            },
            {
              "type": "program",
              "question": "Program 3: Sum variable arguments using rest parameter.",
              "code": "function sum(...nums) {\n  return nums.reduce((a, b) => a + b, 0);\n}\nconsole.log(sum(1, 2, 3, 4));",
              "output": "10"
            },
            {
              "type": "program",
              "question": "Program 4: Remove property password from object using rest destructuring.",
              "code": "const account = { id: 1, email: \"x@y.com\", password: \"secret\" };\nconst { password, ...safeAccount } = account;\nconsole.log(safeAccount);",
              "output": "{ id: 1, email: \"x@y.com\" }"
            },
            {
              "type": "program",
              "question": "Program 5: Append item immutably to existing list.",
              "code": "const tasks = [\"read\", \"code\"];\nconst next = [...tasks, \"sleep\"];\nconsole.log(tasks, next);",
              "output": "[ \"read\", \"code\" ] [ \"read\", \"code\", \"sleep\" ]"
            },
            {
              "type": "program",
              "question": "Program 6: Merge config objects where env overrides defaults.",
              "code": "const defaults = { host: \"localhost\", port: 3000, secure: false };\nconst env = { port: 8080, secure: true };\nconst config = { ...defaults, ...env };\nconsole.log(config);",
              "output": "{ host: \"localhost\", port: 8080, secure: true }"
            },
            {
              "type": "program",
              "question": "Program 7: Convert Math.max usage from array by spreading args.",
              "code": "const nums = [5, 2, 9, 1];\nconsole.log(Math.max(...nums));",
              "output": "9"
            },
            {
              "type": "program",
              "question": "Program 8: Write logger(level, ...messages) using rest.",
              "code": "function logger(level, ...messages) {\n  console.log(`[${level}]`, messages.join(\" | \"));\n}\nlogger(\"INFO\", \"server up\", \"port 3000\");",
              "output": "[INFO] server up | port 3000"
            },
            {
              "type": "program",
              "question": "Program 9: Demonstrate shallow copy behavior with nested object in spread.",
              "code": "const original = { profile: { city: \"Pune\" } };\nconst copy = { ...original };\ncopy.profile.city = \"Delhi\";\nconsole.log(original.profile.city);",
              "output": "Delhi"
            },
            {
              "type": "program",
              "question": "Program 10: Build function prependAndAppend(arr, start, end) returning new array.",
              "code": "function prependAndAppend(arr, start, end) {\n  return [start, ...arr, end];\n}\nconsole.log(prependAndAppend([2, 3, 4], 1, 5));",
              "output": "[ 1, 2, 3, 4, 5 ]"
            }
          ]
        },
        {
          "id": "object-methods",
          "title": "Object.keys/values/entries",
          "category": "Object Operations",
          "description": "Methods to iterate over object properties.",
          "explanation": "JavaScript provides static methods on Object for working with object properties as arrays:\n\nObject.keys(obj) — returns array of own enumerable string-keyed property NAMES\nObject.values(obj) — returns array of own enumerable string-keyed property VALUES\nObject.entries(obj) — returns array of [key, value] pairs\nObject.fromEntries(iterable) — converts [key, value] pairs back to object (inverse of entries)\n\nProperty order (since ES2015):\n1. Integer-like keys in ascending numeric order (e.g., '0', '1', '2')\n2. String keys in insertion order\n3. Symbol keys in insertion order (not included by keys/values/entries)\n\nImportant notes:\n- These methods return only OWN properties (not inherited from prototype)\n- Only ENUMERABLE properties are included (non-enumerable are skipped)\n- Symbol keys are NOT included — use Object.getOwnPropertySymbols() for those\n- Use Reflect.ownKeys(obj) to get ALL own keys (strings + symbols, enumerable + non-enumerable)\n\nCommon patterns:\n- Count properties: Object.keys(obj).length\n- Transform object: Object.fromEntries(Object.entries(obj).map(([k,v]) => [k, v*2]))\n- Filter object: Object.fromEntries(Object.entries(obj).filter(([k,v]) => v > 0))\n- Check empty object: Object.keys(obj).length === 0\n- Iterate: for (const [key, value] of Object.entries(obj)) { ... }\n\nRelated methods:\n- Object.assign() — copy properties (shallow)\n- Object.freeze() / Object.seal() — immutability\n- Object.getOwnPropertyDescriptors() — property metadata",
          "implementation": "const user = {name: 'John', age: 30, city: 'NYC'};\n\nObject.keys(user);    // ['name', 'age', 'city']\nObject.values(user);  // ['John', 30, 'NYC']\nObject.entries(user); // [['name','John'], ['age',30], ['city','NYC']]",
          "example": "const scores = {math: 90, science: 85, history: 88};\n\nObject.entries(scores).forEach(([subject, score]) => {\n  console.log(`${subject}: ${score}`);\n});\n\nconst total = Object.values(scores).reduce((a, b) => a + b);",
          "useCase": "Iterating objects, converting to arrays, filtering object properties",
          "interviewQuestions": [
            {
              "question": "When to use Object.keys vs Object.values vs Object.entries?",
              "answer": "Use keys for property names, values for value lists, entries for key-value iteration and transformations."
            },
            {
              "question": "Do these methods include inherited properties?",
              "answer": "No. They return only own enumerable properties of the object."
            },
            {
              "question": "How can you transform an object using Object.entries?",
              "answer": "Convert to entries, map/filter entries, then rebuild with Object.fromEntries."
            },
            {
              "question": "What order does Object.keys return?",
              "answer": "Numeric-like keys are ordered ascending first, then string keys by insertion order."
            },
            {
              "question": "What is a common edge case with Object.entries and symbol keys?",
              "answer": "Symbol keys are not included by Object.keys/values/entries; use Object.getOwnPropertySymbols when needed."
            },
            {
              "question": "How to iterate key-value pairs safely?",
              "answer": "Use for (const [k,v] of Object.entries(obj)) for predictable own enumerable iteration."
            },
            {
              "question": "When is Object.fromEntries useful?",
              "answer": "After mapping/filtering entries, convert back to object using Object.fromEntries(entries)."
            },
            {
              "question": "Does Object.keys include non-enumerable fields?",
              "answer": "No. It includes only own enumerable string-keyed properties."
            },
            {
              "question": "How to get property descriptors?",
              "answer": "Use Object.getOwnPropertyDescriptors(obj) when attributes like writable/configurable matter."
            },
            {
              "question": "How to include symbols while iterating all own keys?",
              "answer": "Use Reflect.ownKeys(obj) to include string keys and symbol keys."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Predict output: Object.keys({2:\"b\",1:\"a\",x:\"c\"})",
              "answer": "[\"1\",\"2\",\"x\"]",
              "output": "[\"1\",\"2\",\"x\"]"
            },
            {
              "type": "output",
              "question": "Predict output: Object.values({a:1,b:2}).reduce((s,n)=>s+n,0)",
              "answer": "3",
              "output": "3"
            },
            {
              "type": "implement",
              "question": "Write toPairs(obj) using Object.entries."
            },
            {
              "type": "implement",
              "question": "Create pickBy(obj, predicate) using entries + fromEntries."
            },
            {
              "type": "debug",
              "question": "for...in iterates unexpected prototype keys. Fix iteration.",
              "answer": "Use Object.entries/keys or hasOwnProperty check."
            },
            {
              "type": "debug",
              "question": "Need symbol keys too while iterating. Which API?",
              "answer": "Use Reflect.ownKeys(obj)."
            },
            {
              "type": "refactor",
              "question": "Convert object values to total using Object.values + reduce."
            },
            {
              "type": "scenario",
              "question": "Convert query params object to query string using Object.entries."
            },
            {
              "type": "tricky",
              "question": "Do Object.keys/values/entries include inherited properties?",
              "answer": "No, only own enumerable properties."
            },
            {
              "type": "tricky",
              "question": "Do Object.entries include symbol keys?",
              "answer": "No. Use Reflect.ownKeys for symbols."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Print all keys from object using Object.keys.",
              "code": "const obj = { name: \"A\", age: 20, city: \"B\" };\nconsole.log(Object.keys(obj));",
              "output": "[ \"name\", \"age\", \"city\" ]"
            },
            {
              "type": "program",
              "question": "Program 2: Calculate sum of all numeric values using Object.values.",
              "code": "const marks = { math: 90, sci: 85, eng: 95 };\nconst total = Object.values(marks).reduce((a, b) => a + b, 0);\nconsole.log(total);",
              "output": "270"
            },
            {
              "type": "program",
              "question": "Program 3: Loop key-value pairs using Object.entries.",
              "code": "const user = { id: 1, name: \"Amit\" };\nfor (const [k, v] of Object.entries(user)) {\n  console.log(k, v);\n}",
              "output": "id 1\nname Amit"
            },
            {
              "type": "program",
              "question": "Program 4: Convert object to query string using entries.",
              "code": "const params = { q: \"js\", page: 2 };\nconst qs = new URLSearchParams(Object.entries(params)).toString();\nconsole.log(qs);",
              "output": "q=js&page=2"
            },
            {
              "type": "program",
              "question": "Program 5: Filter object keys whose values are numbers only.",
              "code": "const mixed = { a: 1, b: \"x\", c: 3, d: true };\nconst onlyNums = Object.fromEntries(Object.entries(mixed).filter(([, v]) => typeof v === \"number\"));\nconsole.log(onlyNums);",
              "output": "{ a: 1, c: 3 }"
            },
            {
              "type": "program",
              "question": "Program 6: Invert object (key<->value) using entries/fromEntries.",
              "code": "const roleById = { 1: \"admin\", 2: \"user\" };\nconst idByRole = Object.fromEntries(Object.entries(roleById).map(([k, v]) => [v, k]));\nconsole.log(idByRole);",
              "output": "{ admin: \"1\", user: \"2\" }"
            },
            {
              "type": "program",
              "question": "Program 7: Count object properties using Object.keys length.",
              "code": "const cart = { apple: 2, banana: 3, orange: 1 };\nconsole.log(Object.keys(cart).length);",
              "output": "3"
            },
            {
              "type": "program",
              "question": "Program 8: Create array of \"key:value\" strings from object.",
              "code": "const env = { NODE_ENV: \"dev\", PORT: 3000 };\nconst lines = Object.entries(env).map(([k, v]) => `${k}:${v}`);\nconsole.log(lines);",
              "output": "[ \"NODE_ENV:dev\", \"PORT:3000\" ]"
            },
            {
              "type": "program",
              "question": "Program 9: Check if all values are non-empty strings.",
              "code": "const form = { first: \"A\", last: \"B\" };\nconst valid = Object.values(form).every(v => typeof v === \"string\" && v.trim() !== \"\");\nconsole.log(valid);",
              "output": "true"
            },
            {
              "type": "program",
              "question": "Program 10: Build object from transformed entries (uppercase keys).",
              "code": "const input = { a: 1, b: 2 };\nconst upper = Object.fromEntries(Object.entries(input).map(([k, v]) => [k.toUpperCase(), v]));\nconsole.log(upper);",
              "output": "{ A: 1, B: 2 }"
            }
          ]
        },
        {
          "id": "strings",
          "category": "Core Language",
          "title": "Strings",
          "description": "Master JavaScript string fundamentals and methods used heavily in interviews and production code.",
          "explanation": "Strings are immutable sequences of UTF-16 code units in JavaScript. Interview focus includes immutability, common methods (slice, substring, split, replace, includes, startsWith, endsWith, trim), template literals, regex usage, and output-based edge cases.\n\nKey points:\n- Strings are immutable; operations return new strings.\n- Prefer clear method choices (slice vs substring).\n- Template literals improve readability and interpolation.\n- Be careful with case sensitivity and locale operations.",
          "implementation": "const str = \"  JavaScript Interview  \";\nconst clean = str.trim().toLowerCase();\nconst words = clean.split(\" \");\nconst slug = words.join(\"-\");\nconsole.log(slug);",
          "example": "const email = \"USER@Example.com\";\nconst normalized = email.trim().toLowerCase();\nconsole.log(normalized.endsWith(\"@example.com\")); // true",
          "useCase": "Input normalization, search, parsing, slug generation, validation, formatting.",
          "interviewQuestions": [
            {
              "question": "Are JavaScript strings mutable?",
              "answer": "No. Strings are immutable. Any transformation returns a new string."
            },
            {
              "question": "Difference between slice and substring?",
              "answer": "slice supports negative indexes; substring swaps start/end if needed and treats negatives as 0."
            },
            {
              "question": "When to use template literals?",
              "answer": "For interpolation, multiline strings, and improved readability over concatenation."
            },
            {
              "question": "How does split behave with empty separator?",
              "answer": "It splits into individual UTF-16 code units (characters for many common cases)."
            },
            {
              "question": "How to do case-insensitive search safely?",
              "answer": "Normalize both source and query (usually toLowerCase) before includes/indexOf."
            },
            {
              "question": "What does trim remove?",
              "answer": "Leading and trailing whitespace only, not inner spaces."
            },
            {
              "question": "replace vs replaceAll?",
              "answer": "replace replaces first match unless regex global flag used; replaceAll replaces all literal matches."
            },
            {
              "question": "How to reverse a string quickly?",
              "answer": "str.split(\"\").reverse().join(\"\") for basic cases."
            },
            {
              "question": "What is localeCompare used for?",
              "answer": "Locale-aware string comparison for sorting and internationalization."
            },
            {
              "question": "Common bug in string comparison?",
              "answer": "Forgetting normalization (case/whitespace) before comparing user input."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Output: \"abc\".toUpperCase()",
              "answer": "ABC",
              "output": "ABC"
            },
            {
              "type": "output",
              "question": "Output: \"  hi  \".trim().length",
              "answer": "2",
              "output": "2"
            },
            {
              "type": "implement",
              "question": "Implement isPalindrome(str) ignoring spaces and case."
            },
            {
              "type": "implement",
              "question": "Implement countVowels(str)."
            },
            {
              "type": "debug",
              "question": "Bug: using replace(\"a\",\"x\") expected all replacements.",
              "answer": "Use replaceAll or global regex."
            },
            {
              "type": "debug",
              "question": "Bug: case-sensitive includes fails user search.",
              "answer": "Normalize with toLowerCase."
            },
            {
              "type": "scenario",
              "question": "Generate SEO slug from title string."
            },
            {
              "type": "scenario",
              "question": "Mask email username except first 2 chars."
            },
            {
              "type": "tricky",
              "question": "Is \"abc\"[0] assignable?",
              "answer": "No, strings are immutable."
            },
            {
              "type": "tricky",
              "question": "Difference between == and === for strings?",
              "answer": "Usually same for primitive strings; === avoids coercion for mixed types."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Reverse a string.",
              "code": "const s=\"javascript\";\nconsole.log(s.split(\"\").reverse().join(\"\"));",
              "output": "tpircsavaj"
            },
            {
              "type": "program",
              "question": "Program 2: Check palindrome.",
              "code": "function isPalindrome(str){\n  const c=str.toLowerCase().replace(/\\s+/g,\"\");\n  return c===c.split(\"\").reverse().join(\"\");\n}\nconsole.log(isPalindrome(\"Never odd or even\"));",
              "output": "true"
            },
            {
              "type": "program",
              "question": "Program 3: Count vowels.",
              "code": "function countVowels(s){\n  return (s.match(/[aeiou]/gi)||[]).length;\n}\nconsole.log(countVowels(\"Interview\"));",
              "output": "4"
            },
            {
              "type": "program",
              "question": "Program 4: Convert sentence to slug.",
              "code": "const title=\"JavaScript String Methods\";\nconst slug=title.toLowerCase().trim().replace(/\\s+/g,\"-\");\nconsole.log(slug);",
              "output": "javascript-string-methods"
            },
            {
              "type": "program",
              "question": "Program 5: Capitalize first letter of each word.",
              "code": "const s=\"hello world\";\nconst out=s.split(\" \").map(w=>w[0].toUpperCase()+w.slice(1)).join(\" \");\nconsole.log(out);",
              "output": "Hello World"
            },
            {
              "type": "program",
              "question": "Program 6: Remove duplicate characters.",
              "code": "const s=\"aabbccdde\";\nconsole.log([...new Set(s)].join(\"\"));",
              "output": "abcde"
            },
            {
              "type": "program",
              "question": "Program 7: Frequency map of characters.",
              "code": "const s=\"banana\";\nconst freq=[...s].reduce((a,c)=>{a[c]=(a[c]||0)+1;return a;},{});\nconsole.log(freq);",
              "output": "{ b: 1, a: 3, n: 2 }"
            },
            {
              "type": "program",
              "question": "Program 8: Check substring exists case-insensitively.",
              "code": "const text=\"Frontend Interview\";\nconst q=\"interview\";\nconsole.log(text.toLowerCase().includes(q.toLowerCase()));",
              "output": "true"
            },
            {
              "type": "program",
              "question": "Program 9: Mask phone number except last 4.",
              "code": "const phone=\"9876543210\";\nconsole.log(phone.slice(0,-4).replace(/./g,\"*\")+phone.slice(-4));",
              "output": "******3210"
            },
            {
              "type": "program",
              "question": "Program 10: Parse CSV line into array.",
              "code": "const line=\"js,react,next\";\nconsole.log(line.split(\",\"));",
              "output": "[ \"js\", \"react\", \"next\" ]"
            }
          ]
        },
        {
          "id": "functions",
          "category": "Core Language",
          "title": "Functions",
          "description": "Understand function declarations, expressions, arrow functions, closures, higher-order functions, and this binding.",
          "explanation": "Functions are first-class citizens in JavaScript: they can be assigned, passed, and returned. Interviews focus on declaration vs expression hoisting, arrow function this behavior, closure patterns, call/apply/bind, and higher-order function design.\n\nKey points:\n- Declarations are hoisted with definitions.\n- Function expressions are hoisted as variables only.\n- Arrow functions do not bind their own this/arguments.\n- Closures capture lexical scope.",
          "implementation": "function greet(name){\n  return `Hello ${name}`;\n}\nconst shout = function(msg){\n  return msg.toUpperCase();\n};\nconst add = (a,b) => a+b;\nconsole.log(greet(\"Dev\"), shout(\"js\"), add(2,3));",
          "example": "function multiplier(factor){\n  return function(value){\n    return value * factor;\n  };\n}\nconst double = multiplier(2);\nconsole.log(double(8)); // 16",
          "useCase": "Abstraction, callbacks, reusable utilities, event handlers, functional composition.",
          "interviewQuestions": [
            {
              "question": "Function declaration vs function expression?",
              "answer": "Declaration is hoisted with body; expression depends on variable initialization timing."
            },
            {
              "question": "Arrow function this behavior?",
              "answer": "Arrow inherits lexical this from surrounding scope."
            },
            {
              "question": "What is closure?",
              "answer": "A function retaining access to outer lexical variables after outer function execution ends."
            },
            {
              "question": "call vs apply vs bind?",
              "answer": "call/apply invoke immediately with context; bind returns new bound function."
            },
            {
              "question": "What is higher-order function?",
              "answer": "Function that takes/returns another function."
            },
            {
              "question": "Can functions be passed as arguments?",
              "answer": "Yes, functions are first-class values."
            },
            {
              "question": "What is IIFE and use-case?",
              "answer": "Immediately Invoked Function Expression, used for isolated scope."
            },
            {
              "question": "Default params benefit?",
              "answer": "Avoid undefined handling boilerplate and provide safer API."
            },
            {
              "question": "Rest params vs arguments object?",
              "answer": "Rest gives real array and cleaner syntax; arguments is array-like and unavailable in arrows."
            },
            {
              "question": "Common this bug in methods?",
              "answer": "Losing object context when method is passed as callback unbound."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Output: (function(){return typeof arguments})();",
              "answer": "object",
              "output": "object"
            },
            {
              "type": "output",
              "question": "Output: (()=>typeof arguments)()",
              "answer": "depends on outer scope; arrow has no own arguments."
            },
            {
              "type": "implement",
              "question": "Implement once(fn) utility executing function only first time."
            },
            {
              "type": "implement",
              "question": "Implement compose(f,g) returning x => f(g(x))."
            },
            {
              "type": "debug",
              "question": "Method loses this inside setTimeout callback. Fix?",
              "answer": "Use arrow callback or bind(this)."
            },
            {
              "type": "debug",
              "question": "Function expression called before assignment. Why error?",
              "answer": "Variable hoisted but value undefined until assignment."
            },
            {
              "type": "scenario",
              "question": "Create reusable logger(prefix) using closure."
            },
            {
              "type": "scenario",
              "question": "Refactor duplicate tax calculations with higher-order function."
            },
            {
              "type": "tricky",
              "question": "Are arrow functions suitable as constructors?",
              "answer": "No, they cannot be used with new."
            },
            {
              "type": "tricky",
              "question": "Can function declaration appear inside blocks?",
              "answer": "Yes in modern JS, but behavior historically varied; prefer clarity."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Function declaration add(a,b).",
              "code": "function add(a,b){ return a+b; }\nconsole.log(add(2,5));",
              "output": "7"
            },
            {
              "type": "program",
              "question": "Program 2: Function expression multiply.",
              "code": "const multiply = function(a,b){ return a*b; };\nconsole.log(multiply(3,4));",
              "output": "12"
            },
            {
              "type": "program",
              "question": "Program 3: Arrow function square.",
              "code": "const square = n => n*n;\nconsole.log(square(9));",
              "output": "81"
            },
            {
              "type": "program",
              "question": "Program 4: Closure counter.",
              "code": "function counter(){ let c=0; return ()=>++c; }\nconst inc=counter();\nconsole.log(inc(), inc(), inc());",
              "output": "1 2 3"
            },
            {
              "type": "program",
              "question": "Program 5: call/apply/bind demo.",
              "code": "function greet(msg){ console.log(msg + \" \" + this.name); }\nconst user={name:\"Jitender\"};\ngreet.call(user,\"Hi\");\ngreet.apply(user,[\"Hello\"]);\nconst b=greet.bind(user,\"Welcome\"); b();",
              "output": "Hi Jitender\nHello Jitender\nWelcome Jitender"
            },
            {
              "type": "program",
              "question": "Program 6: Higher-order function mapByKey.",
              "code": "const mapByKey = key => arr => arr.map(x=>x[key]);\nconsole.log(mapByKey(\"id\")([{id:1},{id:2}]));",
              "output": "[ 1, 2 ]"
            },
            {
              "type": "program",
              "question": "Program 7: once(fn) implementation.",
              "code": "function once(fn){ let done=false,res; return (...a)=> done?res:(done=true,res=fn(...a)); }\nconst init=once(()=>\"INIT\");\nconsole.log(init(), init());",
              "output": "INIT INIT"
            },
            {
              "type": "program",
              "question": "Program 8: Debounce-like wrapper with function closure state.",
              "code": "function withCount(fn){ let n=0; return (...a)=>{ n++; return fn(n,...a); }; }\nconst f=withCount((n,v)=>`${n}:${v}`);\nconsole.log(f(\"A\"), f(\"B\"));",
              "output": "1:A 2:B"
            },
            {
              "type": "program",
              "question": "Program 9: Currying with functions topic (sum3).",
              "code": "const sum3=a=>b=>c=>a+b+c;\nconsole.log(sum3(1)(2)(3));",
              "output": "6"
            },
            {
              "type": "program",
              "question": "Program 10: Compose two functions.",
              "code": "const compose=(f,g)=>x=>f(g(x));\nconst double=x=>x*2;\nconst plus1=x=>x+1;\nconsole.log(compose(double,plus1)(4));",
              "output": "10"
            }
          ]
        },
        {
          "id": "map",
          "title": "Array.map()",
          "category": "Array Methods",
          "description": "Creates a new array with the results of calling a function on every element.",
          "explanation": "Array.map() creates a new array by calling a callback function on every element of the original array. It does NOT mutate the original array.\n\nSyntax: array.map(callback(element, index, array), thisArg)\n\nKey characteristics:\n- Always returns a new array of the SAME length\n- Callback is called for each element (skips empty slots in sparse arrays)\n- Returns undefined for elements where callback returns nothing\n- Cannot break/stop early — use find/some/every/for...of for that\n\nCommon use cases:\n- Transforming data: numbers.map(n => n * 2)\n- Extracting properties: users.map(u => u.name)\n- Formatting: prices.map(p => `$${p.toFixed(2)}`)\n- React rendering: items.map(item => <Card key={item.id} {...item} />)\n\nmap vs forEach:\n- map returns a new array — use when you NEED the result\n- forEach returns undefined — use for side effects only\n- Never use map and ignore its return value\n\nPerformance: O(n) time, O(n) space for the new array. For large datasets where you don't need all results, consider lazy evaluation or generators.",
          "implementation": "const numbers = [1, 2, 3, 4];\nconst doubled = numbers.map(num => num * 2);\n// [2, 4, 6, 8]",
          "example": "const users = [{name: 'John', age: 25}, {name: 'Jane', age: 30}];\nconst names = users.map(user => user.name);\n// ['John', 'Jane']",
          "useCase": "Transforming data, extracting properties from objects",
          "interviewQuestions": [
            {
              "question": "What does Array.map return?",
              "answer": "A new array of the same length where each item is transformed by the callback result."
            },
            {
              "question": "Why is map preferred over forEach for transformations?",
              "answer": "map is declarative, chainable, and communicates that output array is the goal."
            },
            {
              "question": "What are common mistakes with map in React rendering?",
              "answer": "Forgetting return in callback or forgetting stable key assignment in rendered lists."
            },
            {
              "question": "Can map mutate source array?",
              "answer": "The method itself does not mutate source, but callback can mutate objects by reference if you do it explicitly."
            },
            {
              "question": "When not to use map?",
              "answer": "Do not use map when you ignore the returned array. Use forEach or for...of for side effects only."
            },
            {
              "question": "What are the arguments passed to the map callback?",
              "answer": "Three arguments: (element, index, array). The second arg thisArg sets 'this' inside callback. Arrow functions ignore thisArg."
            },
            {
              "question": "How does map handle sparse arrays?",
              "answer": "map skips empty slots in sparse arrays (does not call callback for them) but preserves the holes in the output array."
            },
            {
              "question": "Can you break or stop early in map?",
              "answer": "No. map always iterates the entire array. For early termination, use for...of, find, some, or every instead."
            },
            {
              "question": "What happens if you forget return in map callback with braces?",
              "answer": "The callback implicitly returns undefined for that element. Common bug: .map(x => { x * 2 }) gives [undefined, ...]. Fix: add return or remove braces."
            },
            {
              "question": "How do you chain map with other array methods?",
              "answer": "map returns an array, so you can chain: arr.filter(predicate).map(transform).sort(compare). Each creates an intermediate array. For performance, use reduce for single-pass."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Predict: [1,2,3].map(n=>n*2)",
              "answer": "[2,4,6]",
              "output": "[2,4,6]"
            },
            {
              "type": "implement",
              "question": "Map users array to usernames array.",
              "code": "const usernames = users.map(u => u.username);"
            },
            {
              "type": "debug",
              "question": "Fix map callback that returns undefined due to braces.",
              "answer": "Add explicit return inside braces or remove braces for implicit return."
            },
            {
              "type": "scenario",
              "question": "You need transform API payload to UI card model using map. Draft mapping fields.",
              "answer": "Return new object with only required fields and formatted values."
            },
            {
              "type": "output",
              "question": "Predict output: [1,2,3].map((n,i)=>n+i)",
              "answer": "[1,3,5]",
              "output": "[1,3,5]"
            },
            {
              "type": "output",
              "question": "Predict output: [1,2].map(function(){ return this.x }, {x:7})",
              "answer": "[7,7]",
              "output": "[7,7]"
            },
            {
              "type": "implement",
              "question": "Implement toCurrency(prices) using map to return strings like \"$10.00\"."
            },
            {
              "type": "implement",
              "question": "Map products to {id, label} where label is `${name} - ${price}`."
            },
            {
              "type": "debug",
              "question": "['1','2','3'].map(parseInt) gives unexpected result. Why?",
              "answer": "parseInt receives (element, index) as arguments: parseInt('1',0)=1, parseInt('2',1)=NaN, parseInt('3',2)=NaN. Use .map(Number) or .map(s => parseInt(s, 10)) instead."
            },
            {
              "type": "debug",
              "question": "Map over sparse array behaves unexpectedly. Why?",
              "answer": "map skips empty slots in sparse arrays."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Double all numbers using map.",
              "code": "const nums=[1,2,3,4];\nconst doubled=nums.map(n=>n*2);\nconsole.log(doubled);",
              "output": "[ 2, 4, 6, 8 ]"
            },
            {
              "type": "program",
              "question": "Program 2: Convert names to uppercase.",
              "code": "const names=[\"jit\",\"ram\"];\nconsole.log(names.map(n=>n.toUpperCase()));",
              "output": "[ \"JIT\", \"RAM\" ]"
            },
            {
              "type": "program",
              "question": "Program 3: Extract ids from object list.",
              "code": "const users=[{id:1,name:\"A\"},{id:2,name:\"B\"}];\nconsole.log(users.map(u=>u.id));",
              "output": "[ 1, 2 ]"
            },
            {
              "type": "program",
              "question": "Program 4: Format prices to 2 decimal strings.",
              "code": "const prices=[10,15.5,3];\nconsole.log(prices.map(p=>`$${p.toFixed(2)}`));",
              "output": "[ \"$10.00\", \"$15.50\", \"$3.00\" ]"
            },
            {
              "type": "program",
              "question": "Program 5: Add index to each element text.",
              "code": "const arr=[\"a\",\"b\",\"c\"];\nconsole.log(arr.map((v,i)=>`${i}:${v}`));",
              "output": "[ \"0:a\", \"1:b\", \"2:c\" ]"
            },
            {
              "type": "program",
              "question": "Program 6: Create boolean pass/fail from marks >= 40.",
              "code": "const marks=[30,40,90];\nconsole.log(marks.map(m=>m>=40));",
              "output": "[ false, true, true ]"
            },
            {
              "type": "program",
              "question": "Program 7: Map nested object array to labels.",
              "code": "const p=[{name:\"Pen\",price:10},{name:\"Book\",price:50}];\nconsole.log(p.map(x=>`${x.name}-${x.price}`));",
              "output": "[ \"Pen-10\", \"Book-50\" ]"
            },
            {
              "type": "program",
              "question": "Program 8: Parse numeric strings to numbers.",
              "code": "const s=[\"1\",\"2\",\"3\"];\nconsole.log(s.map(Number));",
              "output": "[ 1, 2, 3 ]"
            },
            {
              "type": "program",
              "question": "Program 9: Map dates to year values.",
              "code": "const dates=[\"2024-01-01\",\"2026-02-12\"];\nconsole.log(dates.map(d=>new Date(d).getFullYear()));",
              "output": "[ 2024, 2026 ]"
            },
            {
              "type": "program",
              "question": "Program 10: Build slug list from titles.",
              "code": "const titles=[\"Hello World\",\"JS Interview\"];\nconst slugs=titles.map(t=>t.toLowerCase().replace(/\\s+/g,\"-\"));\nconsole.log(slugs);",
              "output": "[ \"hello-world\", \"js-interview\" ]"
            }
          ]
        },
        {
          "id": "filter",
          "title": "Array.filter()",
          "category": "Array Methods",
          "description": "Creates a new array with elements that pass a test condition.",
          "explanation": "Array.filter() creates a new array with all elements that pass a test implemented by the callback function. Returns an empty array if no elements match.\n\nSyntax: array.filter(callback(element, index, array), thisArg)\n\nKey characteristics:\n- Returns a NEW array (original is not mutated)\n- Result array length is ≤ original length\n- Callback should return a truthy/falsy value\n- Does NOT mutate elements — but filtered objects share references\n\nCommon patterns:\n- Remove falsy: arr.filter(Boolean) — removes 0, '', null, undefined, NaN, false\n- Remove duplicates: arr.filter((v, i, a) => a.indexOf(v) === i)\n- Search: items.filter(item => item.name.includes(query))\n- Type guard (TS): arr.filter((x): x is Type => predicate)\n\nImportant gotchas:\n- Filtered objects are NOT cloned — mutating them affects the original\n- filter(Boolean) removes 0 and '' which may be valid data\n- For finding ONE element, use find() instead (short-circuits)\n- Chaining map().filter() creates intermediate arrays — use reduce() for single-pass when performance matters\n\nPerformance: O(n) time. O(k) space where k is the number of matching elements.",
          "implementation": "const numbers = [1, 2, 3, 4, 5, 6];\nconst evens = numbers.filter(num => num % 2 === 0);\n// [2, 4, 6]",
          "example": "const products = [\n  {name: 'Laptop', price: 1000},\n  {name: 'Mouse', price: 25}\n];\nconst expensive = products.filter(p => p.price > 50);",
          "useCase": "Filtering lists, searching, removing unwanted items",
          "interviewQuestions": [
            {
              "question": "How does Array.filter work?",
              "answer": "It returns a new array containing only elements for which callback returns truthy."
            },
            {
              "question": "What is the time complexity of filter?",
              "answer": "O(n), because each element is checked once."
            },
            {
              "question": "How do you remove falsy values quickly?",
              "answer": "Use arr.filter(Boolean), which keeps only truthy values."
            },
            {
              "question": "What is a subtle bug with filter and object mutation?",
              "answer": "Filtering does not clone elements. Mutating returned objects can affect original referenced objects."
            },
            {
              "question": "How to combine map and filter efficiently?",
              "answer": "Use reduce for single pass when performance matters, or keep map/filter for readability in normal cases."
            },
            {
              "question": "What does filter(Boolean) actually do?",
              "answer": "Boolean is called as the callback: Boolean(element). It returns false for 0, '', null, undefined, NaN, false. Removes all falsy values. Be careful: filter(Boolean) removes 0 and '' which might be valid data."
            },
            {
              "question": "How do you filter unique values from an array?",
              "answer": "arr.filter((v, i, a) => a.indexOf(v) === i). This keeps only the first occurrence. For objects, use a Set of keys. For better performance, use [...new Set(arr)]."
            },
            {
              "question": "Does filter create a deep copy of elements?",
              "answer": "No. filter returns a new array but the elements are NOT cloned. Objects in the filtered array share references with the original. Mutating them affects both arrays."
            },
            {
              "question": "What is the difference between filter and find?",
              "answer": "filter returns ALL matching elements (array). find returns only the FIRST match (single element or undefined). find short-circuits (stops early), filter always checks all elements."
            },
            {
              "question": "How does filter work with TypeScript type narrowing?",
              "answer": "Use type predicates: arr.filter((x): x is NonNullable<T> => x != null). This narrows the return type so TypeScript knows the result excludes null/undefined."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Predict: [0,1,2,3].filter(Boolean)",
              "answer": "[1,2,3]",
              "output": "[1,2,3]"
            },
            {
              "type": "implement",
              "question": "Filter active users only from users list.",
              "code": "const active = users.filter(u => u.active);"
            },
            {
              "type": "debug",
              "question": "Filter callback returns object instead of boolean. Is it valid?",
              "answer": "Yes, object is truthy; but return explicit boolean for clarity."
            },
            {
              "type": "refactor",
              "question": "Refactor if-push loop into filter expression.",
              "answer": "Use source.filter(predicate) instead of manual accumulator loop."
            },
            {
              "type": "output",
              "question": "Predict output: [1,2,3,4].filter(n=>n%2===0)",
              "answer": "[2,4]",
              "output": "[2,4]"
            },
            {
              "type": "output",
              "question": "Predict output: [\"\", \"a\", 0, 5].filter(Boolean)",
              "answer": "[\"a\",5]",
              "output": "[\"a\",5]"
            },
            {
              "type": "implement",
              "question": "Filter products in stock and price > 100."
            },
            {
              "type": "implement",
              "question": "Implement removeDuplicates(arr) using filter + indexOf."
            },
            {
              "type": "debug",
              "question": "Filter callback forgets return in braces. What happens?",
              "answer": "All results become falsey and output can become empty array."
            },
            {
              "type": "debug",
              "question": "Filtering objects then mutating item changes source data. Why?",
              "answer": "Objects are referenced; filter does not deep clone items."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Keep even numbers only.",
              "code": "const nums=[1,2,3,4,5,6];\nconsole.log(nums.filter(n=>n%2===0));",
              "output": "[ 2, 4, 6 ]"
            },
            {
              "type": "program",
              "question": "Program 2: Filter words longer than 4 chars.",
              "code": "const words=[\"js\",\"react\",\"node\",\"api\"];\nconsole.log(words.filter(w=>w.length>4));",
              "output": "[ \"react\" ]"
            },
            {
              "type": "program",
              "question": "Program 3: Filter active users.",
              "code": "const users=[{name:\"A\",active:true},{name:\"B\",active:false}];\nconsole.log(users.filter(u=>u.active));",
              "output": "[ { name: \"A\", active: true } ]"
            },
            {
              "type": "program",
              "question": "Program 4: Remove falsy values.",
              "code": "const mixed=[0,1,\"\", \"ok\", null, 7];\nconsole.log(mixed.filter(Boolean));",
              "output": "[ 1, \"ok\", 7 ]"
            },
            {
              "type": "program",
              "question": "Program 5: Filter products with stock > 0.",
              "code": "const p=[{n:\"Pen\",s:0},{n:\"Book\",s:3}];\nconsole.log(p.filter(x=>x.s>0));",
              "output": "[ { n: \"Book\", s: 3 } ]"
            },
            {
              "type": "program",
              "question": "Program 6: Keep unique numbers using filter.",
              "code": "const arr=[1,2,2,3,1,4];\nconst unique=arr.filter((v,i,a)=>a.indexOf(v)===i);\nconsole.log(unique);",
              "output": "[ 1, 2, 3, 4 ]"
            },
            {
              "type": "program",
              "question": "Program 7: Filter emails ending with @gmail.com.",
              "code": "const emails=[\"a@gmail.com\",\"b@yahoo.com\"];\nconsole.log(emails.filter(e=>e.endsWith(\"@gmail.com\")));",
              "output": "[ \"a@gmail.com\" ]"
            },
            {
              "type": "program",
              "question": "Program 8: Filter numbers between 10 and 20.",
              "code": "const nums=[5,12,19,25];\nconsole.log(nums.filter(n=>n>=10&&n<=20));",
              "output": "[ 12, 19 ]"
            },
            {
              "type": "program",
              "question": "Program 9: Filter objects by category.",
              "code": "const items=[{c:\"A\"},{c:\"B\"},{c:\"A\"}];\nconsole.log(items.filter(i=>i.c===\"A\"));",
              "output": "[ { c: \"A\" }, { c: \"A\" } ]"
            },
            {
              "type": "program",
              "question": "Program 10: Exclude blocked usernames list.",
              "code": "const users=[\"ram\",\"sam\",\"tom\"];\nconst blocked=[\"sam\"];\nconsole.log(users.filter(u=>!blocked.includes(u)));",
              "output": "[ \"ram\", \"tom\" ]"
            }
          ]
        },
        {
          "id": "find-findindex",
          "title": "Array.find() & findIndex()",
          "category": "Array Methods",
          "description": "find() returns the first element that satisfies the condition. findIndex() returns its index.",
          "explanation": "Array.find() returns the FIRST element that satisfies the testing function. Array.findIndex() returns the INDEX of that element.\n\nSyntax:\n- array.find(callback(element, index, array))\n- array.findIndex(callback(element, index, array))\n\nReturn values:\n- find(): the element if found, undefined if not found\n- findIndex(): the index if found, -1 if not found\n\nKey characteristics:\n- Both short-circuit — stop searching after first match (efficient!)\n- find vs filter: find returns ONE element, filter returns ALL matches\n- findIndex vs indexOf: findIndex takes a callback (complex conditions), indexOf checks strict equality (simple value lookup)\n\nSafe usage patterns:\n- Nullish coalescing: const user = users.find(u => u.id === id) ?? defaultUser\n- Optional chaining: users.find(u => u.active)?.name\n- Guard clause: const idx = arr.findIndex(pred); if (idx === -1) return;\n\nRelated methods:\n- findLast() / findLastIndex(): search from end (ES2023)\n- some(): returns boolean (just existence check)\n- includes(): checks value equality (no callback)\n\nPerformance: O(n) worst case, but short-circuits on first match.",
          "implementation": "const users = [\n  {id: 1, name: 'John'},\n  {id: 2, name: 'Jane'}\n];\nconst user = users.find(u => u.id === 2);\nconst index = users.findIndex(u => u.id === 2);",
          "example": "const numbers = [5, 12, 8, 130, 44];\nconst found = numbers.find(n => n > 10); // 12\nconst foundIndex = numbers.findIndex(n => n > 10); // 1",
          "useCase": "Searching specific items, locating array positions",
          "interviewQuestions": [
            {
              "question": "Difference between find and filter?",
              "answer": "find returns first matching element; filter returns all matching elements."
            },
            {
              "question": "What does find return when no match exists?",
              "answer": "undefined. findIndex returns -1 when no match exists."
            },
            {
              "question": "When is find preferable for performance?",
              "answer": "When only first match is needed because it short-circuits."
            },
            {
              "question": "How to safely use find result?",
              "answer": "Check for undefined before property access or use optional chaining."
            },
            {
              "question": "What is an interview follow-up after find?",
              "answer": "Compare with some/every and explain short-circuit behavior and intent."
            },
            {
              "question": "What is the difference between findIndex and indexOf?",
              "answer": "indexOf searches by value using strict equality (===). findIndex takes a callback for complex conditions. Use indexOf for primitives, findIndex for objects or complex checks."
            },
            {
              "question": "What are findLast and findLastIndex?",
              "answer": "ES2023 methods that search from the END of the array. findLast returns the last matching element, findLastIndex returns its index. Useful when you want the most recent match."
            },
            {
              "question": "How do you safely use the result of find?",
              "answer": "Always handle undefined: use optional chaining (result?.prop), nullish coalescing (result ?? default), or explicit if-check. Never assume find will always match."
            },
            {
              "question": "Can find/findIndex mutate the original array?",
              "answer": "The methods don't mutate, but the callback CAN mutate elements since objects are passed by reference inside the callback. This is generally bad practice."
            },
            {
              "question": "How would you implement find using reduce?",
              "answer": "arr.reduce((found, el) => found !== undefined ? found : (pred(el) ? el : undefined), undefined). However, reduce can't short-circuit, so find is more efficient."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Predict: [5,10,15].find(n=>n>9)",
              "answer": "10",
              "output": "10"
            },
            {
              "type": "implement",
              "question": "Find first overdue invoice by dueDate.",
              "code": "const overdue = invoices.find(i => i.dueDate < now);"
            },
            {
              "type": "debug",
              "question": "findIndex returns -1 then used directly as array index. Fix?",
              "answer": "Check for -1 before indexing, otherwise handle not found branch."
            },
            {
              "type": "scenario",
              "question": "Need boolean existence check only. Use find or some?",
              "answer": "Use some() since intent is existence and it returns boolean directly."
            },
            {
              "type": "output",
              "question": "Predict output: [4,8,12].find(n=>n>20)",
              "answer": "undefined",
              "output": "undefined"
            },
            {
              "type": "output",
              "question": "Predict output: [4,8,12].findIndex(n=>n>10)",
              "answer": "2",
              "output": "2"
            },
            {
              "type": "implement",
              "question": "Find first user by email from users array."
            },
            {
              "type": "implement",
              "question": "Find index of cart item by id, replace item immutably if found."
            },
            {
              "type": "debug",
              "question": "Accessing .name on find result throws. Fix?",
              "answer": "Handle undefined result before property access."
            },
            {
              "type": "debug",
              "question": "find() returns a reference to the original object. Mutating it changes the source array. How to avoid?",
              "answer": "Clone the result: const result = {...arr.find(predicate)} or use structuredClone for deep copy."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Find first number > 50.",
              "code": "const nums=[10,40,70,80];\nconsole.log(nums.find(n=>n>50));",
              "output": "70"
            },
            {
              "type": "program",
              "question": "Program 2: Find first admin user object.",
              "code": "const users=[{r:\"user\"},{r:\"admin\"}];\nconsole.log(users.find(u=>u.r===\"admin\"));",
              "output": "{ r: \"admin\" }"
            },
            {
              "type": "program",
              "question": "Program 3: Find index of item id=3.",
              "code": "const items=[{id:1},{id:3},{id:4}];\nconsole.log(items.findIndex(i=>i.id===3));",
              "output": "1"
            },
            {
              "type": "program",
              "question": "Program 4: Return fallback when find gives undefined.",
              "code": "const arr=[1,2,3];\nconst found=arr.find(n=>n>10) ?? \"Not found\";\nconsole.log(found);",
              "output": "Not found"
            },
            {
              "type": "program",
              "question": "Program 5: Update first matching task by findIndex immutably.",
              "code": "const tasks=[{id:1,d:false},{id:2,d:false}];\nconst idx=tasks.findIndex(t=>t.id===2);\nconst next=idx===-1?tasks:[...tasks.slice(0,idx),{...tasks[idx],d:true},...tasks.slice(idx+1)];\nconsole.log(next);",
              "output": "[ { id: 1, d: false }, { id: 2, d: true } ]"
            },
            {
              "type": "program",
              "question": "Program 6: Find first string containing \"js\".",
              "code": "const tags=[\"react\",\"js-core\",\"node\"];\nconsole.log(tags.find(t=>t.includes(\"js\")));",
              "output": "js-core"
            },
            {
              "type": "program",
              "question": "Program 7: Find index of first negative number.",
              "code": "const nums=[5,3,-2,-8];\nconsole.log(nums.findIndex(n=>n<0));",
              "output": "2"
            },
            {
              "type": "program",
              "question": "Program 8: Search user by email in array.",
              "code": "const users=[{email:\"a@x.com\"},{email:\"b@y.com\"}];\nconsole.log(users.find(u=>u.email===\"b@y.com\"));",
              "output": "{ email: \"b@y.com\" }"
            },
            {
              "type": "program",
              "question": "Program 9: Find first order with status pending.",
              "code": "const orders=[{id:1,s:\"done\"},{id:2,s:\"pending\"}];\nconsole.log(orders.find(o=>o.s===\"pending\"));",
              "output": "{ id: 2, s: \"pending\" }"
            },
            {
              "type": "program",
              "question": "Program 10: Use findIndex for insertion position by condition.",
              "code": "const arr=[5,10,20,30];\nconst idx=arr.findIndex(n=>n>15);\nconsole.log(idx);",
              "output": "2"
            }
          ]
        },
        {
          "id": "reduce",
          "title": "Array.reduce()",
          "category": "Array Methods",
          "description": "Executes a reducer function on each element, resulting in a single output value.",
          "explanation": "Array.reduce() executes a reducer callback on each element, accumulating a single result. It's the most versatile array method — can implement map, filter, flatMap, and more.\n\nSyntax: array.reduce(callback(accumulator, currentValue, index, array), initialValue)\n\nHow it works:\n1. If initialValue is provided, accumulator starts as initialValue, iteration begins at index 0\n2. If no initialValue, accumulator = first element, iteration begins at index 1\n3. Each iteration: accumulator = callback(accumulator, currentValue)\n4. Final accumulator value is returned\n\nCritical rule — ALWAYS provide initialValue:\n- Without it, reduce on empty array throws TypeError\n- Without it, accumulator type depends on first element (error-prone)\n- Makes your intent explicit: 0 for sums, [] for arrays, {} for objects\n\nCommon patterns:\n- Sum: arr.reduce((sum, n) => sum + n, 0)\n- Flatten: arr.reduce((flat, sub) => flat.concat(sub), [])\n- Group by: arr.reduce((groups, item) => { ... }, {})\n- Frequency map: arr.reduce((freq, item) => { freq[item] = (freq[item] || 0) + 1; return freq; }, {})\n- Pipe/compose: fns.reduce((result, fn) => fn(result), initialVal)\n\nWhen NOT to use reduce:\n- Simple transformations (use map/filter for readability)\n- When the reducer becomes hard to read\n- When you need to break early (use for...of instead)",
          "implementation": "const numbers = [1, 2, 3, 4];\nconst sum = numbers.reduce((acc, curr) => acc + curr, 0);\n// 10",
          "example": "const cart = [\n  {item: 'book', price: 10},\n  {item: 'pen', price: 2}\n];\nconst total = cart.reduce((sum, item) => sum + item.price, 0);\n// 12",
          "useCase": "Calculating totals, flattening arrays, grouping data",
          "interviewQuestions": [
            {
              "question": "What is reduce used for?",
              "answer": "To fold an array into a single accumulated result such as number, object, map, or array."
            },
            {
              "question": "Why is initial value important in reduce?",
              "answer": "It avoids edge-case bugs on empty arrays and makes accumulator type explicit."
            },
            {
              "question": "Common reduce interview tasks?",
              "answer": "Sum, groupBy, flatten, frequency counter, composing pipelines."
            },
            {
              "question": "How to debug hard-to-read reduce logic?",
              "answer": "Name accumulator clearly, return immutable updates, and log intermediate accumulator states."
            },
            {
              "question": "When should reduce be avoided?",
              "answer": "When it harms readability for simple transformations where map/filter are clearer."
            },
            {
              "question": "What happens if you call reduce on an empty array without initialValue?",
              "answer": "Throws TypeError: 'Reduce of empty array with no initial value'. Always provide initialValue to avoid this — it's a common production bug."
            },
            {
              "question": "How does reduce differ from reduceRight?",
              "answer": "reduce iterates left-to-right (index 0 → end). reduceRight iterates right-to-left (end → index 0). Useful for right-to-left composition: fns.reduceRight((result, fn) => fn(result), initial)."
            },
            {
              "question": "How would you implement map using reduce?",
              "answer": "arr.reduce((result, element) => { result.push(transform(element)); return result; }, []). This shows reduce's versatility — it can implement any array method."
            },
            {
              "question": "What is function composition with reduce?",
              "answer": "const pipe = (...fns) => (x) => fns.reduce((result, fn) => fn(result), x). This creates a pipeline: pipe(add1, double, toString)(5) runs each function in sequence."
            },
            {
              "question": "Why is it important to always return the accumulator?",
              "answer": "If any branch of the callback doesn't return the accumulator, it becomes undefined in the next iteration, causing bugs. Always ensure every code path returns the accumulator value."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Predict: [1,2,3].reduce((a,b)=>a+b,0)",
              "answer": "6",
              "output": "6"
            },
            {
              "type": "implement",
              "question": "Create frequency map from words array using reduce.",
              "code": "const freq = words.reduce((acc,w)=>{\n  acc[w]=(acc[w]||0)+1;\n  return acc;\n}, {});"
            },
            {
              "type": "debug",
              "question": "Reduce on empty array without initial value throws. Fix?",
              "answer": "Provide initial value based on accumulator type."
            },
            {
              "type": "refactor",
              "question": "Combine filter+map into one reduce for performance-sensitive path.",
              "answer": "Use conditional push inside reduce accumulator array."
            },
            {
              "type": "output",
              "question": "Predict output: ['a','b','c'].reduce((acc, val) => ({...acc, [val]: val.toUpperCase()}), {})",
              "answer": "{ a: 'A', b: 'B', c: 'C' }",
              "output": "{ a: 'A', b: 'B', c: 'C' }"
            },
            {
              "type": "output",
              "question": "Predict output: [1,2,3].reduce((a,b)=>a*b)",
              "answer": "6",
              "output": "6"
            },
            {
              "type": "implement",
              "question": "Implement sum(arr) using reduce."
            },
            {
              "type": "implement",
              "question": "Implement groupBy(arr, key) using reduce."
            },
            {
              "type": "debug",
              "question": "Reduce callback doesn't return accumulator in one branch of an if/else. What happens?",
              "answer": "Accumulator becomes undefined in the next iteration, causing a runtime error or incorrect result. Always return accumulator from every branch."
            },
            {
              "type": "debug",
              "question": "Accumulator returns undefined in one branch. Impact?",
              "answer": "Next iteration receives undefined, causing runtime bugs."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Sum array using reduce.",
              "code": "const nums=[10,20,30];\nconst total=nums.reduce((a,b)=>a+b,0);\nconsole.log(total);",
              "output": "60"
            },
            {
              "type": "program",
              "question": "Program 2: Multiply all numbers using reduce.",
              "code": "const nums=[2,3,4];\nconsole.log(nums.reduce((a,b)=>a*b,1));",
              "output": "24"
            },
            {
              "type": "program",
              "question": "Program 3: Find max value using reduce.",
              "code": "const nums=[8,3,15,9];\nconst max=nums.reduce((m,n)=>n>m?n:m);\nconsole.log(max);",
              "output": "15"
            },
            {
              "type": "program",
              "question": "Program 4: Flatten nested array one level using reduce.",
              "code": "const nested=[[1,2],[3,4],[5]];\nconst flat=nested.reduce((acc,c)=>acc.concat(c),[]);\nconsole.log(flat);",
              "output": "[ 1, 2, 3, 4, 5 ]"
            },
            {
              "type": "program",
              "question": "Program 5: Build frequency map of characters.",
              "code": "const str=\"aabca\";\nconst freq=[...str].reduce((acc,ch)=>{acc[ch]=(acc[ch]||0)+1;return acc;},{});\nconsole.log(freq);",
              "output": "{ a: 3, b: 1, c: 1 }"
            },
            {
              "type": "program",
              "question": "Program 6: Group users by role using reduce.",
              "code": "const users=[{n:\"A\",r:\"dev\"},{n:\"B\",r:\"qa\"},{n:\"C\",r:\"dev\"}];\nconst grouped=users.reduce((acc,u)=>{(acc[u.r]??=[]).push(u.n);return acc;},{});\nconsole.log(grouped);",
              "output": "{ dev: [ \"A\", \"C\" ], qa: [ \"B\" ] }"
            },
            {
              "type": "program",
              "question": "Program 7: Convert object entries array to object using reduce.",
              "code": "const entries=[[\"a\",1],[\"b\",2]];\nconst obj=entries.reduce((acc,[k,v])=>{acc[k]=v;return acc;},{});\nconsole.log(obj);",
              "output": "{ a: 1, b: 2 }"
            },
            {
              "type": "program",
              "question": "Program 8: Count total cart value.",
              "code": "const cart=[{p:100,q:2},{p:50,q:1}];\nconst total=cart.reduce((sum,i)=>sum+i.p*i.q,0);\nconsole.log(total);",
              "output": "250"
            },
            {
              "type": "program",
              "question": "Program 9: Remove duplicates with reduce.",
              "code": "const arr=[1,2,2,3,1];\nconst uniq=arr.reduce((acc,n)=>acc.includes(n)?acc:[...acc,n],[]);\nconsole.log(uniq);",
              "output": "[ 1, 2, 3 ]"
            },
            {
              "type": "program",
              "question": "Program 10: Compose sentence from words array.",
              "code": "const words=[\"JS\",\"is\",\"awesome\"];\nconst s=words.reduce((acc,w)=> acc ? `${acc} ${w}` : w, \"\");\nconsole.log(s);",
              "output": "JS is awesome"
            }
          ]
        },
        {
          "id": "currying",
          "title": "Currying",
          "description": "Currying is a functional programming technique that transforms a function with multiple arguments into a sequence of functions, each taking a single argument. It allows you to create specialized versions of functions by partially applying arguments. For example, a function add(a, b, c) becomes curriedAdd(a)(b)(c). This enables powerful function composition and reusability patterns.",
          "explanation": "Currying transforms a function that takes multiple arguments into a sequence of functions that each take a single argument. This is a cornerstone of functional programming.\n\nBenefits:\n- Create specialized functions by partial application\n- Better function composition\n- More reusable code\n- Cleaner function signatures\n- Easier to test and reason about\n\nReal-world applications:\n- Event handlers with preset values\n- Configuration functions\n- Higher-order components in React\n- Middleware patterns\n- API request builders",
          "implementation": "function curry(func) {\n  return function curried(...args) {\n    if (args.length >= func.length) {\n      return func.apply(this, args);\n    }\n    return function(...nextArgs) {\n      return curried.apply(this, args.concat(nextArgs));\n    };\n  };\n}",
          "example": "// Basic example\nconst add = (a, b, c) => a + b + c;\nconst curriedAdd = curry(add);\n\nconsole.log(curriedAdd(1)(2)(3)); // 6\nconsole.log(curriedAdd(1, 2)(3)); // 6\nconsole.log(curriedAdd(1)(2, 3)); // 6\n\n// Practical example\nconst multiply = (a, b) => a * b;\nconst curriedMultiply = curry(multiply);\n\n// Create specialized functions\nconst double = curriedMultiply(2);\nconst triple = curriedMultiply(3);\n\nconsole.log(double(5)); // 10\nconsole.log(triple(5)); // 15\n\n// Event handler example\nconst handleClick = curry((id, event) => {\n  console.log(`Button ${id} clicked`);\n});\n\nconst handleButton1 = handleClick('button1');\nconst handleButton2 = handleClick('button2');",
          "useCase": "Function composition, creating specialized functions, event handlers, configuration builders",
          "interviewQuestions": [
            {
              "question": "What is currying?",
              "answer": "Transforming f(a,b,c) into f(a)(b)(c) so arguments can be partially applied."
            },
            {
              "question": "Difference between currying and partial application?",
              "answer": "Currying enforces unary steps. Partial application fixes some arguments without requiring unary function chain."
            },
            {
              "question": "Real use cases of currying in JS apps?",
              "answer": "Configurable validators, reusable event handlers, and composable utility functions."
            },
            {
              "question": "How does function.length help curry implementations?",
              "answer": "It indicates declared parameter count, used to decide when enough args are collected."
            },
            {
              "question": "What is a caveat of currying in modern codebases?",
              "answer": "Overusing it can reduce readability for teammates not used to functional patterns."
            },
            {
              "question": "How do you implement a generic curry function?",
              "answer": "function curry(fn) { return function curried(...args) { if (args.length >= fn.length) return fn(...args); return (...next) => curried(...args, ...next); }; }. Collects args until fn.length is reached, then calls the original function."
            },
            {
              "question": "What is the relationship between currying and closures?",
              "answer": "Currying relies on closures — each returned function closes over the previously provided arguments. const add = a => b => a + b: the inner function (b => a + b) closes over 'a' from the outer scope."
            },
            {
              "question": "How is currying used in functional composition?",
              "answer": "Curried functions are easy to compose: const pipe = (...fns) => x => fns.reduce((v, f) => f(v), x). With curried helpers: pipe(filter(isActive), map(getName), sort(byAlpha))(users)."
            },
            {
              "question": "What is the difference between curry(fn)(1)(2)(3) and fn(1, 2, 3)?",
              "answer": "The curried version allows partial application — you can save intermediate functions: const add5 = curry(add)(5), then reuse add5(3), add5(10). The direct call requires all arguments at once."
            },
            {
              "question": "How does currying work with arrow functions?",
              "answer": "Arrow functions make currying natural: const add = a => b => a + b. Each arrow returns the next function. This is manual currying. For automatic currying of existing functions, use a curry utility."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Predict: const add=a=>b=>a+b; console.log(add(2)(3));",
              "answer": "5",
              "output": "5"
            },
            {
              "type": "implement",
              "question": "Create multiply(a)(b) curry function.",
              "code": "const multiply = a => b => a * b;"
            },
            {
              "type": "scenario",
              "question": "Create validator minLength(n)(value) returning boolean.",
              "code": "const minLength = n => value => value.length >= n;"
            },
            {
              "type": "debug",
              "question": "Currying util fails for optional args. Why?",
              "answer": "Arity-based completion using function.length may not suit optional/default params."
            },
            {
              "type": "output",
              "question": "Predict output: const add=a=>b=>a+b; console.log(add(3)(4));",
              "answer": "7",
              "output": "7"
            },
            {
              "type": "output",
              "question": "Predict output: const mul=a=>b=>c=>a*b*c; mul(2)(3)(4)",
              "answer": "24",
              "output": "24"
            },
            {
              "type": "implement",
              "question": "Implement simple curryAdd(a)(b)."
            },
            {
              "type": "implement",
              "question": "Implement priceWithTax(tax)(price) function."
            },
            {
              "type": "debug",
              "question": "Currying util fails for optional params. Why?",
              "answer": "Arity detection via function.length may not match optional/default arguments."
            },
            {
              "type": "debug",
              "question": "Curried function logs stale value in closure. Why?",
              "answer": "Captured outer variable changed unexpectedly; pass value explicitly to avoid stale closures."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Basic curried add function.",
              "code": "const add=a=>b=>a+b;\nconsole.log(add(5)(7));",
              "output": "12"
            },
            {
              "type": "program",
              "question": "Program 2: Curried multiply function with 3 args.",
              "code": "const mul=a=>b=>c=>a*b*c;\nconsole.log(mul(2)(3)(4));",
              "output": "24"
            },
            {
              "type": "program",
              "question": "Program 3: Curried tax calculator.",
              "code": "const withTax=tax=>price=>price+price*tax;\nconsole.log(withTax(0.18)(100));",
              "output": "118"
            },
            {
              "type": "program",
              "question": "Program 4: Curried greeting by locale.",
              "code": "const greet=locale=>name=>locale===\"hi\"?`Namaste ${name}`:`Hello ${name}`;\nconsole.log(greet(\"hi\")(\"Jitender\"));",
              "output": "Namaste Jitender"
            },
            {
              "type": "program",
              "question": "Program 5: Curried startsWith checker.",
              "code": "const startsWith=prefix=>str=>str.startsWith(prefix);\nconsole.log(startsWith(\"pre\")(\"prefix\"));",
              "output": "true"
            },
            {
              "type": "program",
              "question": "Program 6: Build reusable discount function via currying.",
              "code": "const discount=rate=>price=>price-(price*rate);\nconst tenOff=discount(0.10);\nconsole.log(tenOff(500));",
              "output": "450"
            },
            {
              "type": "program",
              "question": "Program 7: Curried power function.",
              "code": "const power=exp=>base=>base**exp;\nconst square=power(2);\nconsole.log(square(9));",
              "output": "81"
            },
            {
              "type": "program",
              "question": "Program 8: Curried formatter with prefix and suffix.",
              "code": "const formatter=pre=>suf=>val=>`${pre}${val}${suf}`;\nconsole.log(formatter(\"<\",\">\")(\"tag\"));",
              "output": "<tag>"
            },
            {
              "type": "program",
              "question": "Program 9: Generic curry utility for 2 args.",
              "code": "function curry2(fn){return a=>b=>fn(a,b)}\nconst sub=curry2((a,b)=>a-b);\nconsole.log(sub(10)(4));",
              "output": "6"
            },
            {
              "type": "program",
              "question": "Program 10: Curried validator min length.",
              "code": "const minLen=n=>value=>value.length>=n;\nconsole.log(minLen(5)(\"hello\"));",
              "output": "true"
            }
          ],
          "category": "Core Concepts"
        },
        {
          "id": "promises",
          "title": "Promises",
          "description": "Promises represent the eventual completion or failure of an asynchronous operation. They provide a cleaner way to handle async code compared to callbacks, avoiding callback hell.",
          "explanation": "A Promise is an object representing the eventual completion or failure of an asynchronous operation. It's a proxy for a value not necessarily known when the promise is created.\n\nPromise States:\n1. Pending: Initial state, neither fulfilled nor rejected\n2. Fulfilled: Operation completed successfully\n3. Rejected: Operation failed\n\nPromises solve the callback hell problem by allowing you to chain operations using .then() and handle errors with .catch().\n\nKey advantages:\n- Better error handling with .catch()\n- Chainable operations with .then()\n- Multiple promises with Promise.all()\n- Race conditions with Promise.race()\n- Cleaner, more readable code",
          "implementation": "const promise = new Promise((resolve, reject) => {\n  setTimeout(() => {\n    const success = true;\n    if (success) {\n      resolve('Operation successful!');\n    } else {\n      reject('Operation failed!');\n    }\n  }, 1000);\n});\n\npromise\n  .then(result => console.log(result))\n  .catch(error => console.error(error))\n  .finally(() => console.log('Done'));",
          "example": "// API call example\nfunction fetchUser(userId) {\n  return fetch(`/api/users/${userId}`)\n    .then(response => {\n      if (!response.ok) {\n        throw new Error('User not found');\n      }\n      return response.json();\n    });\n}\n\n// Chaining promises\nfetchUser(1)\n  .then(user => {\n    console.log('User:', user);\n    return fetchUserPosts(user.id);\n  })\n  .then(posts => {\n    console.log('Posts:', posts);\n  })\n  .catch(error => {\n    console.error('Error:', error);\n  });",
          "useCase": "API calls, file operations, timers, async operations, chaining async tasks",
          "interviewQuestions": [
            {
              "question": "What are Promise states?",
              "answer": "pending, fulfilled, rejected. State is immutable after settle."
            },
            {
              "question": "How does .catch propagate in chains?",
              "answer": "It catches rejections from previous links and can recover by returning value/promise."
            },
            {
              "question": "Difference between then(onFulfilled, onRejected) and catch?",
              "answer": "catch is preferred for centralized error flow and readability."
            },
            {
              "question": "How do you wrap callback APIs in Promise?",
              "answer": "Create new Promise and call resolve/reject from callback branches."
            },
            {
              "question": "What is an anti-pattern with promises?",
              "answer": "Nesting chains instead of returning promises, which breaks composition."
            },
            {
              "question": "What is the Promise constructor anti-pattern?",
              "answer": "Wrapping an already-promise-returning function in new Promise(). Example: new Promise((resolve) => fetch(url).then(resolve)) — just use fetch(url) directly. Extra wrapping adds overhead and can swallow errors."
            },
            {
              "question": "What is the difference between Promise.resolve() and new Promise(resolve => resolve())?",
              "answer": "Promise.resolve(value) returns an already-resolved promise synchronously. new Promise(resolve => resolve(value)) creates a new promise that resolves on the next microtask. Promise.resolve is more efficient for wrapping known values."
            },
            {
              "question": "Can a Promise be cancelled?",
              "answer": "No, native Promises cannot be cancelled. Once started, they will settle. Use AbortController with fetch for cancellable network requests, or use a cancellation token pattern for custom promises."
            },
            {
              "question": "What happens if you resolve a Promise with another Promise?",
              "answer": "The outer promise 'follows' the inner promise — it adopts the state and value of the inner promise. resolve(anotherPromise) waits for anotherPromise to settle. reject() does NOT unwrap — it rejects with whatever value is given."
            },
            {
              "question": "How does .finally() work and when should you use it?",
              "answer": ".finally(callback) runs after the promise settles (fulfilled or rejected), without receiving the value/reason. It passes through the original result. Use for cleanup: closing connections, hiding loaders, logging. Similar to try-catch-finally."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Predict output order: Promise.resolve().then(()=>console.log(\"A\")); console.log(\"B\");",
              "answer": "B then A",
              "output": "B\nA"
            },
            {
              "type": "implement",
              "question": "Wrap setTimeout in delay(ms) returning Promise.",
              "code": "function delay(ms){\n  return new Promise(resolve => setTimeout(resolve, ms));\n}"
            },
            {
              "type": "debug",
              "question": "Promise chain stops after then. Cause?",
              "answer": "Likely forgot return in then callback, breaking chain value flow."
            },
            {
              "type": "scenario",
              "question": "Need retry API promise 3 times. What structure?",
              "answer": "Use recursive/loop retry wrapper that catches failure and retries until max attempts."
            },
            {
              "type": "output",
              "question": "Predict output: Promise.reject(\"X\").catch(e=>e+\"!\").then(console.log)",
              "answer": "X!",
              "output": "X!"
            },
            {
              "type": "implement",
              "question": "Implement a promisified version of fs.readFile.",
              "code": "function readFileAsync(path) { return new Promise((resolve, reject) => { fs.readFile(path, 'utf8', (err, data) => err ? reject(err) : resolve(data)); }); }"
            },
            {
              "type": "implement",
              "question": "Create a Promise that resolves with a value after validating it, or rejects.",
              "code": "function validateAsync(value) { return new Promise((resolve, reject) => { if(value > 0) resolve(value); else reject('Invalid value'); }); }"
            },
            {
              "type": "debug",
              "question": "Promise.resolve().then(() => { throw 'error' }).then(v => console.log(v)); — why is 'error' never caught?",
              "answer": "There's no .catch() in the chain. The thrown error creates a rejected promise that is unhandled. Add .catch(e => console.error(e)) at the end."
            },
            {
              "type": "debug",
              "question": "Unhandled rejection appears even with catch in another function. Why?",
              "answer": "The rejected promise path was not returned/awaited in caller chain."
            },
            {
              "type": "refactor",
              "question": "Refactor nested then callbacks to flat chain with proper returns."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Create resolved promise and print value.",
              "code": "Promise.resolve(\"Done\").then(console.log);",
              "output": "Done"
            },
            {
              "type": "program",
              "question": "Program 2: Create rejected promise and handle with catch.",
              "code": "Promise.reject(\"Fail\").catch(err=>console.log(\"Handled:\",err));",
              "output": "Handled: Fail"
            },
            {
              "type": "program",
              "question": "Program 3: Implement delay promise and await result.",
              "code": "const delay=ms=>new Promise(r=>setTimeout(r,ms));\ndelay(100).then(()=>console.log(\"After 100ms\"));",
              "output": "After 100ms"
            },
            {
              "type": "program",
              "question": "Program 4: Chain promises for arithmetic operations.",
              "code": "Promise.resolve(5)\n .then(n=>n*2)\n .then(n=>n+1)\n .then(console.log);",
              "output": "11"
            },
            {
              "type": "program",
              "question": "Program 5: Demonstrate finally in promise chain.",
              "code": "Promise.resolve(\"ok\")\n .then(v=>console.log(v))\n .finally(()=>console.log(\"cleanup\"));",
              "output": "ok\ncleanup"
            },
            {
              "type": "program",
              "question": "Program 6: Wrap setTimeout in Promise function.",
              "code": "function wait(msg,ms){\n  return new Promise(res=>setTimeout(()=>res(msg),ms));\n}\nwait(\"hello\",50).then(console.log);",
              "output": "hello"
            },
            {
              "type": "program",
              "question": "Program 7: Promise.all with two resolved promises.",
              "code": "Promise.all([Promise.resolve(1), Promise.resolve(2)])\n .then(v=>console.log(v));",
              "output": "[ 1, 2 ]"
            },
            {
              "type": "program",
              "question": "Program 8: Promise.race timeout example.",
              "code": "const fast=Promise.resolve(\"fast\");\nconst slow=new Promise(r=>setTimeout(()=>r(\"slow\"),100));\nPromise.race([fast,slow]).then(console.log);",
              "output": "fast"
            },
            {
              "type": "program",
              "question": "Program 9: Convert callback API to Promise.",
              "code": "function asyncDouble(n){\n  return new Promise(res=>setTimeout(()=>res(n*2),50));\n}\nasyncDouble(6).then(console.log);",
              "output": "12"
            },
            {
              "type": "program",
              "question": "Program 10: Handle thrown error in then chain.",
              "code": "Promise.resolve(1)\n .then(()=>{throw new Error(\"boom\")})\n .catch(e=>console.log(e.message));",
              "output": "boom"
            }
          ],
          "category": "Core Concepts"
        },
        {
          "id": "async-await",
          "title": "Async/Await",
          "description": "Async/await is syntactic sugar built on top of Promises that makes asynchronous code look and behave like synchronous code, making it easier to read and write.",
          "explanation": "Async/await is modern JavaScript syntax for working with Promises. The async keyword makes a function return a Promise, while await pauses execution until a Promise resolves.\n\nKey concepts:\n- async functions always return a Promise\n- await can only be used inside async functions\n- await pauses execution until Promise resolves\n- Errors are handled with try/catch blocks\n- Much more readable than .then() chains\n\nBest practices:\n- Always use try/catch for error handling\n- Don't await unnecessarily in loops\n- Use Promise.all() for parallel operations\n- Return early to avoid unnecessary awaits\n- Handle errors at appropriate levels",
          "implementation": "async function fetchData() {\n  try {\n    const response = await fetch('/api/data');\n    const data = await response.json();\n    return data;\n  } catch (error) {\n    console.error('Error:', error);\n    throw error;\n  }\n}",
          "example": "// Sequential operations\nasync function getUserWithPosts(userId) {\n  try {\n    const user = await fetchUser(userId);\n    const posts = await fetchUserPosts(userId);\n    const comments = await fetchUserComments(userId);\n    \n    return { user, posts, comments };\n  } catch (error) {\n    console.error('Failed to load user data:', error);\n  }\n}\n\n// Parallel operations (faster!)\nasync function getUserDataParallel(userId) {\n  try {\n    const [user, posts, comments] = await Promise.all([\n      fetchUser(userId),\n      fetchUserPosts(userId),\n      fetchUserComments(userId)\n    ]);\n    \n    return { user, posts, comments };\n  } catch (error) {\n    console.error('Failed to load user data:', error);\n  }\n}",
          "useCase": "API calls, database queries, file operations, any async operation requiring clean code",
          "interviewQuestions": [
            {
              "question": "How is async/await related to promises?",
              "answer": "async functions return promises; await pauses inside async until promise settles."
            },
            {
              "question": "How do you handle errors in async/await?",
              "answer": "Use try/catch around await or attach .catch at call site for centralized handling."
            },
            {
              "question": "Why can await in loops be slow?",
              "answer": "It serializes operations. Use Promise.all for parallelizable tasks."
            },
            {
              "question": "What happens if you forget await?",
              "answer": "You pass unresolved promise forward, often causing logic bugs or unexpected output."
            },
            {
              "question": "What is best practice for top-level async flows?",
              "answer": "Keep async boundaries explicit, handle cancellation/timeouts, and always surface actionable errors."
            },
            {
              "question": "What is top-level await?",
              "answer": "ES2022 allows await at the top level of ES modules (not scripts). The module pauses until the promise resolves. Importing modules wait for it too. Useful for config loading, DB init. Available in Node.js with ESM."
            },
            {
              "question": "How do you run async operations in parallel vs sequentially?",
              "answer": "Sequential: for (const item of items) { await process(item); }. Parallel: await Promise.all(items.map(item => process(item))). Sequential is needed when operations depend on each other; parallel is faster for independent operations."
            },
            {
              "question": "What does an async function return if you don't explicitly return?",
              "answer": "A Promise that resolves with undefined. Every async function returns a Promise, even if it contains no await. async function f() {} returns a Promise<undefined>."
            },
            {
              "question": "Can you use await with non-Promise values?",
              "answer": "Yes. await wraps non-Promise values with Promise.resolve(). So 'await 5' resolves to 5. But it still defers execution to the next microtask, so there's a small performance overhead."
            },
            {
              "question": "How do you handle errors in multiple parallel async operations?",
              "answer": "Use Promise.allSettled() instead of Promise.all() to get results of all operations regardless of individual failures. Or wrap each promise in a try/catch helper: items.map(async item => { try { return await fn(item); } catch (e) { return { error: e }; } })."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Predict: async function f(){return 7} f().then(console.log)",
              "answer": "7",
              "output": "7"
            },
            {
              "type": "implement",
              "question": "Write getJson(url) using async/await with error throw on !ok.",
              "code": "async function getJson(url){\n  const res = await fetch(url);\n  if(!res.ok) throw new Error(\"Request failed\");\n  return res.json();\n}"
            },
            {
              "type": "debug",
              "question": "Unhandled rejection still appears with try/catch. Why?",
              "answer": "Promise may be created but not awaited inside try block, so rejection escapes."
            },
            {
              "type": "refactor",
              "question": "Convert nested then-chain to async/await while keeping error handling.",
              "answer": "Move sequence into async function with await calls and a single try/catch."
            },
            {
              "type": "output",
              "question": "Predict output order: async function f(){console.log(\"A\"); await Promise.resolve(); console.log(\"B\")} f(); console.log(\"C\")",
              "answer": "A, C, B",
              "output": "A\nC\nB"
            },
            {
              "type": "output",
              "question": "What is returned by async function when returning 10?",
              "answer": "A Promise resolved with 10."
            },
            {
              "type": "implement",
              "question": "Implement a retry wrapper that retries an async function up to N times.",
              "code": "async function retry(fn, n) { for (let i = 0; i < n; i++) { try { return await fn(); } catch(e) { if (i === n-1) throw e; } } }"
            },
            {
              "type": "implement",
              "question": "Write async function that fetches users then posts sequentially."
            },
            {
              "type": "debug",
              "question": "async forEach with await doesn't wait for all items. Why?",
              "answer": "forEach doesn't await the callback's return promise. Use for...of loop instead, or map with Promise.all for parallel execution."
            },
            {
              "type": "debug",
              "question": "Parallel tasks run slowly. Cause?",
              "answer": "Using await in loop serializes calls; use Promise.all for parallel execution."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Basic async function returning value.",
              "code": "async function f(){ return 42; }\nf().then(console.log);",
              "output": "42"
            },
            {
              "type": "program",
              "question": "Program 2: Await resolved promise and print.",
              "code": "async function run(){\n  const v = await Promise.resolve(\"ok\");\n  console.log(v);\n}\nrun();",
              "output": "ok"
            },
            {
              "type": "program",
              "question": "Program 3: Async error handling with try/catch.",
              "code": "async function run(){\n  try {\n    await Promise.reject(new Error(\"fail\"));\n  } catch(e){\n    console.log(e.message);\n  }\n}\nrun();",
              "output": "fail"
            },
            {
              "type": "program",
              "question": "Program 4: Sequential async tasks.",
              "code": "const wait = ms => new Promise(r=>setTimeout(r,ms));\nasync function seq(){\n  await wait(10);\n  console.log(\"first\");\n  await wait(10);\n  console.log(\"second\");\n}\nseq();",
              "output": "first\nsecond"
            },
            {
              "type": "program",
              "question": "Program 5: Parallel async tasks with Promise.all + await.",
              "code": "const a=Promise.resolve(1);\nconst b=Promise.resolve(2);\n(async()=>{\n  const [x,y]=await Promise.all([a,b]);\n  console.log(x+y);\n})();",
              "output": "3"
            },
            {
              "type": "program",
              "question": "Program 6: Async wrapper for JSON parse simulation.",
              "code": "async function parseAsync(str){\n  return JSON.parse(str);\n}\nparseAsync(\"{\\\"x\\\":1}\").then(v=>console.log(v.x));",
              "output": "1"
            },
            {
              "type": "program",
              "question": "Program 7: Retry once on failure with async/await.",
              "code": "let tries=0;\nasync function task(){\n  tries++;\n  if(tries===1) throw new Error(\"retry\");\n  return \"success\";\n}\n(async()=>{\n  try{ await task(); }catch{ console.log(await task()); }\n})();",
              "output": "success"
            },
            {
              "type": "program",
              "question": "Program 8: Convert then-chain to async/await result.",
              "code": "const get=()=>Promise.resolve(5);\n(async()=>{\n  const v = await get();\n  console.log(v*2);\n})();",
              "output": "10"
            },
            {
              "type": "program",
              "question": "Program 9: Await in loop (sequential) demo.",
              "code": "const wait=ms=>new Promise(r=>setTimeout(r,ms));\n(async()=>{\n  for(const n of [1,2,3]){\n    await wait(5);\n    console.log(n);\n  }\n})();",
              "output": "1\n2\n3"
            },
            {
              "type": "program",
              "question": "Program 10: Top-level style async IIFE with final log.",
              "code": "(async()=>{\n  const a = await Promise.resolve(\"JS\");\n  console.log(`${a} async`);\n})();",
              "output": "JS async"
            }
          ],
          "category": "Core Concepts"
        },
        {
          "id": "promise-all",
          "title": "Promise.all() & Promise.race()",
          "category": "Async Programming",
          "description": "Promise.all waits for all promises. Promise.race returns the first settled promise.",
          "explanation": "Promise combinators let you work with multiple promises simultaneously. ES2015+ provides four:\n\nPromise.all(iterable):\n- Waits for ALL promises to fulfill\n- Returns array of results in input order\n- FAILS FAST: rejects immediately if ANY promise rejects\n- Non-promise values are wrapped with Promise.resolve()\n\nPromise.allSettled(iterable) (ES2020):\n- Waits for ALL promises to settle (fulfill OR reject)\n- Never rejects — always returns array of {status, value/reason}\n- Use when you need results regardless of individual failures\n\nPromise.race(iterable):\n- Resolves/rejects with the FIRST promise that settles\n- Use for timeout patterns: race against a setTimeout rejection\n- Result takes the state (fulfilled/rejected) of the winner\n\nPromise.any(iterable) (ES2021):\n- Resolves with the FIRST promise that FULFILLS\n- Ignores rejections until ALL reject\n- If all reject, throws AggregateError\n- Use for redundancy: fastest successful response wins\n\nParallel vs Sequential:\n- Promise.all runs promises concurrently (not in parallel — still single-threaded)\n- Be careful with unbounded concurrency — rate-limit or batch large arrays",
          "implementation": "// Promise.all - waits for all\nconst results = await Promise.all([\n  fetch('/api/users'),\n  fetch('/api/posts'),\n  fetch('/api/comments')\n]);\n\n// Promise.race - first to complete\nconst fastest = await Promise.race([\n  fetch('/api/server1'),\n  fetch('/api/server2')\n]);",
          "example": "async function loadPageData() {\n  try {\n    const [users, products, settings] = await Promise.all([\n      fetchUsers(),\n      fetchProducts(),\n      fetchSettings()\n    ]);\n    return {users, products, settings};\n  } catch (error) {\n    console.error('Failed to load:', error);\n  }\n}",
          "useCase": "Parallel API calls, loading multiple resources, timeout implementations",
          "interviewQuestions": [
            {
              "question": "When to use Promise.all?",
              "answer": "When tasks are independent and all results are required together."
            },
            {
              "question": "What happens if one Promise.all task rejects?",
              "answer": "Whole Promise.all rejects immediately with that rejection reason."
            },
            {
              "question": "Difference between all and allSettled?",
              "answer": "all fails-fast; allSettled always resolves with status/result for each input."
            },
            {
              "question": "When to use Promise.race?",
              "answer": "For timeout patterns or taking fastest response among alternatives."
            },
            {
              "question": "What is a production concern with Promise.all on huge arrays?",
              "answer": "Unbounded concurrency can overload APIs or memory; use controlled batching."
            },
            {
              "question": "What is Promise.any and how does it differ from Promise.race?",
              "answer": "Promise.any resolves with the first FULFILLED promise (ignores rejections). Promise.race resolves/rejects with the first SETTLED promise (fulfilled or rejected). Use any for redundancy (fastest success), race for timeouts."
            },
            {
              "question": "What is AggregateError?",
              "answer": "Thrown when ALL promises passed to Promise.any() reject. Contains an .errors property (array of all rejection reasons). It's a subclass of Error, introduced in ES2021."
            },
            {
              "question": "How do you implement a timeout with Promise.race?",
              "answer": "Race the actual promise against a rejecting timeout: Promise.race([fetchData(), new Promise((_, reject) => setTimeout(() => reject(new Error('Timeout')), 5000))]). First to settle wins."
            },
            {
              "question": "Does Promise.all run promises in parallel?",
              "answer": "JavaScript is single-threaded, so promises don't run truly in parallel. They are concurrent — I/O operations overlap while waiting. CPU-bound work still blocks. Promise.all just waits for all to settle."
            },
            {
              "question": "How do you batch/throttle concurrent Promise.all calls?",
              "answer": "Process in chunks: split array into batches of N, await Promise.all for each batch sequentially. Or use a semaphore/pool pattern to limit active promises. Libraries like p-limit can help."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Predict Promise.all([Promise.resolve(1), 2]) result.",
              "answer": "[1, 2]",
              "output": "[1,2]"
            },
            {
              "type": "implement",
              "question": "Fetch users and posts in parallel with Promise.all.",
              "code": "const [users, posts] = await Promise.all([fetchUsers(), fetchPosts()]);"
            },
            {
              "type": "debug",
              "question": "One Promise.all task fails and all data is lost. Alternative?",
              "answer": "Use Promise.allSettled to collect success/failure of each task."
            },
            {
              "type": "scenario",
              "question": "Implement timeout wrapper using Promise.race.",
              "code": "function withTimeout(p, ms){\n  return Promise.race([p, new Promise((_,r)=>setTimeout(()=>r(new Error(\"Timeout\")), ms))]);\n}"
            },
            {
              "type": "output",
              "question": "Predict output: Promise.any([Promise.reject('A'), Promise.resolve('B'), Promise.resolve('C')]).then(console.log)",
              "answer": "B — Promise.any resolves with the first fulfilled promise, ignoring rejections."
            },
            {
              "type": "output",
              "question": "Promise.race between 50ms and 200ms promises resolves with?",
              "answer": "The 50ms promise result."
            },
            {
              "type": "implement",
              "question": "Implement loadDashboardData() with Promise.all(users, stats, notifications)."
            },
            {
              "type": "implement",
              "question": "Write withTimeout(promise, ms) using Promise.race."
            },
            {
              "type": "debug",
              "question": "Promise.all fires hundreds of API calls at once, overwhelming the server. How to fix?",
              "answer": "Batch the promises: split into chunks of N and await Promise.all for each chunk sequentially. Or use a concurrency limiter like p-limit."
            },
            {
              "type": "debug",
              "question": "Order of Promise.all results seems wrong. Why?",
              "answer": "Results are returned by input order, not completion order."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Promise.all with two resolved values.",
              "code": "Promise.all([Promise.resolve(\"A\"), Promise.resolve(\"B\")])\n  .then(console.log);",
              "output": "[ \"A\", \"B\" ]"
            },
            {
              "type": "program",
              "question": "Program 2: Promise.all rejection behavior.",
              "code": "Promise.all([Promise.resolve(1), Promise.reject(\"X\")])\n  .then(console.log)\n  .catch(console.log);",
              "output": "X"
            },
            {
              "type": "program",
              "question": "Program 3: Promise.all order is input order, not finish order.",
              "code": "const slow=new Promise(r=>setTimeout(()=>r(\"slow\"),50));\nconst fast=Promise.resolve(\"fast\");\nPromise.all([slow,fast]).then(console.log);",
              "output": "[ \"slow\", \"fast\" ]"
            },
            {
              "type": "program",
              "question": "Program 4: Promise.race fastest response demo.",
              "code": "const p1=new Promise(r=>setTimeout(()=>r(\"one\"),100));\nconst p2=new Promise(r=>setTimeout(()=>r(\"two\"),20));\nPromise.race([p1,p2]).then(console.log);",
              "output": "two"
            },
            {
              "type": "program",
              "question": "Program 5: Timeout wrapper with race.",
              "code": "function withTimeout(p,ms){\n  return Promise.race([p,new Promise((_,rej)=>setTimeout(()=>rej(\"timeout\"),ms))]);\n}\nwithTimeout(new Promise(r=>setTimeout(()=>r(\"ok\"),30)),10).catch(console.log);",
              "output": "timeout"
            },
            {
              "type": "program",
              "question": "Program 6: Promise.allSettled status inspection.",
              "code": "Promise.allSettled([Promise.resolve(1), Promise.reject(\"e\")])\n  .then(res=>console.log(res.map(x=>x.status)));",
              "output": "[ \"fulfilled\", \"rejected\" ]"
            },
            {
              "type": "program",
              "question": "Program 7: Parallel API simulation with Promise.all.",
              "code": "const api=(v,ms)=>new Promise(r=>setTimeout(()=>r(v),ms));\nPromise.all([api(\"users\",20),api(\"posts\",10)]).then(console.log);",
              "output": "[ \"users\", \"posts\" ]"
            },
            {
              "type": "program",
              "question": "Program 8: Race rejection if fastest promise rejects.",
              "code": "const a=new Promise((_,rej)=>setTimeout(()=>rej(\"bad\"),10));\nconst b=new Promise(r=>setTimeout(()=>r(\"good\"),50));\nPromise.race([a,b]).catch(console.log);",
              "output": "bad"
            },
            {
              "type": "program",
              "question": "Program 9: allSettled to split success and failures.",
              "code": "Promise.allSettled([Promise.resolve(10), Promise.reject(\"E\")])\n.then(r=>{\n  const ok=r.filter(x=>x.status===\"fulfilled\").map(x=>x.value);\n  const err=r.filter(x=>x.status===\"rejected\").map(x=>x.reason);\n  console.log(ok, err);\n});",
              "output": "[ 10 ] [ \"E\" ]"
            },
            {
              "type": "program",
              "question": "Program 10: Promise.any-like fallback with race of resolved tasks (simple).",
              "code": "const p1=new Promise(r=>setTimeout(()=>r(\"backup\"),40));\nconst p2=new Promise(r=>setTimeout(()=>r(\"primary\"),20));\nPromise.race([p1,p2]).then(console.log);",
              "output": "primary"
            }
          ]
        },
        {
          "id": "debouncing",
          "title": "Debouncing",
          "description": "Debouncing limits the rate at which a function is executed. It delays execution until after a specified time period has elapsed since the last invocation. Imagine typing in a search box - without debouncing, a search request would fire for every keystroke. With debouncing, the search only fires after you've stopped typing for a specified duration (e.g., 300ms).",
          "explanation": "Debouncing is essential for optimizing performance in scenarios where rapid consecutive function calls would be wasteful or harmful. The technique works by setting a timer each time the function is called, and clearing any existing timer. Only when the timer completes without interruption does the function actually execute.\n\nKey benefits:\n- Reduces unnecessary API calls\n- Improves application performance\n- Enhances user experience by preventing jank\n- Saves bandwidth and server resources\n\nHow it works:\n1. User triggers an event (e.g., typing)\n2. Timer starts/resets\n3. If user triggers again before timer ends, reset timer\n4. When user stops, timer completes\n5. Function finally executes",
          "implementation": "function debounce(func, delay) {\n  let timeoutId;\n  return function(...args) {\n    clearTimeout(timeoutId);\n    timeoutId = setTimeout(() => {\n      func.apply(this, args);\n    }, delay);\n  };\n}",
          "example": "// Search implementation\nconst searchInput = debounce((query) => {\n  console.log('Searching for:', query);\n  // Make API call here\n  fetch(`/api/search?q=${query}`);\n}, 300);\n\n// Usage in React\nconst handleSearch = (e) => {\n  searchInput(e.target.value);\n};\n\n// Only executes after 300ms of no typing\n<input onChange={handleSearch} />",
          "useCase": "Search inputs, window resize events, auto-save features, form validation",
          "interviewQuestions": [
            {
              "question": "When should debouncing be used?",
              "answer": "When repeated rapid events should trigger action only after user stops firing events."
            },
            {
              "question": "Debounce vs throttle in one sentence?",
              "answer": "Debounce waits for silence; throttle guarantees periodic execution during activity."
            },
            {
              "question": "Leading vs trailing debounce?",
              "answer": "Leading fires immediately then waits; trailing fires after the quiet period ends."
            },
            {
              "question": "What memory bug appears in naive debounce?",
              "answer": "Uncleared timers in component lifecycle can leak work; clear on cleanup/unmount."
            },
            {
              "question": "Where is debounce dangerous?",
              "answer": "Critical actions where delayed execution harms UX or correctness, e.g., urgent controls."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "In trailing debounce(300ms), user types continuously for 2s. How many calls?",
              "answer": "One call after typing stops (if no pauses >= 300ms)."
            },
            {
              "type": "implement",
              "question": "Implement debounce(fn, delay).",
              "code": "function debounce(fn, delay){\n  let t;\n  return (...args)=>{\n    clearTimeout(t);\n    t=setTimeout(()=>fn(...args), delay);\n  };\n}"
            },
            {
              "type": "debug",
              "question": "Debounced React handler uses stale state. Fix?",
              "answer": "Use refs/functional updates or recreate handler carefully with dependencies."
            },
            {
              "type": "scenario",
              "question": "Search API should not fire on every keypress. Apply debounce with 300ms.",
              "answer": "Wrap search trigger in debounced function and call from input change."
            },
            {
              "type": "output",
              "question": "User types continuously for 2s with trailing debounce(300). Calls executed?",
              "answer": "1 final call after typing stops."
            },
            {
              "type": "output",
              "question": "Debounce with leading=true,trailing=false on quick burst gives?",
              "answer": "Only immediate first call in each burst window."
            },
            {
              "type": "implement",
              "question": "Implement debounce(fn, delay) trailing version."
            },
            {
              "type": "implement",
              "question": "Implement debounce with cancel() support."
            },
            {
              "type": "debug",
              "question": "Debounced handler in React uses stale props/state. Fix?",
              "answer": "Use refs/functional updates or recreate debounced callback with correct dependencies."
            },
            {
              "type": "debug",
              "question": "Memory leak in debounced component. Why?",
              "answer": "Pending timer not cleared on unmount; cleanup must clearTimeout."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Basic trailing debounce utility.",
              "code": "function debounce(fn,delay){\n  let t;\n  return (...args)=>{\n    clearTimeout(t);\n    t=setTimeout(()=>fn(...args),delay);\n  };\n}\nconst log=debounce(v=>console.log(v),50);\nlog(\"A\"); log(\"B\"); setTimeout(()=>log(\"C\"),10);",
              "output": "C"
            },
            {
              "type": "program",
              "question": "Program 2: Debounced search simulation.",
              "code": "function debounce(fn, d){let t; return (...a)=>{clearTimeout(t); t=setTimeout(()=>fn(...a),d);};}\nconst search=debounce(q=>console.log(\"search:\",q),80);\nsearch(\"j\"); search(\"js\"); search(\"js \"); search(\"js interview\");",
              "output": "search: js interview"
            },
            {
              "type": "program",
              "question": "Program 3: Debounce with cancel method.",
              "code": "function makeDebounce(fn,d){\n  let t;\n  const wrapped=(...a)=>{clearTimeout(t); t=setTimeout(()=>fn(...a),d);};\n  wrapped.cancel=()=>clearTimeout(t);\n  return wrapped;\n}\nconst d=makeDebounce(console.log,50);\nd(\"will-cancel\"); d.cancel();",
              "output": "(no output)"
            },
            {
              "type": "program",
              "question": "Program 4: Debounce resize handler mock.",
              "code": "function debounce(fn,d){let t;return(...a)=>{clearTimeout(t);t=setTimeout(()=>fn(...a),d)}}\nconst onResize=debounce(()=>console.log(\"recalculate layout\"),60);\nonResize(); onResize(); onResize();",
              "output": "recalculate layout"
            },
            {
              "type": "program",
              "question": "Program 5: Compare direct call vs debounced call count.",
              "code": "let direct=0, deb=0;\nconst inc=()=>deb++;\nfunction debounce(fn,d){let t;return()=>{clearTimeout(t);t=setTimeout(fn,d)}}\nconst d=debounce(inc,40);\nfor(let i=0;i<5;i++){direct++; d();}\nsetTimeout(()=>console.log(direct,deb),60);",
              "output": "5 1"
            },
            {
              "type": "program",
              "question": "Program 6: Leading debounce variant (simple).",
              "code": "function debounceLeading(fn,d){\n  let t=null;\n  return (...a)=>{\n    if(!t) fn(...a);\n    clearTimeout(t);\n    t=setTimeout(()=>{t=null;},d);\n  };\n}\nconst fn=debounceLeading(console.log,50);\nfn(\"A\"); fn(\"B\"); fn(\"C\");",
              "output": "A"
            },
            {
              "type": "program",
              "question": "Program 7: Debounced autosave mock.",
              "code": "function debounce(fn,d){let t;return(...a)=>{clearTimeout(t);t=setTimeout(()=>fn(...a),d)}}\nconst save=debounce(content=>console.log(\"saved:\",content),70);\nsave(\"v1\"); save(\"v2\"); save(\"final\");",
              "output": "saved: final"
            },
            {
              "type": "program",
              "question": "Program 8: Debounce input validation.",
              "code": "function debounce(fn,d){let t;return(v)=>{clearTimeout(t);t=setTimeout(()=>fn(v),d)}}\nconst validate=debounce(v=>console.log(v.length>=3),40);\nvalidate(\"j\"); validate(\"js\"); validate(\"js1\");",
              "output": "true"
            },
            {
              "type": "program",
              "question": "Program 9: Debounce with preserved this using apply.",
              "code": "function debounce(fn,d){let t;return function(...a){clearTimeout(t);t=setTimeout(()=>fn.apply(this,a),d)}}\nconst obj={x:5,print(v){console.log(this.x,v)}};\nobj.d=debounce(obj.print,30);\nobj.d(\"ok\");",
              "output": "5 ok"
            },
            {
              "type": "program",
              "question": "Program 10: Debounced API call simulator with promise.",
              "code": "function debounce(fn,d){let t;return(...a)=>new Promise(res=>{clearTimeout(t);t=setTimeout(()=>res(fn(...a)),d);});}\nconst api=q=>`result:${q}`;\nconst d=debounce(api,40);\nd(\"a\"); d(\"ab\"); d(\"abc\").then(console.log);",
              "output": "result:abc"
            }
          ],
          "category": "Core Concepts"
        },
        {
          "id": "throttling",
          "title": "Throttling",
          "description": "Throttling ensures a function is called at most once in a specified time period, no matter how many times it's triggered. Unlike debouncing (which delays until calm), throttling executes immediately and then enforces a cooldown. Think of it like a rate limiter - if you throttle to 1 second, the function can only run once per second maximum, even if triggered 100 times.",
          "explanation": "Throttling is perfect for events that fire continuously but you only need to respond to them at regular intervals. The key difference from debouncing is that throttling guarantees execution at regular intervals during continuous triggering.\n\nKey differences from debouncing:\n- Throttling: Executes at regular intervals DURING activity\n- Debouncing: Executes once AFTER activity stops\n\nUse throttling when:\n- You need periodic updates during continuous activity\n- Scroll position tracking\n- Mouse movement tracking\n- Resize events where you want intermediate updates\n\nUse debouncing when:\n- You only care about the final state\n- Search input\n- Text field auto-save\n- Form validation",
          "implementation": "function throttle(func, limit) {\n  let inThrottle;\n  return function(...args) {\n    if (!inThrottle) {\n      func.apply(this, args);\n      inThrottle = true;\n      setTimeout(() => inThrottle = false, limit);\n    }\n  };\n}",
          "example": "// Scroll tracking\nconst handleScroll = throttle(() => {\n  const scrollY = window.scrollY;\n  console.log('Scroll position:', scrollY);\n  \n  // Update progress bar\n  updateProgressBar(scrollY);\n}, 1000);\n\nwindow.addEventListener('scroll', handleScroll);\n\n// Mouse move tracking\nconst trackMouse = throttle((e) => {\n  console.log('Mouse at:', e.clientX, e.clientY);\n}, 100);",
          "useCase": "Scroll events, button clicks, API rate limiting, mouse tracking, game loop updates",
          "interviewQuestions": [
            {
              "question": "When is throttling better than debouncing?",
              "answer": "When you need regular updates during continuous events like scroll or mousemove."
            },
            {
              "question": "How does throttle protect performance?",
              "answer": "It limits handler execution rate, reducing layout/repaint and expensive calculations."
            },
            {
              "question": "What is trailing call behavior in throttle?",
              "answer": "After cooldown, final call can run with latest args if throttle implementation supports it."
            },
            {
              "question": "A common bug in throttle implementations?",
              "answer": "Losing last invocation context/args or dropping critical final event state."
            },
            {
              "question": "How to test throttle correctly?",
              "answer": "Use fake timers and assert call counts plus timing boundaries."
            },
            {
              "question": "What problem does throttling solve?",
              "answer": "It prevents expensive handlers from running too frequently during high-frequency events."
            },
            {
              "question": "How is throttle different from debounce for UX?",
              "answer": "Throttle gives periodic feedback; debounce delays feedback until inactivity."
            },
            {
              "question": "What are leading and trailing options?",
              "answer": "Leading runs at start of interval; trailing runs once with latest args at interval end."
            },
            {
              "question": "Why might trailing throttle be needed for scroll progress?",
              "answer": "Without trailing call, final state can be missed."
            },
            {
              "question": "How do you preserve context in throttle wrappers?",
              "answer": "Use regular function and invoke callback via fn.apply(this,args)."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Throttle interval 1000ms, event fires continuously for 2500ms. Approx calls?",
              "answer": "Around 2-3 calls depending on leading/trailing config."
            },
            {
              "type": "output",
              "question": "Difference in behavior: throttle executes during activity or after activity?",
              "answer": "During activity at controlled intervals."
            },
            {
              "type": "implement",
              "question": "Implement basic leading throttle(fn, limit)."
            },
            {
              "type": "implement",
              "question": "Implement throttle with trailing execution support."
            },
            {
              "type": "debug",
              "question": "Final scroll position is not updated with throttle. Fix?",
              "answer": "Add trailing call with last arguments."
            },
            {
              "type": "debug",
              "question": "Throttled callback loses this context. Fix?",
              "answer": "Use fn.apply(this,args) inside wrapped function."
            },
            {
              "type": "refactor",
              "question": "Refactor direct scroll handler to throttled handler for performance."
            },
            {
              "type": "scenario",
              "question": "Design mousemove analytics with throttle and batching."
            },
            {
              "type": "tricky",
              "question": "Throttle vs debounce one-line difference?",
              "answer": "Throttle limits rate; debounce waits for inactivity."
            },
            {
              "type": "tricky",
              "question": "Can throttling still drop intermediate event values?",
              "answer": "Yes, unless implementation stores latest args for trailing call."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Basic throttle implementation.",
              "code": "function throttle(fn, limit){\n  let waiting=false;\n  return (...args)=>{\n    if(waiting) return;\n    waiting=true;\n    fn(...args);\n    setTimeout(()=>waiting=false, limit);\n  };\n}\nconst t=throttle(console.log,100);\nt(\"A\"); t(\"B\");",
              "output": "A"
            },
            {
              "type": "program",
              "question": "Program 2: Throttled scroll handler simulation.",
              "code": "function throttle(fn,limit){let w=false;return(...a)=>{if(w)return;w=true;fn(...a);setTimeout(()=>w=false,limit)}}\nlet calls=0;\nconst onScroll=throttle(()=>{calls++; console.log(\"scroll\",calls)},80);\nfor(let i=0;i<5;i++) onScroll();",
              "output": "scroll 1"
            },
            {
              "type": "program",
              "question": "Program 3: Throttle with preserved context.",
              "code": "function throttle(fn,limit){let w=false;return function(...a){if(w)return;w=true;fn.apply(this,a);setTimeout(()=>w=false,limit)}}\nconst obj={x:10,log(){console.log(this.x)}};\nobj.t=throttle(obj.log,50);\nobj.t();",
              "output": "10"
            },
            {
              "type": "program",
              "question": "Program 4: Count direct vs throttled calls.",
              "code": "let direct=0, thr=0;\nfunction throttle(fn,l){let w=false;return()=>{if(w)return;w=true;fn();setTimeout(()=>w=false,l)}}\nconst t=throttle(()=>thr++,60);\nfor(let i=0;i<10;i++){direct++; t();}\nsetTimeout(()=>console.log(direct,thr),80);",
              "output": "10 1"
            },
            {
              "type": "program",
              "question": "Program 5: Throttle periodic API poll trigger.",
              "code": "function throttle(fn,l){let w=false;return(...a)=>{if(w)return;w=true;fn(...a);setTimeout(()=>w=false,l)}}\nconst hit=throttle((q)=>console.log(\"api\",q),100);\nhit(\"a\"); hit(\"ab\"); hit(\"abc\");",
              "output": "api a"
            },
            {
              "type": "program",
              "question": "Program 6: Trailing throttle version (simple).",
              "code": "function throttleTrailing(fn,limit){\n  let waiting=false,lastArgs=null;\n  return (...args)=>{\n    if(waiting){lastArgs=args;return;}\n    fn(...args); waiting=true;\n    setTimeout(()=>{waiting=false; if(lastArgs){ const a=lastArgs; lastArgs=null; fn(...a);} },limit);\n  };\n}\nconst t=throttleTrailing(console.log,50);\nt(\"A\"); t(\"B\");",
              "output": "A\nB"
            },
            {
              "type": "program",
              "question": "Program 7: Throttled window resize mock.",
              "code": "function throttle(fn,l){let w=false;return()=>{if(w)return;w=true;fn();setTimeout(()=>w=false,l)}}\nconst onResize=throttle(()=>console.log(\"layout updated\"),70);\nonResize(); onResize(); onResize();",
              "output": "layout updated"
            },
            {
              "type": "program",
              "question": "Program 8: Throttle button click spam.",
              "code": "function throttle(fn,l){let w=false;return()=>{if(w)return;w=true;fn();setTimeout(()=>w=false,l)}}\nconst submit=throttle(()=>console.log(\"submitted\"),120);\nsubmit(); submit(); submit();",
              "output": "submitted"
            },
            {
              "type": "program",
              "question": "Program 9: Throttled mouse tracker sample.",
              "code": "function throttle(fn,l){let w=false;return(v)=>{if(w)return;w=true;fn(v);setTimeout(()=>w=false,l)}}\nconst track=throttle(v=>console.log(\"x\",v),50);\ntrack(10); track(20); track(30);",
              "output": "x 10"
            },
            {
              "type": "program",
              "question": "Program 10: Compare debounce vs throttle quickly.",
              "code": "function throttle(fn,l){let w=false;return()=>{if(w)return;w=true;fn();setTimeout(()=>w=false,l)}}\nlet c=0;\nconst t=throttle(()=>{c++;console.log(c)},40);\nfor(let i=0;i<5;i++) t();",
              "output": "1"
            }
          ],
          "category": "Core Concepts"
        },
        {
          "id": "local-storage",
          "category": "Browser APIs",
          "title": "Local Storage and Session Storage",
          "description": "Learn browser storage APIs for persisting client-side data, including JSON serialization and common interview pitfalls.",
          "explanation": "localStorage and sessionStorage are key-value string stores in browsers. localStorage persists across tabs/browser restarts; sessionStorage persists only for tab session.\n\nKey points:\n- Values are strings; serialize objects with JSON.stringify.\n- localStorage is synchronous and can block if overused.\n- Use try/catch for JSON parsing and storage quota issues.\n- Avoid storing sensitive tokens directly if security posture is weak.",
          "implementation": "const user = { id: 1, name: \"Jitender\" };\nlocalStorage.setItem(\"user\", JSON.stringify(user));\nconst restored = JSON.parse(localStorage.getItem(\"user\") || \"null\");\nconsole.log(restored?.name);",
          "example": "sessionStorage.setItem(\"draft\", \"hello\");\nconsole.log(sessionStorage.getItem(\"draft\"));\nsessionStorage.removeItem(\"draft\");",
          "useCase": "Theme preference, draft forms, lightweight caching, onboarding flags, client settings.",
          "interviewQuestions": [
            {
              "question": "localStorage vs sessionStorage?",
              "answer": "localStorage persists across browser sessions; sessionStorage is per-tab and cleared when tab closes."
            },
            {
              "question": "Can we store objects directly?",
              "answer": "No, store as JSON string via JSON.stringify and parse on retrieval."
            },
            {
              "question": "Is localStorage async?",
              "answer": "No, it is synchronous."
            },
            {
              "question": "What data type does getItem return?",
              "answer": "String or null if key not found."
            },
            {
              "question": "How to clear one key vs all keys?",
              "answer": "removeItem(key) for one key, clear() for all keys."
            },
            {
              "question": "Security concern of localStorage?",
              "answer": "XSS can read stored data; avoid storing highly sensitive tokens in unsafe contexts."
            },
            {
              "question": "Storage size limitation?",
              "answer": "Browser-dependent, typically around 5MB per origin."
            },
            {
              "question": "What event tracks storage changes?",
              "answer": "window storage event for cross-tab updates."
            },
            {
              "question": "How to handle malformed JSON in storage?",
              "answer": "Use try/catch around JSON.parse with safe fallback."
            },
            {
              "question": "When to avoid localStorage?",
              "answer": "High-frequency writes or sensitive data requirements."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "What does localStorage.getItem(\"missing\") return?",
              "answer": "null",
              "output": "null"
            },
            {
              "type": "output",
              "question": "If localStorage.setItem(\"x\", 1), stored value type?",
              "answer": "String \"1\""
            },
            {
              "type": "implement",
              "question": "Implement saveJSON(key, value) and loadJSON(key, fallback)."
            },
            {
              "type": "implement",
              "question": "Implement toggleTheme using localStorage persistence."
            },
            {
              "type": "debug",
              "question": "JSON.parse throws from corrupted storage data. Fix?",
              "answer": "Wrap parse in try/catch and fallback to defaults."
            },
            {
              "type": "debug",
              "question": "Stored object appears as [object Object]. Why?",
              "answer": "Object was stored without JSON.stringify."
            },
            {
              "type": "scenario",
              "question": "Save form draft and restore on reload."
            },
            {
              "type": "scenario",
              "question": "Sync logout across tabs using storage event."
            },
            {
              "type": "tricky",
              "question": "Is storage shared across different domains?",
              "answer": "No, it is origin-scoped."
            },
            {
              "type": "tricky",
              "question": "Can storage API be unavailable?",
              "answer": "Yes in some privacy modes or restricted environments; code defensively."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Save and read simple string from localStorage.",
              "code": "localStorage.setItem(\"lang\",\"js\");\nconsole.log(localStorage.getItem(\"lang\"));",
              "output": "js"
            },
            {
              "type": "program",
              "question": "Program 2: Save object in localStorage.",
              "code": "const user={id:1,name:\"Dev\"};\nlocalStorage.setItem(\"user\",JSON.stringify(user));\nconsole.log(JSON.parse(localStorage.getItem(\"user\")).name);",
              "output": "Dev"
            },
            {
              "type": "program",
              "question": "Program 3: Remove key from storage.",
              "code": "localStorage.setItem(\"temp\",\"123\");\nlocalStorage.removeItem(\"temp\");\nconsole.log(localStorage.getItem(\"temp\"));",
              "output": "null"
            },
            {
              "type": "program",
              "question": "Program 4: Clear all storage keys.",
              "code": "localStorage.setItem(\"a\",\"1\");\nlocalStorage.setItem(\"b\",\"2\");\nlocalStorage.clear();\nconsole.log(localStorage.length);",
              "output": "0"
            },
            {
              "type": "program",
              "question": "Program 5: sessionStorage basic save/read.",
              "code": "sessionStorage.setItem(\"draft\",\"hello\");\nconsole.log(sessionStorage.getItem(\"draft\"));",
              "output": "hello"
            },
            {
              "type": "program",
              "question": "Program 6: Safe JSON loader with fallback.",
              "code": "function loadJSON(key,fallback){\n  try{\n    const raw=localStorage.getItem(key);\n    return raw?JSON.parse(raw):fallback;\n  }catch{\n    return fallback;\n  }\n}\nconsole.log(loadJSON(\"missing\",[]));",
              "output": "[]"
            },
            {
              "type": "program",
              "question": "Program 7: Persist theme preference.",
              "code": "function setTheme(theme){ localStorage.setItem(\"theme\",theme); }\nfunction getTheme(){ return localStorage.getItem(\"theme\") || \"light\"; }\nsetTheme(\"dark\");\nconsole.log(getTheme());",
              "output": "dark"
            },
            {
              "type": "program",
              "question": "Program 8: Increment page visit counter in localStorage.",
              "code": "const key=\"visits\";\nconst n=Number(localStorage.getItem(key)||0)+1;\nlocalStorage.setItem(key,String(n));\nconsole.log(localStorage.getItem(key));",
              "output": "1 (or incremented value)"
            },
            {
              "type": "program",
              "question": "Program 9: Store array and append new value.",
              "code": "const key=\"skills\";\nconst arr=JSON.parse(localStorage.getItem(key)||\"[]\");\narr.push(\"javascript\");\nlocalStorage.setItem(key,JSON.stringify(arr));\nconsole.log(JSON.parse(localStorage.getItem(key)));",
              "output": "[ \"javascript\" ] (or appended list)"
            },
            {
              "type": "program",
              "question": "Program 10: Listen storage event (cross-tab sync).",
              "code": "window.addEventListener(\"storage\", (e) => {\n  if (e.key === \"auth\") console.log(\"Auth changed\", e.newValue);\n});",
              "output": "Logs when key changes in another tab"
            }
          ]
        },
        {
          "id": "closures",
          "title": "Closures",
          "description": "Deep dive into JavaScript closures — how functions remember their lexical scope, practical patterns, and common interview traps.",
          "explanation": "A closure is created when a function is defined inside another function and the inner function references variables from the outer function's scope. The inner function 'closes over' those variables, keeping them alive even after the outer function returns.\n\nHow it works internally:\n1. When a function is created, it gets a hidden [[Environment]] reference to the Lexical Environment where it was defined\n2. When the function executes, it creates a new Lexical Environment whose outer reference points to [[Environment]]\n3. Variable lookup follows the scope chain: current scope → outer scope → ... → global scope\n4. The garbage collector cannot free closed-over variables as long as the closure exists\n\nKey characteristics:\n- Closures capture variables by reference, NOT by value\n- Each closure instance gets its own copy of the enclosed variables\n- Closures have access to: own scope, outer function scope, global scope\n- Arrow functions and regular functions both create closures\n\nCommon patterns:\n- Data privacy / encapsulation (module pattern)\n- Function factories (createMultiplier, createCounter)\n- Partial application and currying\n- Event handlers and callbacks\n- Memoization\n\nCommon pitfalls:\n- Loop variable capture with var (classic interview question)\n- Memory leaks from unintended closures holding large objects\n- Stale closures in React useEffect/useState",
          "code": "// Basic closure\nfunction outer() {\n  let count = 0;  // closed-over variable\n  \n  return function inner() {\n    count++;\n    return count;\n  };\n}\n\nconst counter = outer();\nconsole.log(counter()); // 1\nconsole.log(counter()); // 2\nconsole.log(counter()); // 3\n// 'count' lives on because counter still references inner()\n\n// Data privacy with closures\nfunction createBankAccount(initialBalance) {\n  let balance = initialBalance; // private variable\n  \n  return {\n    deposit(amount) {\n      balance += amount;\n      return balance;\n    },\n    withdraw(amount) {\n      if (amount > balance) throw new Error('Insufficient funds');\n      balance -= amount;\n      return balance;\n    },\n    getBalance() {\n      return balance;\n    }\n  };\n}\n\nconst account = createBankAccount(100);\naccount.deposit(50);    // 150\naccount.withdraw(30);   // 120\n// account.balance → undefined (private!)",
          "example": "// Function factory pattern\nfunction createGreeter(greeting) {\n  return function(name) {\n    return `${greeting}, ${name}!`;\n  };\n}\n\nconst sayHello = createGreeter('Hello');\nconst sayHi = createGreeter('Hi');\n\nconsole.log(sayHello('Alice')); // 'Hello, Alice!'\nconsole.log(sayHi('Bob'));      // 'Hi, Bob!'\n// Each closure captures its own 'greeting'\n\n// Memoization using closure\nfunction memoize(fn) {\n  const cache = {};\n  return function(...args) {\n    const key = JSON.stringify(args);\n    if (cache[key] !== undefined) {\n      return cache[key];\n    }\n    cache[key] = fn(...args);\n    return cache[key];\n  };\n}\n\nconst expensiveSquare = memoize((n) => {\n  console.log('Computing...');\n  return n * n;\n});\n\nexpensiveSquare(5); // 'Computing...' → 25\nexpensiveSquare(5); // 25 (cached, no 'Computing...')",
          "useCase": "Data encapsulation, function factories, memoization, event handlers, module pattern, iterators, partial application, maintaining state in callbacks",
          "exercises": [
            {
              "type": "output",
              "question": "What is the output?\nfunction makeCounter() {\n  let count = 0;\n  return { inc: () => ++count, get: () => count };\n}\nconst c = makeCounter();\nc.inc(); c.inc(); c.inc();\nconsole.log(c.get());",
              "answer": "3 — All methods share the same closed-over 'count' variable"
            },
            {
              "type": "output",
              "question": "What is the output?\nfor (var i = 0; i < 3; i++) {\n  setTimeout(() => console.log(i), 0);\n}",
              "answer": "3, 3, 3 — var is function-scoped, all closures share the same 'i' which is 3 after the loop"
            },
            {
              "type": "output",
              "question": "What is the output?\nfor (let i = 0; i < 3; i++) {\n  setTimeout(() => console.log(i), 0);\n}",
              "answer": "0, 1, 2 — let creates a new binding per iteration, each closure captures its own 'i'"
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction outer() {\n  let x = 10;\n  function inner() { console.log(x); }\n  x = 20;\n  return inner;\n}\nouter()();",
              "answer": "20 — Closures capture variables by reference, not by value. x was changed to 20 before inner executes"
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction createFunctions() {\n  var funcs = [];\n  for (var i = 0; i < 3; i++) {\n    funcs.push((function(j) {\n      return function() { return j; };\n    })(i));\n  }\n  return funcs;\n}\nconst fns = createFunctions();\nconsole.log(fns[0](), fns[1](), fns[2]());",
              "answer": "0 1 2 — IIFE creates a new scope for each iteration, capturing the current value of i as j"
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction makeAdder(x) {\n  return function(y) {\n    return x + y;\n  };\n}\nconst add5 = makeAdder(5);\nconst add10 = makeAdder(10);\nconsole.log(add5(3), add10(3));",
              "answer": "8 13 — Each call to makeAdder creates a separate closure with its own 'x'"
            },
            {
              "type": "output",
              "question": "What is the output?\nlet f;\nfunction outer() {\n  let a = 1;\n  f = function() { console.log(a += 1); };\n}\nouter();\nf();\nf();",
              "answer": "2 then 3 — f is a closure over 'a'. Each call mutates the same 'a'"
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction foo() {\n  var a = 2;\n  function bar() {\n    console.log(a);\n  }\n  return bar;\n}\nvar baz = foo();\nbaz();",
              "answer": "2 — bar is a closure that has access to foo's scope"
            },
            {
              "type": "output",
              "question": "What is the output?\nconst arr = [10, 20, 30];\nconst fns = arr.map(num => () => num * 2);\nconsole.log(fns[0](), fns[1](), fns[2]());",
              "answer": "20 40 60 — Arrow functions in map create closures, each capturing its own 'num' parameter"
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction timer() {\n  for (var i = 1; i <= 3; i++) {\n    setTimeout(function() {\n      console.log(i);\n    }, i * 100);\n  }\n}\ntimer();",
              "answer": "4, 4, 4 — var 'i' is shared; loop ends with i=4, all callbacks reference same i"
            }
          ],
          "programExercises": [
            {
              "program": "function counter() {\n  let n = 0;\n  return {\n    increment: () => ++n,\n    decrement: () => --n,\n    value: () => n\n  };\n}\nconst c = counter();\nc.increment();\nc.increment();\nc.decrement();\nconsole.log(c.value());",
              "expectedOutput": "1",
              "explanation": "Private counter with closure — increment twice (2), decrement once (1)"
            },
            {
              "program": "function once(fn) {\n  let called = false;\n  let result;\n  return function(...args) {\n    if (!called) {\n      called = true;\n      result = fn(...args);\n    }\n    return result;\n  };\n}\nconst init = once(() => 'INITIALIZED');\nconsole.log(init());\nconsole.log(init());",
              "expectedOutput": "INITIALIZED\nINITIALIZED",
              "explanation": "once() uses closure to track if fn was called. Both calls return the cached result."
            },
            {
              "program": "function makeMultiplier(x) {\n  return (y) => x * y;\n}\nconst double = makeMultiplier(2);\nconst triple = makeMultiplier(3);\nconsole.log(double(5));\nconsole.log(triple(5));",
              "expectedOutput": "10\n15",
              "explanation": "Function factory — double closes over x=2, triple closes over x=3"
            },
            {
              "program": "const add = (function() {\n  let sum = 0;\n  return function(n) {\n    sum += n;\n    return sum;\n  };\n})();\nconsole.log(add(5));\nconsole.log(add(3));\nconsole.log(add(2));",
              "expectedOutput": "5\n8\n10",
              "explanation": "IIFE creates a running total accumulator with closed-over 'sum'"
            },
            {
              "program": "function secretKeeper(secret) {\n  return {\n    getSecret: () => secret,\n    setSecret: (s) => { secret = s; }\n  };\n}\nconst k = secretKeeper('abc');\nconsole.log(k.getSecret());\nk.setSecret('xyz');\nconsole.log(k.getSecret());",
              "expectedOutput": "abc\nxyz",
              "explanation": "Closures enable private variable pattern — 'secret' is only accessible via methods"
            },
            {
              "program": "function createTimer() {\n  let calls = 0;\n  return function() {\n    calls++;\n    return `Called ${calls} time(s)`;\n  };\n}\nconst t1 = createTimer();\nconst t2 = createTimer();\nconsole.log(t1());\nconsole.log(t1());\nconsole.log(t2());",
              "expectedOutput": "Called 1 time(s)\nCalled 2 time(s)\nCalled 1 time(s)",
              "explanation": "Each createTimer() call creates a SEPARATE closure with its own 'calls' count"
            },
            {
              "program": "const scores = [90, 85, 70];\nconst checks = scores.map(score => () => score >= 80 ? 'Pass' : 'Fail');\nconsole.log(checks.map(fn => fn()).join(', '));",
              "expectedOutput": "Pass, Pass, Fail",
              "explanation": "Each arrow function captures its own 'score' from the map callback"
            },
            {
              "program": "function logger(prefix) {\n  return function(msg) {\n    return `[${prefix}] ${msg}`;\n  };\n}\nconst warn = logger('WARN');\nconst err = logger('ERROR');\nconsole.log(warn('Low disk'));\nconsole.log(err('Crash'));",
              "expectedOutput": "[WARN] Low disk\n[ERROR] Crash",
              "explanation": "Logger factory — each logger closes over its own 'prefix'"
            },
            {
              "program": "function fibonacci() {\n  let prev = 0, curr = 1;\n  return function() {\n    const val = prev;\n    [prev, curr] = [curr, prev + curr];\n    return val;\n  };\n}\nconst fib = fibonacci();\nconsole.log([fib(), fib(), fib(), fib(), fib(), fib(), fib()].join(', '));",
              "expectedOutput": "0, 1, 1, 2, 3, 5, 8",
              "explanation": "Stateful iterator using closure — prev and curr persist between calls"
            },
            {
              "program": "function rateLimit(fn, delay) {\n  let lastCall = 0;\n  return function(...args) {\n    const now = Date.now();\n    if (now - lastCall >= delay) {\n      lastCall = now;\n      return fn(...args);\n    }\n    return 'Rate limited';\n  };\n}\nconst limited = rateLimit(x => x * 2, 1000);\nconsole.log(limited(5));\nconsole.log(limited(10));",
              "expectedOutput": "10\nRate limited",
              "explanation": "Rate limiter using closure to track lastCall timestamp. Second call is too soon."
            }
          ],
          "interviewQuestions": [
            {
              "question": "What is a closure and how does it work?",
              "answer": "A closure is a function that retains access to its outer (lexical) scope's variables even after the outer function has returned. When a function is created, it gets a hidden [[Environment]] reference to the surrounding Lexical Environment. Variable lookup follows the scope chain from inner to outer."
            },
            {
              "question": "What is the classic 'loop + var + setTimeout' problem and how do you fix it?",
              "answer": "Using `var` in a for loop with setTimeout causes all callbacks to share the same variable. Fixes: (1) Use `let` instead of `var` (creates block scope per iteration), (2) Use an IIFE to capture the current value, (3) Use `forEach` or `map` which create a new scope per callback, (4) Pass i as the third argument to setTimeout."
            },
            {
              "question": "Do closures capture variables by value or by reference?",
              "answer": "By reference. Closures don't copy the variable's value at the time of creation — they maintain a live link to the variable. If the variable changes after the closure is created, the closure sees the updated value."
            },
            {
              "question": "How do closures enable the module pattern?",
              "answer": "The module pattern uses an IIFE that returns an object with methods. These methods are closures that have access to private variables defined inside the IIFE. This provides encapsulation — internal state is hidden, only exposed through the returned interface."
            },
            {
              "question": "Can closures cause memory leaks? How?",
              "answer": "Yes. If a closure references a large object that is no longer needed, the garbage collector can't free it because the closure's scope chain still holds a reference. Common cases: event handlers not removed, setInterval callbacks not cleared, storing closures in long-lived data structures."
            },
            {
              "question": "What is a stale closure? Give a React example.",
              "answer": "A stale closure occurs when a closure captures an outdated value. In React: `useEffect(() => { setInterval(() => console.log(count), 1000); }, [])` — the callback captures the initial `count` value and never sees updates. Fix: use a ref, add count to deps, or use the functional form of setState."
            },
            {
              "question": "Explain the difference between lexical scope and dynamic scope in relation to closures.",
              "answer": "JavaScript uses lexical (static) scope — a closure's scope is determined by where the function is DEFINED, not where it is CALLED. Dynamic scope (used by some other languages) would look up variables based on the call stack. This is why closures always reference the enclosing scope at definition time."
            },
            {
              "question": "How would you implement a memoize function using closures?",
              "answer": "Create a function that returns a wrapper. The wrapper uses a closure-scoped cache object. Before calling the original function, check if the args (serialized as a key) exist in the cache. If yes, return cached result. If no, call the function, store the result, and return it."
            },
            {
              "question": "What is an IIFE and how does it relate to closures?",
              "answer": "An IIFE (Immediately Invoked Function Expression) is a function that runs immediately: `(function(){ ... })()`. It creates a new scope. Combined with closures, IIFEs were used (before let/const) to create private variables and avoid polluting the global scope. The returned functions/objects form closures over the IIFE's scope."
            },
            {
              "question": "How do closures work with async operations like Promises?",
              "answer": "When async code (Promise callbacks, setTimeout, async/await) executes, it retains access to the scope where it was defined through closures. The callback 'remembers' the variables from its enclosing scope. This is why you can use local variables inside `.then()` callbacks — the closure keeps them alive until the async operation completes."
            }
          ],
          "category": "Core Concepts"
        },
        {
          "id": "event-loop",
          "title": "Event Loop, Call Stack & Task Queue",
          "description": "Understand how JavaScript executes code — the event loop, call stack, microtasks vs macrotasks, and why setTimeout(fn, 0) isn't truly instant.",
          "explanation": "JavaScript is single-threaded — it has ONE call stack and can execute ONE piece of code at a time. The event loop is the mechanism that coordinates execution between the call stack, Web APIs, and task queues.\n\nExecution flow:\n1. Synchronous code runs on the call stack (LIFO — Last In, First Out)\n2. Async operations (setTimeout, fetch, DOM events) are handed off to Web APIs / Node APIs\n3. When an async operation completes, its callback is pushed to a task queue\n4. The event loop checks: 'Is the call stack empty?' → If yes, move the next task from the queue to the stack\n\nTwo types of task queues:\n• Microtask Queue (higher priority): Promise callbacks (.then, .catch, .finally), queueMicrotask(), MutationObserver\n• Macrotask Queue (lower priority): setTimeout, setInterval, setImmediate (Node), I/O, UI rendering\n\nExecution priority order:\n1. All synchronous code on the call stack\n2. ALL microtasks are drained (including microtasks added during microtask processing)\n3. ONE macrotask is picked from the macrotask queue\n4. Repeat from step 2\n\nKey insights:\n- console.log() is synchronous, runs immediately\n- Promise.resolve().then(cb) → cb goes to microtask queue\n- setTimeout(cb, 0) → cb goes to macrotask queue (minimum delay, not zero)\n- Microtasks ALWAYS run before macrotasks when the stack is empty\n- Long-running microtasks can starve macrotasks and freeze rendering",
          "code": "// Execution order demo\nconsole.log('1 - sync');          // 1. Call stack\n\nsetTimeout(() => {\n  console.log('2 - macrotask');   // 5. Macrotask queue\n}, 0);\n\nPromise.resolve().then(() => {\n  console.log('3 - microtask');   // 3. Microtask queue\n});\n\nPromise.resolve().then(() => {\n  console.log('4 - microtask 2'); // 4. Microtask queue\n});\n\nconsole.log('5 - sync');          // 2. Call stack\n\n// Output order: 1 - sync, 5 - sync, 3 - microtask, 4 - microtask 2, 2 - macrotask\n\n// Microtasks added during microtask processing\nPromise.resolve().then(() => {\n  console.log('A');\n  Promise.resolve().then(() => console.log('B'));  // Added during microtask\n}).then(() => console.log('C'));\n// Output: A, B, C  (B runs before C because it's queued first)",
          "example": "// Real-world: Ensuring DOM update before next operation\nfunction updateAndMeasure(element) {\n  element.textContent = 'Updated';  // Sync DOM mutation\n  \n  // Use microtask to measure after DOM update but before paint\n  queueMicrotask(() => {\n    const height = element.offsetHeight;\n    console.log('Height:', height);\n  });\n}\n\n// Chunking heavy work to keep UI responsive\nfunction processLargeArray(arr, chunkSize = 1000) {\n  let i = 0;\n  function processChunk() {\n    const end = Math.min(i + chunkSize, arr.length);\n    while (i < end) {\n      // Process arr[i]\n      i++;\n    }\n    if (i < arr.length) {\n      // Yield to event loop — allows rendering/user input\n      setTimeout(processChunk, 0);\n    }\n  }\n  processChunk();\n}",
          "useCase": "Understanding async code execution order, debugging race conditions, optimizing UI responsiveness, preventing UI freezes with chunked processing, Promise vs setTimeout ordering",
          "exercises": [
            {
              "type": "output",
              "question": "What is the output order?\nconsole.log('A');\nsetTimeout(() => console.log('B'), 0);\nPromise.resolve().then(() => console.log('C'));\nconsole.log('D');",
              "answer": "A, D, C, B — Sync first (A,D), then microtask (C), then macrotask (B)"
            },
            {
              "type": "output",
              "question": "What is the output order?\nsetTimeout(() => console.log(1), 0);\nsetTimeout(() => console.log(2), 0);\nPromise.resolve().then(() => console.log(3));\nPromise.resolve().then(() => console.log(4));",
              "answer": "3, 4, 1, 2 — All microtasks (3,4) drain before ANY macrotask (1,2)"
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log('start');\nsetTimeout(() => console.log('timeout'), 0);\nPromise.resolve()\n  .then(() => console.log('promise 1'))\n  .then(() => console.log('promise 2'));\nconsole.log('end');",
              "answer": "start, end, promise 1, promise 2, timeout — Chained .then()s are separate microtasks but both run before the macrotask"
            },
            {
              "type": "output",
              "question": "What is the output?\nasync function foo() {\n  console.log('foo start');\n  await Promise.resolve();\n  console.log('foo end');\n}\nconsole.log('start');\nfoo();\nconsole.log('end');",
              "answer": "start, foo start, end, foo end — 'await' pauses foo, 'end' runs sync, then 'foo end' runs as microtask"
            },
            {
              "type": "output",
              "question": "What is the output?\nPromise.resolve().then(() => {\n  console.log(1);\n  setTimeout(() => console.log(2), 0);\n});\nsetTimeout(() => {\n  console.log(3);\n  Promise.resolve().then(() => console.log(4));\n}, 0);",
              "answer": "1, 3, 4, 2 — Microtask(1) runs first, queues macrotask(2). Macrotask(3) runs, queues microtask(4). Microtask(4) drains. Then macrotask(2)."
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(1);\nqueueMicrotask(() => console.log(2));\nsetTimeout(() => console.log(3), 0);\nqueueMicrotask(() => {\n  console.log(4);\n  queueMicrotask(() => console.log(5));\n});\nconsole.log(6);",
              "answer": "1, 6, 2, 4, 5, 3 — Sync(1,6), then drain ALL microtasks(2,4,5 — 5 was added during 4), finally macrotask(3)"
            },
            {
              "type": "output",
              "question": "What is the output?\nasync function a() {\n  console.log(1);\n  await b();\n  console.log(2);\n}\nasync function b() {\n  console.log(3);\n}\nconsole.log(4);\na();\nconsole.log(5);",
              "answer": "4, 1, 3, 5, 2 — 4 sync, a() starts: 1 sync, b() runs: 3 sync, await pauses a, 5 sync, then microtask: 2"
            },
            {
              "type": "output",
              "question": "What is the output?\nsetTimeout(() => console.log('A'), 100);\nsetTimeout(() => console.log('B'), 0);\nnew Promise((resolve) => {\n  console.log('C');\n  resolve();\n}).then(() => console.log('D'));",
              "answer": "C, D, B, A — Promise executor (C) runs sync, microtask (D), then macrotasks in order (B at 0ms, A at 100ms)"
            },
            {
              "type": "concept",
              "question": "Can a microtask starve the browser rendering? Explain.",
              "answer": "Yes. The event loop drains ALL microtasks before rendering or running macrotasks. If microtasks keep adding more microtasks (recursive), the loop never moves to rendering, causing the page to freeze."
            },
            {
              "type": "concept",
              "question": "Why does setTimeout(fn, 0) not execute immediately?",
              "answer": "setTimeout with 0ms queues the callback as a macrotask. It will only run after: (1) the current synchronous code finishes, (2) ALL pending microtasks drain. Additionally, browsers clamp the minimum delay to ~4ms for nested setTimeout calls."
            }
          ],
          "programExercises": [
            {
              "program": "console.log('script start');\nsetTimeout(() => console.log('setTimeout'), 0);\nPromise.resolve().then(() => console.log('promise'));\nconsole.log('script end');",
              "expectedOutput": "script start\nscript end\npromise\nsetTimeout",
              "explanation": "Classic event loop question: sync code first, then microtask queue, then macrotask queue"
            },
            {
              "program": "console.log(1);\nsetTimeout(() => console.log(2), 10);\nsetTimeout(() => console.log(3), 0);\nnew Promise(r => {\n  console.log(4);\n  r();\n}).then(() => console.log(5));\nconsole.log(6);",
              "expectedOutput": "1\n4\n6\n5\n3\n2",
              "explanation": "Promise executor (4) is sync. Microtask (5) before macrotasks. setTimeout 0ms (3) before 10ms (2)."
            },
            {
              "program": "async function foo() {\n  console.log('A');\n  const val = await 42;\n  console.log('B', val);\n}\nconsole.log('C');\nfoo();\nconsole.log('D');",
              "expectedOutput": "C\nA\nD\nB 42",
              "explanation": "await pauses foo() after 'A', 'D' runs sync, then the microtask resumes foo with val=42"
            },
            {
              "program": "Promise.resolve()\n  .then(() => {\n    console.log('then 1');\n    return Promise.resolve('inner');\n  })\n  .then(val => console.log('then 2:', val));\n\nPromise.resolve()\n  .then(() => console.log('then A'))\n  .then(() => console.log('then B'))\n  .then(() => console.log('then C'));",
              "expectedOutput": "then 1\nthen A\nthen B\nthen 2: inner\nthen C",
              "explanation": "Returning a Promise from .then() adds extra microtask ticks. 'then A' and 'then B' interleave before 'then 2' resolves."
            },
            {
              "program": "const p = new Promise(resolve => {\n  console.log('executor');\n  resolve('done');\n  console.log('after resolve');\n});\np.then(val => console.log(val));",
              "expectedOutput": "executor\nafter resolve\ndone",
              "explanation": "Promise executor runs synchronously, even AFTER resolve(). The .then callback waits for the microtask queue."
            },
            {
              "program": "async function first() {\n  console.log(1);\n  await second();\n  console.log(2);\n}\nasync function second() {\n  console.log(3);\n  await third();\n  console.log(4);\n}\nasync function third() {\n  console.log(5);\n}\nfirst();\nconsole.log(6);",
              "expectedOutput": "1\n3\n5\n6\n4\n2",
              "explanation": "Nested awaits: 1→3→5 sync, then 6 sync, then 4 (third resolved), then 2 (second resolved)"
            },
            {
              "program": "setTimeout(() => {\n  console.log('timeout 1');\n  Promise.resolve().then(() => console.log('promise in timeout'));\n}, 0);\nsetTimeout(() => console.log('timeout 2'), 0);\nPromise.resolve().then(() => console.log('promise 1'));",
              "expectedOutput": "promise 1\ntimeout 1\npromise in timeout\ntimeout 2",
              "explanation": "Microtask (promise 1) first. Then macrotask (timeout 1) runs and queues a microtask. That microtask drains before timeout 2."
            },
            {
              "program": "console.log('A');\nqueueMicrotask(() => {\n  console.log('B');\n  queueMicrotask(() => console.log('C'));\n});\nPromise.resolve().then(() => console.log('D'));\nconsole.log('E');",
              "expectedOutput": "A\nE\nB\nD\nC",
              "explanation": "Sync: A, E. Microtasks drain in order: B (queues C), D, then C (added during B processing)."
            },
            {
              "program": "let result = [];\nresult.push('sync 1');\nsetTimeout(() => result.push('macro 1'), 0);\nPromise.resolve().then(() => result.push('micro 1'));\nsetTimeout(() => result.push('macro 2'), 0);\nPromise.resolve().then(() => result.push('micro 2'));\nresult.push('sync 2');\nsetTimeout(() => console.log(result.join(', ')), 100);",
              "expectedOutput": "sync 1, sync 2, micro 1, micro 2, macro 1, macro 2",
              "explanation": "Sync code first, then all microtasks, then macrotasks in order. The 100ms timeout prints the final state."
            },
            {
              "program": "for (let i = 0; i < 3; i++) {\n  Promise.resolve().then(() => console.log('promise', i));\n  setTimeout(() => console.log('timeout', i), 0);\n}\nconsole.log('done');",
              "expectedOutput": "done\npromise 0\npromise 1\npromise 2\ntimeout 0\ntimeout 1\ntimeout 2",
              "explanation": "Sync 'done' first, then ALL microtasks (promise 0,1,2), then ALL macrotasks (timeout 0,1,2)"
            }
          ],
          "interviewQuestions": [
            {
              "question": "Explain the JavaScript event loop.",
              "answer": "The event loop is a mechanism that continuously checks if the call stack is empty. If it is, it first drains ALL microtasks (Promise callbacks, queueMicrotask), then picks ONE macrotask (setTimeout, setInterval, I/O) and pushes it to the call stack. This cycle repeats, with microtasks always having priority over macrotasks."
            },
            {
              "question": "What is the difference between microtasks and macrotasks?",
              "answer": "Microtasks (Promise.then, queueMicrotask, MutationObserver) have higher priority — ALL pending microtasks drain before any macrotask runs. Macrotasks (setTimeout, setInterval, I/O, rendering) are processed one at a time, with the microtask queue draining between each macrotask."
            },
            {
              "question": "Why is JavaScript single-threaded yet non-blocking?",
              "answer": "JavaScript's main execution thread is single-threaded (one call stack). However, async operations like network requests, timers, and file I/O are handled by the browser's Web APIs or Node's libuv in separate threads. When complete, callbacks are queued and the event loop coordinates their execution on the main thread."
            },
            {
              "question": "What is the call stack and how does it relate to stack overflow?",
              "answer": "The call stack is a LIFO data structure that tracks function execution. Each function call pushes a frame, each return pops it. Stack overflow occurs when the stack exceeds its size limit, typically from infinite recursion (a function calling itself without a base case)."
            },
            {
              "question": "Explain what happens when you call setTimeout(fn, 0).",
              "answer": "The callback fn is NOT executed immediately. It's registered with the Web API timer (with 0ms delay), then moved to the macrotask queue. It only executes after: (1) all current synchronous code finishes, (2) all pending microtasks drain. Browsers also clamp nested setTimeout to a minimum of ~4ms."
            },
            {
              "question": "What is queueMicrotask() and when would you use it?",
              "answer": "queueMicrotask(callback) schedules a callback to run as a microtask — after the current sync code but before any macrotasks or rendering. Use it when you need something to run 'very soon' but after the current operation completes, like cleanup or measurement after DOM mutations."
            },
            {
              "question": "How does async/await relate to the event loop?",
              "answer": "An async function runs synchronously until it hits an `await`. At that point, the function pauses and returns a Promise. The code after `await` is scheduled as a microtask (like a .then() callback). Execution continues with whatever is next in the call stack, and the async function resumes when its microtask is picked up."
            },
            {
              "question": "Can you explain why Promise executor functions run synchronously?",
              "answer": "The function passed to `new Promise((resolve, reject) => { ... })` runs immediately and synchronously as part of the Promise constructor. Only the `.then()`, `.catch()`, and `.finally()` callbacks are asynchronous (scheduled as microtasks). This is why `console.log` inside a Promise executor prints before `.then()` callbacks."
            },
            {
              "question": "How would you prevent a long-running task from blocking the UI?",
              "answer": "Break the work into chunks using: (1) setTimeout/requestAnimationFrame to yield to the event loop between chunks, (2) Web Workers for CPU-intensive work in a separate thread, (3) requestIdleCallback for non-urgent work during browser idle time, (4) The scheduler.postTask() API for priority-based scheduling."
            },
            {
              "question": "What is the render/paint step in the event loop?",
              "answer": "Between macrotask processing, the browser may perform rendering: style recalculation, layout, paint, and compositing. The event loop order is: macrotask → drain microtasks → render (if needed) → next macrotask. requestAnimationFrame callbacks run just before the render step, making them ideal for visual updates."
            }
          ],
          "category": "Core Concepts"
        },
        {
          "id": "this-keyword",
          "title": "The 'this' Keyword",
          "description": "Master JavaScript's 'this' binding rules — default, implicit, explicit (call/apply/bind), new binding, and arrow functions.",
          "explanation": "'this' in JavaScript is NOT fixed — it's determined at call time based on HOW a function is called, not WHERE it's defined (except for arrow functions).\n\nThe 4 binding rules (in priority order):\n\n1. new Binding (highest priority)\n   - `new Foo()` → 'this' refers to the newly created object\n\n2. Explicit Binding\n   - `fn.call(obj, args)` → 'this' is obj\n   - `fn.apply(obj, [args])` → 'this' is obj\n   - `fn.bind(obj)` → returns new function with 'this' permanently set to obj\n\n3. Implicit Binding\n   - `obj.method()` → 'this' is obj (the object before the dot)\n   - Lost when method is extracted: `const fn = obj.method; fn()` → 'this' is NOT obj\n\n4. Default Binding (lowest priority)\n   - Standalone function call: `foo()` → 'this' is globalThis (window in browser, global in Node)\n   - In strict mode: 'this' is undefined\n\nArrow functions (special case):\n- Arrow functions do NOT have their own 'this'\n- They inherit 'this' from the enclosing lexical scope (where they're defined)\n- Cannot be re-bound with call/apply/bind\n- This makes them ideal for callbacks and event handlers",
          "code": "// Default binding\nfunction show() { console.log(this); }\nshow(); // window (browser) / global (Node) — strict mode: undefined\n\n// Implicit binding\nconst user = {\n  name: 'Alice',\n  greet() { return `Hi, I'm ${this.name}`; }\n};\nuser.greet(); // 'Hi, I'm Alice' — this = user\n\n// Lost implicit binding\nconst greet = user.greet;\ngreet(); // 'Hi, I'm undefined' — this = window\n\n// Explicit binding\nfunction sayHi() { return `Hi, ${this.name}`; }\nsayHi.call({ name: 'Bob' });   // 'Hi, Bob'\nsayHi.apply({ name: 'Eve' });  // 'Hi, Eve'\n\nconst boundHi = sayHi.bind({ name: 'Dan' });\nboundHi(); // 'Hi, Dan'\n\n// new binding\nfunction Person(name) {\n  this.name = name;\n}\nconst p = new Person('Carol');\nconsole.log(p.name); // 'Carol' — this = new object\n\n// Arrow function — inherits 'this'\nconst team = {\n  name: 'Dev Team',\n  members: ['A', 'B'],\n  list() {\n    return this.members.map(m => `${m} from ${this.name}`);\n    // Arrow fn uses 'this' from list(), which is team\n  }\n};\nteam.list(); // ['A from Dev Team', 'B from Dev Team']",
          "example": "// Common 'this' pitfall: callbacks\nclass Timer {\n  constructor() {\n    this.seconds = 0;\n  }\n  \n  start() {\n    // WRONG: regular function loses 'this'\n    // setInterval(function() { this.seconds++; }, 1000);\n    \n    // CORRECT: arrow function inherits 'this'\n    setInterval(() => {\n      this.seconds++;\n      console.log(this.seconds);\n    }, 1000);\n  }\n}\n\n// Explicit binding for event handlers\nclass Button {\n  constructor(label) {\n    this.label = label;\n    // Bind in constructor\n    this.handleClick = this.handleClick.bind(this);\n  }\n  handleClick() {\n    console.log(`${this.label} clicked`);\n  }\n}",
          "useCase": "Object methods, class methods, event handlers, callbacks, React component methods, constructor functions, method chaining, mixin patterns",
          "exercises": [
            {
              "type": "output",
              "question": "What is the output?\nconst obj = {\n  x: 42,\n  getX: function() { return this.x; }\n};\nconsole.log(obj.getX());\nconst fn = obj.getX;\nconsole.log(fn());",
              "answer": "42, then undefined — First call: implicit binding (this=obj). Second call: default binding (this=window, window.x is undefined)"
            },
            {
              "type": "output",
              "question": "What is the output?\nconst obj = {\n  name: 'Alice',\n  greet: () => `Hi ${this.name}`\n};\nconsole.log(obj.greet());",
              "answer": "Hi undefined — Arrow function doesn't get its own 'this'. It inherits from the surrounding scope (module/global), where this.name is undefined"
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction greet() {\n  return `Hello, ${this.name}`;\n}\nconst a = { name: 'A' };\nconst b = { name: 'B' };\nconsole.log(greet.call(a));\nconsole.log(greet.apply(b));",
              "answer": "Hello, A then Hello, B — call and apply explicitly set 'this'"
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction Person(name) {\n  this.name = name;\n}\nconst p1 = new Person('Dan');\nconst p2 = Person('Eve');\nconsole.log(p1.name);\nconsole.log(p2);",
              "answer": "Dan, then undefined — With 'new', this is a new object. Without 'new', Person returns undefined (and name leaks to global)"
            },
            {
              "type": "output",
              "question": "What is the output?\nconst obj = {\n  val: 10,\n  getVal() { return this.val; },\n  getValArrow: () => this.val\n};\nconsole.log(obj.getVal());\nconsole.log(obj.getValArrow());",
              "answer": "10, then undefined — getVal: implicit binding. getValArrow: arrow fn inherits outer 'this' (not obj)"
            },
            {
              "type": "output",
              "question": "What is the output?\nconst fn = function() { return this.x; }.bind({ x: 1 }).bind({ x: 2 });\nconsole.log(fn());",
              "answer": "1 — bind can only be applied once. The second bind is ignored."
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction Foo() {\n  this.a = 1;\n  return { a: 2 };\n}\nconst foo = new Foo();\nconsole.log(foo.a);",
              "answer": "2 — When a constructor returns an object, that object becomes the result of 'new' instead of 'this'"
            },
            {
              "type": "output",
              "question": "What is the output?\nconst counter = {\n  count: 0,\n  inc() { this.count++; return this; }\n};\nconsole.log(counter.inc().inc().inc().count);",
              "answer": "3 — Method chaining works because inc() returns 'this' (the counter object)"
            },
            {
              "type": "output",
              "question": "What is the output?\n'use strict';\nfunction show() { console.log(this); }\nshow();",
              "answer": "undefined — In strict mode, default binding gives undefined instead of globalThis"
            },
            {
              "type": "output",
              "question": "What is the output?\nclass Dog {\n  constructor(name) { this.name = name; }\n  bark() { return `${this.name} says woof`; }\n}\nconst d = new Dog('Rex');\nconst bark = d.bark;\ntry { console.log(bark()); } catch(e) { console.log(e.message); }",
              "answer": "Cannot read properties of undefined (reading 'name') — Class methods run in strict mode, so extracted method has this=undefined"
            }
          ],
          "programExercises": [
            {
              "program": "const obj = {\n  x: 10,\n  double() { return this.x * 2; }\n};\nconsole.log(obj.double());\nconst { double } = obj;\nconsole.log(double.call({ x: 5 }));",
              "expectedOutput": "20\n10",
              "explanation": "obj.double() → this.x=10 → 20. Extracted and called with {x:5} → this.x=5 → 10"
            },
            {
              "program": "function multiply(a, b) {\n  return this.factor * a * b;\n}\nconst double = multiply.bind({ factor: 2 });\nconst triple = multiply.bind({ factor: 3 });\nconsole.log(double(3, 4));\nconsole.log(triple(3, 4));",
              "expectedOutput": "24\n36",
              "explanation": "bind sets this.factor. double: 2*3*4=24, triple: 3*3*4=36"
            },
            {
              "program": "const user = {\n  name: 'Alice',\n  friends: ['Bob', 'Carol'],\n  listFriends() {\n    return this.friends.map(f => `${this.name} knows ${f}`);\n  }\n};\nconsole.log(user.listFriends().join('\\n'));",
              "expectedOutput": "Alice knows Bob\nAlice knows Carol",
              "explanation": "Arrow function in map inherits 'this' from listFriends(), which is the user object"
            },
            {
              "program": "function greet(greeting, punct) {\n  return `${greeting}, ${this.name}${punct}`;\n}\nconsole.log(greet.call({ name: 'A' }, 'Hi', '!'));\nconsole.log(greet.apply({ name: 'B' }, ['Hey', '?']));",
              "expectedOutput": "Hi, A!\nHey, B?",
              "explanation": "call passes args individually, apply passes args as array. Both set 'this' to the first argument."
            },
            {
              "program": "function Calc(start) {\n  this.value = start;\n}\nCalc.prototype.add = function(n) { this.value += n; return this; };\nCalc.prototype.mul = function(n) { this.value *= n; return this; };\nCalc.prototype.result = function() { return this.value; };\n\nconsole.log(new Calc(2).add(3).mul(4).result());",
              "expectedOutput": "20",
              "explanation": "Method chaining: start=2, +3=5, *4=20. Each method returns 'this' to enable chaining."
            },
            {
              "program": "const obj = {\n  name: 'outer',\n  inner: {\n    name: 'inner',\n    getName() { return this.name; }\n  }\n};\nconsole.log(obj.inner.getName());",
              "expectedOutput": "inner",
              "explanation": "Implicit binding: 'this' is the object directly before the dot — obj.inner, not obj"
            },
            {
              "program": "const nums = {\n  values: [1, 2, 3],\n  sum() {\n    return this.values.reduce((a, b) => a + b, 0);\n  }\n};\nconst sumFn = nums.sum.bind(nums);\nconsole.log(sumFn());",
              "expectedOutput": "6",
              "explanation": "bind permanently attaches 'this' to nums, so sumFn always works correctly"
            },
            {
              "program": "function identify() {\n  return this.name.toUpperCase();\n}\nfunction speak() {\n  return `Hello, I'm ${identify.call(this)}`;\n}\nconst me = { name: 'Kyle' };\nconsole.log(speak.call(me));",
              "expectedOutput": "Hello, I'm KYLE",
              "explanation": "speak is called with this=me, then passes that same 'this' to identify via call()"
            },
            {
              "program": "class EventEmitter {\n  constructor() {\n    this.events = {};\n  }\n  on(event, cb) {\n    (this.events[event] ||= []).push(cb);\n    return this;\n  }\n  emit(event, ...args) {\n    (this.events[event] || []).forEach(cb => cb(...args));\n  }\n}\nconst e = new EventEmitter();\ne.on('greet', name => console.log(`Hi ${name}`));\ne.emit('greet', 'World');",
              "expectedOutput": "Hi World",
              "explanation": "Class-based event emitter using method chaining (on returns this) and closures"
            },
            {
              "program": "const obj = { a: 1 };\nfunction setA(val) { this.a = val; }\nconst bound = setA.bind(obj);\nbound(99);\nconsole.log(obj.a);\nnew bound(200);\nconsole.log(obj.a);",
              "expectedOutput": "99\n99",
              "explanation": "'new' overrides bind for the new object, but obj.a stays 99. The new object gets a=200 but is discarded."
            }
          ],
          "interviewQuestions": [
            {
              "question": "What are the 4 rules of 'this' binding in JavaScript?",
              "answer": "In priority order: (1) new binding — this = new object, (2) Explicit binding — call/apply/bind set this, (3) Implicit binding — this = object before the dot, (4) Default binding — this = globalThis (or undefined in strict mode)."
            },
            {
              "question": "How do arrow functions handle 'this' differently?",
              "answer": "Arrow functions don't have their own 'this'. They inherit 'this' from the enclosing lexical scope at definition time. This cannot be changed with call/apply/bind. This makes them ideal for callbacks where you want to preserve the parent scope's 'this'."
            },
            {
              "question": "What is the difference between call, apply, and bind?",
              "answer": "call(thisArg, arg1, arg2) — invokes immediately with listed args. apply(thisArg, [args]) — invokes immediately with args as array. bind(thisArg, arg1) — returns a NEW function with 'this' permanently set. bind can also partially apply arguments."
            },
            {
              "question": "Can you re-bind a function created with bind()?",
              "answer": "No. Once a function is bound with bind(), subsequent bind() calls cannot override the 'this' value. However, 'new' can override bind because 'new' binding has higher priority than explicit binding."
            },
            {
              "question": "Why does 'this' in a class method become undefined when extracted?",
              "answer": "Class bodies run in strict mode. When you extract a method (const fn = obj.method), calling fn() uses default binding which is undefined in strict mode. Fix: use bind in constructor, use arrow function class fields, or use call/apply."
            },
            {
              "question": "What happens to 'this' when a constructor returns an object?",
              "answer": "If a constructor function explicitly returns an object, that object replaces the 'this' that was created by 'new'. If a constructor returns a primitive (or nothing), the 'this' object is returned as normal. This only applies to objects, not primitives."
            },
            {
              "question": "How does 'this' work in event handlers?",
              "answer": "In DOM event handlers, 'this' refers to the element the handler is attached to (same as e.currentTarget). With arrow functions, 'this' inherits from the outer scope instead. In React class components, you must bind handlers or use arrow functions to preserve the component's 'this'."
            },
            {
              "question": "Explain implicit binding loss with an example.",
              "answer": "When you assign a method to a variable (const fn = obj.method), the implicit binding is lost. fn() is now a standalone call with default binding. Common scenarios: passing methods as callbacks, destructuring methods, or storing methods in arrays."
            },
            {
              "question": "What is 'soft binding' and how does it differ from hard binding (bind)?",
              "answer": "Hard binding (bind) permanently fixes 'this'. Soft binding is a pattern where 'this' defaults to a specific object but CAN be overridden with call/apply. Implementation: check if 'this' is global/undefined, if so use the default, otherwise use the provided 'this'."
            },
            {
              "question": "How does 'this' work inside setTimeout and setInterval?",
              "answer": "In regular functions passed to setTimeout/setInterval, 'this' is globalThis (window). In strict mode, it's undefined. Solutions: (1) Arrow function: setTimeout(() => this.method(), 100), (2) Bind: setTimeout(this.method.bind(this), 100), (3) Variable capture: const self = this."
            }
          ],
          "category": "Core Concepts"
        },
        {
          "id": "prototypes-classes",
          "title": "Prototypes & Classes",
          "description": "Understand JavaScript's prototype chain, prototypal inheritance, ES6 classes, and how 'new' keyword works under the hood.",
          "explanation": "JavaScript uses prototypal inheritance — objects can inherit directly from other objects. Every object has an internal [[Prototype]] link to another object.\n\nPrototype chain:\n1. Every function has a `.prototype` property (an object)\n2. Objects created with `new Fn()` have their [[Prototype]] set to `Fn.prototype`\n3. Property lookup: check own properties → check [[Prototype]] → check [[Prototype]]'s [[Prototype]] → ... → null\n4. `Object.prototype` is at the top of most chains, its [[Prototype]] is null\n\n`__proto__` vs `.prototype`:\n- `__proto__` (or `Object.getPrototypeOf()`) — the actual prototype link on an instance\n- `.prototype` — a property on constructor functions, becomes the `__proto__` of instances\n\nES6 Classes:\n- Syntactic sugar over prototypal inheritance\n- `class` creates a constructor function + prototype\n- `extends` sets up the prototype chain for inheritance\n- `super()` calls the parent constructor\n- Class methods go on the prototype (shared)\n- Arrow function class fields are per-instance (not shared)\n\nKey concepts:\n- `instanceof` walks the prototype chain\n- `hasOwnProperty()` checks only own properties (not inherited)\n- `Object.create(proto)` creates an object with proto as its [[Prototype]]\n- Static methods belong to the class itself, not instances",
          "code": "// Constructor function + prototype\nfunction Animal(name) {\n  this.name = name;\n}\nAnimal.prototype.speak = function() {\n  return `${this.name} makes a sound`;\n};\n\nconst dog = new Animal('Rex');\nconsole.log(dog.speak()); // 'Rex makes a sound'\nconsole.log(dog.hasOwnProperty('name'));    // true (own)\nconsole.log(dog.hasOwnProperty('speak'));   // false (inherited from prototype)\n\n// ES6 Class (same thing, cleaner syntax)\nclass Vehicle {\n  constructor(make, year) {\n    this.make = make;\n    this.year = year;\n  }\n  \n  describe() {\n    return `${this.year} ${this.make}`;\n  }\n  \n  static compare(a, b) {\n    return a.year - b.year;\n  }\n}\n\nclass Car extends Vehicle {\n  constructor(make, year, doors) {\n    super(make, year); // Must call super() before using 'this'\n    this.doors = doors;\n  }\n  \n  describe() {\n    return `${super.describe()} with ${this.doors} doors`;\n  }\n}\n\nconst car = new Car('Honda', 2024, 4);\nconsole.log(car.describe()); // '2024 Honda with 4 doors'\nconsole.log(car instanceof Car);     // true\nconsole.log(car instanceof Vehicle); // true",
          "example": "// Object.create for direct prototypal inheritance\nconst personProto = {\n  greet() {\n    return `Hi, I'm ${this.name}`;\n  },\n  introduce() {\n    return `${this.greet()}, age ${this.age}`;\n  }\n};\n\nconst alice = Object.create(personProto);\nalice.name = 'Alice';\nalice.age = 30;\nconsole.log(alice.introduce()); // \"Hi, I'm Alice, age 30\"\n\n// How 'new' works internally\nfunction myNew(Constructor, ...args) {\n  const obj = Object.create(Constructor.prototype);\n  const result = Constructor.apply(obj, args);\n  return result instanceof Object ? result : obj;\n}\n\n// Private fields with # (ES2022)\nclass BankAccount {\n  #balance;\n  \n  constructor(initial) {\n    this.#balance = initial;\n  }\n  \n  deposit(amount) {\n    this.#balance += amount;\n  }\n  \n  get balance() {\n    return this.#balance;\n  }\n}\n// new BankAccount(100).#balance → SyntaxError!",
          "useCase": "Object-oriented design, inheritance patterns, code reuse, framework internals (React components), design patterns, extending built-ins",
          "exercises": [
            {
              "type": "output",
              "question": "What is the output?\nfunction Foo() {}\nFoo.prototype.x = 10;\nconst a = new Foo();\nconst b = new Foo();\na.x = 20;\nconsole.log(a.x, b.x);",
              "answer": "20, 10 — a.x=20 is set as own property (shadows prototype). b.x reads from prototype (10)"
            },
            {
              "type": "output",
              "question": "What is the output?\nclass A {\n  constructor() { this.name = 'A'; }\n  greet() { return this.name; }\n}\nclass B extends A {\n  constructor() {\n    super();\n    this.name = 'B';\n  }\n}\nconsole.log(new B().greet());",
              "answer": "B — super() sets name='A', then B's constructor overrides to name='B'. greet() reads this.name"
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction Dog(name) { this.name = name; }\nDog.prototype.bark = function() { return this.name; };\nconst d = new Dog('Max');\nconsole.log(d.hasOwnProperty('name'));\nconsole.log(d.hasOwnProperty('bark'));",
              "answer": "true, false — 'name' is an own property (set in constructor). 'bark' is on the prototype."
            },
            {
              "type": "output",
              "question": "What is the output?\nconst proto = { greet() { return 'hello'; } };\nconst obj = Object.create(proto);\nconsole.log(obj.greet());\nconsole.log(Object.getPrototypeOf(obj) === proto);",
              "answer": "hello, true — Object.create sets proto as obj's [[Prototype]]"
            },
            {
              "type": "output",
              "question": "What is the output?\nclass Counter {\n  #count = 0;\n  inc() { return ++this.#count; }\n}\nconst c = new Counter();\nconsole.log(c.inc(), c.inc(), c.inc());",
              "answer": "1 2 3 — Private field #count starts at 0, incremented each call"
            },
            {
              "type": "output",
              "question": "What is the output?\nclass Shape {\n  static count = 0;\n  constructor() { Shape.count++; }\n}\nnew Shape(); new Shape(); new Shape();\nconsole.log(Shape.count);",
              "answer": "3 — Static property is shared across all instances, incremented in constructor"
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction A() {}\nfunction B() {}\nB.prototype = Object.create(A.prototype);\nconst b = new B();\nconsole.log(b instanceof B);\nconsole.log(b instanceof A);\nconsole.log(b instanceof Object);",
              "answer": "true, true, true — prototype chain: b → B.prototype → A.prototype → Object.prototype → null"
            },
            {
              "type": "output",
              "question": "What is the output?\nclass Animal {\n  eat() { return 'eating'; }\n}\nclass Dog extends Animal {\n  eat() { return `dog ${super.eat()}`; }\n}\nconsole.log(new Dog().eat());",
              "answer": "dog eating — super.eat() calls the parent class method"
            },
            {
              "type": "output",
              "question": "What is the output?\nconst arr = [1, 2, 3];\nconsole.log(arr.hasOwnProperty('length'));\nconsole.log(arr.hasOwnProperty('map'));\nconsole.log(typeof arr.map);",
              "answer": "true, false, function — length is own property, map is inherited from Array.prototype"
            },
            {
              "type": "concept",
              "question": "What does Object.create(null) do and when is it useful?",
              "answer": "Creates an object with NO prototype (no inherited properties at all — no toString, hasOwnProperty, etc.). Useful for creating pure dictionaries/maps where you don't want prototype pollution. If/in checks won't find inherited properties."
            }
          ],
          "programExercises": [
            {
              "program": "function Person(name) {\n  this.name = name;\n}\nPerson.prototype.greet = function() {\n  return `Hi, I'm ${this.name}`;\n};\n\nfunction Student(name, grade) {\n  Person.call(this, name);\n  this.grade = grade;\n}\nStudent.prototype = Object.create(Person.prototype);\nStudent.prototype.constructor = Student;\n\nconst s = new Student('Alice', 'A');\nconsole.log(s.greet());\nconsole.log(s instanceof Student);\nconsole.log(s instanceof Person);",
              "expectedOutput": "Hi, I'm Alice\ntrue\ntrue",
              "explanation": "Classical prototypal inheritance: Student inherits from Person via Object.create()"
            },
            {
              "program": "class EventEmitter {\n  #handlers = {};\n  on(event, fn) {\n    (this.#handlers[event] ??= []).push(fn);\n  }\n  emit(event, ...args) {\n    (this.#handlers[event] || []).forEach(fn => fn(...args));\n  }\n}\nconst emitter = new EventEmitter();\nemitter.on('data', (x) => console.log('Got:', x));\nemitter.emit('data', 42);",
              "expectedOutput": "Got: 42",
              "explanation": "Class with private field #handlers. on() stores callbacks, emit() calls them."
            },
            {
              "program": "class LinkedList {\n  #head = null;\n  push(val) {\n    this.#head = { val, next: this.#head };\n  }\n  toArray() {\n    const result = [];\n    let node = this.#head;\n    while (node) { result.push(node.val); node = node.next; }\n    return result;\n  }\n}\nconst list = new LinkedList();\nlist.push(1); list.push(2); list.push(3);\nconsole.log(list.toArray().join(', '));",
              "expectedOutput": "3, 2, 1",
              "explanation": "Stack-like linked list — push prepends, so toArray returns newest first"
            },
            {
              "program": "class Builder {\n  constructor() { this.config = {}; }\n  set(key, val) { this.config[key] = val; return this; }\n  build() { return { ...this.config }; }\n}\nconst result = new Builder()\n  .set('host', 'localhost')\n  .set('port', 3000)\n  .build();\nconsole.log(JSON.stringify(result));",
              "expectedOutput": "{\"host\":\"localhost\",\"port\":3000}",
              "explanation": "Builder pattern using method chaining — each set() returns 'this'"
            },
            {
              "program": "class Stack {\n  #items = [];\n  push(item) { this.#items.push(item); }\n  pop() { return this.#items.pop(); }\n  peek() { return this.#items.at(-1); }\n  get size() { return this.#items.length; }\n}\nconst s = new Stack();\ns.push(10); s.push(20); s.push(30);\ns.pop();\nconsole.log(s.peek(), s.size);",
              "expectedOutput": "20 2",
              "explanation": "Stack class with private #items. After push(10,20,30) and pop(), top is 20, size is 2."
            },
            {
              "program": "const base = { type: 'vehicle' };\nconst car = Object.create(base);\ncar.wheels = 4;\nconst tesla = Object.create(car);\ntesla.brand = 'Tesla';\n\nconsole.log(tesla.brand);  \nconsole.log(tesla.wheels); \nconsole.log(tesla.type);",
              "expectedOutput": "Tesla\n4\nvehicle",
              "explanation": "Prototype chain: tesla → car → base. Property lookup walks up the chain."
            },
            {
              "program": "class Animal {\n  constructor(name) { this.name = name; }\n  toString() { return `Animal: ${this.name}`; }\n}\nclass Cat extends Animal {\n  constructor(name, color) { super(name); this.color = color; }\n  toString() { return `${super.toString()} (${this.color})`; }\n}\nconsole.log(String(new Cat('Whiskers', 'orange')));",
              "expectedOutput": "Animal: Whiskers (orange)",
              "explanation": "Overriding toString() with super call for inheritance chain"
            },
            {
              "program": "class Singleton {\n  static #instance;\n  constructor(value) {\n    if (Singleton.#instance) return Singleton.#instance;\n    this.value = value;\n    Singleton.#instance = this;\n  }\n}\nconst a = new Singleton('first');\nconst b = new Singleton('second');\nconsole.log(a === b);\nconsole.log(b.value);",
              "expectedOutput": "true\nfirst",
              "explanation": "Singleton pattern — constructor returns existing instance on subsequent calls"
            },
            {
              "program": "class Observable {\n  #subs = [];\n  subscribe(fn) { this.#subs.push(fn); return () => this.#subs = this.#subs.filter(s => s !== fn); }\n  notify(data) { this.#subs.forEach(fn => fn(data)); }\n}\nconst obs = new Observable();\nconst unsub = obs.subscribe(v => console.log('A:', v));\nobs.subscribe(v => console.log('B:', v));\nobs.notify(1);\nunsub();\nobs.notify(2);",
              "expectedOutput": "A: 1\nB: 1\nB: 2",
              "explanation": "Observer pattern — subscribe returns unsubscribe function. After unsub(), only B remains."
            },
            {
              "program": "function mixin(target, ...sources) {\n  Object.assign(target.prototype, ...sources);\n}\nclass Base {}\nconst Serializable = { toJSON() { return JSON.stringify(this); } };\nconst Printable = { print() { console.log(this.name); } };\nmixin(Base, Serializable, Printable);\nconst obj = new Base();\nobj.name = 'Test';\nobj.print();",
              "expectedOutput": "Test",
              "explanation": "Mixin pattern — copies methods from multiple objects onto a class prototype"
            }
          ],
          "interviewQuestions": [
            {
              "question": "What is the prototype chain?",
              "answer": "Every JS object has an internal [[Prototype]] link to another object. When accessing a property, JS first checks the object itself, then walks up the chain: instance → Constructor.prototype → parent.prototype → ... → Object.prototype → null. This is how inheritance works in JS."
            },
            {
              "question": "What is the difference between __proto__ and .prototype?",
              "answer": "__proto__ (or Object.getPrototypeOf()) is the actual prototype link on any object. .prototype is a property on constructor functions only — it becomes the __proto__ of objects created with 'new'. Example: new Foo().__proto__ === Foo.prototype."
            },
            {
              "question": "How does the 'new' keyword work step by step?",
              "answer": "1. Creates an empty object. 2. Sets its [[Prototype]] to Constructor.prototype. 3. Calls the constructor with 'this' set to the new object. 4. If constructor returns an object, that's used; otherwise the new object is returned."
            },
            {
              "question": "How are ES6 classes different from constructor functions?",
              "answer": "Classes are syntactic sugar but with differences: (1) Classes must be called with 'new' (constructor functions don't have to). (2) Class methods are non-enumerable. (3) Classes are always in strict mode. (4) Classes don't hoist like function declarations. (5) Classes support static methods, private fields (#), and extends/super."
            },
            {
              "question": "What is Object.create() and how does it differ from 'new'?",
              "answer": "Object.create(proto) creates a new object with proto as its [[Prototype]], without calling a constructor. 'new Constructor()' also creates an object and sets up the prototype, BUT it also calls the constructor function. Object.create(null) creates an object with no prototype at all."
            },
            {
              "question": "Explain private fields (#) in ES6 classes.",
              "answer": "Private fields (declared with #) are truly private — they can only be accessed inside the class body. They are NOT on the prototype, they're per-instance. Accessing #field outside the class throws a SyntaxError. They provide hard privacy, unlike the convention-based _ prefix."
            },
            {
              "question": "What is the difference between instance methods and static methods?",
              "answer": "Instance methods are defined on the prototype (shared by all instances, accessed via 'this'). Static methods are defined on the class constructor itself (accessed via ClassName.method()). Static methods cannot access 'this' as an instance. Use static for utility functions that don't need instance data."
            },
            {
              "question": "How does instanceof work?",
              "answer": "instanceof checks if Constructor.prototype exists anywhere in the object's prototype chain. `obj instanceof Foo` is equivalent to checking if `Foo.prototype` is found traversing `Object.getPrototypeOf(obj)` chain. Can be customized with `Symbol.hasInstance`."
            },
            {
              "question": "What are mixins and how do you implement them in JavaScript?",
              "answer": "Mixins allow combining behaviors from multiple sources (since JS has single inheritance). Implementation: use Object.assign(TargetClass.prototype, mixin1, mixin2) to copy methods. Or use a mixin factory: const Mixin = (superclass) => class extends superclass { ... }."
            },
            {
              "question": "What is the difference between hasOwnProperty() and the 'in' operator?",
              "answer": "hasOwnProperty() checks only the object's OWN properties (not inherited). The 'in' operator checks both own AND inherited properties (walks the prototype chain). For safe checking, use Object.hasOwn(obj, prop) (ES2022) to avoid issues when hasOwnProperty is overridden."
            }
          ],
          "category": "Core Language"
        },
        {
          "id": "scope-hoisting",
          "title": "Scope & Hoisting",
          "description": "Master JavaScript scoping rules — var vs let vs const, function/block scope, temporal dead zone, and hoisting behavior.",
          "explanation": "Scope determines where variables are accessible. JavaScript has three types of scope:\n\n1. Global Scope — accessible everywhere\n2. Function Scope — created by function declarations/expressions\n3. Block Scope — created by { } blocks (only for let/const)\n\nvar vs let vs const:\n- var: function-scoped, hoisted (initialized as undefined), can be re-declared\n- let: block-scoped, hoisted but NOT initialized (Temporal Dead Zone), no re-declaration\n- const: block-scoped, hoisted but NOT initialized (TDZ), no re-assignment, no re-declaration\n- const with objects/arrays: the binding is immutable, but the contents can be mutated\n\nHoisting:\n- JavaScript moves declarations to the top of their scope during compilation\n- Function declarations: fully hoisted (both name and body available)\n- var: hoisted but initialized as undefined\n- let/const: hoisted but NOT initialized → accessing before declaration throws ReferenceError (TDZ)\n- Class declarations: hoisted but NOT initialized (TDZ, like let)\n\nTemporal Dead Zone (TDZ):\n- The period between entering a scope and the let/const declaration being reached\n- Accessing a variable in its TDZ throws ReferenceError\n- TDZ exists to catch bugs — using variables before they're initialized\n\nScope chain:\n- Inner scopes have access to outer scope variables\n- Variable lookup goes from current scope → parent scope → ... → global scope\n- This is called lexical scoping (determined by code structure, not runtime)",
          "code": "// var vs let vs const\nfunction demo() {\n  console.log(a); // undefined (var is hoisted)\n  // console.log(b); // ReferenceError (TDZ)\n  // console.log(c); // ReferenceError (TDZ)\n  \n  var a = 1;\n  let b = 2;\n  const c = 3;\n}\n\n// Block scope\nif (true) {\n  var x = 'var';   // escapes block! (function-scoped)\n  let y = 'let';   // block-scoped\n  const z = 'const'; // block-scoped\n}\nconsole.log(x); // 'var'\n// console.log(y); // ReferenceError\n// console.log(z); // ReferenceError\n\n// Function hoisting\nsayHello(); // Works! Function declarations are fully hoisted\nfunction sayHello() { console.log('Hello'); }\n\n// Function expression - NOT fully hoisted\n// greet(); // TypeError: greet is not a function\nvar greet = function() { console.log('Hi'); };\n\n// const mutation\nconst obj = { a: 1 };\nobj.a = 2;        // OK! Mutating contents\nobj.b = 3;        // OK! Adding properties\n// obj = {};      // TypeError! Cannot reassign const",
          "example": "// Temporal Dead Zone\nlet x = 'outer';\nfunction inner() {\n  // console.log(x); // ReferenceError! x is in TDZ\n  // Even though outer 'x' exists, the local 'let x' below\n  // creates a TDZ from start of block to the declaration\n  let x = 'inner';\n  console.log(x); // 'inner'\n}\n\n// Practical scope example\nfunction createButtons() {\n  const buttons = [];\n  // With var — classic bug\n  for (var i = 0; i < 3; i++) {\n    buttons.push(() => console.log('var:', i)); // All print 3!\n  }\n  // With let — works correctly\n  for (let j = 0; j < 3; j++) {\n    buttons.push(() => console.log('let:', j)); // 0, 1, 2\n  }\n  return buttons;\n}\n\n// IIFE for scope isolation (pre-ES6 pattern)\nvar counter = (function() {\n  var count = 0;\n  return {\n    increment: function() { return ++count; },\n    getCount: function() { return count; }\n  };\n})();",
          "useCase": "Variable declaration best practices, avoiding bugs with var, understanding closure behavior, module patterns, interview questions about hoisting and TDZ",
          "exercises": [
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(a);\nvar a = 5;\nconsole.log(a);",
              "answer": "undefined, then 5 — var declaration is hoisted (value becomes undefined), assignment stays in place"
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(typeof x);\nlet x = 10;",
              "answer": "ReferenceError — let is hoisted but not initialized. 'x' is in the Temporal Dead Zone. typeof does NOT save you from TDZ with let/const."
            },
            {
              "type": "output",
              "question": "What is the output?\nvar x = 1;\nfunction foo() {\n  console.log(x);\n  var x = 2;\n}\nfoo();",
              "answer": "undefined — local var x is hoisted inside foo(), shadowing the global x. At the console.log, it's declared but not yet assigned."
            },
            {
              "type": "output",
              "question": "What is the output?\nfoo();\nbar();\nfunction foo() { console.log('foo'); }\nvar bar = function() { console.log('bar'); };",
              "answer": "foo prints, then TypeError: bar is not a function — Function declarations are fully hoisted. var bar is hoisted as undefined, so bar() fails."
            },
            {
              "type": "output",
              "question": "What is the output?\nconst arr = [1, 2, 3];\narr.push(4);\nconsole.log(arr);",
              "answer": "[1, 2, 3, 4] — const prevents re-assignment of the binding, not mutation of the value. Arrays/objects can still be modified."
            },
            {
              "type": "output",
              "question": "What is the output?\nfor (var i = 0; i < 3; i++) {}\nconsole.log(i);\nfor (let j = 0; j < 3; j++) {}\ntry { console.log(j); } catch(e) { console.log(e.message); }",
              "answer": "3, then 'j is not defined' — var i leaks out of the loop. let j is block-scoped to the loop."
            },
            {
              "type": "output",
              "question": "What is the output?\nvar a = 1;\nvar a = 2;\nconsole.log(a);\nlet b = 1;\n// let b = 2; // Would throw SyntaxError",
              "answer": "2 — var allows re-declaration in the same scope. let does NOT allow re-declaration."
            },
            {
              "type": "output",
              "question": "What is the output?\n(function() {\n  var a = b = 5;\n})();\nconsole.log(typeof a);\nconsole.log(b);",
              "answer": "undefined, then 5 — 'var a = b = 5' means b=5 (no var, becomes global!), a=5 (var, function-scoped). Outside: a is gone, b leaked to global."
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction test() {\n  let x = 1;\n  if (true) {\n    let x = 2;\n    console.log(x);\n  }\n  console.log(x);\n}test();",
              "answer": "2, then 1 — let creates separate bindings in each block. Inner x=2 doesn't affect outer x=1."
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(foo);\nconsole.log(bar);\nfunction foo() { return 1; }\nvar bar = function() { return 2; };",
              "answer": "[Function: foo], undefined — Function declaration is fully hoisted. var bar is hoisted but only as undefined."
            }
          ],
          "programExercises": [
            {
              "program": "console.log(x);\nvar x = 10;\nconsole.log(x);",
              "expectedOutput": "undefined\n10",
              "explanation": "var hoisting: declaration moves up, assignment stays. First log sees undefined, second sees 10."
            },
            {
              "program": "let a = 'global';\nfunction outer() {\n  let a = 'outer';\n  function inner() {\n    let a = 'inner';\n    console.log(a);\n  }\n  inner();\n  console.log(a);\n}\nouter();\nconsole.log(a);",
              "expectedOutput": "inner\nouter\nglobal",
              "explanation": "Each function/block has its own scope. inner sees 'inner', outer sees 'outer', global sees 'global'."
            },
            {
              "program": "function hoistTest() {\n  a = 1;\n  var b = 2;\n}\nhoistTest();\nconsole.log(a);\ntry { console.log(b); } catch(e) { console.log('b not defined'); }",
              "expectedOutput": "1\nb not defined",
              "explanation": "a=1 without var/let/const creates a global variable. b is function-scoped, not accessible outside."
            },
            {
              "program": "const funcs = [];\nfor (let i = 0; i < 3; i++) {\n  funcs.push(() => i);\n}\nconsole.log(funcs.map(f => f()).join(', '));",
              "expectedOutput": "0, 1, 2",
              "explanation": "let creates a new binding per loop iteration. Each closure captures its own i."
            },
            {
              "program": "const funcs = [];\nfor (var i = 0; i < 3; i++) {\n  funcs.push(() => i);\n}\nconsole.log(funcs.map(f => f()).join(', '));",
              "expectedOutput": "3, 3, 3",
              "explanation": "var is function-scoped. All closures share the same i, which is 3 after the loop ends."
            },
            {
              "program": "function foo() {\n  if (true) {\n    var a = 1;\n    let b = 2;\n    const c = 3;\n  }\n  console.log(a);\n  try { console.log(b); } catch(e) { console.log('b error'); }\n}\nfoo();",
              "expectedOutput": "1\nb error",
              "explanation": "var escapes the if-block (function-scoped). let is block-scoped — not accessible outside the if."
            },
            {
              "program": "const obj = Object.freeze({ a: 1, b: { c: 2 } });\ntry { obj.a = 10; } catch(e) {}\nconsole.log(obj.a);\nobj.b.c = 20;\nconsole.log(obj.b.c);",
              "expectedOutput": "1\n20",
              "explanation": "Object.freeze is shallow — top-level props are frozen (a stays 1), but nested objects can still be mutated (b.c changed to 20)."
            },
            {
              "program": "foo();\nfunction foo() { console.log(1); }\nfunction foo() { console.log(2); }\nfunction foo() { console.log(3); }",
              "expectedOutput": "3",
              "explanation": "All three function declarations are hoisted. The last one wins — foo is the third version."
            },
            {
              "program": "var x = 1;\nfunction test() {\n  console.log(x);\n  if (false) {\n    var x = 2;\n  }\n}\ntest();",
              "expectedOutput": "undefined",
              "explanation": "Even though the if(false) block never runs, var x inside it is still hoisted to the function scope, shadowing the global x."
            },
            {
              "program": "const funcs = [];\n{\n  let i = 0;\n  while (i < 3) {\n    const j = i;\n    funcs.push(() => j);\n    i++;\n  }\n}\nconsole.log(funcs.map(f => f()).join(', '));",
              "expectedOutput": "0, 1, 2",
              "explanation": "const j captures the current value of i each iteration. Each closure gets its own j."
            }
          ],
          "interviewQuestions": [
            {
              "question": "What is the difference between var, let, and const?",
              "answer": "var: function-scoped, hoisted as undefined, allows re-declaration. let: block-scoped, hoisted but in TDZ, no re-declaration. const: like let but cannot be re-assigned (the binding is immutable, but object contents can be mutated)."
            },
            {
              "question": "What is hoisting in JavaScript?",
              "answer": "Hoisting is JavaScript's behavior of processing declarations before execution. Function declarations are fully hoisted (name + body). var declarations are hoisted but initialized as undefined. let/const are hoisted but placed in the Temporal Dead Zone — accessing them before their declaration throws ReferenceError."
            },
            {
              "question": "What is the Temporal Dead Zone (TDZ)?",
              "answer": "TDZ is the period from entering a scope until the let/const declaration is reached. The variable exists (is hoisted) but cannot be accessed. Any access (read or write) during TDZ throws ReferenceError. TDZ prevents using variables before they're properly initialized."
            },
            {
              "question": "Why does typeof work for undeclared variables but throws for TDZ variables?",
              "answer": "For undeclared variables, typeof safely returns 'undefined'. But for let/const in TDZ, typeof throws ReferenceError because the variable IS declared (hoisted) but not initialized. The TDZ is a stronger check than 'not declared'."
            },
            {
              "question": "Explain the scope chain in JavaScript.",
              "answer": "When a variable is referenced, JS looks in the current scope first. If not found, it goes to the outer (parent) scope, then that scope's parent, etc., up to the global scope. This chain is determined at compile time by the lexical structure of the code, not at runtime."
            },
            {
              "question": "What is the difference between function scope and block scope?",
              "answer": "Function scope (var): the variable is accessible throughout the entire function, regardless of blocks (if/for/while). Block scope (let/const): the variable is only accessible within the enclosing { } block. Block scope prevents variable leaking."
            },
            {
              "question": "Why does 'var a = b = 5' in a function make b global?",
              "answer": "This is parsed as: b = 5 (no var/let/const → becomes global in non-strict mode), then var a = b (a is function-scoped). In strict mode, b = 5 would throw ReferenceError because implicit globals are not allowed."
            },
            {
              "question": "What happens when you re-declare a variable with var in the same scope?",
              "answer": "var allows re-declaration in the same scope — the second declaration is silently ignored (the variable already exists). let and const throw SyntaxError on re-declaration. This is one reason let/const are preferred — they catch accidental re-declarations."
            },
            {
              "question": "How does hoisting work with function expressions vs function declarations?",
              "answer": "Function declarations are fully hoisted — you can call them before the declaration. Function expressions (var f = function(){}) only hoist the var declaration (as undefined), not the function assignment. So calling f() before the assignment throws TypeError: f is not a function."
            },
            {
              "question": "Can you explain variable shadowing?",
              "answer": "Shadowing occurs when a variable in an inner scope has the same name as one in an outer scope. The inner variable 'shadows' the outer one — any reference in the inner scope uses the local variable. The outer variable is not affected. let can shadow var, but var cannot shadow let in the same function scope."
            }
          ],
          "category": "Core Language"
        },
        {
          "id": "type-coercion",
          "title": "Type Coercion & Equality",
          "description": "Understand JavaScript's type conversion rules — implicit vs explicit coercion, == vs ===, truthy/falsy values, and common interview gotchas.",
          "explanation": "JavaScript is dynamically typed and performs automatic type conversion (coercion) in many situations.\n\nTwo types of coercion:\n1. Explicit (intentional): Number('5'), String(42), Boolean(0), parseInt('10px')\n2. Implicit (automatic): '5' + 3, '5' - 3, if(value), ==\n\n== (loose equality) vs === (strict equality):\n- === checks value AND type without any conversion\n- == performs type coercion before comparing:\n  - null == undefined → true (special case)\n  - Number vs String → String is converted to Number\n  - Boolean involved → Boolean is converted to Number first\n  - Object vs primitive → Object is converted via ToPrimitive (valueOf/toString)\n\nTruthy vs Falsy:\n- Falsy values (only 8): false, 0, -0, 0n (BigInt), '', null, undefined, NaN\n- Everything else is truthy, including: '0', 'false', [], {}, function(){}\n\nThe + operator:\n- If either operand is a string → string concatenation\n- Otherwise → numeric addition\n- Objects are converted via ToPrimitive: valueOf() first, then toString()\n- Unary +value converts to Number\n\nCommon gotchas:\n- [] + [] → '' (arrays become empty strings)\n- [] + {} → '[object Object]'\n- {} + [] → 0 (block statement + unary plus)\n- null + 1 → 1 (null becomes 0)\n- undefined + 1 → NaN (undefined becomes NaN)\n- typeof null → 'object' (historical bug)\n- NaN !== NaN (use Number.isNaN())",
          "code": "// Explicit coercion\nconsole.log(Number('42'));      // 42\nconsole.log(Number(''));        // 0\nconsole.log(Number(true));      // 1\nconsole.log(Number(null));      // 0\nconsole.log(Number(undefined)); // NaN\nconsole.log(Number('abc'));     // NaN\n\nconsole.log(String(42));        // '42'\nconsole.log(String(null));      // 'null'\nconsole.log(String(undefined)); // 'undefined'\n\nconsole.log(Boolean(0));        // false\nconsole.log(Boolean(''));       // false\nconsole.log(Boolean('0'));      // true (non-empty string!)\nconsole.log(Boolean([]));       // true (object!)\nconsole.log(Boolean({}));       // true\n\n// Implicit coercion\nconsole.log('5' + 3);     // '53' (string concat)\nconsole.log('5' - 3);     // 2 (numeric subtraction)\nconsole.log(true + true); // 2 (booleans to numbers)\nconsole.log('5' == 5);    // true (string coerced to number)\nconsole.log(null == undefined); // true (special rule)\nconsole.log(null === undefined); // false (different types)",
          "example": "// Common interview gotchas\nconsole.log([] == false);     // true: [] → '' → 0, false → 0\nconsole.log([] == ![]);       // true: ![] is false, [] → 0, false → 0\nconsole.log('' == false);     // true: '' → 0, false → 0\nconsole.log(' \\t\\n' == 0);    // true: whitespace string → 0\n\n// typeof checks\nconsole.log(typeof 42);        // 'number'\nconsole.log(typeof 'str');     // 'string'\nconsole.log(typeof true);      // 'boolean'\nconsole.log(typeof undefined); // 'undefined'\nconsole.log(typeof null);      // 'object' (bug!)\nconsole.log(typeof []);        // 'object'\nconsole.log(typeof {});        // 'object'\nconsole.log(typeof function(){}); // 'function'\n\n// Safe null check\nconsole.log(null == undefined);  // true\nconsole.log(null == 0);          // false (null only == undefined)\nconsole.log(null == '');         // false\n// Use == null to check for null OR undefined:\nfunction isNullish(x) { return x == null; }",
          "useCase": "Debugging type-related bugs, writing defensive code, understanding comparison operators, interview preparation, safe equality checks",
          "exercises": [
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(1 + '2' + 3);",
              "answer": "'123' — 1+'2' produces '12' (string concat), then '12'+3 produces '123'"
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(+'5' + 3);",
              "answer": "8 — Unary + converts '5' to number 5, then 5+3=8"
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log([] + []);\nconsole.log([] + {});\nconsole.log({} + []);",
              "answer": "'' (empty string), '[object Object]', '[object Object]' — Arrays/objects convert to strings for + operator. Note: {} + [] in a REPL may output 0 if {} is parsed as a block."
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(null == undefined);\nconsole.log(null === undefined);\nconsole.log(null == 0);\nconsole.log(null == false);",
              "answer": "true, false, false, false — null only loosely equals undefined (special rule). null does NOT coerce to 0 with =="
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(NaN === NaN);\nconsole.log(NaN == NaN);\nconsole.log(Number.isNaN(NaN));\nconsole.log(Number.isNaN('abc'));",
              "answer": "false, false, true, false — NaN is never equal to itself. Number.isNaN checks if value IS NaN (not just 'not a number')"
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(true + true + true);\nconsole.log(true + 'false');",
              "answer": "3, 'truefalse' — true→1 for addition. But true+'false' is string concatenation"
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(0 == false);\nconsole.log('' == false);\nconsole.log('0' == false);\nconsole.log([] == false);",
              "answer": "true, true, true, true — All coerce to 0 on both sides"
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(!!'');\nconsole.log(!!'0');\nconsole.log(!!0);\nconsole.log(!!null);\nconsole.log(!!undefined);\nconsole.log(!!NaN);",
              "answer": "false, true, false, false, false, false — '' is falsy, '0' is truthy (non-empty string), rest are falsy values"
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(3 > 2 > 1);",
              "answer": "false — Parsed left to right: (3>2)>1 → true>1 → 1>1 → false"
            },
            {
              "type": "output",
              "question": "What is the output?\nconsole.log(typeof typeof 42);",
              "answer": "'string' — typeof 42 is 'number' (a string). typeof 'number' is 'string'"
            }
          ],
          "programExercises": [
            {
              "program": "console.log('5' - 3);\nconsole.log('5' + 3);\nconsole.log('5' - - '3');",
              "expectedOutput": "2\n53\n8",
              "explanation": "Minus forces number conversion: 5-3=2. Plus with string: concatenation '53'. Double minus: 5-(-3)=8"
            },
            {
              "program": "console.log(1 < 2 < 3);\nconsole.log(3 > 2 > 1);",
              "expectedOutput": "true\nfalse",
              "explanation": "1<2→true(1), 1<3→true. 3>2→true(1), 1>1→false. Left-to-right evaluation with boolean coercion."
            },
            {
              "program": "const a = [1, 2, 3];\nconst b = [1, 2, 3];\nconsole.log(a == b);\nconsole.log(a === b);\nconsole.log(JSON.stringify(a) === JSON.stringify(b));",
              "expectedOutput": "false\nfalse\ntrue",
              "explanation": "Arrays are objects — == and === compare references, not values. Stringify for value comparison."
            },
            {
              "program": "console.log(+'');\nconsole.log(+' ');\nconsole.log(+true);\nconsole.log(+false);\nconsole.log(+null);\nconsole.log(+undefined);\nconsole.log(+[]);\nconsole.log(+{});",
              "expectedOutput": "0\n0\n1\n0\n0\nNaN\n0\nNaN",
              "explanation": "Unary +: empty/space→0, bool→0/1, null→0, undefined→NaN, []→''→0, {}→NaN"
            },
            {
              "program": "console.log(0.1 + 0.2 === 0.3);\nconsole.log((0.1 + 0.2).toFixed(1) === '0.3');\nconsole.log(Math.abs(0.1 + 0.2 - 0.3) < Number.EPSILON);",
              "expectedOutput": "false\ntrue\ntrue",
              "explanation": "IEEE 754 floating point: 0.1+0.2=0.30000000000000004. Use toFixed or epsilon comparison."
            },
            {
              "program": "const values = [0, '', null, undefined, NaN, false, '0', [], {}, 'false'];\nconsole.log('Falsy:', values.filter(v => !v).length);\nconsole.log('Truthy:', values.filter(v => !!v).length);",
              "expectedOutput": "Falsy: 6\nTruthy: 4",
              "explanation": "Falsy: 0, '', null, undefined, NaN, false (6). Truthy: '0', [], {}, 'false' (4)"
            },
            {
              "program": "console.log(null + 1);\nconsole.log(undefined + 1);\nconsole.log('' + 1);\nconsole.log(null + '');",
              "expectedOutput": "1\nNaN\n1\nnull",
              "explanation": "null→0 for math. undefined→NaN. ''+1→'1' (string concat). null+''→'null' (string concat)"
            },
            {
              "program": "console.log(typeof null);\nconsole.log(typeof undefined);\nconsole.log(typeof NaN);\nconsole.log(typeof [1,2]);\nconsole.log(typeof function(){});",
              "expectedOutput": "object\nundefined\nnumber\nobject\nfunction",
              "explanation": "typeof null is 'object' (bug). NaN is type 'number'. Arrays are 'object'. Functions get special 'function' type."
            },
            {
              "program": "console.log([] == ![]);\nconsole.log([] == false);\nconsole.log(![] == false);",
              "expectedOutput": "true\ntrue\nfalse",
              "explanation": "![]=false. []==false: []→''→0, false→0, 0==0. ![]==false: false==false→true. Wait — ![] is false, and false==false is true, so output is true."
            },
            {
              "program": "console.log(Object.is(NaN, NaN));\nconsole.log(Object.is(0, -0));\nconsole.log(Object.is(0, +0));\nconsole.log(0 === -0);",
              "expectedOutput": "true\nfalse\ntrue\ntrue",
              "explanation": "Object.is is like === but handles two edge cases differently: NaN===NaN is true, 0===-0 is false."
            }
          ],
          "interviewQuestions": [
            {
              "question": "What is the difference between == and ===?",
              "answer": "=== (strict equality) checks both value and type without conversion. == (loose equality) performs type coercion before comparing. Use === by default unless you specifically need coercion (like `x == null` to check both null and undefined)."
            },
            {
              "question": "What are all the falsy values in JavaScript?",
              "answer": "There are 8 falsy values: false, 0, -0, 0n (BigInt zero), '' (empty string), null, undefined, NaN. Everything else is truthy, including '0', 'false', [], {}, and functions."
            },
            {
              "question": "Why is typeof null === 'object'?",
              "answer": "This is a historical bug from the first version of JavaScript. In the original implementation, values were stored with a type tag, and null's tag was 0 (same as objects). This can't be fixed without breaking existing code. Use `value === null` for null checks."
            },
            {
              "question": "How does the + operator decide between concatenation and addition?",
              "answer": "If either operand is a string, + performs string concatenation. Otherwise, it converts both to numbers and adds. Objects are converted via ToPrimitive (valueOf then toString). This is why '5'+3='53' but '5'-3=2 (minus always does numeric conversion)."
            },
            {
              "question": "What is the difference between null and undefined?",
              "answer": "undefined means a variable was declared but not assigned, or a missing function parameter/return value. null is an intentional 'no value' assignment. typeof undefined is 'undefined', typeof null is 'object'. null == undefined is true, null === undefined is false."
            },
            {
              "question": "Why is NaN !== NaN and how do you check for NaN?",
              "answer": "NaN is 'Not a Number' but its type is 'number'. By IEEE 754 spec, NaN is not equal to anything, including itself. Check with: Number.isNaN(value) (preferred) or Object.is(value, NaN). Avoid isNaN() which coerces its argument first."
            },
            {
              "question": "What does Object.is() do differently from ===?",
              "answer": "Object.is is almost identical to === with two exceptions: Object.is(NaN, NaN) returns true (=== returns false), and Object.is(0, -0) returns false (=== returns true). It provides the 'same value' comparison."
            },
            {
              "question": "Explain implicit type coercion with examples.",
              "answer": "JS automatically converts types: '5'-3→2 (string to number), if('hello')→true (string to boolean), [1]+[2]→'12' (arrays to strings). The rules depend on the operator: + prefers strings, -, *, / always convert to numbers. == coerces types to match."
            },
            {
              "question": "What is the ToPrimitive abstract operation?",
              "answer": "When an object needs to be converted to a primitive, JS calls ToPrimitive. It tries valueOf() first (for numeric context) or toString() first (for string context). If neither returns a primitive, TypeError is thrown. You can customize it with Symbol.toPrimitive."
            },
            {
              "question": "How would you safely check if a value is a valid number?",
              "answer": "Use: typeof value === 'number' && !Number.isNaN(value) && Number.isFinite(value). Or: Number.isFinite(value) alone (rejects NaN, Infinity, strings). Avoid: isNaN() (coerces strings), typeof NaN === 'number' (true but misleading)."
            }
          ],
          "category": "Core Language"
        },
        {
          "id": "error-handling",
          "title": "Error Handling",
          "description": "Master JavaScript error handling — try/catch/finally, custom errors, error types, async error patterns, and best practices.",
          "explanation": "JavaScript has a built-in error handling mechanism using try/catch/finally. Proper error handling prevents crashes and provides meaningful feedback.\n\nBuilt-in error types:\n- Error: base error class\n- TypeError: wrong type operation (e.g., calling a non-function)\n- ReferenceError: accessing undeclared variable\n- SyntaxError: invalid code syntax\n- RangeError: value out of range (e.g., invalid array length)\n- URIError: malformed URI\n- EvalError: related to eval() (rarely used)\n- AggregateError: wraps multiple errors (Promise.any())\n\ntry/catch/finally rules:\n- catch receives the error object\n- finally ALWAYS executes (even after return/throw)\n- catch is optional if finally is present\n- Errors not caught propagate up the call stack\n- Only runtime errors are caught (not syntax errors in the same script)\n\nAsync error handling:\n- Promise rejections: .catch() or try/catch with async/await\n- Unhandled rejections: 'unhandledrejection' event (browser) or 'unhandledRejection' (Node)\n- async functions: uncaught errors become rejected Promises\n\nBest practices:\n- Always catch specific error types when possible\n- Don't swallow errors silently (empty catch blocks)\n- Use custom error classes for domain-specific errors\n- Log/report errors for debugging\n- Provide user-friendly error messages\n- Use Error.cause (ES2022) for error chaining",
          "code": "// Basic try/catch/finally\ntry {\n  const result = riskyOperation();\n  console.log(result);\n} catch (error) {\n  console.error('Something went wrong:', error.message);\n} finally {\n  console.log('Always runs — cleanup here');\n}\n\n// Custom error class\nclass ValidationError extends Error {\n  constructor(field, message) {\n    super(message);\n    this.name = 'ValidationError';\n    this.field = field;\n  }\n}\n\nfunction validateAge(age) {\n  if (typeof age !== 'number') {\n    throw new TypeError('Age must be a number');\n  }\n  if (age < 0 || age > 150) {\n    throw new ValidationError('age', `Invalid age: ${age}`);\n  }\n  return true;\n}\n\n// Catching specific error types\ntry {\n  validateAge('twenty');\n} catch (e) {\n  if (e instanceof ValidationError) {\n    console.log(`Field ${e.field}: ${e.message}`);\n  } else if (e instanceof TypeError) {\n    console.log(`Type error: ${e.message}`);\n  } else {\n    throw e; // Re-throw unknown errors\n  }\n}",
          "example": "// Async error handling\nasync function fetchUser(id) {\n  try {\n    const response = await fetch(`/api/users/${id}`);\n    if (!response.ok) {\n      throw new Error(`HTTP ${response.status}: ${response.statusText}`);\n    }\n    return await response.json();\n  } catch (error) {\n    if (error instanceof TypeError) {\n      // Network error\n      throw new Error('Network error', { cause: error });\n    }\n    throw error;\n  }\n}\n\n// Error boundary pattern\nasync function safeFetch(url) {\n  try {\n    const res = await fetch(url);\n    return { data: await res.json(), error: null };\n  } catch (error) {\n    return { data: null, error: error.message };\n  }\n}\n\n// Global unhandled rejection handler\nwindow.addEventListener('unhandledrejection', (event) => {\n  console.error('Unhandled rejection:', event.reason);\n  event.preventDefault();\n});",
          "useCase": "API error handling, form validation, graceful degradation, error logging/monitoring, building resilient applications",
          "exercises": [
            {
              "type": "output",
              "question": "What is the output?\ntry {\n  console.log('try');\n  throw new Error('oops');\n  console.log('after throw');\n} catch (e) {\n  console.log('catch:', e.message);\n} finally {\n  console.log('finally');\n}",
              "answer": "try, catch: oops, finally — 'after throw' never runs. throw jumps to catch. finally always runs."
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction foo() {\n  try {\n    return 'try';\n  } finally {\n    return 'finally';\n  }\n}\nconsole.log(foo());",
              "answer": "finally — finally's return overrides try's return. This is a known gotcha."
            },
            {
              "type": "output",
              "question": "What is the output?\ntry {\n  try {\n    throw new Error('inner');\n  } finally {\n    console.log('inner finally');\n  }\n} catch (e) {\n  console.log('outer catch:', e.message);\n}",
              "answer": "inner finally, outer catch: inner — Inner try has no catch, error propagates. Inner finally runs first, then outer catch."
            },
            {
              "type": "output",
              "question": "What is the output?\ntry {\n  null.property;\n} catch (e) {\n  console.log(e.constructor.name);\n}",
              "answer": "TypeError — Accessing a property of null throws TypeError"
            },
            {
              "type": "output",
              "question": "What is the output?\nPromise.reject('error')\n  .catch(e => { console.log('caught:', e); return 'recovered'; })\n  .then(v => console.log('then:', v));",
              "answer": "caught: error, then: recovered — catch handles the rejection and returns a value, so .then receives it"
            },
            {
              "type": "output",
              "question": "What is the output?\nasync function test() {\n  try {\n    await Promise.reject('fail');\n  } catch (e) {\n    console.log('caught:', e);\n  }\n  console.log('continues');\n}\ntest();",
              "answer": "caught: fail, continues — try/catch with await catches the rejection, execution continues normally"
            },
            {
              "type": "output",
              "question": "What is the output?\nconst err = new Error('test');\nconsole.log(err.message);\nconsole.log(err.name);\nconsole.log(typeof err.stack);",
              "answer": "test, Error, string — Error objects have message, name, and stack (stack trace) properties"
            },
            {
              "type": "output",
              "question": "What is the output?\ntry {\n  undeclaredVariable;\n} catch (e) {\n  console.log(e instanceof ReferenceError);\n  console.log(e.message.includes('not defined'));\n}",
              "answer": "true, true — Accessing an undeclared variable throws ReferenceError with 'not defined' message"
            },
            {
              "type": "output",
              "question": "What is the output?\nfunction test() {\n  let result = 0;\n  try {\n    result = 1;\n    throw new Error();\n  } catch (e) {\n    result = 2;\n    return result;\n  } finally {\n    result = 3;\n  }\n}\nconsole.log(test());",
              "answer": "2 — catch's return value (2) is captured before finally runs. finally changes result to 3 but doesn't override the return value (no return in finally)."
            },
            {
              "type": "output",
              "question": "What is the output?\nPromise.resolve()\n  .then(() => { throw new Error('oops'); })\n  .then(() => console.log('skip'))\n  .catch(e => console.log(e.message))\n  .then(() => console.log('after catch'));",
              "answer": "oops, after catch — Error skips the next .then(), caught by .catch(), chain continues after catch"
            }
          ],
          "programExercises": [
            {
              "program": "class AppError extends Error {\n  constructor(message, statusCode) {\n    super(message);\n    this.name = 'AppError';\n    this.statusCode = statusCode;\n  }\n}\ntry {\n  throw new AppError('Not Found', 404);\n} catch (e) {\n  console.log(`${e.name}: ${e.message} (${e.statusCode})`);\n}",
              "expectedOutput": "AppError: Not Found (404)",
              "explanation": "Custom error class with additional properties for structured error handling"
            },
            {
              "program": "function divide(a, b) {\n  if (b === 0) throw new RangeError('Cannot divide by zero');\n  return a / b;\n}\n\n[10, 0, 5].forEach(b => {\n  try {\n    console.log(`10/${b} = ${divide(10, b)}`);\n  } catch (e) {\n    console.log(e.message);\n  }\n});",
              "expectedOutput": "10/10 = 1\nCannot divide by zero\n10/5 = 2",
              "explanation": "Error handling in a loop — each iteration handles errors independently"
            },
            {
              "program": "async function fetchData(shouldFail) {\n  if (shouldFail) throw new Error('Network error');\n  return { data: 'success' };\n}\n\n(async () => {\n  const results = await Promise.allSettled([\n    fetchData(false),\n    fetchData(true),\n    fetchData(false)\n  ]);\n  results.forEach((r, i) => {\n    console.log(`${i}: ${r.status}${r.reason ? ' - ' + r.reason.message : ''}`);\n  });\n})();",
              "expectedOutput": "0: fulfilled\n1: rejected - Network error\n2: fulfilled",
              "explanation": "Promise.allSettled never rejects — it reports the status of each promise individually"
            },
            {
              "program": "function retry(fn, attempts = 3) {\n  for (let i = 1; i <= attempts; i++) {\n    try {\n      return fn(i);\n    } catch (e) {\n      if (i === attempts) throw e;\n      console.log(`Attempt ${i} failed`);\n    }\n  }\n}\ntry {\n  const result = retry((attempt) => {\n    if (attempt < 3) throw new Error('fail');\n    return 'success';\n  });\n  console.log(result);\n} catch (e) {\n  console.log('All failed');\n}",
              "expectedOutput": "Attempt 1 failed\nAttempt 2 failed\nsuccess",
              "explanation": "Retry pattern — tries up to 3 times. First 2 fail, third succeeds."
            },
            {
              "program": "function parseJSON(str) {\n  try {\n    return { value: JSON.parse(str), error: null };\n  } catch (e) {\n    return { value: null, error: e.message };\n  }\n}\nconsole.log(parseJSON('{\"a\":1}').value);\nconsole.log(parseJSON('invalid').error);",
              "expectedOutput": "{ a: 1 }\nUnexpected token 'i', \"invalid\" is not valid JSON",
              "explanation": "Safe JSON parsing — returns result object instead of throwing. Inspired by Go's error pattern."
            },
            {
              "program": "class Queue {\n  #items = [];\n  enqueue(item) { this.#items.push(item); }\n  dequeue() {\n    if (this.#items.length === 0) throw new Error('Queue is empty');\n    return this.#items.shift();\n  }\n}\nconst q = new Queue();\nq.enqueue('a'); q.enqueue('b');\nconsole.log(q.dequeue());\nconsole.log(q.dequeue());\ntry { q.dequeue(); } catch (e) { console.log(e.message); }",
              "expectedOutput": "a\nb\nQueue is empty",
              "explanation": "Data structure with error handling — dequeue from empty queue throws descriptive error"
            },
            {
              "program": "const errors = [];\nfor (const val of ['5', 'abc', '10', null]) {\n  try {\n    if (val === null) throw new TypeError('Value cannot be null');\n    const num = Number(val);\n    if (isNaN(num)) throw new RangeError(`'${val}' is not a number`);\n    console.log(num);\n  } catch (e) {\n    errors.push(e.message);\n  }\n}\nconsole.log('Errors:', errors.length);",
              "expectedOutput": "5\n10\nErrors: 2",
              "explanation": "Collecting errors while continuing processing. 'abc' and null cause errors, '5' and '10' succeed."
            },
            {
              "program": "async function pipeline(...fns) {\n  let result = null;\n  for (const fn of fns) {\n    result = await fn(result);\n  }\n  return result;\n}\n\npipeline(\n  () => 5,\n  (x) => x * 2,\n  (x) => { if (x > 8) throw new Error('too big'); return x; },\n  (x) => x + 1\n).then(console.log).catch(e => console.log('Pipeline error:', e.message));",
              "expectedOutput": "Pipeline error: too big",
              "explanation": "Async pipeline with error propagation — step 3 rejects because 10 > 8"
            },
            {
              "program": "function withTimeout(promise, ms) {\n  const timeout = new Promise((_, reject) =>\n    setTimeout(() => reject(new Error('Timeout')), ms)\n  );\n  return Promise.race([promise, timeout]);\n}\n\nconst slow = new Promise(r => setTimeout(() => r('done'), 200));\nwithTimeout(slow, 100).catch(e => console.log(e.message));\nwithTimeout(slow, 300).then(v => console.log(v));",
              "expectedOutput": "Timeout\ndone",
              "explanation": "Promise timeout pattern — first call times out (100<200), second succeeds (300>200)"
            },
            {
              "program": "const err = new Error('outer', { cause: new Error('inner') });\nconsole.log(err.message);\nconsole.log(err.cause.message);",
              "expectedOutput": "outer\ninner",
              "explanation": "Error.cause (ES2022) — chains errors for better debugging context"
            }
          ],
          "interviewQuestions": [
            {
              "question": "What is the difference between throw and return in error handling?",
              "answer": "throw creates an error that unwinds the call stack until caught by a try/catch. return simply exits the function with a value. throw is for exceptional situations, return is for normal flow. Some patterns use return { error } instead of throwing for expected failure cases."
            },
            {
              "question": "Can finally override a return value?",
              "answer": "Yes. If finally has a return statement, it overrides the return value from try or catch. This is considered bad practice. However, if finally doesn't have a return, it cannot change the return value — even if it modifies the variable being returned (because the expression is already evaluated)."
            },
            {
              "question": "How do you handle errors in Promise chains vs async/await?",
              "answer": "Promise chains: use .catch() at the end of the chain (catches any error above it). async/await: use try/catch blocks around await calls. Both work, but async/await with try/catch is generally more readable for complex flows."
            },
            {
              "question": "What happens to unhandled Promise rejections?",
              "answer": "In Node.js, unhandled rejections trigger an 'unhandledRejection' event and may terminate the process (Node 15+). In browsers, they trigger 'unhandledrejection' on window. Always add .catch() to promises or use try/catch with async/await."
            },
            {
              "question": "When should you create custom error classes?",
              "answer": "When you need to distinguish between error types (instanceof checks), add extra context (status codes, field names), or create domain-specific errors (ValidationError, AuthError). Custom errors should extend Error and set this.name. Use Error.cause for wrapping lower-level errors."
            },
            {
              "question": "What is error chaining with Error.cause?",
              "answer": "ES2022 introduced the 'cause' option: new Error('message', { cause: originalError }). This links errors together for better debugging — you can see the original error that triggered a higher-level error. Like Java's exception chaining."
            },
            {
              "question": "Why should you avoid empty catch blocks?",
              "answer": "Empty catch blocks silently swallow errors, making bugs invisible. At minimum, log the error. Better: handle specific error types and re-throw unknown ones. If you intentionally ignore an error, add a comment explaining why."
            },
            {
              "question": "What is the difference between Error and exception?",
              "answer": "In JavaScript, Error is a built-in object type with message, name, and stack properties. An exception is the act of throwing — you can throw ANY value (strings, numbers, objects), but it's best practice to throw Error objects because they provide stack traces."
            },
            {
              "question": "How does error handling work with generators?",
              "answer": "Generators have a .throw() method that throws an error inside the generator at the yield point. The generator can catch it with try/catch internally. If uncaught, the error propagates to the caller. This is used by async/await (which uses generators internally)."
            },
            {
              "question": "What is the optional catch binding?",
              "answer": "ES2019 allows omitting the catch parameter when you don't need the error object: try { ... } catch { ... }. This is useful when you only care about whether an operation succeeded, not the specific error."
            }
          ],
          "category": "Core Language"
        },
        {
          "id": "es6-modules",
          "title": "ES6 Modules",
          "description": "Learn JavaScript modules — import/export syntax, named vs default exports, CommonJS vs ESM, dynamic imports, and module patterns.",
          "explanation": "JavaScript modules allow splitting code into separate files with explicit imports/exports.\n\nES Modules (ESM) — the modern standard:\n- import/export syntax\n- Static analysis (imports resolved at compile time)\n- Tree-shakeable (dead code elimination)\n- Always in strict mode\n- Top-level 'this' is undefined (not window)\n\nExport types:\n1. Named exports: export const x = 5; or export { x, y }\n2. Default export: export default function() {} (one per module)\n3. Re-exports: export { x } from './other'\n4. Namespace export: export * from './other'\n\nImport types:\n1. Named: import { x, y } from './mod'\n2. Default: import myName from './mod'\n3. Namespace: import * as mod from './mod'\n4. Side-effect only: import './mod' (runs module, imports nothing)\n5. Dynamic: const mod = await import('./mod') (lazy loading, returns Promise)\n\nCommonJS (CJS) vs ESM:\n- CJS: require()/module.exports — synchronous, dynamic, Node.js original\n- ESM: import/export — async, static, browser + Node standard\n- CJS loads at runtime (can be conditional). ESM is analyzed at compile time.\n- ESM can import CJS, but CJS cannot require() ESM (without dynamic import)\n\nModule patterns:\n- Barrel files: index.js that re-exports from multiple files\n- Lazy loading: dynamic import() for code splitting\n- Circular dependencies: ESM handles them better than CJS (live bindings vs copies)",
          "code": "// Named exports\nexport const PI = 3.14159;\nexport function add(a, b) { return a + b; }\nexport class Calculator {\n  multiply(a, b) { return a * b; }\n}\n\n// Default export\nexport default function greet(name) {\n  return `Hello, ${name}`;\n}\n\n// Importing named exports\nimport { PI, add, Calculator } from './math.js';\n\n// Importing default export\nimport greet from './greet.js';\n\n// Renaming imports\nimport { add as sum } from './math.js';\n\n// Namespace import\nimport * as MathLib from './math.js';\nconsole.log(MathLib.PI); // 3.14159\n\n// Dynamic import (code splitting)\nasync function loadFeature() {\n  const module = await import('./heavy-feature.js');\n  module.init();\n}\n\n// Re-exports (barrel file)\nexport { add, subtract } from './arithmetic.js';\nexport { default as Logger } from './logger.js';",
          "example": "// CommonJS (Node.js traditional)\nconst fs = require('fs');\nmodule.exports = { readFile: fs.readFileSync };\nmodule.exports.helper = function() {};\n\n// ESM equivalent\nimport fs from 'fs';\nexport const readFile = fs.readFileSync;\nexport function helper() {}\n\n// Conditional imports (only possible with dynamic import)\nasync function loadPolyfill() {\n  if (!window.IntersectionObserver) {\n    await import('intersection-observer');\n  }\n}\n\n// Top-level await (ES2022, ESM only)\nconst config = await fetch('/config.json').then(r => r.json());\nexport default config;\n\n// Module pattern (pre-ESM, still useful)\nconst Counter = (() => {\n  let count = 0;\n  return {\n    increment: () => ++count,\n    getCount: () => count\n  };\n})();",
          "useCase": "Code organization, code splitting, lazy loading, dependency management, tree-shaking, bundler optimization, shared utility libraries",
          "exercises": [
            {
              "type": "concept",
              "question": "What is the difference between named and default exports?",
              "answer": "Named exports: multiple per module, imported with exact name (or renamed with 'as'). Default export: one per module, imported with any name. Named: export const x = 5; import { x }. Default: export default 5; import whatever."
            },
            {
              "type": "concept",
              "question": "What happens when you do: import './side-effects.js'?",
              "answer": "The module is loaded and executed but nothing is imported. Used for modules that modify global state, register service workers, add polyfills, or have side effects that should run on import."
            },
            {
              "type": "concept",
              "question": "Can you use import statements inside if blocks?",
              "answer": "No. Static import statements must be at the top level of the module. For conditional loading, use dynamic import(): if (condition) { const mod = await import('./mod.js'); }. Dynamic import() returns a Promise."
            },
            {
              "type": "concept",
              "question": "What is a barrel file?",
              "answer": "An index.js file that re-exports from multiple modules: export { A } from './a'; export { B } from './b'. Consumers import from one place: import { A, B } from './components'. Simplifies imports but can hurt tree-shaking if not careful."
            },
            {
              "type": "concept",
              "question": "What are live bindings in ESM?",
              "answer": "ESM exports are live references — if the exporting module changes a value, importers see the updated value. CJS copies values at require() time. Example: if a.js exports let count=0 and increments it, importers see the new count."
            },
            {
              "type": "concept",
              "question": "How do you handle circular dependencies?",
              "answer": "ESM handles circular deps better than CJS because of live bindings. CJS may give partial objects. Best practice: avoid circular deps by restructuring code (extract shared logic to a third module). Tools like madge can detect cycles."
            },
            {
              "type": "concept",
              "question": "What is tree-shaking?",
              "answer": "Tree-shaking is dead code elimination — bundlers (Webpack, Rollup, esbuild) analyze static imports to remove unused exports. Only works with ESM (static analysis). Doesn't work with CJS (dynamic require). import * can still be tree-shaken if only specific properties are used."
            },
            {
              "type": "concept",
              "question": "What is the 'type: module' field in package.json?",
              "answer": "It tells Node.js to treat .js files as ES modules (import/export). Without it, .js files are treated as CommonJS. Alternatively, use .mjs for ESM and .cjs for CommonJS regardless of this setting."
            },
            {
              "type": "output",
              "question": "What is the output?\n// a.js\nexport let count = 0;\nexport function increment() { count++; }\n\n// b.js\nimport { count, increment } from './a.js';\nconsole.log(count);\nincrement();\nconsole.log(count);",
              "answer": "0, then 1 — ESM live bindings: count is a live reference to a.js's count variable. increment() changes it, and b.js sees the update."
            },
            {
              "type": "concept",
              "question": "What is import.meta?",
              "answer": "import.meta is an object available in ES modules with metadata about the current module. import.meta.url gives the module's URL. In Node.js, used to get __filename equivalent: new URL(import.meta.url).pathname. Also used for Vite's import.meta.env."
            }
          ],
          "programExercises": [
            {
              "program": "// Simulating module pattern (runs in single file)\nconst MathModule = (() => {\n  const PI = 3.14159;\n  function area(r) { return PI * r * r; }\n  function circumference(r) { return 2 * PI * r; }\n  return { area, circumference };\n})();\n\nconsole.log(MathModule.area(5).toFixed(2));\nconsole.log(MathModule.circumference(5).toFixed(2));",
              "expectedOutput": "78.54\n31.42",
              "explanation": "IIFE module pattern — PI is private, only area and circumference are exposed"
            },
            {
              "program": "// Simulating named exports and imports\nconst moduleA = { add: (a, b) => a + b, multiply: (a, b) => a * b };\nconst { add, multiply } = moduleA;\nconsole.log(add(2, 3));\nconsole.log(multiply(4, 5));",
              "expectedOutput": "5\n20",
              "explanation": "Destructuring simulates named imports from a module"
            },
            {
              "program": "// Simulating default + named exports\nconst myModule = {\n  default: function greet(name) { return `Hi ${name}`; },\n  VERSION: '1.0',\n  MAX: 100\n};\nconst greet = myModule.default;\nconst { VERSION, MAX } = myModule;\nconsole.log(greet('World'));\nconsole.log(VERSION, MAX);",
              "expectedOutput": "Hi World\n1.0 100",
              "explanation": "Simulating a module with both default and named exports"
            },
            {
              "program": "// Dynamic import simulation with lazy loading\nconst modules = {\n  math: () => ({ add: (a,b) => a+b }),\n  string: () => ({ upper: (s) => s.toUpperCase() })\n};\n\nasync function loadModule(name) {\n  // Simulates: const mod = await import(`./modules/${name}.js`)\n  return modules[name]();\n}\n\n(async () => {\n  const math = await loadModule('math');\n  console.log(math.add(1, 2));\n  const str = await loadModule('string');\n  console.log(str.upper('hello'));\n})();",
              "expectedOutput": "3\nHELLO",
              "explanation": "Simulating dynamic imports for lazy loading modules"
            },
            {
              "program": "// Namespace import pattern\nconst Utils = {\n  format: (n) => n.toFixed(2),\n  parse: (s) => parseFloat(s),\n  clamp: (n, min, max) => Math.min(Math.max(n, min), max)\n};\n\nconsole.log(Utils.format(3.14159));\nconsole.log(Utils.parse('42.5'));\nconsole.log(Utils.clamp(150, 0, 100));",
              "expectedOutput": "3.14\n42.5\n100",
              "explanation": "Namespace import pattern (import * as Utils) groups related utilities"
            },
            {
              "program": "// Re-export / barrel file simulation\nconst componentA = { render: () => 'A' };\nconst componentB = { render: () => 'B' };\nconst componentC = { render: () => 'C' };\n\n// Barrel: export { componentA, componentB, componentC }\nconst Components = { componentA, componentB, componentC };\n\nObject.values(Components).forEach(c => console.log(c.render()));",
              "expectedOutput": "A\nB\nC",
              "explanation": "Barrel file pattern — re-exports multiple components from a single entry point"
            },
            {
              "program": "// Singleton module pattern\nconst createDB = (() => {\n  let instance;\n  return () => {\n    if (!instance) {\n      instance = { connected: true, query: (q) => `Result: ${q}` };\n      console.log('DB created');\n    }\n    return instance;\n  };\n})();\n\nconst db1 = createDB();\nconst db2 = createDB();\nconsole.log(db1 === db2);\nconsole.log(db1.query('SELECT 1'));",
              "expectedOutput": "DB created\ntrue\nResult: SELECT 1",
              "explanation": "Modules are singletons — they execute once and cache the result. Same behavior as ESM."
            },
            {
              "program": "// Plugin architecture with modules\nconst plugins = [];\nfunction registerPlugin(plugin) { plugins.push(plugin); }\nfunction runPlugins(data) { return plugins.reduce((d, p) => p(d), data); }\n\nregisterPlugin(s => s.toUpperCase());\nregisterPlugin(s => s.split('').reverse().join(''));\nregisterPlugin(s => `[${s}]`);\n\nconsole.log(runPlugins('hello'));",
              "expectedOutput": "[OLLEH]",
              "explanation": "Plugin pattern — modules register transform functions that are applied in sequence"
            },
            {
              "program": "// Dependency injection pattern\nfunction createService(logger) {\n  return {\n    process(data) {\n      logger.log(`Processing: ${data}`);\n      return data.toUpperCase();\n    }\n  };\n}\nconst fakeLogger = { log: (msg) => console.log(`[LOG] ${msg}`) };\nconst service = createService(fakeLogger);\nconsole.log(service.process('test'));",
              "expectedOutput": "[LOG] Processing: test\nTEST",
              "explanation": "Instead of importing directly, inject dependencies — easier to test and swap implementations"
            },
            {
              "program": "// Feature flags with conditional loading\nconst features = { darkMode: true, analytics: false };\nconst loaded = [];\n\nfor (const [name, enabled] of Object.entries(features)) {\n  if (enabled) {\n    // Simulates: await import(`./features/${name}.js`)\n    loaded.push(name);\n  }\n}\nconsole.log('Loaded features:', loaded.join(', '));",
              "expectedOutput": "Loaded features: darkMode",
              "explanation": "Conditional dynamic imports — only load enabled features (code splitting)"
            }
          ],
          "interviewQuestions": [
            {
              "question": "What is the difference between CommonJS and ES Modules?",
              "answer": "CJS: require()/module.exports, synchronous, copies values, dynamic (can require conditionally), default in Node.js. ESM: import/export, async, live bindings, static (analyzed at compile time), tree-shakeable. ESM is the modern standard for both browser and Node."
            },
            {
              "question": "What is dynamic import() and when would you use it?",
              "answer": "import() returns a Promise that resolves to the module. Used for: code splitting (load on demand), conditional loading, loading modules in non-module scripts, and lazy loading heavy features. Example: const { Chart } = await import('./chart.js')."
            },
            {
              "question": "Why are ES modules better for tree-shaking?",
              "answer": "ESM imports are static — bundlers can analyze the dependency graph at build time and remove unused exports. CJS require() is dynamic (can be inside if-blocks, use variables for paths), so bundlers can't statically determine what's used."
            },
            {
              "question": "What happens if two modules import the same module?",
              "answer": "The module is only executed once. Both imports get the same module instance (singleton behavior). This is why modules work well for shared state — all importers see the same exported values."
            },
            {
              "question": "What are live bindings in ES modules?",
              "answer": "ESM exports are live references to the original variable. If the exporting module changes the value, all importers see the updated value. CJS creates a copy at require() time, so changes aren't reflected. This also helps with circular dependencies."
            },
            {
              "question": "How do circular dependencies work in ESM vs CJS?",
              "answer": "CJS: require() returns a partial object (whatever has been exported so far), can cause bugs. ESM: uses live bindings and hoists imports, so circular deps usually work if you don't access the import synchronously during evaluation. Best practice: avoid circular deps."
            },
            {
              "question": "What is import.meta and what properties does it have?",
              "answer": "import.meta is a meta-property for modules containing metadata. import.meta.url: the full URL of the current module. In Node: used to get __dirname equivalent. In Vite: import.meta.env for environment variables. import.meta.resolve() for resolving module specifiers."
            },
            {
              "question": "What is the difference between export default and named exports?",
              "answer": "Named exports: multiple per file, imported by exact name, better for tree-shaking, more IDE-friendly (auto-import). Default export: one per file, imported with any name, common for components/classes. Some style guides prefer named exports exclusively for consistency."
            },
            {
              "question": "How do you configure Node.js to use ES modules?",
              "answer": "Three ways: (1) Add \"type\": \"module\" in package.json — all .js files are ESM. (2) Use .mjs extension. (3) Use --input-type=module flag. For CJS in an ESM package, use .cjs extension. TypeScript uses tsconfig's module and moduleResolution settings."
            },
            {
              "question": "What is top-level await and what are its implications?",
              "answer": "ES2022 allows await at the top level of ES modules (not in scripts). The module's execution pauses until the promise resolves. Any module importing it will wait too. Useful for config loading, DB connections. Risk: can slow down module graph loading if overused."
            }
          ],
          "category": "Core Language"
        },
        {
          "id": "set-map-weakmap",
          "title": "Set, Map, WeakMap & WeakSet",
          "description": "Learn modern JavaScript data structures — Set, Map, WeakMap, WeakSet — their use cases, differences from objects/arrays, and memory management.",
          "explanation": "ES6 introduced four collection types that solve specific problems plain objects and arrays can't.\n\nSet — a collection of unique values:\n- No duplicates (uses SameValueZero algorithm, like === but NaN === NaN)\n- Preserves insertion order\n- Methods: add(), delete(), has(), clear(), forEach()\n- Iterable: can use for...of, spread, destructuring\n- Property: size (not length)\n- Use for: removing duplicates, fast lookup, set operations (union, intersection)\n\nMap — key-value pairs with any key type:\n- Keys can be ANY type (objects, functions, primitives) — unlike objects (string/symbol keys only)\n- Preserves insertion order\n- Methods: set(), get(), has(), delete(), clear(), forEach()\n- Property: size\n- Better than objects when: keys aren't strings, you need ordered iteration, you frequently add/remove entries\n\nWeakMap — Map with weakly held object keys:\n- Keys must be objects (or symbols)\n- Keys are held weakly — if no other reference exists, the key/value pair is garbage collected\n- NOT iterable, no size property, no clear()\n- Methods: set(), get(), has(), delete()\n- Use for: private data, caching, DOM node metadata\n\nWeakSet — Set with weakly held object values:\n- Values must be objects\n- Weakly held — garbage collected when no other references\n- NOT iterable, no size, no clear()\n- Methods: add(), has(), delete()\n- Use for: tracking objects (visited nodes, tagged objects)\n\nWeak collections prevent memory leaks — they don't prevent garbage collection of their entries.",
          "code": "// Set\nconst set = new Set([1, 2, 3, 2, 1]);\nconsole.log(set.size);      // 3 (duplicates removed)\nset.add(4);\nset.delete(1);\nconsole.log(set.has(2));    // true\nconsole.log([...set]);      // [2, 3, 4]\n\n// Remove duplicates from array\nconst unique = [...new Set([1, 2, 2, 3, 3, 3])]; // [1, 2, 3]\n\n// Set operations\nconst a = new Set([1, 2, 3]);\nconst b = new Set([2, 3, 4]);\nconst union = new Set([...a, ...b]);     // {1,2,3,4}\nconst intersection = new Set([...a].filter(x => b.has(x))); // {2,3}\nconst difference = new Set([...a].filter(x => !b.has(x)));  // {1}\n\n// Map\nconst map = new Map();\nmap.set('key', 'value');\nmap.set(42, 'number key');\nmap.set({}, 'object key');\nconsole.log(map.get('key'));   // 'value'\nconsole.log(map.size);         // 3\n\n// Map from entries\nconst m = new Map([['a', 1], ['b', 2]]);\nfor (const [key, val] of m) {\n  console.log(`${key}: ${val}`);\n}",
          "example": "// WeakMap for private data\nconst privateData = new WeakMap();\nclass User {\n  constructor(name, password) {\n    this.name = name;\n    privateData.set(this, { password });\n  }\n  checkPassword(attempt) {\n    return privateData.get(this).password === attempt;\n  }\n}\nconst user = new User('Alice', 'secret');\nconsole.log(user.name);              // 'Alice'\nconsole.log(user.password);           // undefined (private!)\nconsole.log(user.checkPassword('secret')); // true\n\n// WeakMap for caching\nconst cache = new WeakMap();\nfunction expensiveOperation(obj) {\n  if (cache.has(obj)) return cache.get(obj);\n  const result = /* heavy computation */ JSON.stringify(obj);\n  cache.set(obj, result);\n  return result;\n}\n\n// WeakSet for tracking\nconst visited = new WeakSet();\nfunction processNode(node) {\n  if (visited.has(node)) return; // Already processed\n  visited.add(node);\n  // Process node...\n}",
          "useCase": "Deduplication, fast lookups, caching, private data, DOM metadata, frequency counting, set operations (union/intersection), preventing memory leaks",
          "exercises": [
            {
              "type": "output",
              "question": "What is the output?\nconst s = new Set([1, 2, 3, 2, 1, 3]);\nconsole.log(s.size);\nconsole.log([...s]);",
              "answer": "3, then [1, 2, 3] — Set removes duplicates, preserves insertion order"
            },
            {
              "type": "output",
              "question": "What is the output?\nconst m = new Map();\nm.set('a', 1);\nm.set('b', 2);\nm.set('a', 3);\nconsole.log(m.size);\nconsole.log(m.get('a'));",
              "answer": "2, 3 — Setting same key 'a' again overwrites the value. Size stays 2."
            },
            {
              "type": "output",
              "question": "What is the output?\nconst s = new Set();\ns.add(NaN);\ns.add(NaN);\nconsole.log(s.size);\nconsole.log(s.has(NaN));",
              "answer": "1, true — Set treats NaN as equal to NaN (SameValueZero algorithm), unlike ==="
            },
            {
              "type": "output",
              "question": "What is the output?\nconst s = new Set();\ns.add({});\ns.add({});\nconsole.log(s.size);",
              "answer": "2 — Each {} is a different object reference. Set compares by reference for objects."
            },
            {
              "type": "output",
              "question": "What is the output?\nconst m = new Map();\nconst key1 = { id: 1 };\nconst key2 = { id: 1 };\nm.set(key1, 'a');\nm.set(key2, 'b');\nconsole.log(m.size);\nconsole.log(m.get(key1));\nconsole.log(m.get({ id: 1 }));",
              "answer": "2, 'a', undefined — Map uses reference equality for object keys. key1 ≠ key2 ≠ new {id:1}"
            },
            {
              "type": "output",
              "question": "What is the output?\nconst obj = {};\nobj[1] = 'a';\nobj['1'] = 'b';\nconsole.log(Object.keys(obj).length);\n\nconst map = new Map();\nmap.set(1, 'a');\nmap.set('1', 'b');\nconsole.log(map.size);",
              "answer": "1, then 2 — Object converts keys to strings (1 and '1' are same). Map keeps key types separate."
            },
            {
              "type": "output",
              "question": "What is the output?\nconst s = new Set([1, 2, 3, 4, 5]);\nconst result = [...s].filter(x => x % 2 === 0);\nconsole.log(result);",
              "answer": "[2, 4] — Spread Set to array, then filter for even numbers"
            },
            {
              "type": "concept",
              "question": "Why can't WeakMap and WeakSet be iterated?",
              "answer": "Because their entries are weakly held — they can be garbage collected at any time. If you could iterate, the entries might appear/disappear unpredictably. The GC schedule is non-deterministic, so allowing iteration would create inconsistent behavior."
            },
            {
              "type": "concept",
              "question": "When would you use a Map over a plain object?",
              "answer": "Use Map when: (1) keys are not strings/symbols, (2) you need to preserve insertion order for iteration, (3) you frequently add/delete keys (Map is optimized for this), (4) you need the size property, (5) you don't want prototype pollution."
            },
            {
              "type": "concept",
              "question": "How does WeakMap help prevent memory leaks?",
              "answer": "WeakMap holds keys weakly — if the object key has no other references, both the key and value are garbage collected. Without WeakMap, storing metadata about objects in a regular Map/object keeps those objects alive forever, causing memory leaks."
            }
          ],
          "programExercises": [
            {
              "program": "// Remove duplicates\nconst arr = [1, 'a', 2, 'a', 3, 1, 2];\nconsole.log([...new Set(arr)].join(', '));",
              "expectedOutput": "1, a, 2, 3",
              "explanation": "Set removes duplicates, spread converts back to array. Works with mixed types."
            },
            {
              "program": "// Word frequency counter\nconst text = 'the cat sat on the mat the cat';\nconst freq = new Map();\ntext.split(' ').forEach(word => {\n  freq.set(word, (freq.get(word) || 0) + 1);\n});\nfor (const [word, count] of freq) {\n  console.log(`${word}: ${count}`);\n}",
              "expectedOutput": "the: 3\ncat: 2\nsat: 1\non: 1\nmat: 1",
              "explanation": "Map as frequency counter — preserves insertion order of first occurrence"
            },
            {
              "program": "// Set operations\nconst a = new Set([1, 2, 3, 4]);\nconst b = new Set([3, 4, 5, 6]);\n\nconst union = new Set([...a, ...b]);\nconst intersection = new Set([...a].filter(x => b.has(x)));\nconst difference = new Set([...a].filter(x => !b.has(x)));\n\nconsole.log('Union:', [...union].join(', '));\nconsole.log('Intersection:', [...intersection].join(', '));\nconsole.log('Difference:', [...difference].join(', '));",
              "expectedOutput": "Union: 1, 2, 3, 4, 5, 6\nIntersection: 3, 4\nDifference: 1, 2",
              "explanation": "Classic set operations using Set with spread and filter"
            },
            {
              "program": "// Map for caching function results\nconst cache = new Map();\nfunction fibonacci(n) {\n  if (cache.has(n)) return cache.get(n);\n  const result = n <= 1 ? n : fibonacci(n - 1) + fibonacci(n - 2);\n  cache.set(n, result);\n  return result;\n}\nconsole.log(fibonacci(10));\nconsole.log(fibonacci(20));\nconsole.log('Cache size:', cache.size);",
              "expectedOutput": "55\n6765\nCache size: 21",
              "explanation": "Memoization with Map — caches fibonacci results for instant subsequent lookups"
            },
            {
              "program": "// Group by using Map\nconst people = [\n  { name: 'Alice', dept: 'eng' },\n  { name: 'Bob', dept: 'sales' },\n  { name: 'Carol', dept: 'eng' },\n  { name: 'Dave', dept: 'sales' },\n];\nconst grouped = new Map();\nfor (const p of people) {\n  if (!grouped.has(p.dept)) grouped.set(p.dept, []);\n  grouped.get(p.dept).push(p.name);\n}\nfor (const [dept, names] of grouped) {\n  console.log(`${dept}: ${names.join(', ')}`);\n}",
              "expectedOutput": "eng: Alice, Carol\nsales: Bob, Dave",
              "explanation": "Map for grouping — each key maps to an array of values"
            },
            {
              "program": "// Two-way Map (bidirectional lookup)\nclass BiMap {\n  #forward = new Map();\n  #reverse = new Map();\n  set(key, value) { this.#forward.set(key, value); this.#reverse.set(value, key); }\n  get(key) { return this.#forward.get(key); }\n  getKey(value) { return this.#reverse.get(value); }\n}\nconst codes = new BiMap();\ncodes.set('US', 'United States');\ncodes.set('UK', 'United Kingdom');\nconsole.log(codes.get('US'));\nconsole.log(codes.getKey('United Kingdom'));",
              "expectedOutput": "United States\nUK",
              "explanation": "Bidirectional map — lookup by key or by value in O(1) time"
            },
            {
              "program": "// Using Map to index objects\nconst users = [\n  { id: 1, name: 'Alice' },\n  { id: 2, name: 'Bob' },\n  { id: 3, name: 'Carol' }\n];\nconst byId = new Map(users.map(u => [u.id, u]));\nconsole.log(byId.get(2).name);\nconsole.log(byId.has(4));",
              "expectedOutput": "Bob\nfalse",
              "explanation": "Map created from array of [key, value] pairs — instant O(1) lookup by ID"
            },
            {
              "program": "// Set as seen-tracker for array intersection\nfunction intersect(arr1, arr2) {\n  const set1 = new Set(arr1);\n  return arr2.filter(x => set1.has(x));\n}\nconsole.log(intersect([1,2,3,4,5], [3,4,5,6,7]).join(', '));",
              "expectedOutput": "3, 4, 5",
              "explanation": "Converting one array to Set for O(1) lookups makes intersection O(n) instead of O(n²)"
            },
            {
              "program": "// Map iteration methods\nconst m = new Map([['a', 1], ['b', 2], ['c', 3]]);\nconsole.log([...m.keys()].join(', '));\nconsole.log([...m.values()].join(', '));\nconsole.log([...m.entries()].map(([k,v]) => `${k}=${v}`).join(', '));",
              "expectedOutput": "a, b, c\n1, 2, 3\na=1, b=2, c=3",
              "explanation": "Map provides keys(), values(), entries() iterators — all preserve insertion order"
            },
            {
              "program": "// Converting between Map and Object\nconst obj = { x: 1, y: 2, z: 3 };\nconst map = new Map(Object.entries(obj));\nconsole.log(map.get('y'));\n\nconst backToObj = Object.fromEntries(map);\nconsole.log(JSON.stringify(backToObj));",
              "expectedOutput": "2\n{\"x\":1,\"y\":2,\"z\":3}",
              "explanation": "Object.entries → Map, Map → Object.fromEntries. Round-trip conversion."
            }
          ],
          "interviewQuestions": [
            {
              "question": "What is the difference between Map and a plain object?",
              "answer": "Map: any key type, ordered, has size property, no prototype keys, optimized for frequent additions/deletions, iterable. Object: string/symbol keys only, enumeration order is complex, no size, has prototype chain, better for fixed known keys, JSON-compatible."
            },
            {
              "question": "What is the difference between Set and an Array?",
              "answer": "Set: unique values only, has O(1) has() check, no index access, no duplicates allowed. Array: allows duplicates, O(n) includes() check, index access, ordered with push/pop/shift. Use Set for uniqueness checks, Array for ordered collections with duplicates."
            },
            {
              "question": "What is a WeakMap and why is it useful?",
              "answer": "WeakMap holds object keys weakly — when the key object has no other references, the entry is garbage collected. Useful for: storing private data per object, caching without memory leaks, associating metadata with DOM nodes. Not iterable, no size property."
            },
            {
              "question": "How does Set determine if two values are equal?",
              "answer": "Set uses the SameValueZero algorithm: like === but treats NaN as equal to NaN. For objects, it uses reference equality (same reference = same value). Two different objects with identical properties are considered different in a Set."
            },
            {
              "question": "What is the difference between WeakMap and Map?",
              "answer": "Map: any key type, strongly held, iterable, has size. WeakMap: object/symbol keys only, weakly held (GC-eligible), not iterable, no size, no clear(). Use Map for general key-value storage, WeakMap when you want automatic cleanup when keys are dereferenced."
            },
            {
              "question": "How would you implement a cache that doesn't cause memory leaks?",
              "answer": "Use WeakMap with objects as keys: when the object is garbage collected, the cached value is too. For primitive keys, use Map with an eviction strategy (LRU, TTL). WeakRef + FinalizationRegistry can also help with advanced caching scenarios."
            },
            {
              "question": "What are the new Set methods proposed in ES2025?",
              "answer": "Set is getting proper set operation methods: .union(other), .intersection(other), .difference(other), .symmetricDifference(other), .isSubsetOf(other), .isSupersetOf(other), .isDisjointFrom(other). These return new Sets and work with any iterable."
            },
            {
              "question": "When would you use WeakSet over Set?",
              "answer": "WeakSet when: (1) tracking objects without preventing GC (e.g., visited nodes in a graph), (2) tagging objects (e.g., marking DOM elements as processed), (3) checking if an object belongs to a group. Can't iterate WeakSet, so use Set when you need to list all values."
            },
            {
              "question": "Can you convert a Map to JSON and back?",
              "answer": "Not directly — JSON.stringify(map) gives '{}'. Convert first: JSON.stringify([...map]) serializes as array of pairs. To restore: new Map(JSON.parse(json)). Only works if keys and values are JSON-compatible (not objects)."
            },
            {
              "question": "What is the performance difference between Map/Set and Object/Array?",
              "answer": "Map.has()/Set.has(): O(1) average. Array.includes(): O(n). Object property access: O(1) average. Map/Set are optimized for frequent add/delete. Objects are optimized for fixed-shape property access. For large collections with frequent membership tests, Set/Map are significantly faster."
            }
          ],
          "category": "Data Structures"
        }
      ],
      "quiz": [
        {
          "id": 1,
          "question": "What is the main difference between debouncing and throttling?",
          "options": [
            "Debouncing delays execution until calm, throttling limits execution frequency",
            "Debouncing is faster than throttling",
            "Throttling only works with events, debouncing works with any function",
            "They are the same thing with different names"
          ],
          "correctAnswer": 0,
          "explanation": "Debouncing delays function execution until after a period of inactivity, while throttling ensures the function executes at most once per specified time interval."
        },
        {
          "id": 2,
          "question": "What is the output of: typeof null?",
          "options": [
            "'null'",
            "'object'",
            "'undefined'",
            "'number'"
          ],
          "correctAnswer": 1,
          "explanation": "This is a known JavaScript bug. typeof null returns 'object' due to a legacy implementation issue that can't be fixed for backward compatibility."
        },
        {
          "id": 3,
          "question": "What is a closure in JavaScript?",
          "options": [
            "A way to close browser windows",
            "A function that has access to variables in its outer scope",
            "A method to end a loop",
            "A type of object"
          ],
          "correctAnswer": 1,
          "explanation": "A closure is a function that has access to variables in its outer (enclosing) lexical scope, even after the outer function has returned."
        },
        {
          "id": 4,
          "question": "What will console.log(0.1 + 0.2 === 0.3) output?",
          "options": [
            "true",
            "false",
            "undefined",
            "NaN"
          ],
          "correctAnswer": 1,
          "explanation": "Due to floating-point precision issues in JavaScript, 0.1 + 0.2 actually equals 0.30000000000000004, not 0.3."
        },
        {
          "id": 5,
          "question": "What does 'use strict' do in JavaScript?",
          "options": [
            "Makes code run faster",
            "Enables strict mode which catches common coding errors",
            "Compiles code to machine language",
            "Enables ES6 features"
          ],
          "correctAnswer": 1,
          "explanation": "'use strict' enables strict mode, which catches common coding mistakes, prevents use of reserved keywords, and disallows certain unsafe actions."
        },
        {
          "id": 6,
          "question": "What is the difference between == and ===?",
          "options": [
            "No difference",
            "== checks value and type, === only checks value",
            "=== checks value and type, == only checks value",
            "=== is faster than =="
          ],
          "correctAnswer": 2,
          "explanation": "=== (strict equality) checks both value and type without type coercion, while == (loose equality) performs type coercion before comparison."
        },
        {
          "id": 7,
          "question": "What is hoisting in JavaScript?",
          "options": [
            "Moving functions to top of file",
            "Variable and function declarations are moved to top of scope during compilation",
            "Lifting heavy objects",
            "A design pattern"
          ],
          "correctAnswer": 1,
          "explanation": "Hoisting is JavaScript's behavior of moving declarations to the top of their scope before code execution. Variables declared with var and function declarations are hoisted."
        },
        {
          "id": 8,
          "question": "What will this code output? console.log([] + [])",
          "options": [
            "[]",
            "''",
            "'[][]'",
            "undefined"
          ],
          "correctAnswer": 1,
          "explanation": "When adding arrays, JavaScript converts them to strings. Empty arrays become empty strings, so '' + '' = ''."
        },
        {
          "id": 9,
          "question": "What is the purpose of Promise.all()?",
          "options": [
            "Execute promises one after another",
            "Execute multiple promises in parallel and wait for all to complete",
            "Cancel all promises",
            "Create a new promise"
          ],
          "correctAnswer": 1,
          "explanation": "Promise.all() takes an array of promises and returns a single promise that resolves when all input promises have resolved, or rejects if any promise rejects."
        },
        {
          "id": 10,
          "question": "What does the spread operator (...) do?",
          "options": [
            "Spreads butter",
            "Expands an iterable into individual elements",
            "Creates a range of numbers",
            "Multiplies values"
          ],
          "correctAnswer": 1,
          "explanation": "The spread operator (...) expands an iterable (like an array) into individual elements. It's useful for copying arrays, combining arrays, and passing array elements as function arguments."
        },
        {
          "id": 11,
          "question": "What is the difference between let, const, and var?",
          "options": [
            "No difference, just preference",
            "let and const are block-scoped, var is function-scoped",
            "const is faster than let and var",
            "var is the newest syntax"
          ],
          "correctAnswer": 1,
          "explanation": "let and const are block-scoped and not hoisted to the top. var is function-scoped and hoisted. const cannot be reassigned after declaration."
        },
        {
          "id": 12,
          "question": "What is the output of: console.log(typeof NaN)?",
          "options": [
            "'NaN'",
            "'number'",
            "'undefined'",
            "'object'"
          ],
          "correctAnswer": 1,
          "explanation": "NaN (Not-a-Number) ironically has the type 'number' in JavaScript. It's a special numeric value representing an invalid number."
        },
        {
          "id": 13,
          "question": "What does Array.prototype.map() return?",
          "options": [
            "The same array modified",
            "A new array with transformed elements",
            "Nothing (undefined)",
            "An object"
          ],
          "correctAnswer": 1,
          "explanation": "map() creates and returns a new array with the results of calling a provided function on every element. It doesn't modify the original array."
        },
        {
          "id": 14,
          "question": "What is event delegation?",
          "options": [
            "Passing events between functions",
            "Attaching a single event listener to a parent to handle events on children",
            "Preventing default events",
            "Creating custom events"
          ],
          "correctAnswer": 1,
          "explanation": "Event delegation uses event bubbling to handle events at a higher level in the DOM. You attach an event listener to a parent element to manage events from its children."
        },
        {
          "id": 15,
          "question": "What is the purpose of the 'this' keyword?",
          "options": [
            "References the current file",
            "References the context in which a function is called",
            "References the global object always",
            "References the parent function"
          ],
          "correctAnswer": 1,
          "explanation": "'this' refers to the object that is executing the current function. Its value depends on how the function is called (method, regular function, arrow function, etc.)."
        },
        {
          "id": 16,
          "question": "What is the difference between .call(), .apply(), and .bind()?",
          "options": [
            "They are the same",
            ".call() and .apply() invoke immediately with different argument formats, .bind() returns a new function",
            ".bind() is deprecated",
            "They only work with classes"
          ],
          "correctAnswer": 1,
          "explanation": ".call() invokes function with arguments separated by commas. .apply() uses array of arguments. .bind() returns a new function with 'this' bound without invoking."
        },
        {
          "id": 17,
          "question": "What is the output of: console.log(1 + '1')?",
          "options": [
            "2",
            "'11'",
            "11",
            "Error"
          ],
          "correctAnswer": 1,
          "explanation": "When adding a number and string, JavaScript converts the number to a string and performs concatenation, resulting in '11'."
        },
        {
          "id": 18,
          "question": "What is a callback function?",
          "options": [
            "A function that calls itself",
            "A function passed as an argument to another function",
            "A function that returns a value",
            "A deprecated pattern"
          ],
          "correctAnswer": 1,
          "explanation": "A callback is a function passed as an argument to another function, to be executed later, often after an asynchronous operation completes."
        },
        {
          "id": 19,
          "question": "What does Object.freeze() do?",
          "options": [
            "Stops JavaScript execution",
            "Makes an object immutable (prevents modifications)",
            "Converts object to string",
            "Copies an object"
          ],
          "correctAnswer": 1,
          "explanation": "Object.freeze() makes an object immutable. You can't add, delete, or modify its properties. Nested objects are not frozen unless explicitly frozen."
        },
        {
          "id": 20,
          "question": "What is the event loop in JavaScript?",
          "options": [
            "A loop that processes events",
            "Mechanism that handles async operations and callback execution",
            "A for loop variant",
            "A DOM event handler"
          ],
          "correctAnswer": 1,
          "explanation": "The event loop is JavaScript's concurrency model. It continuously checks the call stack and task queues, executing callbacks when the stack is empty."
        },
        {
          "id": 21,
          "question": "What is destructuring in JavaScript?",
          "options": [
            "Deleting objects",
            "Extracting values from arrays or objects into distinct variables",
            "Breaking code into modules",
            "A debugging technique"
          ],
          "correctAnswer": 1,
          "explanation": "Destructuring allows unpacking values from arrays or properties from objects into distinct variables using a concise syntax."
        },
        {
          "id": 22,
          "question": "What does Array.prototype.filter() do?",
          "options": [
            "Removes all elements",
            "Creates array with elements that pass a test",
            "Modifies original array",
            "Sorts array elements"
          ],
          "correctAnswer": 1,
          "explanation": "filter() creates a new array with all elements that pass the test implemented by the provided function. It doesn't modify the original array."
        },
        {
          "id": 23,
          "question": "What is the temporal dead zone?",
          "options": [
            "A timezone issue",
            "Period between scope entry and declaration where let/const variables can't be accessed",
            "A debugging tool",
            "A performance issue"
          ],
          "correctAnswer": 1,
          "explanation": "The temporal dead zone is the period from entering a scope until a let/const variable is declared, where accessing the variable throws a ReferenceError."
        },
        {
          "id": 24,
          "question": "What is a pure function?",
          "options": [
            "A function without bugs",
            "Function that always returns same output for same input with no side effects",
            "A built-in function",
            "A function with one parameter"
          ],
          "correctAnswer": 1,
          "explanation": "A pure function always returns the same result for the same arguments and has no side effects (doesn't modify external state)."
        },
        {
          "id": 25,
          "question": "What does Array.prototype.reduce() do?",
          "options": [
            "Reduces array size",
            "Executes reducer function on array to produce single output value",
            "Removes duplicates",
            "Filters negative numbers"
          ],
          "correctAnswer": 1,
          "explanation": "reduce() executes a reducer function on each array element, resulting in a single output value. It's useful for summing, flattening arrays, or any accumulation operation."
        },
        {
          "id": 26,
          "question": "What is the difference between null and undefined?",
          "options": [
            "They are exactly the same",
            "null is assigned, undefined means no value has been assigned",
            "undefined is newer than null",
            "null is a string, undefined is not"
          ],
          "correctAnswer": 1,
          "explanation": "undefined means a variable has been declared but not assigned a value. null is an assignment value representing intentional absence of any object value."
        },
        {
          "id": 27,
          "question": "What does the 'new' keyword do?",
          "options": [
            "Creates a new file",
            "Creates a new instance of an object from constructor function",
            "Updates existing object",
            "Declares new variable"
          ],
          "correctAnswer": 1,
          "explanation": "The 'new' keyword creates an instance of a user-defined object type or built-in object that has a constructor function. It sets up the prototype chain properly."
        },
        {
          "id": 28,
          "question": "What is memoization?",
          "options": [
            "Remembering code",
            "Caching function results to avoid repeated calculations",
            "Memory management",
            "A debugging technique"
          ],
          "correctAnswer": 1,
          "explanation": "Memoization is an optimization technique that stores function results for specific inputs, returning cached result when same input occurs again instead of recalculating."
        },
        {
          "id": 29,
          "question": "What does Promise.race() do?",
          "options": [
            "Compares promise speeds",
            "Returns promise that resolves/rejects first from array of promises",
            "Creates racing game",
            "Cancels slowest promise"
          ],
          "correctAnswer": 1,
          "explanation": "Promise.race() returns a promise that resolves or rejects as soon as one of the promises in the iterable resolves or rejects, with the value/reason from that promise."
        },
        {
          "id": 30,
          "question": "What is the purpose of Symbol in JavaScript?",
          "options": [
            "Mathematical operations",
            "Creating unique identifiers, especially for object properties",
            "Text formatting",
            "Creating emojis"
          ],
          "correctAnswer": 1,
          "explanation": "Symbol is a primitive data type that creates unique, immutable values, commonly used as unique property keys to avoid naming collisions."
        },
        {
          "id": 31,
          "question": "What is the output of: console.log(![])?",
          "options": [
            "true",
            "false",
            "undefined",
            "[]"
          ],
          "correctAnswer": 1,
          "explanation": "An empty array is a truthy value in JavaScript. The ! operator negates it, so ![] evaluates to false."
        },
        {
          "id": 32,
          "question": "What does Array.isArray() do?",
          "options": [
            "Converts to array",
            "Checks if value is an array",
            "Counts array elements",
            "Sorts array"
          ],
          "correctAnswer": 1,
          "explanation": "Array.isArray() determines whether the passed value is an Array, returning true or false. It's more reliable than typeof for checking arrays."
        },
        {
          "id": 33,
          "question": "What is a generator function?",
          "options": [
            "Function that generates random numbers",
            "Function that can pause execution and resume later using yield",
            "Function that creates other functions",
            "Built-in utility function"
          ],
          "correctAnswer": 1,
          "explanation": "Generator functions (function*) can pause execution with yield keyword and resume later. They return a generator object that conforms to iterator protocol."
        },
        {
          "id": 34,
          "question": "What does Object.assign() do?",
          "options": [
            "Deletes object properties",
            "Copies properties from source objects to target object",
            "Creates new object type",
            "Assigns object to variable"
          ],
          "correctAnswer": 1,
          "explanation": "Object.assign() copies all enumerable own properties from one or more source objects to a target object. It's commonly used for shallow cloning or merging objects."
        },
        {
          "id": 35,
          "question": "What is the difference between forEach and map?",
          "options": [
            "No difference",
            "forEach executes function on each element, map returns new array",
            "map is slower",
            "forEach is deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "forEach() executes a function on each element and returns undefined. map() creates and returns a new array with transformed elements."
        },
        {
          "id": 36,
          "question": "What is a WeakMap?",
          "options": [
            "A slow Map",
            "Map with weak references to keys allowing garbage collection",
            "Map with limited size",
            "Deprecated data structure"
          ],
          "correctAnswer": 1,
          "explanation": "WeakMap holds weak references to keys (must be objects), allowing them to be garbage collected if no other references exist. Values can be any type."
        },
        {
          "id": 37,
          "question": "What does the finally block do in try-catch?",
          "options": [
            "Catches remaining errors",
            "Executes code regardless of try-catch outcome",
            "Prevents errors",
            "Only runs on errors"
          ],
          "correctAnswer": 1,
          "explanation": "The finally block executes after try and catch blocks, regardless of whether an exception was thrown or caught. It's useful for cleanup operations."
        },
        {
          "id": 38,
          "question": "What is the rest parameter in functions?",
          "options": [
            "Parameter that sleeps",
            "Syntax (...args) that collects remaining arguments into array",
            "Optional parameter",
            "Last parameter only"
          ],
          "correctAnswer": 1,
          "explanation": "Rest parameters (...args) allow representing an indefinite number of arguments as an array. It must be the last parameter in function definition."
        },
        {
          "id": 39,
          "question": "What does JSON.stringify() do?",
          "options": [
            "Parses JSON",
            "Converts JavaScript value to JSON string",
            "Validates JSON",
            "Minifies JSON"
          ],
          "correctAnswer": 1,
          "explanation": "JSON.stringify() converts a JavaScript object or value to a JSON string. It's often used when sending data to a server or for deep cloning simple objects."
        },
        {
          "id": 40,
          "question": "What is a Set in JavaScript?",
          "options": [
            "An array",
            "Collection that stores unique values of any type",
            "A function",
            "An object method"
          ],
          "correctAnswer": 1,
          "explanation": "Set is a collection of unique values. Any duplicate values are ignored. It provides methods like add(), delete(), has(), and can be iterated."
        },
        {
          "id": 41,
          "question": "What is the output of: console.log([] == false)?",
          "options": [
            "false",
            "true",
            "undefined",
            "Error"
          ],
          "correctAnswer": 1,
          "explanation": "Due to type coercion, empty array converts to empty string, which converts to 0, and false also converts to 0. So 0 == 0 is true."
        },
        {
          "id": 42,
          "question": "What does Object.keys() return?",
          "options": [
            "Object values",
            "Array of object's own enumerable property names",
            "Number of properties",
            "Object type"
          ],
          "correctAnswer": 1,
          "explanation": "Object.keys() returns an array of a given object's own enumerable property names, in the same order as a normal loop would."
        },
        {
          "id": 43,
          "question": "What is the module pattern?",
          "options": [
            "CSS pattern",
            "Design pattern that provides encapsulation and private state",
            "Import/export syntax",
            "File organization"
          ],
          "correctAnswer": 1,
          "explanation": "The module pattern uses closures to create private variables and methods, exposing only a public API. It helps organize code and avoid global namespace pollution."
        },
        {
          "id": 44,
          "question": "What does Array.prototype.some() do?",
          "options": [
            "Returns some elements",
            "Tests whether at least one element passes the test",
            "Returns random elements",
            "Removes some elements"
          ],
          "correctAnswer": 1,
          "explanation": "some() tests whether at least one element in the array passes the test implemented by the provided function. Returns true or false."
        },
        {
          "id": 45,
          "question": "What is the difference between slice and splice?",
          "options": [
            "No difference",
            "slice returns new array without modifying, splice modifies original",
            "splice is deprecated",
            "slice only works on strings"
          ],
          "correctAnswer": 1,
          "explanation": "slice() returns a shallow copy of portion of array without modifying original. splice() changes original array by removing, replacing, or adding elements."
        },
        {
          "id": 46,
          "question": "What is IIFE (Immediately Invoked Function Expression)?",
          "options": [
            "A delayed function",
            "Function that executes immediately after definition",
            "Anonymous function",
            "Recursive function"
          ],
          "correctAnswer": 1,
          "explanation": "IIFE is a function that runs immediately after it's defined. Syntax: (function(){ ... })() or (() => { ... })(). Used to create private scope."
        },
        {
          "id": 47,
          "question": "What does Array.prototype.every() do?",
          "options": [
            "Returns every element",
            "Tests whether all elements pass the test",
            "Loops forever",
            "Creates copy of array"
          ],
          "correctAnswer": 1,
          "explanation": "every() tests whether all elements in the array pass the test implemented by the provided function. Returns true if all pass, false otherwise."
        },
        {
          "id": 48,
          "question": "What is the difference between arguments and rest parameters?",
          "options": [
            "No difference",
            "arguments is array-like object, rest parameters are real arrays",
            "rest parameters are deprecated",
            "arguments work in arrow functions"
          ],
          "correctAnswer": 1,
          "explanation": "arguments is an array-like object available in regular functions. Rest parameters (...args) are actual arrays and work in arrow functions, making them more flexible."
        },
        {
          "id": 49,
          "question": "What does isNaN() do?",
          "options": [
            "Creates NaN",
            "Checks if value is NaN after type coercion",
            "Removes NaN from array",
            "Converts to NaN"
          ],
          "correctAnswer": 1,
          "explanation": "isNaN() checks if a value is NaN after attempting type coercion. Number.isNaN() is stricter and doesn't coerce, only returns true for actual NaN."
        },
        {
          "id": 50,
          "question": "What is the prototype chain?",
          "options": [
            "Chain of function calls",
            "Mechanism where objects inherit properties from other objects",
            "Linked list data structure",
            "Error handling chain"
          ],
          "correctAnswer": 1,
          "explanation": "The prototype chain is how JavaScript objects inherit features from one another. When accessing a property, JS looks up the chain until it finds the property or reaches null."
        },
        {
          "id": 51,
          "question": "What does Object.create() do?",
          "options": [
            "Deletes object",
            "Creates new object with specified prototype",
            "Copies object",
            "Freezes object"
          ],
          "correctAnswer": 1,
          "explanation": "Object.create() creates a new object with the specified prototype object and properties. It's useful for setting up inheritance without using constructors."
        },
        {
          "id": 52,
          "question": "What is the difference between function declaration and expression?",
          "options": [
            "No difference",
            "Declarations are hoisted, expressions are not",
            "Expressions are faster",
            "Declarations are deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "Function declarations are fully hoisted (can be called before definition). Function expressions (including arrow functions) are not hoisted and must be defined before use."
        },
        {
          "id": 53,
          "question": "What does Array.from() do?",
          "options": [
            "Gets array from server",
            "Creates array from array-like or iterable object",
            "Converts array to object",
            "Removes array elements"
          ],
          "correctAnswer": 1,
          "explanation": "Array.from() creates a new, shallow-copied Array instance from an array-like or iterable object (like NodeList, Set, Map, or string)."
        },
        {
          "id": 54,
          "question": "What is short-circuit evaluation?",
          "options": [
            "Fast code execution",
            "Logical operators stop evaluating once result is determined",
            "Breaking out of loops",
            "Error handling"
          ],
          "correctAnswer": 1,
          "explanation": "Short-circuit evaluation means && stops at first falsy value, || stops at first truthy value, without evaluating remaining expressions. Useful for default values and conditionals."
        },
        {
          "id": 55,
          "question": "What does the delete operator do?",
          "options": [
            "Deletes files",
            "Removes property from object",
            "Deletes variables",
            "Clears memory"
          ],
          "correctAnswer": 1,
          "explanation": "The delete operator removes a property from an object. It returns true if successful, false otherwise. It doesn't delete variables or functions."
        },
        {
          "id": 56,
          "question": "What is the comma operator?",
          "options": [
            "Creates lists",
            "Evaluates multiple expressions, returns last one",
            "Separates parameters",
            "Concatenates strings"
          ],
          "correctAnswer": 1,
          "explanation": "The comma operator evaluates each operand from left to right and returns the value of the last operand. Rarely used except in for loops."
        },
        {
          "id": 57,
          "question": "What is a polyfill?",
          "options": [
            "Performance optimizer",
            "Code that implements feature not natively supported by browser",
            "Security patch",
            "Testing tool"
          ],
          "correctAnswer": 1,
          "explanation": "A polyfill is code that implements a feature on browsers that don't support it natively. It provides backward compatibility for newer JavaScript features."
        },
        {
          "id": 58,
          "question": "What does String.prototype.trim() do?",
          "options": [
            "Shortens string length",
            "Removes whitespace from both ends of string",
            "Converts to lowercase",
            "Removes all spaces"
          ],
          "correctAnswer": 1,
          "explanation": "trim() removes whitespace from both ends of a string. trimStart() and trimEnd() remove from beginning or end only. It doesn't modify original string."
        },
        {
          "id": 59,
          "question": "What is the difference between Map and Object?",
          "options": [
            "No difference",
            "Map allows any type as key, maintains insertion order, has size property",
            "Object is newer",
            "Map is slower"
          ],
          "correctAnswer": 1,
          "explanation": "Map allows any value (including objects) as keys, maintains insertion order, has size property, and better performance for frequent additions/deletions. Objects have prototype properties."
        },
        {
          "id": 60,
          "question": "What does the in operator do?",
          "options": [
            "Logs in user",
            "Checks if property exists in object or its prototype chain",
            "Adds property to object",
            "Imports module"
          ],
          "correctAnswer": 1,
          "explanation": "The 'in' operator returns true if the specified property is in the object or its prototype chain. Different from hasOwnProperty() which checks only own properties."
        },
        {
          "id": 61,
          "question": "What is BigInt used for?",
          "options": [
            "Large files",
            "Representing integers larger than Number.MAX_SAFE_INTEGER",
            "Performance",
            "Binary operations"
          ],
          "correctAnswer": 1,
          "explanation": "BigInt is a numeric primitive that can represent integers with arbitrary precision, beyond the safe integer limit of Number (2^53 - 1). Created with n suffix or BigInt()."
        },
        {
          "id": 62,
          "question": "What does Array.prototype.flat() do?",
          "options": [
            "Removes duplicates",
            "Flattens nested arrays into single-level array",
            "Sorts array",
            "Removes falsy values"
          ],
          "correctAnswer": 1,
          "explanation": "flat() creates a new array with all sub-array elements concatenated into it recursively up to specified depth. Default depth is 1. flat(Infinity) flattens all levels."
        },
        {
          "id": 63,
          "question": "What is the optional chaining operator (?.)? ",
          "options": [
            "Ternary operator",
            "Safely accesses nested properties without checking each level",
            "Question mark operator",
            "Comparison operator"
          ],
          "correctAnswer": 1,
          "explanation": "Optional chaining (?.) allows reading value of property deep within object chain without validating each reference. Returns undefined if reference is nullish instead of throwing error."
        },
        {
          "id": 64,
          "question": "What does the nullish coalescing operator (??) do?",
          "options": [
            "Checks null values",
            "Returns right operand when left is null or undefined",
            "Creates null values",
            "Compares null and undefined"
          ],
          "correctAnswer": 1,
          "explanation": "Nullish coalescing (??) returns right operand when left is null or undefined (not other falsy values like 0 or ''). Different from || which checks all falsy values."
        },
        {
          "id": 65,
          "question": "What is the difference between undefined and not defined?",
          "options": [
            "Same thing",
            "undefined is a value, not defined means variable doesn't exist",
            "undefined is an error",
            "not defined is deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "undefined is a primitive value assigned to declared variables with no value. 'not defined' (ReferenceError) occurs when trying to access a variable that hasn't been declared."
        },
        {
          "id": 66,
          "question": "What does String.prototype.split() return?",
          "options": [
            "Split strings",
            "Array of strings split at specified delimiter",
            "Number of parts",
            "Modified string"
          ],
          "correctAnswer": 1,
          "explanation": "split() divides a string into an ordered list of substrings based on a delimiter (string or regex), returning these substrings as an array."
        },
        {
          "id": 67,
          "question": "What is the purpose of WeakSet?",
          "options": [
            "Small sets",
            "Set with weak object references allowing garbage collection",
            "Set with limited size",
            "Deprecated structure"
          ],
          "correctAnswer": 1,
          "explanation": "WeakSet is a collection of objects (only) with weak references. Objects can be garbage collected if no other references exist. No size property, not iterable."
        },
        {
          "id": 68,
          "question": "What does Number.isInteger() do?",
          "options": [
            "Converts to integer",
            "Checks if value is an integer",
            "Rounds number",
            "Counts digits"
          ],
          "correctAnswer": 1,
          "explanation": "Number.isInteger() determines whether the passed value is an integer. Returns true for integers, false for floats, NaN, Infinity, and non-numbers."
        },
        {
          "id": 69,
          "question": "What is the difference between parameters and arguments?",
          "options": [
            "No difference",
            "Parameters are in function definition, arguments are actual values passed",
            "Parameters are deprecated",
            "Arguments are global"
          ],
          "correctAnswer": 1,
          "explanation": "Parameters are variables in function definition. Arguments are the actual values passed to function when called. function fn(param) { } vs fn(argument)."
        },
        {
          "id": 70,
          "question": "What does Object.values() return?",
          "options": [
            "Object keys",
            "Array of object's own enumerable property values",
            "Number of properties",
            "Object copy"
          ],
          "correctAnswer": 1,
          "explanation": "Object.values() returns an array of a given object's own enumerable property values, in the same order as for...in loop (but without prototype properties)."
        },
        {
          "id": 71,
          "question": "What is tail call optimization?",
          "options": [
            "Array optimization",
            "Optimization where recursive function call in tail position reuses stack frame",
            "String optimization",
            "Loop optimization"
          ],
          "correctAnswer": 1,
          "explanation": "Tail call optimization allows recursive function to reuse same stack frame when function call is in tail position (last operation), preventing stack overflow."
        },
        {
          "id": 72,
          "question": "What does Array.prototype.includes() do?",
          "options": [
            "Adds elements",
            "Checks if array includes certain value, returns boolean",
            "Merges arrays",
            "Counts occurrences"
          ],
          "correctAnswer": 1,
          "explanation": "includes() determines whether an array includes a certain value among its entries, returning true or false. More readable than indexOf() !== -1."
        },
        {
          "id": 73,
          "question": "What is a higher-order function?",
          "options": [
            "Complex function",
            "Function that takes function as argument or returns function",
            "Fast function",
            "Built-in function"
          ],
          "correctAnswer": 1,
          "explanation": "Higher-order function takes one or more functions as arguments or returns a function. Examples: map, filter, reduce. Enables functional programming patterns."
        },
        {
          "id": 74,
          "question": "What does String.prototype.repeat() do?",
          "options": [
            "Finds repeated characters",
            "Returns string repeated specified number of times",
            "Removes repeated characters",
            "Counts repetitions"
          ],
          "correctAnswer": 1,
          "explanation": "repeat() constructs and returns a new string containing specified number of copies of the string on which it was called, concatenated together."
        },
        {
          "id": 75,
          "question": "What is the difference between for...in and for...of?",
          "options": [
            "No difference",
            "for...in iterates enumerable properties, for...of iterates iterable values",
            "for...of is deprecated",
            "for...in is faster"
          ],
          "correctAnswer": 1,
          "explanation": "for...in loops over enumerable property names (including inherited). for...of loops over values of iterable objects (Arrays, Maps, Sets, etc.)."
        },
        {
          "id": 76,
          "question": "What does Object.entries() return?",
          "options": [
            "Object keys",
            "Array of object's [key, value] pairs",
            "Entry count",
            "Object values"
          ],
          "correctAnswer": 1,
          "explanation": "Object.entries() returns an array of a given object's own enumerable property [key, value] pairs. Useful for iterating or converting to Map."
        },
        {
          "id": 77,
          "question": "What is a Proxy in JavaScript?",
          "options": [
            "Network proxy",
            "Object that wraps another object to intercept operations",
            "Design pattern",
            "Security feature"
          ],
          "correctAnswer": 1,
          "explanation": "Proxy creates a wrapper around object allowing you to intercept and customize fundamental operations (property lookup, assignment, enumeration, function invocation, etc.)."
        },
        {
          "id": 78,
          "question": "What does String.prototype.padStart() do?",
          "options": [
            "Removes padding",
            "Pads string from start with another string until target length",
            "Aligns text",
            "Adds prefix"
          ],
          "correctAnswer": 1,
          "explanation": "padStart() pads the current string with another string (repeated if needed) from the start until the resulting string reaches the given length."
        },
        {
          "id": 79,
          "question": "What is the Reflect API?",
          "options": [
            "Reflection in mirrors",
            "Built-in object providing methods for interceptable JavaScript operations",
            "Debugging tool",
            "Performance monitor"
          ],
          "correctAnswer": 1,
          "explanation": "Reflect is built-in object providing methods for interceptable JavaScript operations. Similar to Proxy traps but as functions. Makes Object operations more functional."
        },
        {
          "id": 80,
          "question": "What does Array.prototype.findIndex() do?",
          "options": [
            "Finds all indexes",
            "Returns index of first element satisfying test function",
            "Counts elements",
            "Sorts by index"
          ],
          "correctAnswer": 1,
          "explanation": "findIndex() returns the index of the first element that satisfies the test function. Returns -1 if no element passes the test."
        },
        {
          "id": 81,
          "question": "What is the difference between shallow copy and deep copy?",
          "options": [
            "No difference",
            "Shallow copies references, deep copy creates independent copies",
            "Deep copy is faster",
            "Shallow copy is deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "Shallow copy copies only first level (nested objects are still referenced). Deep copy recursively copies all levels, creating completely independent objects."
        },
        {
          "id": 82,
          "question": "What does String.prototype.startsWith() do?",
          "options": [
            "Gets first character",
            "Checks if string starts with specified characters",
            "Removes start of string",
            "Adds prefix"
          ],
          "correctAnswer": 1,
          "explanation": "startsWith() determines whether a string begins with the characters of a specified string, returning true or false. Can specify start position."
        },
        {
          "id": 83,
          "question": "What is the Iterator protocol?",
          "options": [
            "Loop syntax",
            "Protocol defining standard way to produce sequence of values",
            "Array method",
            "Design pattern"
          ],
          "correctAnswer": 1,
          "explanation": "Iterator protocol defines standard way to produce sequence of values. Object is iterator when it implements next() method returning {value, done} object."
        },
        {
          "id": 84,
          "question": "What does Math.trunc() do?",
          "options": [
            "Rounds number",
            "Returns integer part by removing fractional digits",
            "Truncates string",
            "Limits range"
          ],
          "correctAnswer": 1,
          "explanation": "Math.trunc() returns integer part of number by removing any fractional digits. Different from Math.floor() for negative numbers. trunc(-1.5) = -1, floor(-1.5) = -2."
        },
        {
          "id": 85,
          "question": "What is the Intl object?",
          "options": [
            "Internet object",
            "Internationalization API for language-sensitive operations",
            "Internal object",
            "Interface object"
          ],
          "correctAnswer": 1,
          "explanation": "Intl provides language-sensitive string comparison, number formatting, and date/time formatting. Includes DateTimeFormat, NumberFormat, Collator, etc."
        },
        {
          "id": 86,
          "question": "What does Array.prototype.copyWithin() do?",
          "options": [
            "Copies array",
            "Shallow copies part of array to another location in same array",
            "Duplicates elements",
            "Creates array copy"
          ],
          "correctAnswer": 1,
          "explanation": "copyWithin() shallow copies part of array to another location in the same array without modifying its length. Modifies array in place."
        },
        {
          "id": 87,
          "question": "What is the difference between window and document?",
          "options": [
            "No difference",
            "window is global browser object, document is DOM representation",
            "document is newer",
            "window is deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "window is global browser object representing browser window. document is property of window representing DOM (Document Object Model) - the HTML page content."
        },
        {
          "id": 88,
          "question": "What does String.prototype.localeCompare() do?",
          "options": [
            "Compares lengths",
            "Compares strings according to locale, returns number",
            "Finds location",
            "Translates string"
          ],
          "correctAnswer": 1,
          "explanation": "localeCompare() compares strings according to locale (language/region) rules. Returns negative if before, positive if after, 0 if equal. Handles special characters properly."
        },
        {
          "id": 89,
          "question": "What is the purpose of void operator?",
          "options": [
            "Creates empty space",
            "Evaluates expression and returns undefined",
            "Deletes variables",
            "Checks for void"
          ],
          "correctAnswer": 1,
          "explanation": "void operator evaluates expression and returns undefined. Often used with void 0 to get undefined value safely, or in href=\"javascript:void(0)\" to prevent navigation."
        },
        {
          "id": 90,
          "question": "What does Number.parseFloat() do?",
          "options": [
            "Creates float",
            "Parses string and returns floating point number",
            "Checks if float",
            "Converts to integer"
          ],
          "correctAnswer": 1,
          "explanation": "Number.parseFloat() (or global parseFloat()) parses string argument and returns floating point number. Stops parsing at first non-numeric character."
        },
        {
          "id": 91,
          "question": "What is a tagged template literal?",
          "options": [
            "HTML template",
            "Function that processes template literal, receiving parts and values",
            "String with tags",
            "Labeled template"
          ],
          "correctAnswer": 1,
          "explanation": "Tagged template literal is advanced form where function processes template literal. Function receives array of string parts and values, can return formatted result."
        },
        {
          "id": 92,
          "question": "What does Object.getOwnPropertyNames() return?",
          "options": [
            "All property names",
            "Array of all own property names including non-enumerable",
            "Enumerable properties only",
            "Inherited properties"
          ],
          "correctAnswer": 1,
          "explanation": "Object.getOwnPropertyNames() returns array of all own property names (including non-enumerable) found directly on object, excluding Symbol properties and inherited."
        },
        {
          "id": 93,
          "question": "What is the instanceof operator?",
          "options": [
            "Creates instances",
            "Checks if object is instance of constructor/class",
            "Counts instances",
            "Compares instances"
          ],
          "correctAnswer": 1,
          "explanation": "instanceof tests whether object's prototype chain contains the prototype property of constructor. Returns true if object is instance of specified constructor."
        },
        {
          "id": 94,
          "question": "What does Array.prototype.fill() do?",
          "options": [
            "Fills array to capacity",
            "Fills array elements with static value from start to end index",
            "Removes empty slots",
            "Adds elements"
          ],
          "correctAnswer": 1,
          "explanation": "fill() fills all elements from start index to end index with static value. Modifies original array. Useful for initializing arrays with default values."
        },
        {
          "id": 95,
          "question": "What is the difference between innerHTML and textContent?",
          "options": [
            "No difference",
            "innerHTML parses HTML, textContent gets/sets text only",
            "textContent is deprecated",
            "innerHTML is faster"
          ],
          "correctAnswer": 1,
          "explanation": "innerHTML gets/sets HTML content (parses tags). textContent gets/sets text content only (treats tags as text). textContent is faster and safer against XSS."
        },
        {
          "id": 96,
          "question": "What does String.prototype.match() return?",
          "options": [
            "Boolean",
            "Array of matches or null if no match",
            "Match count",
            "Matched string only"
          ],
          "correctAnswer": 1,
          "explanation": "match() retrieves result of matching string against regular expression. Returns array of matches (with capture groups) or null if no match found."
        },
        {
          "id": 97,
          "question": "What is the globalThis object?",
          "options": [
            "Global variable",
            "Standard way to access global 'this' across environments",
            "Window object",
            "Module scope"
          ],
          "correctAnswer": 1,
          "explanation": "globalThis provides standard way to access global 'this' value (global object) across different environments (browser: window, Node: global, workers: self)."
        },
        {
          "id": 98,
          "question": "What does Array.of() do?",
          "options": [
            "Gets elements of array",
            "Creates new array from arguments regardless of type or number",
            "Checks array type",
            "Converts to array"
          ],
          "correctAnswer": 1,
          "explanation": "Array.of() creates new Array instance from variable number of arguments, regardless of type. Difference from Array constructor: Array.of(5) creates [5], Array(5) creates empty array length 5."
        },
        {
          "id": 99,
          "question": "What is the purpose of Object.seal()?",
          "options": [
            "Encrypts object",
            "Prevents adding/removing properties but allows modifying existing ones",
            "Makes object immutable",
            "Closes object"
          ],
          "correctAnswer": 1,
          "explanation": "Object.seal() prevents adding new properties or deleting existing ones. Existing properties can still be modified. Less restrictive than freeze(), more than preventExtensions()."
        },
        {
          "id": 100,
          "question": "What does String.prototype.replace() do?",
          "options": [
            "Removes characters",
            "Returns new string with pattern replaced",
            "Modifies original string",
            "Finds and counts"
          ],
          "correctAnswer": 1,
          "explanation": "replace() returns new string with some or all matches of pattern replaced by replacement. Doesn't modify original. Use replaceAll() for all occurrences or regex with g flag."
        },
        {
          "id": 101,
          "question": "What is the output? const { a = 1 } = { a: undefined }; console.log(a);",
          "options": [
            "1",
            "undefined",
            "null",
            "Throws error"
          ],
          "correctAnswer": 0,
          "explanation": "Default value is applied when property value is undefined."
        },
        {
          "id": 102,
          "question": "Which syntax renames a destructured property?",
          "options": [
            "const { name => userName } = user",
            "const { name as userName } = user",
            "const { name: userName } = user",
            "const { userName: name } = user"
          ],
          "correctAnswer": 2,
          "explanation": "Property rename syntax is { sourceKey: localVariableName }."
        },
        {
          "id": 103,
          "question": "Output of: const {x=2} = {x:null}; console.log(x);",
          "options": [
            "2",
            "null",
            "undefined",
            "0"
          ],
          "correctAnswer": 1,
          "explanation": "Defaults apply only for undefined, not for null."
        },
        {
          "id": 104,
          "question": "What is true for object spread {...obj}?",
          "options": [
            "Deep copy",
            "Shallow copy",
            "Reference copy only",
            "Always immutable recursively"
          ],
          "correctAnswer": 1,
          "explanation": "Object spread clones only top-level properties."
        },
        {
          "id": 105,
          "question": "Output: const a=[1,2]; const b=[...a]; a.push(3); console.log(b.length);",
          "options": [
            "2",
            "3",
            "0",
            "Throws"
          ],
          "correctAnswer": 0,
          "explanation": "b is a new array copy; later push on a does not affect b length."
        },
        {
          "id": 106,
          "question": "Rest parameter in function signature collects values into:",
          "options": [
            "Object",
            "Set",
            "Array",
            "Promise"
          ],
          "correctAnswer": 2,
          "explanation": "Rest syntax (...args) collects remaining args into an array."
        },
        {
          "id": 107,
          "question": "Object.entries(obj) returns:",
          "options": [
            "Array of keys",
            "Array of values",
            "Array of [key, value] pairs",
            "Map instance"
          ],
          "correctAnswer": 2,
          "explanation": "entries returns key-value tuple array."
        },
        {
          "id": 108,
          "question": "Output: Object.keys({2:\"b\",1:\"a\",x:\"c\"})[0] ?",
          "options": [
            "2",
            "1",
            "x",
            "undefined"
          ],
          "correctAnswer": 1,
          "explanation": "Numeric-like keys are ordered ascending, so 1 comes first."
        },
        {
          "id": 109,
          "question": "Which method gives only own enumerable values?",
          "options": [
            "for...in",
            "Object.values",
            "Reflect.ownKeys",
            "Object.getOwnPropertyNames"
          ],
          "correctAnswer": 1,
          "explanation": "Object.values returns own enumerable property values."
        },
        {
          "id": 110,
          "question": "Array.map callback should return:",
          "options": [
            "Boolean only",
            "New transformed value for each element",
            "Nothing",
            "Promise always"
          ],
          "correctAnswer": 1,
          "explanation": "map transforms each element and returns a new array."
        },
        {
          "id": 111,
          "question": "Output: [1,2,3].map(n=>{ n*2 })",
          "options": [
            "[2,4,6]",
            "[undefined,undefined,undefined]",
            "[]",
            "Error"
          ],
          "correctAnswer": 1,
          "explanation": "With braces, explicit return is required."
        },
        {
          "id": 112,
          "question": "map mutates original array by default?",
          "options": [
            "Always",
            "Never",
            "Only in strict mode",
            "Only for numbers"
          ],
          "correctAnswer": 1,
          "explanation": "map returns new array; source is unchanged unless callback mutates nested references."
        },
        {
          "id": 113,
          "question": "Output: [0,1,2].filter(Boolean)",
          "options": [
            "[0,1,2]",
            "[1,2]",
            "[0,2]",
            "[]"
          ],
          "correctAnswer": 1,
          "explanation": "Boolean removes falsy values, including 0."
        },
        {
          "id": 114,
          "question": "filter callback should return:",
          "options": [
            "Transformed value",
            "Truthy/falsy decision",
            "Index only",
            "Accumulator"
          ],
          "correctAnswer": 1,
          "explanation": "filter keeps elements where callback result is truthy."
        },
        {
          "id": 115,
          "question": "Which is better when you need just first match?",
          "options": [
            "filter",
            "map",
            "find",
            "reduce"
          ],
          "correctAnswer": 2,
          "explanation": "find short-circuits at first match."
        },
        {
          "id": 116,
          "question": "find returns what when not found?",
          "options": [
            "-1",
            "null",
            "undefined",
            "false"
          ],
          "correctAnswer": 2,
          "explanation": "find returns undefined for no match."
        },
        {
          "id": 117,
          "question": "Output: [4,8,12].findIndex(n=>n>10)",
          "options": [
            "2",
            "1",
            "-1",
            "12"
          ],
          "correctAnswer": 0,
          "explanation": "12 is at index 2."
        },
        {
          "id": 118,
          "question": "find vs findIndex difference?",
          "options": [
            "Same return type",
            "find returns item, findIndex returns position",
            "findIndex is async",
            "find mutates array"
          ],
          "correctAnswer": 1,
          "explanation": "find gives element; findIndex gives numeric index."
        },
        {
          "id": 119,
          "question": "What does reduce require for safe empty-array handling?",
          "options": [
            "sort first",
            "initial accumulator value",
            "map first",
            "no callback"
          ],
          "correctAnswer": 1,
          "explanation": "Provide initial value to avoid TypeError on empty arrays."
        },
        {
          "id": 120,
          "question": "Output: [1,2,3].reduce((a,b)=>a+b)",
          "options": [
            "3",
            "5",
            "6",
            "Error"
          ],
          "correctAnswer": 2,
          "explanation": "Without initial value, accumulator starts at first element, result is 6."
        },
        {
          "id": 121,
          "question": "Best structure for frequency counter with reduce?",
          "options": [
            "Array accumulator",
            "Object/Map accumulator",
            "Boolean accumulator",
            "String accumulator"
          ],
          "correctAnswer": 1,
          "explanation": "Object or Map is typical for key-count aggregation."
        },
        {
          "id": 122,
          "question": "Currying converts f(a,b) into:",
          "options": [
            "f(a+b)",
            "f(a)(b)",
            "f([a,b])",
            "f(a,b,c)"
          ],
          "correctAnswer": 1,
          "explanation": "Curried function takes one argument per invocation chain."
        },
        {
          "id": 123,
          "question": "Output: const add=a=>b=>a+b; add(1)(4)",
          "options": [
            "5",
            "14",
            "undefined",
            "NaN"
          ],
          "correctAnswer": 0,
          "explanation": "First call captures a=1, second adds b=4."
        },
        {
          "id": 124,
          "question": "Main advantage of currying in interviews?",
          "options": [
            "Less memory always",
            "Enables partial application and composability",
            "Faster runtime always",
            "Avoids closures"
          ],
          "correctAnswer": 1,
          "explanation": "Currying improves reusability/composition patterns."
        },
        {
          "id": 125,
          "question": "Promise callback queue runs in:",
          "options": [
            "Macro task queue only",
            "Microtask queue",
            "Call stack directly",
            "Render queue"
          ],
          "correctAnswer": 1,
          "explanation": "then/catch callbacks run in microtask queue after current stack."
        },
        {
          "id": 126,
          "question": "Output order: Promise.resolve().then(()=>console.log(\"A\")); console.log(\"B\")",
          "options": [
            "A then B",
            "B then A",
            "Only A",
            "Only B"
          ],
          "correctAnswer": 1,
          "explanation": "Synchronous log runs first, then microtask callback."
        },
        {
          "id": 127,
          "question": "How to propagate value to next then?",
          "options": [
            "throw value",
            "return value",
            "console.log value",
            "setTimeout value"
          ],
          "correctAnswer": 1,
          "explanation": "Return statement passes resolution value through chain."
        },
        {
          "id": 128,
          "question": "async function always returns:",
          "options": [
            "Plain value",
            "Promise",
            "Generator",
            "Observable"
          ],
          "correctAnswer": 1,
          "explanation": "async wraps return value into resolved Promise."
        },
        {
          "id": 129,
          "question": "Output: async function f(){return 3}; f() instanceof Promise",
          "options": [
            "true",
            "false",
            "undefined",
            "throws"
          ],
          "correctAnswer": 0,
          "explanation": "All async functions return Promise instances."
        },
        {
          "id": 130,
          "question": "Best way to run independent async calls together?",
          "options": [
            "await in loop",
            "Promise.all with await",
            "Nested try blocks",
            "setInterval"
          ],
          "correctAnswer": 1,
          "explanation": "Promise.all provides concurrent execution for independent tasks."
        },
        {
          "id": 131,
          "question": "Promise.allSettled returns:",
          "options": [
            "First success only",
            "Array of status/result for each promise",
            "Single boolean",
            "Throws always"
          ],
          "correctAnswer": 1,
          "explanation": "allSettled never short-circuits and reports each promise state."
        },
        {
          "id": 132,
          "question": "Output: await Promise.all([Promise.resolve(1), Promise.resolve(2)])",
          "options": [
            "1",
            "2",
            "[1,2]",
            "undefined"
          ],
          "correctAnswer": 2,
          "explanation": "all resolves to array of values in input order."
        },
        {
          "id": 133,
          "question": "Promise.race is best for:",
          "options": [
            "Collecting all errors",
            "Timeout/fallback fastest-response patterns",
            "Sorting promises",
            "Retry logic only"
          ],
          "correctAnswer": 1,
          "explanation": "race settles with first settled promise."
        },
        {
          "id": 134,
          "question": "Debounce primarily optimizes:",
          "options": [
            "One-time startup code",
            "High-frequency burst events",
            "CPU threads",
            "Memory allocation only"
          ],
          "correctAnswer": 1,
          "explanation": "Debounce reduces redundant calls during rapid event bursts."
        },
        {
          "id": 135,
          "question": "In trailing debounce, function executes when:",
          "options": [
            "Event starts",
            "Cooldown starts",
            "Silence window completes",
            "Every interval"
          ],
          "correctAnswer": 2,
          "explanation": "Trailing debounce fires after no new events for delay duration."
        },
        {
          "id": 136,
          "question": "Output: debounced fn called 5 times quickly with delay 200ms; how many executions (trailing only)?",
          "options": [
            "0",
            "1",
            "5",
            "Depends but never 1"
          ],
          "correctAnswer": 1,
          "explanation": "Rapid calls collapse into one final trailing invocation."
        },
        {
          "id": 137,
          "question": "Throttle ensures:",
          "options": [
            "Only last call runs",
            "At most one call per interval",
            "No dropped calls ever",
            "Infinite retries"
          ],
          "correctAnswer": 1,
          "explanation": "Throttle rate-limits execution frequency."
        },
        {
          "id": 138,
          "question": "Best use case for throttle:",
          "options": [
            "Submit button once",
            "Scroll position updates",
            "Build-time transpilation",
            "Static data parse"
          ],
          "correctAnswer": 1,
          "explanation": "Scroll/mousemove need periodic updates, not every event."
        },
        {
          "id": 139,
          "question": "Output style question: throttle 1000ms with leading true over 2500ms continuous events gives approximately:",
          "options": [
            "1 call",
            "2-3 calls",
            "10 calls",
            "2500 calls"
          ],
          "correctAnswer": 1,
          "explanation": "Execution count depends on implementation, usually around 3 with leading/trailing options."
        },
        {
          "id": 140,
          "question": "Output: const {a=1} = {a:null}; console.log(a);",
          "options": [
            "1",
            "null",
            "undefined",
            "Error"
          ],
          "correctAnswer": 1,
          "explanation": "Default is not used for null; only for undefined."
        },
        {
          "id": 141,
          "question": "Output: const [x=3,y=4] = [undefined,2]; console.log(x+y);",
          "options": [
            "5",
            "6",
            "7",
            "NaN"
          ],
          "correctAnswer": 0,
          "explanation": "x defaults to 3, y is 2, total is 5."
        },
        {
          "id": 142,
          "question": "Which is safest function signature for destructuring optional arg?",
          "options": [
            "function f({a}){}",
            "function f(obj){const {a}=obj}",
            "function f({a} = {}){}",
            "function f(...a){}"
          ],
          "correctAnswer": 2,
          "explanation": "Default empty object prevents crash when arg is missing."
        },
        {
          "id": 143,
          "question": "What does const {a: alias} = obj do?",
          "options": [
            "Creates key alias in obj",
            "Renames extracted variable only",
            "Deletes a from obj",
            "Creates deep copy"
          ],
          "correctAnswer": 1,
          "explanation": "It renames local variable, not object key."
        },
        {
          "id": 144,
          "question": "Output: let a=1,b=2; [a,b]=[b,a]; console.log(a,b);",
          "options": [
            "1 2",
            "2 1",
            "undefined undefined",
            "Error"
          ],
          "correctAnswer": 1,
          "explanation": "Array destructuring swap works without temp variable."
        },
        {
          "id": 145,
          "question": "Output: const a=[1,[2]]; const b=[...a]; b[1][0]=9; console.log(a[1][0]);",
          "options": [
            "2",
            "9",
            "undefined",
            "Error"
          ],
          "correctAnswer": 1,
          "explanation": "Nested array reference is shared because spread is shallow."
        },
        {
          "id": 146,
          "question": "What is true for rest in objects?",
          "options": [
            "Collects inherited properties too",
            "Collects remaining own enumerable properties",
            "Creates deep clone",
            "Works only on arrays"
          ],
          "correctAnswer": 1,
          "explanation": "Object rest collects remaining own enumerable properties."
        },
        {
          "id": 147,
          "question": "Output: function g(...x){return x[0]+x[2]} console.log(g(1,2,3));",
          "options": [
            "3",
            "4",
            "5",
            "6"
          ],
          "correctAnswer": 1,
          "explanation": "x[0]=1 and x[2]=3 => 4."
        },
        {
          "id": 148,
          "question": "Which operation is immutable?",
          "options": [
            "arr.push(x)",
            "[...arr, x]",
            "obj.a=2",
            "delete obj.a"
          ],
          "correctAnswer": 1,
          "explanation": "Spread creates a new array rather than mutating original."
        },
        {
          "id": 149,
          "question": "Output: const o={a:1}; const p={...o}; o.a=5; console.log(p.a);",
          "options": [
            "1",
            "5",
            "undefined",
            "Error"
          ],
          "correctAnswer": 0,
          "explanation": "Primitive value copied at spread time; later mutation on o does not change p.a."
        },
        {
          "id": 150,
          "question": "Output: Object.keys({a:1,b:2}).length",
          "options": [
            "0",
            "1",
            "2",
            "3"
          ],
          "correctAnswer": 2,
          "explanation": "Two own enumerable keys exist."
        },
        {
          "id": 151,
          "question": "Output: Object.fromEntries([[\"x\",10],[\"y\",20]]).y",
          "options": [
            "10",
            "20",
            "undefined",
            "Error"
          ],
          "correctAnswer": 1,
          "explanation": "fromEntries reconstructs object with provided pairs."
        },
        {
          "id": 152,
          "question": "Best method to transform object values and rebuild object?",
          "options": [
            "Object.keys only",
            "Object.values only",
            "Object.entries + map + Object.fromEntries",
            "JSON.stringify"
          ],
          "correctAnswer": 2,
          "explanation": "Entries pipeline is idiomatic and explicit for object transforms."
        },
        {
          "id": 153,
          "question": "Output: const o=Object.create({z:9}); o.a=1; console.log(Object.keys(o));",
          "options": [
            "[\"a\",\"z\"]",
            "[\"z\"]",
            "[\"a\"]",
            "[]"
          ],
          "correctAnswer": 2,
          "explanation": "Object.keys excludes inherited prototype keys."
        },
        {
          "id": 154,
          "question": "Which includes symbol keys?",
          "options": [
            "Object.keys",
            "Object.entries",
            "Reflect.ownKeys",
            "Object.values"
          ],
          "correctAnswer": 2,
          "explanation": "Reflect.ownKeys returns all own keys including symbols."
        },
        {
          "id": 155,
          "question": "Throttle best use-case?",
          "options": [
            "Typing search input",
            "Continuous scroll updates",
            "One-time init",
            "Static config load"
          ],
          "correctAnswer": 1,
          "explanation": "Throttle is ideal for frequent continuous events like scroll/resize."
        },
        {
          "id": 156,
          "question": "In throttle, if events fire faster than interval, calls are:",
          "options": [
            "All executed",
            "Rate-limited",
            "Queued forever",
            "Converted to promises"
          ],
          "correctAnswer": 1,
          "explanation": "Throttle limits execution frequency."
        },
        {
          "id": 157,
          "question": "String methods mutate original string?",
          "options": [
            "Yes",
            "No",
            "Only slice mutates",
            "Only replace mutates"
          ],
          "correctAnswer": 1,
          "explanation": "Strings are immutable in JavaScript."
        },
        {
          "id": 158,
          "question": "Output: \"Hello\".slice(1,4)",
          "options": [
            "ell",
            "ello",
            "Hel",
            "ll"
          ],
          "correctAnswer": 0,
          "explanation": "slice extracts from index 1 up to (not including) 4."
        },
        {
          "id": 159,
          "question": "Arrow function has its own this?",
          "options": [
            "Yes",
            "No",
            "Only in strict mode",
            "Only in classes"
          ],
          "correctAnswer": 1,
          "explanation": "Arrow functions lexically inherit this."
        },
        {
          "id": 160,
          "question": "Which invokes function immediately with provided this?",
          "options": [
            "bind",
            "call",
            "freeze",
            "map"
          ],
          "correctAnswer": 1,
          "explanation": "call invokes immediately; bind returns a new bound function."
        },
        {
          "id": 161,
          "question": "localStorage value type is:",
          "options": [
            "Any JSON type directly",
            "String only",
            "Number only",
            "Object only"
          ],
          "correctAnswer": 1,
          "explanation": "Storage APIs store string values."
        },
        {
          "id": 162,
          "question": "sessionStorage scope is:",
          "options": [
            "Shared across all tabs forever",
            "Current tab/session",
            "Server-side only",
            "Global system"
          ],
          "correctAnswer": 1,
          "explanation": "sessionStorage is scoped to tab session."
        },
        {
          "id": 163,
          "question": "Best way to store object in localStorage?",
          "options": [
            "setItem(key, obj)",
            "setItem(key, JSON.stringify(obj))",
            "setItem(key, obj.toString())",
            "Not possible"
          ],
          "correctAnswer": 1,
          "explanation": "Serialize objects with JSON.stringify."
        }
      ],
      "topicCount": 26,
      "quizCount": 163
    },
    {
      "slug": "kubernetes",
      "meta": {
        "title": "Kubernetes Interview Preparation",
        "description": "Cover Kubernetes architecture, workloads, networking, and operational troubleshooting in an interview-first format."
      },
      "topics": [
        {
          "id": "pods",
          "title": "Pods",
          "category": "Kubernetes Basics",
          "description": "The smallest deployable unit in Kubernetes. A pod runs one or more containers.",
          "explanation": "Pods are the atomic unit of deployment in Kubernetes - they represent one or more tightly coupled containers that share networking, storage, and lifecycle. Understanding pod lifecycle phases, container restart policies, init containers, and multi-container patterns (sidecar, ambassador, adapter) is fundamental.\n\nInterview focus:\n- Pod lifecycle and phases (Pending, Running, Succeeded, Failed, Unknown)\n- Container restart policies (Always, OnFailure, Never)\n- Multi-container patterns and communication\n- Pod networking (localhost communication, shared volumes)\n- Init containers vs sidecar containers\n- Resource requests vs limits and QoS classes\n- Pod affinity and anti-affinity\n- Troubleshooting CrashLoopBackOff, ImagePullBackOff, OOMKilled",
          "code": "# pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\n  labels:\n    app: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:latest\n    ports:\n    - containerPort: 80\n    resources:\n      requests:\n        memory: \"64Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"128Mi\"\n        cpu: \"500m\"",
          "command": "# Create pod from YAML\nkubectl apply -f pod.yaml\n\n# List pods\nkubectl get pods\nkubectl get pods -o wide\n\n# Describe pod details\nkubectl describe pod nginx-pod\n\n# View pod logs\nkubectl logs nginx-pod\n\n# Execute command in pod\nkubectl exec -it nginx-pod -- bash\n\n# Delete pod\nkubectl delete pod nginx-pod\n\n# Delete pod immediately\nkubectl delete pod nginx-pod --force --grace-period=0",
          "example": "# Multi-container pod\napiVersion: v1\nkind: Pod\nmetadata:\n  name: multi-container-pod\nspec:\n  containers:\n  - name: app\n    image: myapp:latest\n    ports:\n    - containerPort: 8080\n  - name: sidecar\n    image: logging-agent:latest\n\n# Pod with environment variables\nspec:\n  containers:\n  - name: app\n    image: myapp:latest\n    env:\n    - name: DATABASE_URL\n      value: \"postgres://db:5432\"\n    - name: SECRET_KEY\n      valueFrom:\n        secretKeyRef:\n          name: app-secret\n          key: secret-key",
          "useCase": "Running applications, debugging, sidecar patterns, init containers",
          "interviewQuestions": [
            {
              "question": "What is a Pod and why is it the basic unit in Kubernetes?",
              "answer": "A Pod is the smallest deployable unit that can contain one or more containers sharing the same network namespace, IP address, and storage volumes. It's the basic unit because Kubernetes doesn't manage containers directly - it schedules, scales, and manages Pods. Containers in a Pod can communicate via localhost and share volumes."
            },
            {
              "question": "Explain Pod lifecycle phases. What does Pending mean vs Running?",
              "answer": "Phases: Pending (accepted but not scheduled/images pulling), Running (bound to node, at least one container running), Succeeded (all containers terminated successfully), Failed (terminated with failure), Unknown (can't determine state). Pending often indicates scheduling issues or image pull problems."
            },
            {
              "question": "What is the difference between container restartPolicy: Always, OnFailure, and Never?",
              "answer": "Always: restart regardless of exit code (typical for long-running apps). OnFailure: restart only on non-zero exit (jobs/batch). Never: never restart (one-time tasks). Default is Always. Policy applies to all containers in the Pod."
            },
            {
              "question": "What is CrashLoopBackOff and how do you debug it?",
              "answer": "Container repeatedly crashes and restarts with exponential backoff delay. Debug: kubectl logs pod-name, kubectl logs pod-name --previous (previous crash), kubectl describe pod (events), check application errors, verify image, check resource limits, liveness/readiness probes."
            },
            {
              "question": "What are Init Containers and how do they differ from regular containers?",
              "answer": "Init containers run before app containers, run to completion sequentially, must succeed before app starts. Uses: wait for services, setup/config, security checks. Regular containers run in parallel continuously. Init containers don't support liveness/readiness probes."
            },
            {
              "question": "How do containers in the same Pod communicate with each other?",
              "answer": "Via localhost since they share network namespace. Example: container A on port 8080, container B can reach it at localhost:8080. They also share volumes for file-based communication. No service needed for intra-pod communication."
            },
            {
              "question": "What is the difference between resource requests and limits?",
              "answer": "Requests: guaranteed resources, used for scheduling decisions (node must have this available). Limits: maximum allowed, container throttled (CPU) or killed (memory) if exceeded. QoS classes: Guaranteed (requests=limits), Burstable (has limits), BestEffort (no requests/limits)."
            },
            {
              "question": "What happens if a Pod exceeds its memory limit?",
              "answer": "Pod is OOMKilled (Out Of Memory). Container restarts based on restartPolicy. kubectl describe pod shows OOMKilled in last state. kubectl get events shows memory exceeded. Solution: increase memory limit, optimize app, check for memory leaks."
            },
            {
              "question": "Predict output: kubectl get pod mypod -o jsonpath='{.status.phase}'",
              "answer": "Returns pod phase as string: Pending, Running, Succeeded, Failed, or Unknown. Useful for scripting and automation to check pod state programmatically."
            },
            {
              "question": "What is the sidecar pattern and give a real-world example?",
              "answer": "Sidecar: additional container that enhances/extends main app container. Example: logging sidecar (Fluentd) reads app logs from shared volume and forwards to centralized logging. Other examples: service mesh proxy (Envoy/Istio), monitoring agent, config reloader."
            }
          ],
          "exercises": [
            {
              "type": "output",
              "question": "Pod has 2 containers. First exits with code 0, second with code 1. What is Pod phase?",
              "answer": "Failed - if ANY container fails, Pod phase is Failed (unless restartPolicy causes restart)."
            },
            {
              "type": "command",
              "question": "Get only pod names in current namespace",
              "answer": "kubectl get pods -o custom-columns=NAME:.metadata.name --no-headers"
            },
            {
              "type": "debug",
              "question": "Pod stuck in ImagePullBackOff. What are the top 3 causes?",
              "answer": "1) Image doesn't exist or wrong tag 2) No access to private registry (imagePullSecrets missing) 3) Network issues reaching registry. Check: kubectl describe pod, verify image name/tag, check registry credentials."
            },
            {
              "type": "scenario",
              "question": "Create pod that runs busybox, sleeps 3600s, with 100Mi memory limit",
              "answer": "kubectl run busybox --image=busybox --restart=Never --limits=memory=100Mi -- sleep 3600"
            },
            {
              "type": "tricky",
              "question": "Can two containers in same Pod bind to the same port?",
              "answer": "No! They share network namespace. Port conflict occurs. Use different ports or listen on different interfaces."
            },
            {
              "type": "output",
              "question": "kubectl logs mypod with 3 containers. What happens?",
              "answer": "Error: Must specify container with -c flag when pod has multiple containers. Example: kubectl logs mypod -c container-name"
            },
            {
              "type": "troubleshoot",
              "question": "Pod Running but app not accessible. How to investigate?",
              "answer": "1) kubectl exec -it pod -- curl localhost:port (test from inside) 2) Check service selector 3) Check readiness probe 4) kubectl logs 5) kubectl describe pod (events) 6) Verify exposed ports"
            },
            {
              "type": "command",
              "question": "View previous crashed container's logs",
              "answer": "kubectl logs pod-name -c container-name --previous"
            },
            {
              "type": "scenario",
              "question": "Pod needs to wait for database to be ready before starting. How?",
              "answer": "Use init container that checks DB connectivity (e.g., nc -z db-host 5432 or curl). Only starts app containers when init succeeds."
            },
            {
              "type": "tricky",
              "question": "Predict: Pod has restartPolicy: OnFailure. Container exits with code 0. Does it restart?",
              "answer": "No. OnFailure only restarts on non-zero exit code. Exit code 0 = success, no restart. Pod phase becomes Succeeded."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Create pod with 2 nginx containers, delete it imperatively",
              "code": "# This is tricky - can't have 2 containers with same name\nkubectl run pod1 --image=nginx --dry-run=client -o yaml > pod.yaml\n# Edit yaml to add second container\nkubectl apply -f pod.yaml\nkubectl delete pod pod1 --force --grace-period=0",
              "output": "Pod created with 2 containers, immediately deleted"
            },
            {
              "type": "program",
              "question": "Program 2: Multi-container pod - app on 8080, sidecar logger accessing shared volume",
              "code": "apiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: app-logger\\nspec:\\n  volumes:\\n  - name: shared-logs\\n    emptyDir: {}\\n  containers:\\n  - name: app\\n    image: busybox\\n    command: [\"sh\", \"-c\", \"while true; do echo $(date) >> /logs/app.log; sleep 5; done\"]\\n    volumeMounts:\\n    - name: shared-logs\\n      mountPath: /logs\\n  - name: logger\\n    image: busybox\\n    command: [\"sh\", \"-c\", \"tail -f /logs/app.log\"]\\n    volumeMounts:\\n    - name: shared-logs\\n      mountPath: /logs",
              "output": "App writes logs, sidecar reads and displays them continuously"
            },
            {
              "type": "program",
              "question": "Program 3: Pod with init container that waits for service to be available",
              "code": "apiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: myapp\\nspec:\\n  initContainers:\\n  - name: wait-for-db\\n    image: busybox\\n    command: ['sh', '-c', 'until nslookup db-service; do echo waiting for db; sleep 2; done']\\n  containers:\\n  - name: app\\n    image: nginx",
              "output": "Init waits for db-service DNS, then app container starts"
            },
            {
              "type": "program",
              "question": "Program 4: Create pod, check its IP, exec into it and curl itself",
              "code": "kubectl run testpod --image=nginx\\nPOD_IP=$(kubectl get pod testpod -o jsonpath='{.status.podIP}')\\necho $POD_IP\\nkubectl exec testpod -- curl -s localhost:80",
              "output": "Shows pod IP (e.g., 10.244.1.5), nginx welcome page from curl"
            },
            {
              "type": "program",
              "question": "Program 5: Trigger OOMKilled by exceeding memory limit",
              "code": "kubectl run oom-test --image=progrium/stress --limits=memory=50Mi -- --vm 1 --vm-bytes 100M\\nkubectl wait --for=condition=Ready pod/oom-test --timeout=30s\\nkubectl get pod oom-test\\nkubectl describe pod oom-test | grep -A 5 'Last State'",
              "output": "Pod shows OOMKilled, restarts repeatedly (CrashLoopBackOff)"
            },
            {
              "type": "program",
              "question": "Program 6: Extract all container names from a multi-container pod",
              "code": "kubectl get pod multi-pod -o jsonpath='{.spec.containers[*].name}'",
              "output": "app sidecar (space-separated list of containers, initContainers not included)"
            },
            {
              "type": "program",
              "question": "Program 7: Pod that exits successfully, verify Succeeded phase",
              "code": "kubectl run success-pod --image=busybox --restart=Never -- sh -c 'echo success && exit 0'\\nsleep 5\\nkubectl get pod success-pod -o jsonpath='{.status.phase}'",
              "output": "Succeeded"
            },
            {
              "type": "program",
              "question": "Program 8: Create pod with init container that waits for a service",
              "code": "kubectl apply -f - <<EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  name: init-demo\nspec:\n  initContainers:\n  - name: wait-for-svc\n    image: busybox\n    command: ['sh', '-c', 'until nslookup mydb; do echo waiting; sleep 2; done']\n  containers:\n  - name: app\n    image: nginx\nEOF\nkubectl get pod init-demo",
              "output": "Pod stuck in Init:0/1 until 'mydb' service is created, then transitions to Running"
            },
            {
              "type": "program",
              "question": "Program 9: Set resource requests and limits, check QoS class",
              "code": "kubectl run guaranteed --image=nginx --requests='cpu=100m,memory=128Mi' --limits='cpu=100m,memory=128Mi'\nkubectl get pod guaranteed -o jsonpath='{.status.qosClass}'",
              "output": "Guaranteed (requests == limits for all containers)"
            },
            {
              "type": "program",
              "question": "Program 10: Create multi-container pod, verify shared network namespace",
              "code": "kubectl apply -f - <<EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  name: shared-net\nspec:\n  containers:\n  - name: web\n    image: nginx\n    ports: [{containerPort: 80}]\n  - name: sidecar\n    image: busybox\n    command: ['sh', '-c', 'sleep 10 && wget -qO- localhost:80']\nEOF\nsleep 12\nkubectl logs shared-net -c sidecar",
              "output": "nginx welcome page HTML — sidecar accessed web container via localhost"
            }
          ]
        },
        {
          "id": "services",
          "title": "Services",
          "category": "Kubernetes Basics",
          "description": "Expose pods to network traffic with stable endpoints and load balancing.",
          "explanation": "Services provide stable networking endpoints for ephemeral Pods, enabling service discovery and load balancing. Understanding service types (ClusterIP, NodePort, LoadBalancer, ExternalName), endpoint management, and kube-proxy modes is essential for building distributed systems.\n\nInterview focus:\n- Service types and when to use each\n- Label selectors and endpoint selection\n- ClusterIP vs NodePort vs LoadBalancer\n- Headless services and StatefulSets\n- Session affinity and load balancing\n- DNS resolution (service-name.namespace.svc.cluster.local)\n- EndpointSlices vs Endpoints\n- kube-proxy modes (iptables, ipvs, userspace)",
          "code": "# service.yaml - ClusterIP (internal)\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-service\nspec:\n  selector:\n    app: nginx\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 80\n  type: ClusterIP\n\n# service-loadbalancer.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-lb\nspec:\n  selector:\n    app: nginx\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 80\n  type: LoadBalancer",
          "command": "# Create service\nkubectl apply -f service.yaml\n\n# List services\nkubectl get services\nkubectl get svc\n\n# Describe service\nkubectl describe service nginx-service\n\n# Get service endpoints\nkubectl get endpoints nginx-service\n\n# Delete service\nkubectl delete service nginx-service\n\n# Port forwarding for testing\nkubectl port-forward service/nginx-service 8080:80",
          "example": "# NodePort service (external access)\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-nodeport\nspec:\n  type: NodePort\n  selector:\n    app: nginx\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 80\n    nodePort: 30080\n\n# Headless service (for StatefulSets)\napiVersion: v1\nkind: Service\nmetadata:\n  name: mysql-headless\nspec:\n  clusterIP: None\n  selector:\n    app: mysql\n  ports:\n  - port: 3306",
          "useCase": "Service discovery, load balancing, exposing applications, networking",
          "interviewQuestions": [
            {
              "question": "Explain the 4 Service types and when to use each.",
              "answer": "ClusterIP (default): internal cluster access only, for backend services. NodePort: exposes on each node's IP at static port (30000-32767), for development/testing. LoadBalancer: cloud provider LB, for production external access. ExternalName: maps to external DNS, for integrating external services."
            },
            {
              "question": "How does a Service discover Pods? What happens if Pod labels change?",
              "answer": "Service uses selector to match Pod labels. Continuously watches for matching Pods, updates Endpoints automatically. If Pod labels change and no longer match, it's removed from Endpoints. If changed to match, it's added. Dynamic and real-time."
            },
            {
              "question": "What is a headless service and why use it?",
              "answer": "Service with clusterIP: None. No load balancing, DNS returns all Pod IPs instead of single VIP. Use for StatefulSets (stable network identity), client-side load balancing, peer discovery. Example: Cassandra, Kafka, databases needing direct pod access."
            },
            {
              "question": "Output: kubectl get svc mysvc shows CLUSTER-IP as <none>. What type is it?",
              "answer": "Headless service (clusterIP: None). Used for StatefulSets or when clients need direct pod IPs. DNS returns A records for each pod instead of single ClusterIP."
            },
            {
              "question": "Explain port, targetPort, and nodePort in Service spec.",
              "answer": "port: Service's exposed port (other pods use this). targetPort: Pod's container port (where traffic routes). nodePort: External port on nodes (30000-32767). Example: port:80, targetPort:8080 means service:80 → pod:8080."
            },
            {
              "question": "Service has selector app=web but no Endpoints. What are 3 possible reasons?",
              "answer": "1) No Pods with label app=web exist 2) Pods exist but not Ready (readiness probe failing) 3) Pods in different namespace (service and pods must be in same namespace) 4) Typo in selector or labels."
            },
            {
              "question": "What is sessionAffinity and when would you use it?",
              "answer": "Routes traffic from same client IP to same Pod. Values: None (default), ClientIP. Use for: stateful apps without shared storage, WebSocket connections, connection pooling. Only considers client IP, not cookies/headers."
            },
            {
              "question": "Tricky: Can a Service route to Pods in different namespaces?",
              "answer": "No. Services only route to Pods in the same namespace. Workaround: use ExternalName service or manual Endpoints to point to service in another namespace."
            },
            {
              "question": "How do you access a service from another namespace?",
              "answer": "Use FQDN: service-name.namespace.svc.cluster.local. Example: mysql.database.svc.cluster.local. Within same namespace, just service-name works. Cross-namespace requires full DNS name."
            },
            {
              "question": "What happens when LoadBalancer service is created in non-cloud environment?",
              "answer": "Stays in Pending state with no external IP assigned. Cloud controller manager handles LB provisioning. On-prem: use MetalLB, NodePort, or Ingress. kubectl get svc shows <pending> under EXTERNAL-IP."
            }
          ],
          "exercises": [
            {
              "type": "command",
              "question": "Create ClusterIP service exposing Pod on port 8080 imperatively",
              "answer": "kubectl expose pod mypod --port=8080 --name=mysvc"
            },
            {
              "type": "output",
              "question": "Service YAML has port:80, targetPort:8080. If you curl service:80, where does traffic go?",
              "answer": "Pod's container on port 8080. Service port 80 maps to pod container port 8080."
            },
            {
              "type": "scenario",
              "question": "Expose deployment with 3 replicas using NodePort on port 30001",
              "answer": "kubectl expose deployment myapp --type=NodePort --port=80 --target-port=8080 --node-port=30001"
            },
            {
              "type": "debug",
              "question": "Service created but can't reach pods. How to debug?",
              "answer": "1) kubectl get endpoints servicename (check if populated) 2) kubectl get pods --show-labels (verify labels match selector) 3) kubectl describe pod (check readiness) 4) Test pod directly: kubectl exec"
            },
            {
              "type": "tricky",
              "question": "Can two services select the same pods?",
              "answer": "Yes! Multiple services can select same pods with same labels. Use for: different ports, internal vs external access, canary routing with different selectors."
            },
            {
              "type": "command",
              "question": "Get DNS name for service mysql in namespace production",
              "answer": "mysql.production.svc.cluster.local"
            },
            {
              "type": "scenario",
              "question": "Create headless service for StatefulSet",
              "answer": "kubectl create service clusterip myapp --tcp=80:80 --clusterip=None"
            },
            {
              "type": "output",
              "question": "NodePort range in Kubernetes defaults?",
              "answer": "30000-32767. Can configure apiserver --service-node-port-range flag to change."
            },
            {
              "type": "troubleshoot",
              "question": "LoadBalancer service external IP shows <pending> for 10 minutes. Why?",
              "answer": "Not in cloud environment or cloud controller not configured. Check: kubectl get events, cloud provider integration, use NodePort or Ingress instead."
            },
            {
              "type": "command",
              "question": "Port forward local 8080 to service port 80",
              "answer": "kubectl port-forward svc/myservice 8080:80"
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Create deployment, expose as ClusterIP, test from another pod",
              "code": "kubectl create deployment web --image=nginx --replicas=2\nkubectl expose deployment web --port=80\nkubectl run test --image=busybox --rm -it -- wget -qO- web:80",
              "output": "Nginx welcome page HTML returned from service load-balanced across 2 pods"
            },
            {
              "type": "program",
              "question": "Program 2: Verify service selects pods by checking endpoints",
              "code": "kubectl create deployment app --image=nginx --replicas=3\nkubectl expose deployment app --port=80\nkubectl get endpoints app -o yaml\nkubectl get pods -l app=app -o wide",
              "output": "Endpoints show 3 pod IPs matching the 3 pod IPs from get pods"
            },
            {
              "type": "program",
              "question": "Program 3: Create NodePort service, access from outside cluster",
              "code": "kubectl create deployment np --image=nginx\nkubectl expose deployment np --type=NodePort --port=80\nNODE_PORT=$(kubectl get svc np -o jsonpath='{.spec.ports[0].nodePort}')\nNODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[0].address}')\ncurl http://$NODE_IP:$NODE_PORT",
              "output": "Nginx welcome page accessible via node IP and NodePort"
            },
            {
              "type": "program",
              "question": "Program 4: Test headless service returning all pod IPs",
              "code": "kubectl create deployment hl --image=nginx --replicas=3\nkubectl expose deployment hl --port=80 --cluster-ip=None\nkubectl run test --image=busybox --rm -it -- nslookup hl",
              "output": "DNS returns 3 A records with individual pod IPs, not single ClusterIP"
            },
            {
              "type": "program",
              "question": "Program 5: Service with no matching pods has empty endpoints",
              "code": "kubectl create service clusterip orphan --tcp=80:80\nkubectl get endpoints orphan\nkubectl get svc orphan",
              "output": "Service exists but endpoints show <none> (no matching pods)"
            },
            {
              "type": "program",
              "question": "Program 6: Test cross-namespace service access with FQDN",
              "code": "kubectl create namespace ns1\nkubectl create namespace ns2\nkubectl create deployment web -n ns1 --image=nginx\nkubectl expose deployment web -n ns1 --port=80\nkubectl run test -n ns2 --image=busybox --rm -it -- wget -qO- web.ns1.svc.cluster.local:80",
              "output": "Pod in ns2 successfully reaches service in ns1 using FQDN"
            },
            {
              "type": "program",
              "question": "Program 7: Session affinity routes same client to same pod",
              "code": "kubectl create deployment sticky --image=nginx --replicas=3\nkubectl expose deployment sticky --port=80\nkubectl patch svc sticky -p '{\"spec\":{\"sessionAffinity\":\"ClientIP\"}}'\nfor i in {1..5}; do kubectl run test-$i --image=busybox --rm --restart=Never -- wget -qO- sticky:80; done",
              "output": "Same client IP consistently routed to same pod (check pod names in logs)"
            },
            {
              "type": "program",
              "question": "Program 8: Create ExternalName service to alias an external DNS",
              "code": "kubectl create service externalname ext-db --external-name=db.example.com\nkubectl get svc ext-db -o jsonpath='{.spec.externalName}'",
              "output": "db.example.com — pods can access db.example.com via ext-db service name"
            },
            {
              "type": "program",
              "question": "Program 9: Verify service endpoints match running pods",
              "code": "kubectl create deployment ep-test --image=nginx --replicas=3\nkubectl expose deployment ep-test --port=80\nkubectl get endpoints ep-test\nkubectl get pods -l app=ep-test -o jsonpath='{.items[*].status.podIP}'",
              "output": "Endpoint IPs match pod IPs exactly — 3 addresses listed"
            },
            {
              "type": "program",
              "question": "Program 10: Test service DNS from within cluster",
              "code": "kubectl create deployment dns-test --image=nginx\nkubectl expose deployment dns-test --port=80\nkubectl run dnsutils --image=busybox --rm -it -- nslookup dns-test.default.svc.cluster.local",
              "output": "Name: dns-test.default.svc.cluster.local, Address: 10.x.x.x (ClusterIP)"
            }
          ]
        },
        {
          "id": "namespaces",
          "title": "Namespaces",
          "category": "Kubernetes Basics",
          "description": "Virtual clusters for organizing and isolating resources.",
          "explanation": "Namespaces provide logical isolation and resource organization within a cluster. They enable multi-tenancy, resource quotas, network policies, and RBAC. Understanding namespace scope, default namespaces, and cross-namespace communication is key for cluster management.\n\nInterview focus:\n- Default namespaces (default, kube-system, kube-public, kube-node-lease)\n- Namespace-scoped vs cluster-scoped resources\n- ResourceQuotas and LimitRanges\n- Cross-namespace communication\n- Namespace deletion and cascading deletion\n- Context and namespace management in kubectl\n- Network policies and namespace isolation",
          "code": "# namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: dev\n  labels:\n    environment: development",
          "command": "# Create namespace\nkubectl create namespace dev\nkubectl apply -f namespace.yaml\n\n# List namespaces\nkubectl get namespaces\nkubectl get ns\n\n# Get resources in namespace\nkubectl get pods -n dev\nkubectl get all -n dev\n\n# Set default namespace for context\nkubectl config set-context --current --namespace=dev\n\n# Delete namespace (deletes all resources)\nkubectl delete namespace dev\n\n# Describe namespace\nkubectl describe namespace dev",
          "example": "# Deploy to specific namespace\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\n  namespace: dev\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:latest\n\n# Create resources in namespace\nkubectl apply -f deployment.yaml -n dev\nkubectl create deployment nginx --image=nginx -n production",
          "useCase": "Multi-tenancy, environment separation, resource isolation, organization",
          "interviewQuestions": [
            {
              "question": "What are the 4 default namespaces in Kubernetes and their purposes?",
              "answer": "default: objects with no namespace specified. kube-system: system pods (kube-dns, metrics-server). kube-public: publicly readable, reserved for cluster usage. kube-node-lease: node heartbeat leases for node health detection."
            },
            {
              "question": "Which resources are namespace-scoped vs cluster-scoped?",
              "answer": "Namespace-scoped: Pods, Services, Deployments, ConfigMaps, Secrets, PVCs. Cluster-scoped: Nodes, PersistentVolumes, StorageClasses, Namespaces, ClusterRoles. Use kubectl api-resources --namespaced=true/false to list."
            },
            {
              "question": "What happens when you delete a namespace?",
              "answer": "Cascading deletion: all resources in namespace deleted (Pods, Services, Deployments, etc). PersistentVolumes survive (cluster-scoped). Operation can take time if pods have finalizers. Use --grace-period=0 --force cautiously."
            },
            {
              "question": "Tricky: Two pods in different namespaces have same name. Can they coexist?",
              "answer": "Yes. Names must be unique within a namespace, not cluster-wide. dev/mypod and prod/mypod are different resources."
            },
            {
              "question": "Output: kubectl config set-context --current --namespace=production. What changes?",
              "answer": "It sets the default namespace for the current context to production. Commands without -n use production."
            },
            {
              "question": "How do you prevent resource exhaustion in a namespace?",
              "answer": "Use ResourceQuota (namespace totals) and LimitRange (per-pod/container defaults and limits)."
            },
            {
              "question": "Can pods in namespace A access services in namespace B?",
              "answer": "Yes, using FQDN like service-name.namespace-b.svc.cluster.local unless NetworkPolicy restricts traffic."
            },
            {
              "question": "Predict: kubectl get pods without -n flag. Which namespace is queried?",
              "answer": "Current context namespace; if unset, default namespace."
            },
            {
              "question": "What is the label selector for namespace isolation in NetworkPolicy?",
              "answer": "Use namespaceSelector with matchLabels (for example env=prod)."
            },
            {
              "question": "Tricky: Can you create a pod named 'kube-system'?",
              "answer": "Yes. That's just a pod name. The reserved namespace kube-system is a different resource type."
            }
          ],
          "exercises": [
            {
              "type": "command",
              "question": "Create namespace named staging",
              "answer": "kubectl create namespace staging"
            },
            {
              "type": "scenario",
              "question": "Deploy nginx in production namespace imperatively",
              "answer": "kubectl create deployment nginx --image=nginx -n production"
            },
            {
              "type": "command",
              "question": "Get all pods across all namespaces",
              "answer": "kubectl get pods --all-namespaces or kubectl get pods -A"
            },
            {
              "type": "output",
              "question": "kubectl delete ns test. What happens to pods in test namespace?",
              "answer": "All namespaced resources in test are deleted by cascading deletion."
            },
            {
              "type": "command",
              "question": "Set default namespace to development for current context",
              "answer": "kubectl config set-context --current --namespace=development"
            },
            {
              "type": "debug",
              "question": "kubectl get pods returns empty but pods exist. What's wrong?",
              "answer": "You are likely querying the wrong namespace; use -A or set correct context namespace."
            },
            {
              "type": "scenario",
              "question": "Create ResourceQuota limiting namespace to 10 pods max",
              "answer": "kubectl create quota pod-limit --hard=pods=10 -n myns"
            },
            {
              "type": "command",
              "question": "List only namespace names (no headers)",
              "answer": "kubectl get ns -o custom-columns=NAME:.metadata.name --no-headers"
            },
            {
              "type": "tricky",
              "question": "Can you create a namespace named 'default'?",
              "answer": "No, it already exists and namespace names must be unique."
            },
            {
              "type": "troubleshoot",
              "question": "Namespace deletion stuck in Terminating state. How to force?",
              "answer": "Find blocking finalizers and remove them carefully. Last resort: patch finalizers to null."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Create namespace, deploy pod, verify isolation from default",
              "code": "kubectl create namespace isolated\nkubectl run pod1 -n isolated --image=nginx\nkubectl run pod2 --image=nginx\nkubectl get pods -n isolated\nkubectl get pods",
              "output": "pod1 only visible in isolated namespace, pod2 only in default"
            },
            {
              "type": "program",
              "question": "Program 2: Test cross-namespace service access",
              "code": "kubectl create namespace ns1\nkubectl create namespace ns2\nkubectl create deployment web -n ns1 --image=nginx\nkubectl expose deployment web -n ns1 --port=80\nkubectl run test -n ns2 --image=busybox --rm -it -- wget -qO- web.ns1.svc.cluster.local",
              "output": "Pod in ns2 successfully accesses service in ns1 via FQDN"
            },
            {
              "type": "program",
              "question": "Program 3: Create ResourceQuota, exceed it, observe rejection",
              "code": "kubectl create namespace limited\nkubectl create quota limit --hard=pods=2 -n limited\nkubectl run pod1 -n limited --image=nginx\nkubectl run pod2 -n limited --image=nginx\nkubectl run pod3 -n limited --image=nginx\nkubectl get pods -n limited",
              "output": "pod1 and pod2 created, pod3 fails with quota error"
            },
            {
              "type": "program",
              "question": "Program 4: Switch default namespace in context, verify",
              "code": "kubectl config set-context --current --namespace=kube-system\nkubectl get pods\nkubectl config view --minify | grep namespace",
              "output": "Shows kube-system pods, confirms namespace in current context"
            },
            {
              "type": "program",
              "question": "Program 5: Delete namespace and verify cascading deletion",
              "code": "kubectl create namespace temp\nkubectl run pod1 -n temp --image=nginx\nkubectl create deployment dep1 -n temp --image=nginx\nkubectl delete namespace temp\nkubectl get all -n temp",
              "output": "All resources deleted, namespace temp removed"
            },
            {
              "type": "program",
              "question": "Program 6: Count pods per namespace",
              "code": "kubectl get pods -A --no-headers | awk '{print $1}' | sort | uniq -c",
              "output": "Lists each namespace with pod count"
            },
            {
              "type": "program",
              "question": "Program 7: Label namespace and select by label",
              "code": "kubectl create namespace env-prod\nkubectl label namespace env-prod environment=production\nkubectl get namespaces -l environment=production",
              "output": "env-prod namespace listed with environment=production label"
            },
            {
              "type": "program",
              "question": "Program 8: Set default namespace for current context",
              "code": "kubectl config set-context --current --namespace=kube-system\nkubectl get pods\nkubectl config set-context --current --namespace=default",
              "output": "Shows kube-system pods without -n flag, then resets to default"
            },
            {
              "type": "program",
              "question": "Program 9: Create ResourceQuota and test limit enforcement",
              "code": "kubectl create namespace quota-ns\nkubectl create quota my-quota -n quota-ns --hard=pods=2,requests.cpu=500m\nkubectl create deployment test -n quota-ns --image=nginx --replicas=3\nkubectl get events -n quota-ns | grep quota",
              "output": "Only 2 pods created, 3rd pod fails with 'exceeded quota' error"
            },
            {
              "type": "program",
              "question": "Program 10: List all resources across ALL namespaces",
              "code": "kubectl get all -A --no-headers | awk '{print $1}' | cut -d/ -f1 | sort | uniq -c | sort -rn\nkubectl api-resources --namespaced=false",
              "output": "Resource count per namespace; list of cluster-scoped resources (nodes, PVs, namespaces)"
            }
          ]
        },
        {
          "id": "statefulsets",
          "title": "StatefulSets",
          "category": "Kubernetes Workloads",
          "description": "Managing stateful applications with stable identities, ordered deployment, and persistent storage.",
          "explanation": "A StatefulSet manages stateful applications that require stable network identities, persistent storage, and ordered deployment/scaling.\n\nKey guarantees:\n- Stable, unique pod names: <statefulset-name>-<ordinal> (web-0, web-1, web-2). Names persist across rescheduling.\n- Stable DNS: Each pod gets a DNS record: <pod-name>.<headless-service>.<namespace>.svc.cluster.local.\n- Ordered deployment: Pods are created sequentially (0, 1, 2...). Pod N+1 waits until Pod N is Running and Ready.\n- Ordered deletion: Pods are terminated in reverse order (2, 1, 0) during scale-down.\n- Ordered rolling updates: Pods are updated in reverse ordinal order.\n\nComponents:\n- Headless Service (clusterIP: None): Required for pod DNS records. Does not load-balance — clients connect to specific pods.\n- volumeClaimTemplates: Each pod gets its own PVC (web-0-data, web-1-data). PVCs survive pod deletion and rescheduling.\n\nUse cases:\n- Databases: MySQL, PostgreSQL (primary-replica with stable IDs).\n- Distributed systems: Kafka, ZooKeeper, etcd (need stable network identity for cluster membership).\n- Caches: Redis Cluster (needs consistent hashing with stable endpoints).\n\nPod Management Policies:\n- OrderedReady (default): Sequential create/delete, wait for Ready between pods.\n- Parallel: Create/delete all pods simultaneously. Use when ordering doesn't matter but stable identity does.\n\nUpdate Strategies:\n- RollingUpdate (default): Updates in reverse ordinal order. partition field allows canary updates (only pods >= partition ordinal are updated).\n- OnDelete: Pods only updated when manually deleted.\n\nStatefulSet vs Deployment:\n- Deployment: Stateless, random pod names, shared PVC, parallel scaling.\n- StatefulSet: Stateful, predictable pod names, per-pod PVCs, ordered operations.\n- Use Deployment unless you specifically need stable identity or per-pod storage.",
          "code": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  serviceName: web-headless\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.25\n        ports:\n        - containerPort: 80\n        volumeMounts:\n        - name: data\n          mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      resources:\n        requests:\n          storage: 1Gi",
          "command": "# Create StatefulSet\nkubectl apply -f statefulset.yaml\n\n# Watch ordered pod creation\nkubectl get pods -w -l app=web\n\n# Check pod DNS\nkubectl run -it dns-test --image=busybox --rm -- nslookup web-0.web-headless\n\n# Scale StatefulSet\nkubectl scale statefulset web --replicas=5\n\n# Check PVCs (one per pod)\nkubectl get pvc\n\n# Partition update (canary)\nkubectl patch statefulset web -p '{\"spec\":{\"updateStrategy\":{\"rollingUpdate\":{\"partition\":2}}}}'",
          "example": "# Headless Service for StatefulSet\napiVersion: v1\nkind: Service\nmetadata:\n  name: web-headless\nspec:\n  clusterIP: None\n  selector:\n    app: web\n  ports:\n  - port: 80\n---\n# MySQL StatefulSet with init container for replication setup\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: mysql\nspec:\n  serviceName: mysql-headless\n  replicas: 3\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      initContainers:\n      - name: init-mysql\n        image: mysql:8.0\n        command: ['bash', '-c', 'echo server-id=$(($(hostname | grep -o \"[0-9]*$\") + 1)) > /mnt/conf.d/server-id.cnf']\n        volumeMounts:\n        - name: conf\n          mountPath: /mnt/conf.d\n      containers:\n      - name: mysql\n        image: mysql:8.0\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: password\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/mysql\n        - name: conf\n          mountPath: /etc/mysql/conf.d\n      volumes:\n      - name: conf\n        emptyDir: {}\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      resources:\n        requests:\n          storage: 10Gi",
          "useCase": "Databases, distributed systems (Kafka, ZooKeeper), caches (Redis Cluster), any app needing stable identity or per-pod storage",
          "interviewQuestions": [
            {
              "question": "What is a StatefulSet and when would you use one?",
              "answer": "StatefulSet manages stateful applications needing stable pod names, persistent per-pod storage, and ordered deployment. Use for databases (MySQL, PostgreSQL), distributed systems (Kafka, etcd, ZooKeeper), and any workload requiring stable network identity. Pods get predictable names (web-0, web-1) and dedicated PVCs."
            },
            {
              "question": "How does a StatefulSet differ from a Deployment?",
              "answer": "Deployment: random pod names, shared PVC, parallel scaling, for stateless apps. StatefulSet: predictable ordinal names (app-0, app-1), per-pod PVC via volumeClaimTemplates, ordered create/delete, requires headless Service. Use Deployment unless you need stable identity or individual storage."
            },
            {
              "question": "Why does a StatefulSet require a Headless Service?",
              "answer": "Headless Service (clusterIP: None) creates individual DNS records for each pod: <pod>.<service>.<namespace>.svc.cluster.local. This enables stable network identity — other pods can connect to specific StatefulSet members by DNS name (mysql-0.mysql-headless) even after rescheduling."
            },
            {
              "question": "What happens to PVCs when a StatefulSet pod is deleted?",
              "answer": "PVCs are NOT deleted when pods are deleted or StatefulSet is scaled down. This preserves data. When scaled back up, the same PVC is reattached to the pod with the same ordinal. Must manually delete PVCs to reclaim storage. persistentVolumeClaimRetentionPolicy (1.27+) can automate this."
            },
            {
              "question": "Explain the partition feature in StatefulSet rolling updates.",
              "answer": "partition in updateStrategy.rollingUpdate specifies an ordinal: only pods with ordinal >= partition are updated. Example: partition=2 with 5 replicas → only pods 2,3,4 get updated; pods 0,1 keep old version. Enables canary deployments. Set partition=0 to complete the rollout."
            },
            {
              "question": "How do you handle StatefulSet scaling in production?",
              "answer": "Scale up: new pods created in order, each gets new PVC. Scale down: pods removed in reverse order (highest ordinal first), PVCs retained. Considerations: check application cluster membership before scaling down (e.g., Kafka partition reassignment), ensure quorum is maintained."
            },
            {
              "question": "What are pod management policies in StatefulSet?",
              "answer": "OrderedReady (default): Pods created/deleted sequentially, waits for Ready between each. Parallel: All pods created/deleted simultaneously. Use Parallel when ordering doesn't matter but stable identity does (e.g., cache cluster where all nodes are equal)."
            },
            {
              "question": "How do you perform a rolling restart of a StatefulSet?",
              "answer": "kubectl rollout restart statefulset <name>. Pods restart in reverse ordinal order (highest first). Unlike Deployment, no surge — each pod terminates before next starts. Use kubectl rollout status statefulset <name> to monitor. Can also use OnDelete strategy for manual control."
            },
            {
              "question": "What are the challenges of running databases on Kubernetes with StatefulSets?",
              "answer": "Challenges: Storage performance (cloud PVs may be slow), backup/restore complexity, replication setup (init containers or operators), failover handling, connection management. Solutions: Use database operators (MySQL Operator, PostgreSQL Operator) that automate these concerns."
            },
            {
              "question": "How does DNS work for StatefulSet pods?",
              "answer": "Each pod gets DNS: <pod-name>.<headless-service>.<namespace>.svc.cluster.local. Example: mysql-0.mysql-headless.default.svc.cluster.local. SRV records also created for port discovery. DNS updates when pod is rescheduled to new node. Application can use short name within same namespace: mysql-0.mysql-headless."
            }
          ],
          "exercises": [
            {
              "type": "write",
              "question": "Write a StatefulSet manifest for a 3-replica Redis cluster with 5Gi persistent storage per pod.",
              "answer": "apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: redis\nspec:\n  serviceName: redis-headless\n  replicas: 3\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:7\n        ports:\n        - containerPort: 6379\n        volumeMounts:\n        - name: data\n          mountPath: /data\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      resources:\n        requests:\n          storage: 5Gi"
            },
            {
              "type": "command",
              "question": "Scale a StatefulSet named 'db' from 3 to 5 replicas and verify ordered creation.",
              "answer": "kubectl scale statefulset db --replicas=5\nkubectl get pods -w -l app=db  # Watch db-3 then db-4 created in order"
            },
            {
              "type": "explain",
              "question": "Why are StatefulSet PVCs not deleted on scale-down?",
              "answer": "Data safety: PVCs contain application state (database data). Accidental scale-down shouldn't cause data loss. When scaled back up, the same PVC reattaches to the pod with the same ordinal. Must manually delete PVCs (kubectl delete pvc data-web-2) to reclaim storage."
            },
            {
              "type": "troubleshoot",
              "question": "StatefulSet pod web-1 is stuck in Pending. web-0 is Running. What to check?",
              "answer": "Check: (1) kubectl describe pod web-1 for events, (2) PVC status — StorageClass may have no available PVs, (3) Node resources (CPU/memory insufficient), (4) Node affinity/tolerations, (5) kubectl get pvc to see if PVC is Bound or Pending."
            },
            {
              "type": "scenario",
              "question": "You need to update the container image for a 5-pod StatefulSet but test on one pod first.",
              "answer": "Use partition update: kubectl patch statefulset web -p '{\"spec\":{\"updateStrategy\":{\"rollingUpdate\":{\"partition\":4}}}}' — only web-4 gets updated. Test web-4. If OK, lower partition to 0: kubectl patch statefulset web -p '{\"spec\":{\"updateStrategy\":{\"rollingUpdate\":{\"partition\":0}}}}' to update all."
            },
            {
              "type": "write",
              "question": "Write a Headless Service for a StatefulSet with app=postgres selector.",
              "answer": "apiVersion: v1\nkind: Service\nmetadata:\n  name: postgres-headless\nspec:\n  clusterIP: None\n  selector:\n    app: postgres\n  ports:\n  - port: 5432\n    targetPort: 5432"
            },
            {
              "type": "command",
              "question": "Check the DNS record of a specific StatefulSet pod.",
              "answer": "kubectl run -it dns-test --image=busybox:1.36 --rm --restart=Never -- nslookup web-0.web-headless.default.svc.cluster.local"
            },
            {
              "type": "scenario",
              "question": "A StatefulSet pod is deleted but its PVC still exists. What happens when the pod is recreated?",
              "answer": "The controller recreates the pod with the same ordinal (e.g., web-2). The existing PVC (data-web-2) is automatically reattached. Data from the previous pod is preserved. This is the core value of StatefulSets — data survives pod restarts and rescheduling."
            },
            {
              "type": "explain",
              "question": "When should you use Parallel pod management policy?",
              "answer": "Use Parallel when pods don't depend on each other during startup but still need stable identity and per-pod storage. Example: cache nodes that auto-discover peers, stateless workers with persistent scratch space. Faster scaling since all pods start simultaneously."
            },
            {
              "type": "command",
              "question": "Perform a rolling restart of a StatefulSet and watch the progress.",
              "answer": "kubectl rollout restart statefulset web\nkubectl rollout status statefulset web\nkubectl get pods -w -l app=web  # Watch pods restart in reverse ordinal order"
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Create a headless service and StatefulSet",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: v1\nkind: Service\nmetadata:\n  name: web-headless\nspec:\n  clusterIP: None\n  selector:\n    app: web\n  ports:\n  - port: 80\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  serviceName: web-headless\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.25-alpine\n        ports:\n        - containerPort: 80\nEOF\nkubectl get pods -l app=web",
              "output": "web-0   1/1   Running   web-1   1/1   Running   web-2   1/1   Running"
            },
            {
              "type": "program",
              "question": "Program 2: Verify ordered pod creation",
              "code": "kubectl delete statefulset web\nkubectl apply -f statefulset.yaml\nkubectl get pods -w -l app=web --output-watch-events",
              "output": "Events show web-0 created first, then web-1 after web-0 is Ready, then web-2"
            },
            {
              "type": "program",
              "question": "Program 3: Verify stable DNS for each pod",
              "code": "kubectl run -it dns-check --image=busybox:1.36 --rm --restart=Never -- sh -c '\n  nslookup web-0.web-headless\n  nslookup web-1.web-headless\n  nslookup web-2.web-headless\n'",
              "output": "Each pod resolves to its individual IP address via headless service DNS"
            },
            {
              "type": "program",
              "question": "Program 4: StatefulSet with volumeClaimTemplates",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: db\nspec:\n  serviceName: db-headless\n  replicas: 2\n  selector:\n    matchLabels:\n      app: db\n  template:\n    metadata:\n      labels:\n        app: db\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:15-alpine\n        env:\n        - name: POSTGRES_PASSWORD\n          value: secret\n        volumeMounts:\n        - name: pgdata\n          mountPath: /var/lib/postgresql/data\n  volumeClaimTemplates:\n  - metadata:\n      name: pgdata\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      resources:\n        requests:\n          storage: 2Gi\nEOF\nkubectl get pvc",
              "output": "pgdata-db-0 Bound   pgdata-db-1 Bound (each pod gets its own PVC)"
            },
            {
              "type": "program",
              "question": "Program 5: Canary update with partition",
              "code": "kubectl patch statefulset web -p '{\"spec\":{\"updateStrategy\":{\"rollingUpdate\":{\"partition\":2}}}}'\nkubectl set image statefulset web nginx=nginx:1.26-alpine\nkubectl get pods -l app=web -o custom-columns=NAME:.metadata.name,IMAGE:.spec.containers[0].image",
              "output": "web-0 nginx:1.25-alpine   web-1 nginx:1.25-alpine   web-2 nginx:1.26-alpine (only web-2 updated)"
            },
            {
              "type": "program",
              "question": "Program 6: Scale down and verify PVC retention",
              "code": "kubectl scale statefulset web --replicas=1\nkubectl get pods -l app=web\nkubectl get pvc | grep web",
              "output": "Only web-0 running, but PVCs for web-1 and web-2 still exist (data preserved)"
            },
            {
              "type": "program",
              "question": "Program 7: Use init container to set server-id based on ordinal",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: mysql\nspec:\n  serviceName: mysql-headless\n  replicas: 3\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      initContainers:\n      - name: set-id\n        image: busybox\n        command: ['sh', '-c', 'echo server-id=$(($(hostname | grep -o \"[0-9]*$\") + 1)) > /config/server-id.cnf && cat /config/server-id.cnf']\n        volumeMounts:\n        - name: config\n          mountPath: /config\n      containers:\n      - name: mysql\n        image: mysql:8.0\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: secret\n        volumeMounts:\n        - name: config\n          mountPath: /etc/mysql/conf.d\n      volumes:\n      - name: config\n        emptyDir: {}\nEOF\nkubectl logs mysql-0 -c set-id",
              "output": "server-id=1 (mysql-1 gets server-id=2, mysql-2 gets server-id=3)"
            },
            {
              "type": "program",
              "question": "Program 8: Rolling restart and monitoring",
              "code": "kubectl rollout restart statefulset web\nkubectl rollout status statefulset web",
              "output": "Waiting for partitioned roll out... Waiting for 1 pods to be ready... statefulset rolling update complete 3/3"
            },
            {
              "type": "program",
              "question": "Program 9: Compare pod names in Deployment vs StatefulSet",
              "code": "kubectl create deployment test-deploy --image=nginx --replicas=3\nkubectl get pods -l app=test-deploy -o name\nkubectl get pods -l app=web -o name",
              "output": "Deployment: pod/test-deploy-6d4f5b-xk9zm (random suffix). StatefulSet: pod/web-0, pod/web-1, pod/web-2 (predictable ordinal)"
            },
            {
              "type": "program",
              "question": "Program 10: Delete StatefulSet without deleting pods (orphan)",
              "code": "kubectl delete statefulset web --cascade=orphan\nkubectl get pods -l app=web\nkubectl get statefulset web",
              "output": "Pods still running (orphaned), StatefulSet deleted. Pods can be adopted by recreating StatefulSet with same selector."
            }
          ]
        },
        {
          "id": "daemonsets",
          "title": "DaemonSets",
          "category": "Kubernetes Workloads",
          "description": "Running a pod on every node for cluster-wide services like logging, monitoring, and networking.",
          "explanation": "A DaemonSet ensures that a copy of a pod runs on every (or selected) node in the cluster. When nodes are added, the DaemonSet automatically schedules pods on them. When nodes are removed, the pods are garbage collected.\n\nCommon use cases:\n- Log collection: Fluentd, Filebeat, Logstash on every node to ship logs.\n- Monitoring: Prometheus Node Exporter, Datadog agent, New Relic.\n- Networking: Calico, Cilium, kube-proxy (cluster networking CNI plugins).\n- Storage: Ceph, GlusterFS daemons for distributed storage.\n- Security: Falco, Sysdig for runtime security monitoring.\n\nScheduling behavior:\n- By default, runs on ALL nodes (including control plane if tolerations allow).\n- Use nodeSelector or nodeAffinity to target specific nodes.\n- Use tolerations to run on tainted nodes (e.g., control plane nodes have NoSchedule taint).\n- DaemonSet pods are scheduled by the default scheduler (since K8s 1.12), not the DaemonSet controller directly.\n\nUpdate strategies:\n- RollingUpdate (default): Pods are updated one at a time. maxUnavailable controls how many can be down simultaneously (default: 1). maxSurge (1.22+) allows creating new pod before terminating old.\n- OnDelete: Pods only updated when manually deleted. Useful for careful, node-by-node upgrades.\n\nDaemonSet vs Deployment:\n- DaemonSet: One pod per node, no replicas field, auto-schedules on new nodes.\n- Deployment: N replicas scheduled anywhere, scheduler decides placement.\n- Don't use DaemonSet for web apps — use Deployment.\n\nResource considerations:\n- DaemonSet pods consume resources on EVERY node. Set resource requests/limits carefully.\n- Large DaemonSet pods reduce available resources for application workloads.\n- Consider Priority Classes to ensure DaemonSet pods are not evicted.\n\nDaemonSet pods and node draining:\n- kubectl drain ignores DaemonSet pods by default (--ignore-daemonsets flag).\n- DaemonSet pods are expected to run on every node, so drain doesn't evict them.\n- They are recreated immediately if forced deleted.",
          "code": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluentd\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      app: fluentd\n  template:\n    metadata:\n      labels:\n        app: fluentd\n    spec:\n      tolerations:\n      - key: node-role.kubernetes.io/control-plane\n        effect: NoSchedule\n      containers:\n      - name: fluentd\n        image: fluentd:v1.16\n        resources:\n          requests:\n            cpu: 100m\n            memory: 200Mi\n          limits:\n            cpu: 200m\n            memory: 400Mi\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: containers\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: containers\n        hostPath:\n          path: /var/lib/docker/containers",
          "command": "# Create DaemonSet\nkubectl apply -f daemonset.yaml\n\n# Check DaemonSet status\nkubectl get daemonset -n kube-system\n\n# See which nodes have DaemonSet pods\nkubectl get pods -l app=fluentd -o wide\n\n# Check desired vs current vs ready\nkubectl describe daemonset fluentd -n kube-system\n\n# Rolling update\nkubectl set image daemonset/fluentd fluentd=fluentd:v1.17 -n kube-system\n\n# Check rollout status\nkubectl rollout status daemonset/fluentd -n kube-system\n\n# Rollback\nkubectl rollout undo daemonset/fluentd -n kube-system",
          "example": "# Node Exporter DaemonSet for Prometheus monitoring\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-exporter\n  namespace: monitoring\nspec:\n  selector:\n    matchLabels:\n      app: node-exporter\n  updateStrategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n  template:\n    metadata:\n      labels:\n        app: node-exporter\n    spec:\n      hostNetwork: true\n      hostPID: true\n      nodeSelector:\n        kubernetes.io/os: linux\n      tolerations:\n      - operator: Exists\n      containers:\n      - name: node-exporter\n        image: prom/node-exporter:v1.7.0\n        args:\n        - --path.procfs=/host/proc\n        - --path.sysfs=/host/sys\n        ports:\n        - containerPort: 9100\n          hostPort: 9100\n        resources:\n          requests:\n            cpu: 50m\n            memory: 64Mi\n          limits:\n            cpu: 100m\n            memory: 128Mi\n        volumeMounts:\n        - name: proc\n          mountPath: /host/proc\n          readOnly: true\n        - name: sys\n          mountPath: /host/sys\n          readOnly: true\n      volumes:\n      - name: proc\n        hostPath:\n          path: /proc\n      - name: sys\n        hostPath:\n          path: /sys",
          "useCase": "Log collection (Fluentd/Filebeat), monitoring agents (Node Exporter/Datadog), CNI plugins, storage daemons, security agents",
          "interviewQuestions": [
            {
              "question": "What is a DaemonSet and when would you use it?",
              "answer": "DaemonSet ensures one pod runs on every (or selected) node. Use for cluster-wide services: log collection (Fluentd), monitoring (Node Exporter), networking (CNI plugins like Calico), storage daemons. Automatically deploys to new nodes and cleans up on removed nodes."
            },
            {
              "question": "How does a DaemonSet differ from a Deployment with node affinity?",
              "answer": "DaemonSet: guarantees exactly one pod per matched node, auto-schedules on new nodes, no replicas field. Deployment with affinity: sets desired replicas, scheduler may place multiple on one node, doesn't auto-adapt to cluster changes. DaemonSet is declaratively 'one per node'."
            },
            {
              "question": "How do you run a DaemonSet only on specific nodes?",
              "answer": "Use nodeSelector for simple label matching: nodeSelector: {disk: ssd}. Use nodeAffinity for complex expressions (In, NotIn, Exists). Label target nodes: kubectl label node worker-1 disk=ssd. DaemonSet only runs on nodes matching the selector."
            },
            {
              "question": "How do you run a DaemonSet on control plane nodes?",
              "answer": "Control plane nodes have taint: node-role.kubernetes.io/control-plane:NoSchedule. Add toleration to DaemonSet pod spec: tolerations: [{key: node-role.kubernetes.io/control-plane, effect: NoSchedule}]. Or tolerate everything: [{operator: Exists}] (runs on ALL nodes regardless of taints)."
            },
            {
              "question": "What happens to DaemonSet pods during kubectl drain?",
              "answer": "By default, drain ignores DaemonSet pods (requires --ignore-daemonsets flag). This is intentional — DaemonSet pods should always run. Without the flag, drain fails with error. DaemonSet pods are NOT evicted during drain but other pods are safely relocated."
            },
            {
              "question": "How does the DaemonSet rolling update work?",
              "answer": "RollingUpdate (default): terminates old pod, creates new pod on same node. maxUnavailable (default: 1) controls parallelism. Pods updated one node at a time. maxSurge (1.22+): creates new pod before terminating old (zero-downtime on each node). OnDelete: manual — pod only updated when you delete it."
            },
            {
              "question": "What hostPath volumes are commonly used with DaemonSets?",
              "answer": "/var/log for collecting node logs, /var/lib/docker/containers for container logs, /proc and /sys for system metrics, /etc for reading node configuration, /run for socket access (e.g., Docker socket). Always mount with readOnly: true when possible."
            },
            {
              "question": "How does a DaemonSet affect cluster resource planning?",
              "answer": "DaemonSet pods run on EVERY node, consuming CPU/memory on each. With 100 nodes and 200Mi per DaemonSet pod, that's 20Gi total. Multiple DaemonSets compound this. Plan node sizing: total node resources = DaemonSet overhead + application workloads + system reserved. Use resource requests/limits."
            },
            {
              "question": "Can you have more than one DaemonSet pod per node?",
              "answer": "No — DaemonSet guarantees exactly one pod per matching node. If you need multiple instances, put them in one pod as separate containers (sidecar pattern). Or use a Deployment with pod anti-affinity (soft) for approximate distribution."
            },
            {
              "question": "How do DaemonSets interact with Pod Priority and Preemption?",
              "answer": "DaemonSet pods can use PriorityClass. High-priority DaemonSet pods can preempt lower-priority pods on a node. Critical system DaemonSets (logging, monitoring) should have high priority (system-cluster-critical or system-node-critical) to avoid eviction during resource pressure."
            }
          ],
          "exercises": [
            {
              "type": "write",
              "question": "Write a DaemonSet for a Filebeat log shipper that mounts /var/log from the host.",
              "answer": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: filebeat\nspec:\n  selector:\n    matchLabels:\n      app: filebeat\n  template:\n    metadata:\n      labels:\n        app: filebeat\n    spec:\n      containers:\n      - name: filebeat\n        image: elastic/filebeat:8.11.0\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n          readOnly: true\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log"
            },
            {
              "type": "command",
              "question": "Check how many nodes have DaemonSet pods running and how many are ready.",
              "answer": "kubectl get daemonset -A\n# Shows DESIRED, CURRENT, READY, UP-TO-DATE, AVAILABLE for each DaemonSet"
            },
            {
              "type": "explain",
              "question": "Why do DaemonSets commonly use hostNetwork: true?",
              "answer": "hostNetwork lets the pod use the node's network namespace directly. Monitoring agents (Node Exporter on port 9100) need to be accessible on the node IP. CNI plugins need host networking to configure networking for other pods. Avoids NAT and port mapping overhead."
            },
            {
              "type": "troubleshoot",
              "question": "A DaemonSet shows DESIRED=5 but CURRENT=3. What could be wrong?",
              "answer": "Check: (1) Node taints preventing scheduling (kubectl describe node), (2) nodeSelector doesn't match all nodes, (3) Resource constraints (insufficient CPU/memory on 2 nodes), (4) PodSecurityPolicy/PSA blocking the pod, (5) kubectl describe daemonset for events."
            },
            {
              "type": "scenario",
              "question": "You need to update a DaemonSet but want to control the rollout node by node.",
              "answer": "Use OnDelete update strategy. Change the DaemonSet spec. Then manually delete pods one node at a time: kubectl delete pod fluentd-xxxxx. New pod is created with updated spec. Verify each node before proceeding. This gives maximum control over rollout."
            },
            {
              "type": "write",
              "question": "Write a DaemonSet that runs only on nodes labeled gpu=true.",
              "answer": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: gpu-monitor\nspec:\n  selector:\n    matchLabels:\n      app: gpu-monitor\n  template:\n    metadata:\n      labels:\n        app: gpu-monitor\n    spec:\n      nodeSelector:\n        gpu: \"true\"\n      containers:\n      - name: monitor\n        image: nvidia/dcgm-exporter\n        resources:\n          limits:\n            nvidia.com/gpu: 1"
            },
            {
              "type": "command",
              "question": "Perform a rolling update of a DaemonSet changing the image.",
              "answer": "kubectl set image daemonset/fluentd fluentd=fluentd:v1.17\nkubectl rollout status daemonset/fluentd\nkubectl get pods -l app=fluentd -o custom-columns=NODE:.spec.nodeName,IMAGE:.spec.containers[0].image"
            },
            {
              "type": "explain",
              "question": "What is the difference between DaemonSet tolerations operator: Exists and operator: Equal?",
              "answer": "operator: Exists matches any taint with the specified key (regardless of value). operator: Equal matches taint with specific key AND value. tolerations: [{operator: Exists}] (no key) tolerates ALL taints — pod runs on every node including tainted control plane nodes."
            },
            {
              "type": "scenario",
              "question": "Adding a new node to cluster. How does the DaemonSet react?",
              "answer": "When new node joins and becomes Ready, the DaemonSet controller detects it and creates a pod on the new node (if node matches nodeSelector/affinity). Fully automatic — no manual intervention needed. Pod inherits the current DaemonSet spec."
            },
            {
              "type": "command",
              "question": "Check which nodes are NOT running a specific DaemonSet pod.",
              "answer": "# Compare all nodes vs nodes with pods\nkubectl get nodes -o name | sort > /tmp/all\nkubectl get pods -l app=fluentd -o jsonpath='{range .items[*]}{.spec.nodeName}{\"\\n\"}{end}' | sort > /tmp/have\ndiff /tmp/all /tmp/have"
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Create a DaemonSet and verify one pod per node",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: logger\nspec:\n  selector:\n    matchLabels:\n      app: logger\n  template:\n    metadata:\n      labels:\n        app: logger\n    spec:\n      containers:\n      - name: logger\n        image: busybox\n        command: ['sh', '-c', 'while true; do echo $(hostname) logging; sleep 60; done']\nEOF\nkubectl get daemonset logger\nkubectl get pods -l app=logger -o wide",
              "output": "DESIRED=N CURRENT=N READY=N (one pod per node, each on different node)"
            },
            {
              "type": "program",
              "question": "Program 2: DaemonSet with nodeSelector targeting specific nodes",
              "code": "kubectl label node $(kubectl get nodes -o name | head -1 | cut -d/ -f2) tier=edge\ncat <<EOF | kubectl apply -f -\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: edge-agent\nspec:\n  selector:\n    matchLabels:\n      app: edge-agent\n  template:\n    metadata:\n      labels:\n        app: edge-agent\n    spec:\n      nodeSelector:\n        tier: edge\n      containers:\n      - name: agent\n        image: busybox\n        command: ['sleep', '3600']\nEOF\nkubectl get daemonset edge-agent",
              "output": "DESIRED=1 (only runs on node labeled tier=edge)"
            },
            {
              "type": "program",
              "question": "Program 3: DaemonSet with toleration for control plane",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: all-nodes\nspec:\n  selector:\n    matchLabels:\n      app: all-nodes\n  template:\n    metadata:\n      labels:\n        app: all-nodes\n    spec:\n      tolerations:\n      - operator: Exists\n      containers:\n      - name: agent\n        image: busybox\n        command: ['sleep', '3600']\nEOF\nkubectl get pods -l app=all-nodes -o wide",
              "output": "Pod running on EVERY node including control plane (tolerates all taints)"
            },
            {
              "type": "program",
              "question": "Program 4: DaemonSet rolling update",
              "code": "kubectl set image daemonset/logger logger=alpine\nkubectl rollout status daemonset/logger\nkubectl get pods -l app=logger -o custom-columns=NAME:.metadata.name,IMAGE:.spec.containers[0].image,NODE:.spec.nodeName",
              "output": "All pods updated to alpine image, one at a time (rolling)"
            },
            {
              "type": "program",
              "question": "Program 5: DaemonSet with OnDelete strategy",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: manual-update\nspec:\n  updateStrategy:\n    type: OnDelete\n  selector:\n    matchLabels:\n      app: manual\n  template:\n    metadata:\n      labels:\n        app: manual\n    spec:\n      containers:\n      - name: app\n        image: nginx:1.25\nEOF\nkubectl set image daemonset/manual-update app=nginx:1.26\nkubectl get pods -l app=manual -o custom-columns=NAME:.metadata.name,IMAGE:.spec.containers[0].image",
              "output": "Still shows nginx:1.25 — pods not updated until manually deleted"
            },
            {
              "type": "program",
              "question": "Program 6: Check DaemonSet status details",
              "code": "kubectl get daemonset logger -o jsonpath='{\"Desired: \"}{.status.desiredNumberScheduled}{\"\\nCurrent: \"}{.status.currentNumberScheduled}{\"\\nReady: \"}{.status.numberReady}{\"\\nUpdated: \"}{.status.updatedNumberScheduled}{\"\\n\"}'",
              "output": "Desired: 3  Current: 3  Ready: 3  Updated: 3"
            },
            {
              "type": "program",
              "question": "Program 7: DaemonSet with hostPath volume for log collection",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: log-collector\nspec:\n  selector:\n    matchLabels:\n      app: log-collector\n  template:\n    metadata:\n      labels:\n        app: log-collector\n    spec:\n      containers:\n      - name: collector\n        image: busybox\n        command: ['sh', '-c', 'tail -f /var/log/syslog || tail -f /var/log/messages || sleep 3600']\n        volumeMounts:\n        - name: hostlog\n          mountPath: /var/log\n          readOnly: true\n      volumes:\n      - name: hostlog\n        hostPath:\n          path: /var/log\nEOF\nkubectl logs $(kubectl get pods -l app=log-collector -o name | head -1) | head -5",
              "output": "Shows host system logs from /var/log mounted into the container"
            },
            {
              "type": "program",
              "question": "Program 8: Rollback a DaemonSet update",
              "code": "kubectl rollout history daemonset/logger\nkubectl rollout undo daemonset/logger\nkubectl rollout status daemonset/logger\nkubectl get pods -l app=logger -o custom-columns=NAME:.metadata.name,IMAGE:.spec.containers[0].image",
              "output": "DaemonSet rolled back to previous image version"
            },
            {
              "type": "program",
              "question": "Program 9: DaemonSet with resource limits",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: resource-ds\nspec:\n  selector:\n    matchLabels:\n      app: resource-ds\n  template:\n    metadata:\n      labels:\n        app: resource-ds\n    spec:\n      containers:\n      - name: agent\n        image: busybox\n        command: ['sleep', '3600']\n        resources:\n          requests:\n            cpu: 50m\n            memory: 64Mi\n          limits:\n            cpu: 100m\n            memory: 128Mi\nEOF\nkubectl describe pod $(kubectl get pods -l app=resource-ds -o name | head -1) | grep -A4 'Limits\\|Requests'",
              "output": "Limits: cpu=100m, memory=128Mi  Requests: cpu=50m, memory=64Mi"
            },
            {
              "type": "program",
              "question": "Program 10: List all DaemonSets in cluster including system ones",
              "code": "kubectl get daemonsets --all-namespaces -o custom-columns='NAMESPACE:.metadata.namespace,NAME:.metadata.name,DESIRED:.status.desiredNumberScheduled,READY:.status.numberReady,IMAGE:.spec.template.spec.containers[0].image'",
              "output": "Shows all DaemonSets across namespaces (kube-proxy, CNI plugin, custom DaemonSets) with status"
            }
          ]
        },
        {
          "id": "jobs-cronjobs",
          "title": "Jobs & CronJobs",
          "category": "Kubernetes Workloads",
          "description": "Running batch tasks, one-time operations, and scheduled workloads in Kubernetes.",
          "explanation": "Jobs create one or more pods that run to completion. CronJobs create Jobs on a schedule.\n\nJob types:\n- Non-parallel (default): Single pod, runs once. Good for one-time tasks (database migration).\n- Parallel with fixed completion count: spec.completions=N, runs N pods total. spec.parallelism controls concurrent pods.\n- Parallel work queue: spec.completions unset, spec.parallelism=N. Pods process items from a queue until all done.\n\nJob behavior:\n- Pods run until exit code 0 (success). Non-zero exit = failure.\n- spec.backoffLimit (default: 6): Max retries before marking Job as failed. Exponential backoff (10s, 20s, 40s...).\n- spec.activeDeadlineSeconds: Maximum time for the Job to run. Overrides backoffLimit.\n- restartPolicy must be Never or OnFailure (not Always — Jobs must terminate).\n- ttlSecondsAfterFinished: Auto-delete completed Job after N seconds (cleanup).\n\nJob completion modes (1.24+):\n- NonIndexed (default): Pods are interchangeable.\n- Indexed: Each pod gets a unique index (0 to completions-1) via JOB_COMPLETION_INDEX env var. Useful for parallel processing where each pod handles a different data shard.\n\nCronJob:\n- Uses standard cron syntax: minute hour day-of-month month day-of-week.\n- spec.schedule: '*/5 * * * *' (every 5 minutes).\n- spec.concurrencyPolicy: Allow (default, concurrent runs OK), Forbid (skip if previous still running), Replace (kill previous, start new).\n- spec.startingDeadlineSeconds: Window to start missed runs.\n- spec.successfulJobsHistoryLimit (default: 3): Keep N successful Jobs.\n- spec.failedJobsHistoryLimit (default: 1): Keep N failed Jobs.\n- spec.suspend: true pauses future runs without deleting the CronJob.\n\nBest practices:\n- Always set activeDeadlineSeconds to prevent runaway Jobs.\n- Use ttlSecondsAfterFinished for automatic cleanup.\n- Set resource requests/limits — batch Jobs can consume excessive resources.\n- Use Forbid concurrencyPolicy for Jobs that shouldn't overlap (e.g., DB backups).\n- Log Job output to persistent storage — pod logs disappear when pods are garbage collected.",
          "code": "# Job\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: db-migrate\nspec:\n  ttlSecondsAfterFinished: 300\n  backoffLimit: 3\n  activeDeadlineSeconds: 600\n  template:\n    spec:\n      restartPolicy: Never\n      containers:\n      - name: migrate\n        image: myapp:latest\n        command: [\"python\", \"manage.py\", \"migrate\"]\n---\n# CronJob\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: daily-backup\nspec:\n  schedule: \"0 2 * * *\"\n  concurrencyPolicy: Forbid\n  successfulJobsHistoryLimit: 7\n  failedJobsHistoryLimit: 3\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          restartPolicy: OnFailure\n          containers:\n          - name: backup\n            image: postgres:15\n            command: [\"pg_dump\", \"-h\", \"db-service\", \"-U\", \"admin\", \"mydb\"]",
          "command": "# Create a Job\nkubectl apply -f job.yaml\n\n# Watch Job progress\nkubectl get jobs -w\n\n# View Job pod logs\nkubectl logs job/db-migrate\n\n# Create Job imperatively\nkubectl create job test --image=busybox -- echo 'Hello Job'\n\n# Create CronJob\nkubectl create cronjob hourly-task --image=busybox --schedule='0 * * * *' -- echo 'Hourly'\n\n# List CronJobs\nkubectl get cronjobs\n\n# Trigger CronJob manually\nkubectl create job manual-run --from=cronjob/daily-backup\n\n# Suspend CronJob\nkubectl patch cronjob daily-backup -p '{\"spec\":{\"suspend\":true}}'",
          "example": "# Parallel Job with indexed completions\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: parallel-process\nspec:\n  completions: 5\n  parallelism: 3\n  completionMode: Indexed\n  template:\n    spec:\n      restartPolicy: Never\n      containers:\n      - name: worker\n        image: busybox\n        command: ['sh', '-c', 'echo Processing shard $JOB_COMPLETION_INDEX && sleep 10']\n---\n# CronJob with volume for persistent output\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: report-gen\nspec:\n  schedule: \"0 6 * * 1\"\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          restartPolicy: OnFailure\n          containers:\n          - name: reporter\n            image: python:3.11-alpine\n            command: ['python', '-c', 'import datetime; print(f\"Report generated at {datetime.datetime.now()}\")']\n            volumeMounts:\n            - name: reports\n              mountPath: /reports\n          volumes:\n          - name: reports\n            persistentVolumeClaim:\n              claimName: reports-pvc",
          "useCase": "Database migrations, ETL pipelines, batch processing, scheduled backups, report generation, cleanup tasks, data exports",
          "interviewQuestions": [
            {
              "question": "What is the difference between a Job and a CronJob?",
              "answer": "Job: Runs once (or N times) to completion. Creates pods that exit after task is done. CronJob: Creates Jobs on a schedule (cron syntax). Like a recurring Job. CronJob is to Job what crontab is to a shell command. A CronJob never runs pods directly — it creates a Job which creates a pod."
            },
            {
              "question": "What restartPolicy values are valid for Jobs?",
              "answer": "Only Never or OnFailure. Never: pod is never restarted, new pod is created on failure (useful for debugging — failed pods remain for log inspection). OnFailure: container is restarted in same pod. Always is NOT valid — Jobs must terminate. The backoffLimit controls total retry attempts."
            },
            {
              "question": "How does Job parallelism work?",
              "answer": "spec.completions: total successful pods needed. spec.parallelism: max concurrent pods. Example: completions=10, parallelism=3 means 10 pods must succeed, at most 3 running simultaneously. With Indexed completionMode, each pod gets a unique index (JOB_COMPLETION_INDEX env var)."
            },
            {
              "question": "Explain CronJob concurrencyPolicy options.",
              "answer": "Allow (default): Multiple Jobs can run simultaneously from the same CronJob. Forbid: If previous Job still running, skip this schedule. Replace: Kill the running Job and start a new one. Use Forbid for tasks that shouldn't overlap (DB backup). Use Replace when only latest matters."
            },
            {
              "question": "How do you handle Job failures?",
              "answer": "backoffLimit (default: 6): Max retries before Job marked Failed. Exponential backoff between retries. activeDeadlineSeconds: Overall time limit. restartPolicy: Never (new pod per retry, keeps failed pods for debugging) vs OnFailure (restart in same pod). Monitor with: kubectl describe job."
            },
            {
              "question": "How do you clean up completed Jobs?",
              "answer": "Options: (1) ttlSecondsAfterFinished in Job spec — auto-deletes after N seconds, (2) CronJob's successfulJobsHistoryLimit/failedJobsHistoryLimit (defaults: 3/1), (3) Manual: kubectl delete jobs --field-selector status.successful=1. Without cleanup, completed Job pods accumulate."
            },
            {
              "question": "How would you trigger a CronJob run manually?",
              "answer": "kubectl create job manual-run --from=cronjob/my-cronjob. Creates a one-time Job from the CronJob template. Useful for testing or running an ad-hoc execution without waiting for the schedule. The Job is independent of the CronJob's schedule."
            },
            {
              "question": "What is Indexed completion mode?",
              "answer": "Each pod gets a unique index (0 to completions-1) via JOB_COMPLETION_INDEX environment variable. Useful for parallel processing where each pod handles a different data shard, file batch, or partition. Example: 5 completions → pods get indices 0,1,2,3,4, each processes its partition."
            },
            {
              "question": "How do you prevent a CronJob from running during maintenance?",
              "answer": "Set spec.suspend: true — kubectl patch cronjob myJob -p '{\"spec\":{\"suspend\":true}}'. Pauses future scheduled runs without deleting the CronJob. Set back to false to resume. startingDeadlineSeconds controls how long missed runs can be caught up."
            },
            {
              "question": "What happens if a CronJob misses many scheduled runs?",
              "answer": "If more than 100 schedules are missed (e.g., CronJob suspended too long), K8s logs error and doesn't start. startingDeadlineSeconds defines the window: if >100 schedules would fire in that window, CronJob fails. Set an appropriate deadline to handle short outages without cascading."
            }
          ],
          "exercises": [
            {
              "type": "command",
              "question": "Create a Job that runs a one-time database migration using a Python image.",
              "answer": "kubectl create job db-migrate --image=python:3.11 -- python -c \"print('Migration complete')\"\nkubectl get job db-migrate\nkubectl logs job/db-migrate"
            },
            {
              "type": "write",
              "question": "Write a CronJob that runs every day at midnight to clean up temporary files.",
              "answer": "apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: cleanup\nspec:\n  schedule: \"0 0 * * *\"\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      ttlSecondsAfterFinished: 3600\n      template:\n        spec:\n          restartPolicy: OnFailure\n          containers:\n          - name: cleanup\n            image: busybox\n            command: ['sh', '-c', 'find /tmp -mtime +7 -delete && echo Done']"
            },
            {
              "type": "explain",
              "question": "What is the difference between restartPolicy: Never and OnFailure in a Job?",
              "answer": "Never: On failure, pod status becomes Failed, Job creates a NEW pod for retry. Failed pods remain (useful for debugging logs). OnFailure: Container is restarted within the SAME pod. Pod is not replaced. Use Never for debugging; OnFailure for simpler cleanup and less pod sprawl."
            },
            {
              "type": "scenario",
              "question": "A CronJob runs every 5 minutes but sometimes takes 7 minutes. What happens?",
              "answer": "With concurrencyPolicy: Allow (default), a new Job starts while previous still running — two Jobs overlap. With Forbid: next run is skipped until current finishes. With Replace: running Job is killed and new one starts. Fix: use Forbid or increase interval to avoid overlap."
            },
            {
              "type": "troubleshoot",
              "question": "A Job keeps restarting pods and never completes. How to debug?",
              "answer": "Check: (1) kubectl describe job <name> for events, (2) kubectl logs <pod> for error output, (3) Exit code (non-zero = failure), (4) Check backoffLimit (default: 6), (5) Check activeDeadlineSeconds, (6) Container might OOM — check resource limits, (7) Image pull issues."
            },
            {
              "type": "command",
              "question": "Trigger a CronJob to run immediately without waiting for its schedule.",
              "answer": "kubectl create job manual-test --from=cronjob/daily-backup\nkubectl get jobs\nkubectl logs job/manual-test"
            },
            {
              "type": "write",
              "question": "Write a parallel Job that processes 10 items with 3 concurrent workers.",
              "answer": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: parallel-job\nspec:\n  completions: 10\n  parallelism: 3\n  template:\n    spec:\n      restartPolicy: Never\n      containers:\n      - name: worker\n        image: busybox\n        command: ['sh', '-c', 'echo Processing item && sleep 5']"
            },
            {
              "type": "command",
              "question": "Suspend a running CronJob and then resume it.",
              "answer": "kubectl patch cronjob daily-backup -p '{\"spec\":{\"suspend\":true}}'\nkubectl get cronjob daily-backup  # Shows SUSPEND=True\nkubectl patch cronjob daily-backup -p '{\"spec\":{\"suspend\":false}}'"
            },
            {
              "type": "scenario",
              "question": "You need a Job that must finish within 10 minutes or fail, with max 2 retries.",
              "answer": "apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: time-limited\nspec:\n  activeDeadlineSeconds: 600\n  backoffLimit: 2\n  template:\n    spec:\n      restartPolicy: Never\n      containers:\n      - name: task\n        image: myapp\n        command: ['./process.sh']"
            },
            {
              "type": "command",
              "question": "Clean up all completed Jobs older than 1 hour using TTL.",
              "answer": "# Add ttlSecondsAfterFinished: 3600 to Job spec\n# Or manually:\nkubectl delete jobs --field-selector status.successful=1"
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Create a simple one-time Job",
              "code": "kubectl create job hello --image=busybox -- echo 'Hello from Job'\nkubectl wait --for=condition=complete job/hello --timeout=30s\nkubectl logs job/hello\nkubectl get job hello",
              "output": "Hello from Job / job.batch/hello condition met / COMPLETIONS 1/1"
            },
            {
              "type": "program",
              "question": "Program 2: Job with multiple completions",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: multi-job\nspec:\n  completions: 4\n  parallelism: 2\n  template:\n    spec:\n      restartPolicy: Never\n      containers:\n      - name: worker\n        image: busybox\n        command: ['sh', '-c', 'echo Pod $(hostname) done && sleep 3']\nEOF\nkubectl get pods -l job-name=multi-job -w",
              "output": "2 pods run at a time, then next 2. Total 4 pods complete. COMPLETIONS: 4/4"
            },
            {
              "type": "program",
              "question": "Program 3: Indexed Job with JOB_COMPLETION_INDEX",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: indexed-job\nspec:\n  completions: 5\n  parallelism: 5\n  completionMode: Indexed\n  template:\n    spec:\n      restartPolicy: Never\n      containers:\n      - name: worker\n        image: busybox\n        command: ['sh', '-c', 'echo \"I am shard $JOB_COMPLETION_INDEX\"']\nEOF\nkubectl wait --for=condition=complete job/indexed-job --timeout=60s\nfor i in 0 1 2 3 4; do kubectl logs indexed-job-$i; done",
              "output": "I am shard 0 / I am shard 1 / I am shard 2 / I am shard 3 / I am shard 4"
            },
            {
              "type": "program",
              "question": "Program 4: Job with backoff limit and failure",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: fail-job\nspec:\n  backoffLimit: 2\n  template:\n    spec:\n      restartPolicy: Never\n      containers:\n      - name: fail\n        image: busybox\n        command: ['sh', '-c', 'exit 1']\nEOF\nsleep 30\nkubectl get job fail-job\nkubectl get pods -l job-name=fail-job",
              "output": "COMPLETIONS: 0/1, 3 failed pods (original + 2 retries). Job status: Failed"
            },
            {
              "type": "program",
              "question": "Program 5: Create a CronJob that runs every minute",
              "code": "kubectl create cronjob minute-task --image=busybox --schedule='* * * * *' -- date\necho 'Waiting 70 seconds for first run...'\nsleep 70\nkubectl get cronjobs\nkubectl get jobs --sort-by=.metadata.creationTimestamp\nkubectl logs $(kubectl get pods --sort-by=.metadata.creationTimestamp -l job-name -o name | tail -1)",
              "output": "CronJob created. After 1 minute: Job appears. Pod log shows current date/time."
            },
            {
              "type": "program",
              "question": "Program 6: Trigger CronJob manually",
              "code": "kubectl create cronjob backup --image=busybox --schedule='0 0 * * *' -- echo 'backup done'\nkubectl create job manual-backup --from=cronjob/backup\nkubectl wait --for=condition=complete job/manual-backup --timeout=30s\nkubectl logs job/manual-backup",
              "output": "backup done (Job created from CronJob template, ran immediately)"
            },
            {
              "type": "program",
              "question": "Program 7: Job with activeDeadlineSeconds timeout",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: timeout-job\nspec:\n  activeDeadlineSeconds: 10\n  template:\n    spec:\n      restartPolicy: Never\n      containers:\n      - name: slow\n        image: busybox\n        command: ['sleep', '300']\nEOF\nsleep 15\nkubectl describe job timeout-job | grep -A2 'Conditions'",
              "output": "Type: Failed, Reason: DeadlineExceeded — Job killed after 10 seconds"
            },
            {
              "type": "program",
              "question": "Program 8: CronJob with Forbid concurrency policy",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: no-overlap\nspec:\n  schedule: '* * * * *'\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          restartPolicy: OnFailure\n          containers:\n          - name: slow\n            image: busybox\n            command: ['sleep', '90']\nEOF\nsleep 130\nkubectl get jobs -l job-name | wc -l",
              "output": "Only 1 Job exists — second schedule was skipped because first still running"
            },
            {
              "type": "program",
              "question": "Program 9: Job with ttlSecondsAfterFinished auto-cleanup",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: auto-cleanup\nspec:\n  ttlSecondsAfterFinished: 30\n  template:\n    spec:\n      restartPolicy: Never\n      containers:\n      - name: quick\n        image: busybox\n        command: ['echo', 'done']\nEOF\nkubectl wait --for=condition=complete job/auto-cleanup --timeout=30s\necho 'Job completed. Waiting 35s for TTL cleanup...'\nsleep 35\nkubectl get job auto-cleanup 2>&1",
              "output": "Error: jobs.batch \"auto-cleanup\" not found (auto-deleted after 30s)"
            },
            {
              "type": "program",
              "question": "Program 10: Suspend and resume a CronJob",
              "code": "kubectl create cronjob suspend-test --image=busybox --schedule='* * * * *' -- echo 'tick'\nsleep 65\nkubectl get jobs | grep suspend-test | wc -l\nkubectl patch cronjob suspend-test -p '{\"spec\":{\"suspend\":true}}'\necho 'Suspended. Waiting 65s...'\nsleep 65\nkubectl get jobs | grep suspend-test | wc -l\nkubectl patch cronjob suspend-test -p '{\"spec\":{\"suspend\":false}}'",
              "output": "1 Job ran before suspend. No new Jobs during suspension. Resumes after unsuspend."
            }
          ]
        },
        {
          "id": "ingress",
          "title": "Ingress & Ingress Controllers",
          "category": "Kubernetes Networking",
          "description": "HTTP/HTTPS routing, TLS termination, and external access management with Ingress resources.",
          "explanation": "Ingress exposes HTTP/HTTPS routes from outside the cluster to services within. It provides URL-based routing, TLS termination, virtual hosting, and load balancing — capabilities that plain Services (NodePort, LoadBalancer) lack.\n\nComponents:\n- Ingress resource: Declarative routing rules (YAML). Defines which hostname/path maps to which Service.\n- Ingress Controller: The actual proxy that implements the rules. NOT included by default — must be installed. Popular controllers: NGINX Ingress, Traefik, HAProxy, AWS ALB, Istio Gateway.\n\nRouting types:\n- Host-based: Route by domain name. api.example.com → api-service, web.example.com → web-service.\n- Path-based: Route by URL path. example.com/api → api-service, example.com/web → web-service.\n- Combined: Both host and path rules in one Ingress.\n\nPath types (pathType field):\n- Prefix: Matches URL path prefix. /api matches /api, /api/, /api/v1.\n- Exact: Exact match only. /api matches only /api, NOT /api/.\n- ImplementationSpecific: Behavior depends on IngressClass.\n\nTLS termination:\n- Ingress handles SSL/TLS at the edge. Backend services communicate over HTTP.\n- Store TLS certificate in a Kubernetes Secret (type: kubernetes.io/tls).\n- Reference the Secret in the Ingress spec.tls section.\n- Use cert-manager for automatic certificate provisioning from Let's Encrypt.\n\nIngressClass:\n- Specifies which Ingress Controller handles this Ingress.\n- Multiple controllers can coexist (e.g., NGINX for public, Traefik for internal).\n- spec.ingressClassName: 'nginx' or annotation kubernetes.io/ingress.class.\n\nIngress vs Gateway API:\n- Ingress: Simple, HTTP-only routing. Widely supported. Limited features.\n- Gateway API (newer): Richer model — supports TCP/UDP, traffic splitting, header modification. Replaces Ingress long-term.\n- Gateway API has separate resources: GatewayClass, Gateway, HTTPRoute.\n\nBest practices:\n- Always configure TLS for production Ingress.\n- Use cert-manager for automatic certificate management.\n- Set rate limiting and WAF rules via annotations.\n- Configure health checks for backends.\n- Use defaultBackend for catch-all 404 handling.",
          "code": "# Simple Ingress with path-based routing\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: app-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: myapp.example.com\n    http:\n      paths:\n      - path: /api\n        pathType: Prefix\n        backend:\n          service:\n            name: api-service\n            port:\n              number: 80\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: web-service\n            port:\n              number: 80",
          "command": "# Install NGINX Ingress Controller\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml\n\n# Create Ingress\nkubectl apply -f ingress.yaml\n\n# List Ingresses\nkubectl get ingress\n\n# Describe Ingress (shows rules, backends, events)\nkubectl describe ingress app-ingress\n\n# Check Ingress Controller pods\nkubectl get pods -n ingress-nginx\n\n# Get external IP of Ingress Controller\nkubectl get svc -n ingress-nginx\n\n# Create TLS secret for Ingress\nkubectl create secret tls myapp-tls --cert=tls.crt --key=tls.key",
          "example": "# Ingress with TLS and multiple hosts\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: multi-host-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/proxy-body-size: \"10m\"\n    cert-manager.io/cluster-issuer: letsencrypt-prod\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - api.example.com\n    - web.example.com\n    secretName: example-tls\n  rules:\n  - host: api.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: api-service\n            port:\n              number: 8080\n  - host: web.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: web-service\n            port:\n              number: 3000\n  defaultBackend:\n    service:\n      name: default-backend\n      port:\n        number: 80",
          "useCase": "HTTP routing, TLS termination, virtual hosting, URL-based routing, API gateway, SSL offloading",
          "interviewQuestions": [
            {
              "question": "What is the difference between Ingress and a LoadBalancer Service?",
              "answer": "LoadBalancer Service: One external IP per service, L4 (TCP/UDP), no path/host routing. Ingress: Single entry point for multiple services, L7 (HTTP/HTTPS), path-based and host-based routing, TLS termination. Ingress is more cost-effective (one LB for many services) and feature-rich."
            },
            {
              "question": "What is an Ingress Controller and why is it needed?",
              "answer": "Ingress resource is just configuration — it doesn't do anything alone. The Ingress Controller is a pod running a reverse proxy (NGINX, Traefik, HAProxy) that reads Ingress resources and configures routing rules. K8s doesn't include one by default — you must install it."
            },
            {
              "question": "How does Ingress handle TLS/SSL?",
              "answer": "TLS certificate and key stored in a Kubernetes Secret (type: kubernetes.io/tls). Ingress references the Secret in spec.tls. The Ingress Controller terminates TLS at the edge — traffic to backend services is HTTP. Use cert-manager for automatic certificate provisioning from Let's Encrypt."
            },
            {
              "question": "Explain path-based vs host-based routing in Ingress.",
              "answer": "Path-based: Single domain, route by URL path. example.com/api → api-service, example.com/web → web-service. Host-based: Route by hostname. api.example.com → api-service, web.example.com → web-service. Can combine both: api.example.com/v1 → api-v1-service."
            },
            {
              "question": "What are Ingress pathType options?",
              "answer": "Prefix: Matches URL path prefix. /api matches /api, /api/, /api/users. Exact: Exact match only. /api matches only /api. ImplementationSpecific: Controller-dependent behavior. Always specify pathType — it's required since networking.k8s.io/v1."
            },
            {
              "question": "How do you handle multiple Ingress Controllers in one cluster?",
              "answer": "Use IngressClass. Each controller registers an IngressClass (e.g., nginx, traefik). Ingress resources specify which controller via spec.ingressClassName. One can be set as default (isDefaultClass annotation). Enables separation: public Ingress via NGINX, internal via Traefik."
            },
            {
              "question": "What is the default backend in Ingress?",
              "answer": "defaultBackend handles requests that don't match any rule (host/path). Returns a custom 404 page or catch-all response. Can be specified per Ingress or at the controller level. Without it, unmatched requests get the controller's default 404 page."
            },
            {
              "question": "How does cert-manager work with Ingress?",
              "answer": "cert-manager watches Ingress resources with annotation cert-manager.io/cluster-issuer. Automatically creates Certificate resource, solves ACME challenge (HTTP01 or DNS01), obtains certificate from Let's Encrypt, stores in specified Secret, and renews before expiration."
            },
            {
              "question": "What is the Gateway API and how does it compare to Ingress?",
              "answer": "Gateway API: Next-generation replacement for Ingress. Supports TCP/UDP (not just HTTP), traffic splitting, header manipulation, role-based resource model (GatewayClass→Gateway→HTTPRoute). More expressive and extensible. Ingress remains simpler for basic HTTP routing."
            },
            {
              "question": "How do you implement rate limiting with Ingress?",
              "answer": "NGINX Ingress: annotations like nginx.ingress.kubernetes.io/limit-rps: '10' (10 requests/second), limit-connections, limit-rpm. Can set custom response code. For more advanced: use external auth (oauth2-proxy), WAF integration, or service mesh (Istio) rate limiting."
            }
          ],
          "exercises": [
            {
              "type": "write",
              "question": "Write an Ingress that routes /api to api-service:8080 and / to frontend-service:3000.",
              "answer": "apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: app-routing\nspec:\n  ingressClassName: nginx\n  rules:\n  - http:\n      paths:\n      - path: /api\n        pathType: Prefix\n        backend:\n          service:\n            name: api-service\n            port:\n              number: 8080\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: frontend-service\n            port:\n              number: 3000"
            },
            {
              "type": "write",
              "question": "Write an Ingress with TLS termination for myapp.example.com.",
              "answer": "apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: tls-ingress\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - myapp.example.com\n    secretName: myapp-tls\n  rules:\n  - host: myapp.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: myapp\n            port:\n              number: 80"
            },
            {
              "type": "command",
              "question": "Install NGINX Ingress Controller and verify it's running.",
              "answer": "kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml\nkubectl get pods -n ingress-nginx\nkubectl get svc -n ingress-nginx"
            },
            {
              "type": "troubleshoot",
              "question": "Ingress returns 503. Backend service exists. What to check?",
              "answer": "Check: (1) Service selector matches pod labels, (2) kubectl get endpoints <service> — should list pod IPs, (3) Pod is Running and passing readiness probe, (4) Port numbers match (Ingress→Service→Pod), (5) kubectl describe ingress for events/errors, (6) Ingress Controller logs."
            },
            {
              "type": "explain",
              "question": "Why do you need an Ingress Controller? What happens without one?",
              "answer": "Ingress resource is just a spec — routing rules stored in etcd. Without a controller, nothing reads or implements those rules. Creating Ingress resources without a controller has no effect. The controller (NGINX, Traefik) is the actual reverse proxy that configures itself from Ingress resources."
            },
            {
              "type": "scenario",
              "question": "You have 20 microservices. Should you use 20 LoadBalancer Services or Ingress?",
              "answer": "Ingress. 20 LoadBalancers = 20 external IPs, 20 cloud LB costs (~$15-18/month each). One Ingress Controller with one LoadBalancer: single entry point, path/host routing to all 20 services, centralized TLS, much cheaper and manageable."
            },
            {
              "type": "command",
              "question": "Create a TLS secret from certificate files for use in Ingress.",
              "answer": "kubectl create secret tls myapp-tls --cert=./tls.crt --key=./tls.key\nkubectl get secret myapp-tls -o yaml"
            },
            {
              "type": "write",
              "question": "Write an Ingress with host-based routing: api.example.com and web.example.com.",
              "answer": "apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: multi-host\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: api.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: api-svc\n            port:\n              number: 8080\n  - host: web.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: web-svc\n            port:\n              number: 3000"
            },
            {
              "type": "explain",
              "question": "What is the rewrite-target annotation and when is it needed?",
              "answer": "When Ingress path is /api but backend expects /. Without rewrite: request to /api/users → backend receives /api/users (404 if backend doesn't know /api prefix). With nginx.ingress.kubernetes.io/rewrite-target: /: /api/users → backend receives /users. Essential for prefix-stripped routing."
            },
            {
              "type": "scenario",
              "question": "How do you handle WebSocket connections through Ingress?",
              "answer": "NGINX Ingress supports WebSocket by default (Connection upgrade headers). For long-lived connections, increase timeouts: nginx.ingress.kubernetes.io/proxy-read-timeout: '3600', proxy-send-timeout: '3600'. For sticky sessions: nginx.ingress.kubernetes.io/affinity: cookie."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Deploy two services and route with path-based Ingress",
              "code": "kubectl create deployment api --image=hashicorp/http-echo -- -text='API response'\nkubectl expose deployment api --port=80 --target-port=5678\nkubectl create deployment web --image=hashicorp/http-echo -- -text='Web response'\nkubectl expose deployment web --port=80 --target-port=5678\ncat <<EOF | kubectl apply -f -\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: path-routing\nspec:\n  ingressClassName: nginx\n  rules:\n  - http:\n      paths:\n      - path: /api\n        pathType: Prefix\n        backend:\n          service:\n            name: api\n            port:\n              number: 80\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: web\n            port:\n              number: 80\nEOF\nkubectl get ingress path-routing",
              "output": "Ingress created. /api → 'API response', / → 'Web response'"
            },
            {
              "type": "program",
              "question": "Program 2: Create TLS secret and Ingress with HTTPS",
              "code": "openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj '/CN=myapp.local'\nkubectl create secret tls myapp-tls --cert=tls.crt --key=tls.key\ncat <<EOF | kubectl apply -f -\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: tls-ingress\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - myapp.local\n    secretName: myapp-tls\n  rules:\n  - host: myapp.local\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: web\n            port:\n              number: 80\nEOF\nkubectl describe ingress tls-ingress | grep -A3 TLS",
              "output": "TLS: myapp-tls terminates myapp.local. HTTPS enabled."
            },
            {
              "type": "program",
              "question": "Program 3: Host-based routing with multiple domains",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: host-routing\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: api.local\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: api\n            port:\n              number: 80\n  - host: web.local\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: web\n            port:\n              number: 80\nEOF\nkubectl get ingress host-routing",
              "output": "Two hosts configured. api.local → api service, web.local → web service"
            },
            {
              "type": "program",
              "question": "Program 4: Ingress with rate limiting annotations",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: rate-limited\n  annotations:\n    nginx.ingress.kubernetes.io/limit-rps: \"5\"\n    nginx.ingress.kubernetes.io/limit-burst-multiplier: \"3\"\nspec:\n  ingressClassName: nginx\n  rules:\n  - http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: web\n            port:\n              number: 80\nEOF\nkubectl describe ingress rate-limited | grep -i limit",
              "output": "Rate limiting annotations applied: 5 requests/sec with burst multiplier 3"
            },
            {
              "type": "program",
              "question": "Program 5: Check Ingress Controller logs for debugging",
              "code": "kubectl logs -n ingress-nginx -l app.kubernetes.io/component=controller --tail=20",
              "output": "NGINX Ingress Controller access/error logs showing routing decisions and configuration reloads"
            },
            {
              "type": "program",
              "question": "Program 6: Ingress with default backend for 404 handling",
              "code": "kubectl create deployment default-backend --image=hashicorp/http-echo -- -text='404 Not Found'\nkubectl expose deployment default-backend --port=80 --target-port=5678\ncat <<EOF | kubectl apply -f -\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: with-default\nspec:\n  ingressClassName: nginx\n  defaultBackend:\n    service:\n      name: default-backend\n      port:\n        number: 80\n  rules:\n  - host: myapp.local\n    http:\n      paths:\n      - path: /app\n        pathType: Prefix\n        backend:\n          service:\n            name: web\n            port:\n              number: 80\nEOF\nkubectl describe ingress with-default | grep -i default",
              "output": "Default backend: default-backend:80. Any unmatched request → '404 Not Found'"
            },
            {
              "type": "program",
              "question": "Program 7: Verify Ingress endpoints are healthy",
              "code": "kubectl get ingress -o wide\nkubectl describe ingress path-routing | grep -A5 Rules\nkubectl get endpoints api web",
              "output": "Shows Ingress ADDRESS, routing rules, and backend endpoint IPs confirming healthy backends"
            },
            {
              "type": "program",
              "question": "Program 8: Ingress with rewrite-target annotation",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: rewrite-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\nspec:\n  ingressClassName: nginx\n  rules:\n  - http:\n      paths:\n      - path: /api(/|$)(.*)\n        pathType: ImplementationSpecific\n        backend:\n          service:\n            name: api\n            port:\n              number: 80\nEOF\nkubectl describe ingress rewrite-ingress",
              "output": "Rewrite target configured: /api/users → backend receives /users (prefix stripped)"
            },
            {
              "type": "program",
              "question": "Program 9: List all IngressClasses in cluster",
              "code": "kubectl get ingressclass\nkubectl describe ingressclass nginx",
              "output": "Shows available IngressClasses (nginx, etc.) and which is default"
            },
            {
              "type": "program",
              "question": "Program 10: Test Ingress routing with curl",
              "code": "INGRESS_IP=$(kubectl get ingress path-routing -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\ncurl -H 'Host: myapp.local' http://$INGRESS_IP/\ncurl -H 'Host: myapp.local' http://$INGRESS_IP/api",
              "output": "/ returns 'Web response', /api returns 'API response' — routing works correctly"
            }
          ]
        },
        {
          "id": "rbac",
          "title": "RBAC (Role-Based Access Control)",
          "category": "Kubernetes Security",
          "description": "Controlling access to Kubernetes resources using Roles, ClusterRoles, RoleBindings, and ClusterRoleBindings.",
          "explanation": "RBAC (Role-Based Access Control) regulates access to Kubernetes resources based on the roles assigned to users, groups, or service accounts.\n\nCore objects:\n- Role: Grants permissions within a specific namespace. Contains rules with apiGroups, resources, and verbs.\n- ClusterRole: Like Role but cluster-wide. Can grant access to cluster-scoped resources (nodes, namespaces) or across all namespaces.\n- RoleBinding: Binds a Role (or ClusterRole) to subjects within a namespace.\n- ClusterRoleBinding: Binds a ClusterRole to subjects cluster-wide.\n\nSubjects (who gets access):\n- User: External identity (certificate CN, OIDC token). Not a K8s object — managed externally.\n- Group: Set of users. system:masters (cluster admin), system:authenticated, system:unauthenticated.\n- ServiceAccount: In-cluster identity for pods. Created in a namespace. Pods use ServiceAccount tokens to authenticate to the API server.\n\nVerbs (what actions are allowed):\n- get, list, watch: Read operations.\n- create, update, patch, delete: Write operations.\n- deletecollection: Delete multiple resources.\n- Special: use (PodSecurityPolicies), bind, escalate (prevent privilege escalation), impersonate.\n\nKey principles:\n- Least privilege: Grant minimum permissions needed. Start with no access, add incrementally.\n- Namespace isolation: Use Roles + RoleBindings for team/environment isolation.\n- Avoid cluster-admin: Don't bind cluster-admin ClusterRole to regular users.\n- Audit: kubectl auth can-i to test permissions. kubectl auth can-i --list to see all permissions.\n\nDefault ClusterRoles:\n- cluster-admin: Full access to everything (superuser).\n- admin: Full access within a namespace (no ResourceQuotas or namespace itself).\n- edit: Read/write most resources in a namespace (no Roles, RoleBindings).\n- view: Read-only access to most resources (no Secrets by default).\n\nService Account best practices:\n- Don't use default ServiceAccount — create dedicated ones per workload.\n- Disable auto-mounting: automountServiceAccountToken: false when not needed.\n- Use projected token volumes (bound tokens) instead of legacy long-lived tokens.\n- K8s 1.24+ no longer auto-creates Secret-based tokens for ServiceAccounts.",
          "code": "# Role: read-only access to pods in 'dev' namespace\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: pod-reader\n  namespace: dev\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"pods/log\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n---\n# RoleBinding: bind pod-reader to user 'jane'\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: jane-pod-reader\n  namespace: dev\nsubjects:\n- kind: User\n  name: jane\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: pod-reader\n  apiGroup: rbac.authorization.k8s.io\n---\n# ClusterRole: read nodes across cluster\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: node-reader\nrules:\n- apiGroups: [\"\"]\n  resources: [\"nodes\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n---\n# ClusterRoleBinding: bind to group\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: ops-node-reader\nsubjects:\n- kind: Group\n  name: ops-team\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: node-reader\n  apiGroup: rbac.authorization.k8s.io",
          "command": "# Check if you can perform an action\nkubectl auth can-i create deployments --namespace dev\n\n# Check permissions as another user\nkubectl auth can-i get pods --as jane --namespace dev\n\n# List all permissions for current user\nkubectl auth can-i --list\n\n# Create Role imperatively\nkubectl create role pod-reader --verb=get,list,watch --resource=pods -n dev\n\n# Create RoleBinding imperatively\nkubectl create rolebinding jane-read --role=pod-reader --user=jane -n dev\n\n# Create ClusterRole\nkubectl create clusterrole node-reader --verb=get,list,watch --resource=nodes\n\n# Create ClusterRoleBinding\nkubectl create clusterrolebinding ops-nodes --clusterrole=node-reader --group=ops-team\n\n# Create ServiceAccount\nkubectl create serviceaccount app-sa -n dev\n\n# Bind ClusterRole to ServiceAccount in namespace\nkubectl create rolebinding app-sa-edit --clusterrole=edit --serviceaccount=dev:app-sa -n dev",
          "example": "# Full RBAC setup for a dev team\n# 1. Create namespace\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: team-alpha\n---\n# 2. ServiceAccount for the team's app\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: alpha-app\n  namespace: team-alpha\n---\n# 3. Role: manage deployments and services\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: alpha-developer\n  namespace: team-alpha\nrules:\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\", \"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"pods/log\", \"services\", \"configmaps\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n- apiGroups: [\"\"]\n  resources: [\"secrets\"]\n  verbs: [\"get\", \"list\"]\n---\n# 4. Bind to team group\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: alpha-developers\n  namespace: team-alpha\nsubjects:\n- kind: Group\n  name: team-alpha-devs\n  apiGroup: rbac.authorization.k8s.io\n- kind: ServiceAccount\n  name: alpha-app\n  namespace: team-alpha\nroleRef:\n  kind: Role\n  name: alpha-developer\n  apiGroup: rbac.authorization.k8s.io",
          "useCase": "Multi-tenant clusters, team isolation, CI/CD service accounts, compliance, least-privilege access, audit requirements",
          "interviewQuestions": [
            {
              "question": "What is RBAC in Kubernetes and why is it important?",
              "answer": "RBAC controls who (subjects) can do what (verbs) on which resources. Uses 4 objects: Role (namespace-scoped permissions), ClusterRole (cluster-wide), RoleBinding, ClusterRoleBinding. Important for security, multi-tenancy, compliance, and preventing unauthorized access. Enabled by default since K8s 1.8."
            },
            {
              "question": "What is the difference between Role and ClusterRole?",
              "answer": "Role: namespace-scoped, grants permissions within a specific namespace. ClusterRole: cluster-scoped, can grant access to cluster resources (nodes, namespaces, PVs) or same permissions across all namespaces. A ClusterRole can be bound in a namespace via RoleBinding (common pattern for reusable roles)."
            },
            {
              "question": "Can a RoleBinding reference a ClusterRole? What happens?",
              "answer": "Yes. RoleBinding + ClusterRole grants the ClusterRole's permissions but only within the RoleBinding's namespace. Common pattern: define ClusterRole once (e.g., 'edit'), bind it per namespace with RoleBindings. Avoids duplicating Role definitions across namespaces."
            },
            {
              "question": "How do ServiceAccounts work in RBAC?",
              "answer": "ServiceAccount is an in-cluster identity for pods. Created per namespace. Pod specifies serviceAccountName. K8s auto-mounts a token. ServiceAccount can be bound to Roles/ClusterRoles via RoleBinding/ClusterRoleBinding. Subject format: system:serviceaccount:<namespace>:<name>."
            },
            {
              "question": "How do you check what permissions a user or ServiceAccount has?",
              "answer": "kubectl auth can-i <verb> <resource> — checks your own permissions. Add --as=<user> to impersonate. kubectl auth can-i --list — shows all permissions. kubectl auth can-i --list --as=system:serviceaccount:dev:app-sa — check ServiceAccount permissions. Also: kubectl get rolebindings,clusterrolebindings."
            },
            {
              "question": "What is the principle of least privilege in RBAC?",
              "answer": "Grant only the minimum permissions required. Don't use cluster-admin for regular users. Create specific Roles per use case. Use namespace-scoped Roles instead of ClusterRoles when possible. Regularly audit permissions. Avoid wildcard (*) in verbs or resources. Review and remove unused bindings."
            },
            {
              "question": "Explain the default ClusterRoles (cluster-admin, admin, edit, view).",
              "answer": "cluster-admin: Superuser, all resources all verbs. admin: Full access within a namespace (no quota/namespace mgmt). edit: Read/write most namespace resources (no roles/bindings). view: Read-only (no secrets). These are aggregated ClusterRoles — custom ClusterRoles can extend them."
            },
            {
              "question": "How do you prevent privilege escalation in RBAC?",
              "answer": "K8s prevents creating Roles with more permissions than you have. Can't bind a Role you can't create. The 'escalate' verb is needed to create Roles with permissions beyond your own. The 'bind' verb controls who can create RoleBindings. Never give wildcard (*) permissions to non-admins."
            },
            {
              "question": "How do you implement multi-tenancy with RBAC?",
              "answer": "Create namespace per tenant. Define Roles with tenant-specific permissions. Create RoleBindings for tenant users/groups. Add ResourceQuotas and LimitRanges per namespace. Use NetworkPolicies for network isolation. Consider OPA/Kyverno for additional policy enforcement beyond RBAC."
            },
            {
              "question": "What changed with ServiceAccount tokens in Kubernetes 1.24+?",
              "answer": "K8s 1.24+ no longer auto-creates long-lived Secret-based tokens for ServiceAccounts. Instead uses projected bound tokens: time-limited, audience-bound, auto-rotated. More secure — tokens expire and can't be extracted. For long-lived tokens (discouraged), manually create: kubectl create token <sa-name>."
            }
          ],
          "exercises": [
            {
              "type": "command",
              "question": "Create a Role that allows reading pods and their logs in the 'staging' namespace.",
              "answer": "kubectl create role pod-log-reader --verb=get,list,watch --resource=pods,pods/log -n staging"
            },
            {
              "type": "command",
              "question": "Bind the pod-log-reader Role to user 'alice' in the 'staging' namespace.",
              "answer": "kubectl create rolebinding alice-pod-reader --role=pod-log-reader --user=alice -n staging"
            },
            {
              "type": "explain",
              "question": "Why should you avoid using the default ServiceAccount?",
              "answer": "The default ServiceAccount exists in every namespace and gets auto-mounted to pods. If granted extra permissions, ALL pods in that namespace inherit them (unintended privilege). Create dedicated ServiceAccounts per workload with specific permissions. Set automountServiceAccountToken: false on default."
            },
            {
              "type": "troubleshoot",
              "question": "A user gets 'forbidden' when trying to list pods in namespace 'dev'. How to debug?",
              "answer": "Check: (1) kubectl auth can-i list pods -n dev --as=<user>, (2) kubectl get rolebindings -n dev — verify binding exists, (3) kubectl describe rolebinding <name> — verify subject matches user, (4) Check if Role has 'list' verb for 'pods', (5) Verify user identity (certificate CN or OIDC claim)."
            },
            {
              "type": "write",
              "question": "Write a ClusterRole that allows managing deployments across all namespaces.",
              "answer": "apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: deployment-manager\nrules:\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]"
            },
            {
              "type": "scenario",
              "question": "Your CI/CD pipeline needs to deploy to the 'production' namespace only. How to set up RBAC?",
              "answer": "Create ServiceAccount 'ci-deployer' in 'production'. Create Role with verbs on deployments, services, configmaps, secrets. Create RoleBinding binding the Role to the ServiceAccount. Generate a token: kubectl create token ci-deployer -n production. Use token in CI/CD kubeconfig."
            },
            {
              "type": "command",
              "question": "Check all permissions for a ServiceAccount named 'app-sa' in namespace 'dev'.",
              "answer": "kubectl auth can-i --list --as=system:serviceaccount:dev:app-sa -n dev"
            },
            {
              "type": "write",
              "question": "Write a RoleBinding that binds the built-in 'view' ClusterRole to a group 'interns' in namespace 'sandbox'.",
              "answer": "apiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: interns-view\n  namespace: sandbox\nsubjects:\n- kind: Group\n  name: interns\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: view\n  apiGroup: rbac.authorization.k8s.io"
            },
            {
              "type": "scenario",
              "question": "A developer needs to exec into pods for debugging but shouldn't delete them. What Role?",
              "answer": "apiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: pod-debugger\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"\"]\n  resources: [\"pods/exec\", \"pods/log\"]\n  verbs: [\"get\", \"create\"]"
            },
            {
              "type": "command",
              "question": "List all RoleBindings and ClusterRoleBindings that reference a specific user.",
              "answer": "kubectl get rolebindings,clusterrolebindings --all-namespaces -o json | python3 -c \"import sys,json; data=json.load(sys.stdin); [print(i['metadata']['name'], i['metadata'].get('namespace','cluster-wide')) for i in data['items'] for s in i.get('subjects',[]) if s.get('name')=='alice']\""
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Create Role and RoleBinding, test access",
              "code": "kubectl create namespace rbac-test\nkubectl create role pod-reader --verb=get,list --resource=pods -n rbac-test\nkubectl create rolebinding test-read --role=pod-reader --user=testuser -n rbac-test\nkubectl auth can-i list pods -n rbac-test --as=testuser\nkubectl auth can-i delete pods -n rbac-test --as=testuser",
              "output": "yes / no (can list pods but cannot delete them)"
            },
            {
              "type": "program",
              "question": "Program 2: Create ServiceAccount and bind to Role",
              "code": "kubectl create serviceaccount app-sa -n rbac-test\nkubectl create role app-role --verb=get,list,create,update --resource=deployments.apps,services -n rbac-test\nkubectl create rolebinding app-sa-binding --role=app-role --serviceaccount=rbac-test:app-sa -n rbac-test\nkubectl auth can-i create deployments -n rbac-test --as=system:serviceaccount:rbac-test:app-sa",
              "output": "yes (ServiceAccount can create deployments in rbac-test namespace)"
            },
            {
              "type": "program",
              "question": "Program 3: Use built-in ClusterRole with namespace RoleBinding",
              "code": "kubectl create rolebinding view-binding --clusterrole=view --user=viewer -n rbac-test\nkubectl auth can-i list pods -n rbac-test --as=viewer\nkubectl auth can-i list pods -n default --as=viewer\nkubectl auth can-i create pods -n rbac-test --as=viewer",
              "output": "yes / no / no (view role only in rbac-test, read-only)"
            },
            {
              "type": "program",
              "question": "Program 4: List all permissions for a user",
              "code": "kubectl auth can-i --list --as=testuser -n rbac-test",
              "output": "Resources: pods  Verbs: [get list]\nplus non-resource URLs and self-subject access reviews"
            },
            {
              "type": "program",
              "question": "Program 5: Create ClusterRole and ClusterRoleBinding",
              "code": "kubectl create clusterrole node-viewer --verb=get,list,watch --resource=nodes\nkubectl create clusterrolebinding all-node-view --clusterrole=node-viewer --group=developers\nkubectl auth can-i list nodes --as=devuser --as-group=developers",
              "output": "yes (any user in 'developers' group can list nodes cluster-wide)"
            },
            {
              "type": "program",
              "question": "Program 6: Pod with specific ServiceAccount",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sa-test\n  namespace: rbac-test\nspec:\n  serviceAccountName: app-sa\n  automountServiceAccountToken: true\n  containers:\n  - name: test\n    image: bitnami/kubectl\n    command: ['sleep', '3600']\nEOF\nkubectl exec -n rbac-test sa-test -- kubectl auth can-i list deployments",
              "output": "yes (pod uses app-sa ServiceAccount which has deployment permissions)"
            },
            {
              "type": "program",
              "question": "Program 7: Role with resource names restriction",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: specific-cm-reader\n  namespace: rbac-test\nrules:\n- apiGroups: [\"\"]\n  resources: [\"configmaps\"]\n  resourceNames: [\"app-config\", \"db-config\"]\n  verbs: [\"get\"]\nEOF\nkubectl create rolebinding cm-reader --role=specific-cm-reader --user=limited -n rbac-test\nkubectl auth can-i get configmaps/app-config -n rbac-test --as=limited\nkubectl auth can-i get configmaps/other-config -n rbac-test --as=limited",
              "output": "yes / no (can only read specific named ConfigMaps)"
            },
            {
              "type": "program",
              "question": "Program 8: Audit all RoleBindings in a namespace",
              "code": "kubectl get rolebindings -n rbac-test -o custom-columns='BINDING:.metadata.name,ROLE:.roleRef.name,ROLE-KIND:.roleRef.kind,SUBJECTS:.subjects[*].name'",
              "output": "Lists all bindings with associated roles and subjects in one view"
            },
            {
              "type": "program",
              "question": "Program 9: Create token for ServiceAccount",
              "code": "kubectl create token app-sa -n rbac-test --duration=1h\n# Decode token header\nTOKEN=$(kubectl create token app-sa -n rbac-test --duration=1h)\necho $TOKEN | cut -d. -f2 | base64 -d 2>/dev/null | python3 -m json.tool",
              "output": "JWT token with sub:system:serviceaccount:rbac-test:app-sa, audience, expiry"
            },
            {
              "type": "program",
              "question": "Program 10: Disable ServiceAccount auto-mount on pod",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: no-sa-mount\n  namespace: rbac-test\nspec:\n  automountServiceAccountToken: false\n  containers:\n  - name: app\n    image: busybox\n    command: ['sh', '-c', 'ls /var/run/secrets/kubernetes.io/serviceaccount/ 2>&1 || echo No token mounted; sleep 3600']\nEOF\nkubectl logs no-sa-mount -n rbac-test",
              "output": "No token mounted (pod cannot authenticate to API server — more secure)"
            }
          ]
        },
        {
          "id": "probes",
          "title": "Probes & Health Checks",
          "category": "Kubernetes Workloads",
          "description": "Liveness, readiness, and startup probes for container health management and traffic control.",
          "explanation": "Kubernetes probes check container health and control pod lifecycle and traffic routing.\n\nThree probe types:\n\n1. Liveness Probe: Is the container alive?\n- If fails: kubelet kills the container and restarts it (based on restartPolicy).\n- Use case: Detect deadlocks, infinite loops, stuck processes.\n- Don't check dependencies (DB, external API) — those failures shouldn't trigger restarts.\n\n2. Readiness Probe: Is the container ready to serve traffic?\n- If fails: Pod removed from Service endpoints (no traffic routed to it).\n- Container is NOT restarted — just removed from load balancing.\n- Use case: Warming caches, loading data, waiting for dependencies.\n- Pod stays Running but not Ready until probe passes again.\n\n3. Startup Probe: Has the container finished starting?\n- Disables liveness and readiness probes until it succeeds.\n- If fails: kubelet kills the container (like liveness).\n- Use case: Slow-starting applications (Java apps, large ML models).\n- Prevents liveness probe from killing the container during long startup.\n\nProbe mechanisms:\n- httpGet: HTTP GET to a path/port. 200-399 = success.\n- tcpSocket: TCP connection to a port. Connection established = success.\n- exec: Run a command in the container. Exit code 0 = success.\n- grpc: gRPC health check (K8s 1.27+ stable). Checks gRPC health protocol.\n\nKey parameters:\n- initialDelaySeconds: Wait before first probe (default: 0).\n- periodSeconds: How often to probe (default: 10).\n- timeoutSeconds: Probe timeout (default: 1).\n- successThreshold: Consecutive successes to be considered up (default: 1). For readiness, can be >1.\n- failureThreshold: Consecutive failures before action (default: 3).\n\nBest practices:\n- Always configure readiness probes for services receiving traffic.\n- Use startup probes instead of large initialDelaySeconds for slow apps.\n- Liveness probes should be simple and fast — don't check external dependencies.\n- Readiness probes can check dependencies (DB connection, cache availability).\n- Set timeoutSeconds < periodSeconds to avoid overlapping probes.\n- Use different endpoints for liveness (/healthz) and readiness (/ready).\n- Don't make liveness and readiness probes identical — they serve different purposes.\n\nCommon anti-patterns:\n- Checking external dependencies in liveness probe → cascading restarts when DB goes down.\n- No readiness probe → traffic sent to unready pods during startup.\n- Too aggressive liveness probe → container restart loops under load.\n- Same probe for liveness and readiness → container restarts when it should just stop receiving traffic.",
          "code": "# Pod with all three probe types\napiVersion: v1\nkind: Pod\nmetadata:\n  name: app\nspec:\n  containers:\n  - name: app\n    image: myapp:1.0\n    ports:\n    - containerPort: 8080\n    startupProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n      failureThreshold: 30\n      periodSeconds: 10\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n      periodSeconds: 10\n      timeoutSeconds: 3\n      failureThreshold: 3\n    readinessProbe:\n      httpGet:\n        path: /ready\n        port: 8080\n      periodSeconds: 5\n      timeoutSeconds: 2\n      failureThreshold: 3\n      successThreshold: 1",
          "command": "# Check pod probe status\nkubectl describe pod app | grep -A5 'Liveness\\|Readiness\\|Startup'\n\n# Check pod conditions (Ready status)\nkubectl get pod app -o jsonpath='{.status.conditions}' | python3 -m json.tool\n\n# Watch pod ready status\nkubectl get pods -w\n\n# Check endpoints (readiness affects this)\nkubectl get endpoints my-service\n\n# Check container restart count (liveness failures)\nkubectl get pod app -o jsonpath='{.status.containerStatuses[0].restartCount}'\n\n# View events for probe failures\nkubectl get events --field-selector involvedObject.name=app",
          "example": "# Deployment with comprehensive health checks\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: myapp:2.0\n        ports:\n        - containerPort: 8080\n        # Startup: Allow up to 5 minutes for slow Java app\n        startupProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          failureThreshold: 30\n          periodSeconds: 10\n        # Liveness: Simple check, don't verify dependencies\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          periodSeconds: 15\n          timeoutSeconds: 3\n          failureThreshold: 3\n        # Readiness: Check app + dependencies\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n            httpHeaders:\n            - name: Accept\n              value: application/json\n          periodSeconds: 5\n          timeoutSeconds: 2\n          successThreshold: 2\n          failureThreshold: 3\n        resources:\n          requests:\n            cpu: 200m\n            memory: 256Mi\n---\n# TCP and exec probe examples\napiVersion: v1\nkind: Pod\nmetadata:\n  name: db\nspec:\n  containers:\n  - name: postgres\n    image: postgres:15\n    ports:\n    - containerPort: 5432\n    livenessProbe:\n      tcpSocket:\n        port: 5432\n      periodSeconds: 10\n    readinessProbe:\n      exec:\n        command: ['pg_isready', '-U', 'postgres']\n      periodSeconds: 5",
          "useCase": "Zero-downtime deployments, self-healing containers, traffic management, graceful startup for slow apps, dependency readiness",
          "interviewQuestions": [
            {
              "question": "What are the three types of Kubernetes probes and their purposes?",
              "answer": "Liveness: checks if container is alive. Fails → container restarted. Detects deadlocks/hangs. Readiness: checks if container can serve traffic. Fails → removed from Service endpoints (no traffic). Not restarted. Startup: one-time check for slow-starting apps. Disables liveness/readiness until it passes. Fails → kills container."
            },
            {
              "question": "What happens when a liveness probe fails?",
              "answer": "After failureThreshold consecutive failures, kubelet kills the container and restarts it (based on restartPolicy). restartCount increments. If restarts keep failing, enters CrashLoopBackOff with exponential backoff (10s, 20s, 40s... up to 5 min). Events show 'Liveness probe failed' messages."
            },
            {
              "question": "What happens when a readiness probe fails?",
              "answer": "Pod is removed from Service endpoints — no new traffic routed to it. Existing connections may continue (depends on implementation). Container is NOT restarted. Pod stays Running but READY becomes 0/1. When probe passes again, pod is re-added to endpoints. Useful for temporary issues."
            },
            {
              "question": "Why shouldn't liveness probes check external dependencies?",
              "answer": "If liveness checks DB and DB goes down, ALL pods get killed and restart simultaneously → cascading failure. App isn't broken, DB is. Restarting app won't fix DB. Use readiness probe for dependency checks (stops traffic but doesn't restart). Liveness should only check if the app process itself is healthy."
            },
            {
              "question": "When should you use a startup probe instead of initialDelaySeconds?",
              "answer": "Startup probe is better for apps with variable startup time. initialDelaySeconds is fixed — too short and liveness kills the container, too long and failures are detected late. Startup probe allows failureThreshold * periodSeconds window (e.g., 30*10=300s) while checking actively. Also enables faster failure detection."
            },
            {
              "question": "What are the four probe mechanisms available?",
              "answer": "httpGet: HTTP GET request, 2xx-3xx = success. Most common for web apps. tcpSocket: TCP connection attempt, connection = success. Good for databases. exec: Run command, exit 0 = success. Flexible but adds overhead. grpc: Native gRPC health check protocol (1.27+ stable). For gRPC services."
            },
            {
              "question": "Explain the probe configuration parameters.",
              "answer": "initialDelaySeconds: Wait before first probe. periodSeconds: Interval between probes (default: 10). timeoutSeconds: Max time for probe response (default: 1). failureThreshold: Consecutive failures to trigger action (default: 3). successThreshold: Consecutive successes to be considered healthy (default: 1, for readiness can be >1)."
            },
            {
              "question": "How do probes interact with rolling deployments?",
              "answer": "During rolling update, new pods must pass readiness probe before old pods are terminated. If new pod never becomes ready, rollout stalls (maxUnavailable/maxSurge control behavior). minReadySeconds adds additional wait after readiness. Without readiness probe, pod is considered ready immediately → users may hit unready pods."
            },
            {
              "question": "What is a common anti-pattern with liveness and readiness probes?",
              "answer": "Using the same endpoint for both. They serve different purposes: liveness detects if app is broken (restart it), readiness detects if app is temporarily unable to serve (stop traffic). If identical, any readiness issue triggers a restart, which may be unnecessary. Use /healthz for liveness, /ready for readiness."
            },
            {
              "question": "How do probes affect pod scheduling and eviction?",
              "answer": "Probes don't affect scheduling (that's resource-based). But readiness affects endpoint inclusion — pod failing readiness won't receive traffic. Liveness failures cause restarts, increasing restartCount. Pods in CrashLoopBackOff may eventually be evicted. PodDisruptionBudget considers Ready pods for voluntary disruption decisions."
            }
          ],
          "exercises": [
            {
              "type": "write",
              "question": "Write a pod spec with an HTTP liveness probe on /healthz port 8080, checking every 15 seconds.",
              "answer": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: health-check\nspec:\n  containers:\n  - name: app\n    image: myapp:1.0\n    ports:\n    - containerPort: 8080\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n      periodSeconds: 15\n      timeoutSeconds: 3\n      failureThreshold: 3"
            },
            {
              "type": "explain",
              "question": "Why use a startup probe for a Java application?",
              "answer": "Java apps (especially Spring Boot) can take 30-120+ seconds to start (JVM warmup, classpath scanning, bean initialization). Without startup probe, a liveness probe would kill the container before it finishes starting. Startup probe allows failureThreshold*periodSeconds (e.g., 30*10=300s) for startup, then liveness takes over."
            },
            {
              "type": "write",
              "question": "Write a readiness probe using exec that runs 'pg_isready' for a PostgreSQL container.",
              "answer": "readinessProbe:\n  exec:\n    command: ['pg_isready', '-U', 'postgres', '-d', 'mydb']\n  periodSeconds: 5\n  timeoutSeconds: 2\n  failureThreshold: 3\n  successThreshold: 1"
            },
            {
              "type": "troubleshoot",
              "question": "A pod shows Running but 0/1 Ready. What could cause this?",
              "answer": "Readiness probe is failing. Check: (1) kubectl describe pod <name> — look for 'Readiness probe failed' events, (2) Probe endpoint not responding (app not ready), (3) Wrong port or path in probe config, (4) timeoutSeconds too low, (5) App dependency not available (DB down), (6) Container still starting (no startup probe)."
            },
            {
              "type": "scenario",
              "question": "Your app takes 2 minutes to warm its cache on startup. How to configure probes?",
              "answer": "Use startup probe: failureThreshold=24, periodSeconds=5 (allows 120s). After startup succeeds, liveness and readiness probes activate. Liveness: check /healthz (simple, every 10s). Readiness: check /ready which verifies cache is warm. Don't use initialDelaySeconds=120 — it's a fixed delay with no active checking."
            },
            {
              "type": "command",
              "question": "Check why a container keeps restarting using events and probe status.",
              "answer": "kubectl describe pod <name> | grep -A10 'Events'\nkubectl get events --field-selector involvedObject.name=<name> --sort-by=.lastTimestamp\nkubectl get pod <name> -o jsonpath='{.status.containerStatuses[0].restartCount}'"
            },
            {
              "type": "write",
              "question": "Write a TCP liveness probe for a Redis container on port 6379.",
              "answer": "livenessProbe:\n  tcpSocket:\n    port: 6379\n  initialDelaySeconds: 5\n  periodSeconds: 10\n  timeoutSeconds: 2\n  failureThreshold: 3"
            },
            {
              "type": "scenario",
              "question": "During a rolling deployment, new pods pass liveness but not readiness. What happens?",
              "answer": "Rollout stalls. New pods are Running but not Ready. Old pods remain. No traffic goes to new pods (not in endpoints). Deployment controller waits for new pods to be Ready before terminating old pods (respecting maxUnavailable). progressDeadlineSeconds (default: 600s) defines timeout before rollout is marked failed."
            },
            {
              "type": "explain",
              "question": "When should you use tcpSocket vs httpGet vs exec probes?",
              "answer": "httpGet: Best for web apps with health endpoints. Most informative (can check app logic). tcpSocket: Good for databases, caches, services without HTTP (Redis, MySQL). Checks if port accepts connections. exec: Most flexible, runs any command. Good for custom checks (pg_isready, redis-cli ping). Higher overhead than others."
            },
            {
              "type": "troubleshoot",
              "question": "Liveness probe succeeds but app returns 500 errors to users. What's wrong?",
              "answer": "Liveness probe endpoint (/healthz) only checks if process is alive, not functional correctness. Add a readiness probe that checks actual functionality (/ready) — verify DB connection, dependency availability. Readiness failure removes pod from endpoints, preventing 500 errors reaching users."
            }
          ],
          "programExercises": [
            {
              "type": "program",
              "question": "Program 1: Pod with HTTP liveness probe",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: liveness-http\nspec:\n  containers:\n  - name: web\n    image: nginx:alpine\n    ports:\n    - containerPort: 80\n    livenessProbe:\n      httpGet:\n        path: /\n        port: 80\n      periodSeconds: 5\n      failureThreshold: 3\nEOF\nsleep 10\nkubectl describe pod liveness-http | grep -A3 'Liveness'",
              "output": "Liveness: http-get http://:80/ delay=0s timeout=1s period=5s #success=1 #failure=3"
            },
            {
              "type": "program",
              "question": "Program 2: Liveness probe failure causing restart",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: liveness-fail\nspec:\n  containers:\n  - name: app\n    image: busybox\n    command: ['sh', '-c', 'touch /tmp/healthy; sleep 20; rm /tmp/healthy; sleep 600']\n    livenessProbe:\n      exec:\n        command: ['cat', '/tmp/healthy']\n      periodSeconds: 5\n      failureThreshold: 3\nEOF\necho 'Waiting 40s for failure...'\nsleep 40\nkubectl get pod liveness-fail\nkubectl describe pod liveness-fail | grep -A3 'Events' | tail -5",
              "output": "RESTARTS: 1+ (healthy for 20s, then /tmp/healthy removed, probe fails, container restarted)"
            },
            {
              "type": "program",
              "question": "Program 3: Readiness probe affecting Service endpoints",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: ready-test\n  labels:\n    app: ready-test\nspec:\n  containers:\n  - name: web\n    image: nginx:alpine\n    ports:\n    - containerPort: 80\n    readinessProbe:\n      httpGet:\n        path: /ready\n        port: 80\n      periodSeconds: 5\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: ready-svc\nspec:\n  selector:\n    app: ready-test\n  ports:\n  - port: 80\nEOF\nsleep 10\nkubectl get endpoints ready-svc\nkubectl get pod ready-test",
              "output": "Endpoints: <none> (pod Running but 0/1 Ready — /ready returns 404, not in endpoints)"
            },
            {
              "type": "program",
              "question": "Program 4: Startup probe for slow-starting app",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: slow-start\nspec:\n  containers:\n  - name: app\n    image: busybox\n    command: ['sh', '-c', 'sleep 30 && echo ready > /tmp/started && sleep 3600']\n    startupProbe:\n      exec:\n        command: ['cat', '/tmp/started']\n      failureThreshold: 10\n      periodSeconds: 5\n    livenessProbe:\n      exec:\n        command: ['cat', '/tmp/started']\n      periodSeconds: 10\nEOF\necho 'Waiting 40s for startup...'\nsleep 40\nkubectl get pod slow-start\nkubectl describe pod slow-start | grep -E 'Started|Ready'",
              "output": "Pod Ready after ~30s. Startup probe succeeded, liveness probe now active. No premature restart."
            },
            {
              "type": "program",
              "question": "Program 5: TCP socket probe for database",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: db-probe\nspec:\n  containers:\n  - name: redis\n    image: redis:7-alpine\n    ports:\n    - containerPort: 6379\n    livenessProbe:\n      tcpSocket:\n        port: 6379\n      periodSeconds: 10\n    readinessProbe:\n      tcpSocket:\n        port: 6379\n      periodSeconds: 5\nEOF\nsleep 15\nkubectl describe pod db-probe | grep -A3 'Liveness\\|Readiness'",
              "output": "Liveness: tcp-socket :6379  Readiness: tcp-socket :6379 — both passing"
            },
            {
              "type": "program",
              "question": "Program 6: All three probes on one container",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: triple-probe\nspec:\n  containers:\n  - name: nginx\n    image: nginx:alpine\n    ports:\n    - containerPort: 80\n    startupProbe:\n      httpGet:\n        path: /\n        port: 80\n      failureThreshold: 10\n      periodSeconds: 3\n    livenessProbe:\n      httpGet:\n        path: /\n        port: 80\n      periodSeconds: 10\n      failureThreshold: 3\n    readinessProbe:\n      httpGet:\n        path: /\n        port: 80\n      periodSeconds: 5\n      failureThreshold: 2\nEOF\nsleep 15\nkubectl describe pod triple-probe | grep -E 'Startup|Liveness|Readiness'",
              "output": "All three probes shown: Startup (http :80), Liveness (http :80 period=10s), Readiness (http :80 period=5s)"
            },
            {
              "type": "program",
              "question": "Program 7: Monitor probe events in real-time",
              "code": "kubectl get events --watch --field-selector reason=Unhealthy &\ncat <<EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: unhealthy-pod\nspec:\n  containers:\n  - name: fail\n    image: busybox\n    command: ['sleep', '3600']\n    livenessProbe:\n      httpGet:\n        path: /\n        port: 8080\n      periodSeconds: 3\n      failureThreshold: 2\nEOF\nsleep 15\nkubectl get pod unhealthy-pod",
              "output": "Events show: Liveness probe failed: connection refused. Container restarted after 2 failures."
            },
            {
              "type": "program",
              "question": "Program 8: Readiness probe with custom HTTP headers",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: header-probe\nspec:\n  containers:\n  - name: web\n    image: nginx:alpine\n    readinessProbe:\n      httpGet:\n        path: /\n        port: 80\n        httpHeaders:\n        - name: Accept\n          value: application/json\n        - name: X-Health-Check\n          value: \"true\"\n      periodSeconds: 5\nEOF\nsleep 10\nkubectl describe pod header-probe | grep -A5 Readiness",
              "output": "Readiness probe with custom headers Accept and X-Health-Check configured"
            },
            {
              "type": "program",
              "question": "Program 9: Check restart count and last state after probe failure",
              "code": "kubectl get pod liveness-fail -o jsonpath='Restart Count: {.status.containerStatuses[0].restartCount}\nLast State: {.status.containerStatuses[0].lastState.terminated.reason}\nExit Code: {.status.containerStatuses[0].lastState.terminated.exitCode}'",
              "output": "Restart Count: 2+  Last State: Error  Exit Code: 137 (SIGKILL from liveness failure)"
            },
            {
              "type": "program",
              "question": "Program 10: Deployment with probes controlling rolling update",
              "code": "cat <<EOF | kubectl apply -f -\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: probe-deploy\nspec:\n  replicas: 3\n  strategy:\n    rollingUpdate:\n      maxUnavailable: 1\n      maxSurge: 1\n  selector:\n    matchLabels:\n      app: probe-deploy\n  template:\n    metadata:\n      labels:\n        app: probe-deploy\n    spec:\n      containers:\n      - name: web\n        image: nginx:alpine\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 80\n          periodSeconds: 5\n          failureThreshold: 2\nEOF\nkubectl rollout status deployment/probe-deploy\nkubectl get pods -l app=probe-deploy",
              "output": "3/3 pods Ready. During updates, new pods must pass readiness before old pods terminate."
            }
          ]
        }
      ],
      "quiz": [
        {
          "question": "What is a Pod in Kubernetes?",
          "options": [
            "The smallest deployable unit that can contain one or more containers",
            "A container",
            "A type of storage",
            "A network interface"
          ],
          "correctAnswer": 0,
          "explanation": "A Pod is the smallest and simplest Kubernetes object. It represents a single instance of a running process and can contain one or more tightly coupled containers that share network and storage."
        },
        {
          "question": "What does a Deployment resource do?",
          "options": [
            "Stores configuration",
            "Manages a replicated application with rolling updates",
            "Creates networks",
            "Monitors logs"
          ],
          "correctAnswer": 1,
          "explanation": "A Deployment manages replica Pods and provides declarative updates for Pods and ReplicaSets. It handles rolling updates, rollbacks, and ensures the desired number of replicas are running."
        },
        {
          "question": "What is the purpose of a Service in Kubernetes?",
          "options": [
            "To build images",
            "To store data",
            "To provide a stable endpoint to access Pods",
            "To monitor resources"
          ],
          "correctAnswer": 2,
          "explanation": "A Service provides a stable network endpoint to access a set of Pods. Even as Pods are created and destroyed, the Service maintains a consistent way to reach your application."
        },
        {
          "question": "What does kubectl apply do?",
          "options": [
            "Deletes resources",
            "Backs up the cluster",
            "Restarts containers",
            "Creates or updates resources from a configuration file"
          ],
          "correctAnswer": 3,
          "explanation": "'kubectl apply' creates new resources or updates existing ones based on the configuration in a file. It's declarative and idempotent, making it safe to run multiple times."
        },
        {
          "question": "What is a ConfigMap used for?",
          "options": [
            "To store non-sensitive configuration data as key-value pairs",
            "To store sensitive data",
            "To create deployments",
            "To monitor resources"
          ],
          "correctAnswer": 0,
          "explanation": "ConfigMaps store non-sensitive configuration data in key-value pairs. They allow you to decouple configuration from container images, making applications more portable."
        },
        {
          "question": "How is a Secret different from a ConfigMap?",
          "options": [
            "They are the same",
            "Secrets are intended for sensitive data and are base64 encoded",
            "ConfigMaps are encrypted",
            "Secrets are faster"
          ],
          "correctAnswer": 1,
          "explanation": "Secrets are similar to ConfigMaps but specifically designed for sensitive information like passwords and tokens. They are base64 encoded and have additional security features."
        },
        {
          "question": "What does 'kubectl get pods -o wide' show compared to regular 'kubectl get pods'?",
          "options": [
            "The same information",
            "Only running pods",
            "Additional details like node placement and IP addresses",
            "Fewer details"
          ],
          "correctAnswer": 2,
          "explanation": "The '-o wide' flag provides additional details including the node each Pod is running on, Pod IP addresses, and nominated nodes, which is useful for debugging and monitoring."
        },
        {
          "question": "What is Kubernetes?",
          "options": [
            "A container runtime",
            "An operating system",
            "A programming language",
            "An open-source container orchestration platform"
          ],
          "correctAnswer": 3,
          "explanation": "Kubernetes (K8s) is an open-source container orchestration platform that automates deployment, scaling, and management of containerized applications across clusters of hosts."
        },
        {
          "question": "What is a Node in Kubernetes?",
          "options": [
            "A worker machine (VM or physical) that runs Pods",
            "A container",
            "A network node",
            "A data node"
          ],
          "correctAnswer": 0,
          "explanation": "A Node is a worker machine (virtual or physical) in Kubernetes that runs Pods. Each node contains services necessary to run Pods: kubelet, container runtime, and kube-proxy."
        },
        {
          "question": "What is a Cluster?",
          "options": [
            "A group of containers",
            "A set of Nodes managed by Kubernetes control plane",
            "A data cluster",
            "A network cluster"
          ],
          "correctAnswer": 1,
          "explanation": "A Cluster is a set of worker machines (nodes) that run containerized applications. Every cluster has at least one worker node and a control plane that manages the cluster."
        },
        {
          "question": "What is the Control Plane?",
          "options": [
            "A dashboard",
            "A control interface",
            "Components that manage cluster state and make scheduling decisions",
            "A monitoring tool"
          ],
          "correctAnswer": 2,
          "explanation": "The Control Plane manages the Kubernetes cluster, making global decisions (scheduling), detecting and responding to events. Includes API server, scheduler, controller manager, and etcd."
        },
        {
          "question": "What is kubectl?",
          "options": [
            "A container",
            "A config file",
            "A cluster manager",
            "Command-line tool for interacting with Kubernetes clusters"
          ],
          "correctAnswer": 3,
          "explanation": "kubectl is the command-line tool for communicating with Kubernetes API server. It allows you to deploy applications, inspect resources, view logs, and manage cluster operations."
        },
        {
          "question": "What does kubectl get pods do?",
          "options": [
            "Lists all Pods in the current namespace",
            "Creates pods",
            "Deletes pods",
            "Updates pods"
          ],
          "correctAnswer": 0,
          "explanation": "kubectl get pods lists all Pods in the current namespace showing name, status, restarts, and age. Use -A or --all-namespaces to see pods across all namespaces."
        },
        {
          "question": "What is a Namespace?",
          "options": [
            "A named space",
            "Virtual cluster for resource isolation and organization",
            "A storage namespace",
            "A network namespace"
          ],
          "correctAnswer": 1,
          "explanation": "Namespace provides a mechanism for isolating groups of resources within a single cluster. Names of resources must be unique within a namespace but not across namespaces."
        },
        {
          "question": "What is the default namespace?",
          "options": [
            "kube-system",
            "default namespace for objects without other namespace",
            "default",
            "public"
          ],
          "correctAnswer": 2,
          "explanation": "The 'default' namespace is where objects are placed when no other namespace is specified. Kubernetes also has kube-system, kube-public, and kube-node-lease namespaces."
        },
        {
          "question": "What does kubectl describe do?",
          "options": [
            "Describes use cases",
            "Lists resources",
            "Creates descriptions",
            "Shows detailed information about a resource"
          ],
          "correctAnswer": 3,
          "explanation": "kubectl describe provides detailed information about a resource including events, conditions, and configuration. More detailed than kubectl get. Example: kubectl describe pod my-pod."
        },
        {
          "question": "What is a ReplicaSet?",
          "options": [
            "Ensures specified number of Pod replicas are running",
            "A set of replicas",
            "A data replica",
            "A backup set"
          ],
          "correctAnswer": 0,
          "explanation": "ReplicaSet ensures a specified number of Pod replicas are running at any time. Usually managed by Deployment. Creates/deletes Pods to maintain desired replica count."
        },
        {
          "question": "What is the difference between Deployment and ReplicaSet?",
          "options": [
            "No difference",
            "Deployment manages ReplicaSets and provides declarative updates",
            "ReplicaSet is newer",
            "Deployment is deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "Deployment is higher-level concept that manages ReplicaSets and provides declarative updates, rolling updates, and rollbacks. ReplicaSet just maintains replica count."
        },
        {
          "question": "What does kubectl logs do?",
          "options": [
            "Creates logs",
            "Views system logs",
            "Prints container logs from a Pod",
            "Deletes logs"
          ],
          "correctAnswer": 2,
          "explanation": "kubectl logs retrieves logs from a container in a Pod. Use -f to follow logs, -c to specify container in multi-container pod, --previous for previous container instance."
        },
        {
          "question": "What does kubectl exec do?",
          "options": [
            "Executes commands",
            "Creates executables",
            "Executes pods",
            "Runs a command inside a container in a Pod"
          ],
          "correctAnswer": 3,
          "explanation": "kubectl exec executes commands in a container. kubectl exec -it pod-name -- /bin/bash opens interactive shell. Useful for debugging and troubleshooting."
        },
        {
          "question": "What is a Label in Kubernetes?",
          "options": [
            "Key-value pairs attached to objects for identification and selection",
            "A name tag",
            "A text label",
            "A description"
          ],
          "correctAnswer": 0,
          "explanation": "Labels are key-value pairs attached to objects like Pods. Used to organize and select subsets of objects. Selectors use labels to query and filter resources."
        },
        {
          "question": "What is a Selector?",
          "options": [
            "Selection tool",
            "Mechanism to filter resources based on labels",
            "Dropdown selector",
            "Query selector"
          ],
          "correctAnswer": 1,
          "explanation": "Selectors use labels to identify sets of objects. Two types: equality-based (=, ==, !=) and set-based (in, notin, exists). Services and ReplicaSets use selectors."
        },
        {
          "question": "What is an Annotation?",
          "options": [
            "A note",
            "A label",
            "Non-identifying metadata attached to objects",
            "A comment"
          ],
          "correctAnswer": 2,
          "explanation": "Annotations are key-value pairs for attaching arbitrary non-identifying metadata. Unlike labels, not used for selection. Used for tooling, libraries, or user information."
        },
        {
          "question": "What are the types of Services?",
          "options": [
            "Only ClusterIP",
            "Public and Private",
            "Internal and External",
            "ClusterIP, NodePort, LoadBalancer, ExternalName"
          ],
          "correctAnswer": 3,
          "explanation": "Service types: ClusterIP (internal only, default), NodePort (exposes on node port), LoadBalancer (cloud load balancer), ExternalName (DNS CNAME)."
        },
        {
          "question": "What is ClusterIP Service?",
          "options": [
            "Service accessible only within cluster on internal IP",
            "IP address",
            "Cluster address",
            "External IP"
          ],
          "correctAnswer": 0,
          "explanation": "ClusterIP is the default Service type. Exposes Service on internal IP within cluster. Only reachable from within cluster, not from outside."
        },
        {
          "question": "What is NodePort Service?",
          "options": [
            "Node address",
            "Exposes Service on static port on each Node's IP",
            "Port mapping",
            "SSH port"
          ],
          "correctAnswer": 1,
          "explanation": "NodePort exposes Service on a static port (30000-32767 by default) on each Node's IP. Accessible from outside cluster using <NodeIP>:<NodePort>."
        },
        {
          "question": "What is LoadBalancer Service?",
          "options": [
            "Load balancing tool",
            "Internal balancer",
            "Exposes Service via cloud provider's load balancer",
            "Traffic distributor"
          ],
          "correctAnswer": 2,
          "explanation": "LoadBalancer creates external load balancer (in supported cloud providers) and assigns external IP. Automatically creates NodePort and ClusterIP Services."
        },
        {
          "question": "What is a DaemonSet?",
          "options": [
            "A daemon process",
            "Background task",
            "System service",
            "Ensures all or selected Nodes run a copy of a Pod"
          ],
          "correctAnswer": 3,
          "explanation": "DaemonSet ensures all (or some) Nodes run a copy of a Pod. As nodes are added/removed, Pods are added/removed. Used for node monitoring, logging, storage daemons."
        },
        {
          "question": "What is a StatefulSet?",
          "options": [
            "Manages stateful applications with stable identity and storage",
            "Stateful application",
            "State manager",
            "Static set"
          ],
          "correctAnswer": 0,
          "explanation": "StatefulSet is for stateful applications requiring stable network identity, stable persistent storage, and ordered deployment/scaling. Used for databases, queues."
        },
        {
          "question": "What is the difference between Deployment and StatefulSet?",
          "options": [
            "No difference",
            "StatefulSet provides stable identity and ordered deployment, Deployment doesn't",
            "Deployment is newer",
            "StatefulSet is faster"
          ],
          "correctAnswer": 1,
          "explanation": "StatefulSet maintains sticky identity for each Pod (ordinal index, stable hostname, stable storage). Deployment treats Pods as interchangeable. Use StatefulSet for stateful apps."
        },
        {
          "question": "What is a Job?",
          "options": [
            "Work task",
            "Cron job",
            "Creates Pods to run a task to completion",
            "Batch job"
          ],
          "correctAnswer": 2,
          "explanation": "Job creates one or more Pods and ensures specified number successfully complete. Used for batch processing, one-time tasks. Tracks successful completions."
        },
        {
          "question": "What is a CronJob?",
          "options": [
            "Cron scheduler",
            "Scheduled task",
            "Time-based job",
            "Creates Jobs on repeating schedule"
          ],
          "correctAnswer": 3,
          "explanation": "CronJob creates Jobs on a repeating schedule written in Cron format. Used for periodic tasks like backups, report generation, sending emails."
        },
        {
          "question": "What is a Volume in Kubernetes?",
          "options": [
            "Directory accessible to containers in a Pod",
            "Storage volume",
            "Disk volume",
            "Data volume"
          ],
          "correctAnswer": 0,
          "explanation": "Volume is a directory accessible to containers in a Pod. Comes in many types (emptyDir, hostPath, PersistentVolume). Data persists across container restarts."
        },
        {
          "question": "What is a PersistentVolume (PV)?",
          "options": [
            "Permanent storage",
            "Cluster-wide storage resource provisioned by admin",
            "Volume backup",
            "Persistent data"
          ],
          "correctAnswer": 1,
          "explanation": "PersistentVolume is a piece of storage provisioned by admin or dynamically using StorageClass. Cluster resource independent of Pod lifecycle. Has lifecycle independent of Pods."
        },
        {
          "question": "What is a PersistentVolumeClaim (PVC)?",
          "options": [
            "Volume request",
            "Claim ticket",
            "Request for storage by a user/Pod",
            "Storage claim"
          ],
          "correctAnswer": 2,
          "explanation": "PVC is a request for storage by user. Claims can request specific size and access modes. Kubernetes binds PVC to matching PV. Pods use PVCs to access storage."
        },
        {
          "question": "What is a StorageClass?",
          "options": [
            "Storage type",
            "Disk class",
            "Storage category",
            "Describes storage profiles and enables dynamic provisioning"
          ],
          "correctAnswer": 3,
          "explanation": "StorageClass describes storage 'classes' (performance tiers) and enables dynamic provisioning of PersistentVolumes. Admins can offer different classes (fast SSD, slow HDD)."
        },
        {
          "question": "What are volume access modes?",
          "options": [
            "ReadWriteOnce, ReadOnlyMany, ReadWriteMany, ReadWriteOncePod",
            "Read and Write",
            "Public and Private",
            "Local and Remote"
          ],
          "correctAnswer": 0,
          "explanation": "Access modes: ReadWriteOnce (RWO - single node R/W), ReadOnlyMany (ROX - many nodes read-only), ReadWriteMany (RWX - many nodes R/W), ReadWriteOncePod (RWOP - single pod)."
        },
        {
          "question": "What is an Ingress?",
          "options": [
            "Entrance",
            "Manages external HTTP/HTTPS access to services in cluster",
            "Network ingress",
            "Entry point"
          ],
          "correctAnswer": 1,
          "explanation": "Ingress manages external HTTP/HTTPS access to Services. Provides load balancing, SSL termination, name-based virtual hosting. Requires Ingress Controller to function."
        },
        {
          "question": "What is an Ingress Controller?",
          "options": [
            "Traffic controller",
            "Network controller",
            "Component that fulfills Ingress rules (e.g., nginx, traefik)",
            "API controller"
          ],
          "correctAnswer": 2,
          "explanation": "Ingress Controller is a component that fulfills Ingress rules. Not started automatically. Popular controllers: nginx, traefik, HAProxy, Kong. Reads Ingress resources and configures routing."
        },
        {
          "question": "What is a NetworkPolicy?",
          "options": [
            "Network rules",
            "Network configuration",
            "Firewall policy",
            "Specification for controlling network traffic between Pods"
          ],
          "correctAnswer": 3,
          "explanation": "NetworkPolicy controls traffic flow at IP address or port level. Acts like firewall rules for Pods. Requires network plugin that supports NetworkPolicies (Calico, Cilium)."
        },
        {
          "question": "What does kubectl delete do?",
          "options": [
            "Deletes resources from cluster",
            "Deletes files",
            "Removes containers",
            "Clears cache"
          ],
          "correctAnswer": 0,
          "explanation": "kubectl delete removes resources from cluster. Can delete by file (kubectl delete -f file.yaml), by resource name, or by label selector. Use --grace-period for controlled shutdown."
        },
        {
          "question": "What does kubectl scale do?",
          "options": [
            "Scales images",
            "Changes number of replicas for a resource",
            "Scales cluster",
            "Measures scale"
          ],
          "correctAnswer": 1,
          "explanation": "kubectl scale changes replica count for Deployment, ReplicaSet, or StatefulSet. Example: kubectl scale deployment nginx --replicas=5. Can also use autoscaling."
        },
        {
          "question": "What is a Horizontal Pod Autoscaler (HPA)?",
          "options": [
            "Pod scaler",
            "Horizontal scaling",
            "Automatically scales number of Pods based on metrics",
            "Auto-balancer"
          ],
          "correctAnswer": 2,
          "explanation": "HPA automatically scales replica count based on observed metrics (CPU, memory, custom metrics). Periodically queries metrics and adjusts replicas to meet target."
        },
        {
          "question": "What is a Vertical Pod Autoscaler (VPA)?",
          "options": [
            "Vertical scaling",
            "Resource adjuster",
            "Pod resizer",
            "Automatically adjusts CPU and memory requests/limits for containers"
          ],
          "correctAnswer": 3,
          "explanation": "VPA automatically sets resource requests and limits for containers based on usage. Frees users from setting resource requirements. Can update running Pods or just provide recommendations."
        },
        {
          "question": "What is a LimitRange?",
          "options": [
            "Policy to constrain resource allocations per Pod/Container in namespace",
            "Resource limits",
            "Range limit",
            "Boundary setting"
          ],
          "correctAnswer": 0,
          "explanation": "LimitRange constrains resource allocation (CPU, memory) per Pod or Container. Sets default requests/limits and enforces min/max values in a namespace."
        },
        {
          "question": "What is a ResourceQuota?",
          "options": [
            "Resource limit",
            "Constraints on aggregate resource consumption per namespace",
            "Quota system",
            "Usage limit"
          ],
          "correctAnswer": 1,
          "explanation": "ResourceQuota limits aggregate resource consumption per namespace. Can limit total CPU/memory, number of objects (Pods, Services), storage requests. Enforces limits at namespace level."
        },
        {
          "question": "What does kubectl rollout status do?",
          "options": [
            "Rolls out updates",
            "Creates rollout",
            "Shows status of a rollout",
            "Stops rollout"
          ],
          "correctAnswer": 2,
          "explanation": "kubectl rollout status shows the status of a rollout. kubectl rollout status deployment/nginx watches rollout until completion. Useful for CI/CD pipelines."
        },
        {
          "question": "What does kubectl rollout undo do?",
          "options": [
            "Undoes changes",
            "Cancels deployment",
            "Removes rollout",
            "Rolls back to previous revision"
          ],
          "correctAnswer": 3,
          "explanation": "kubectl rollout undo rolls back to previous revision. Can specify revision with --to-revision. Useful when new deployment has issues. View history with rollout history."
        },
        {
          "question": "What does kubectl rollout restart do?",
          "options": [
            "Triggers rolling restart of Pods",
            "Restarts cluster",
            "Reboots nodes",
            "Restarts service"
          ],
          "correctAnswer": 0,
          "explanation": "kubectl rollout restart triggers a rolling restart of all Pods managed by resource without changing configuration. Useful for picking up ConfigMap/Secret changes."
        },
        {
          "question": "What is a Probe in Kubernetes?",
          "options": [
            "Investigation tool",
            "Health check performed by kubelet on containers",
            "Network probe",
            "Diagnostic tool"
          ],
          "correctAnswer": 1,
          "explanation": "Probe is a diagnostic performed by kubelet on containers. Three types: liveness (restart if fails), readiness (remove from service if fails), startup (delay other probes)."
        },
        {
          "question": "What is a Liveness Probe?",
          "options": [
            "Life check",
            "Status check",
            "Checks if container is alive, restarts if fails",
            "Running check"
          ],
          "correctAnswer": 2,
          "explanation": "Liveness Probe checks if container is running. If probe fails, kubelet kills and restarts container. Used to detect deadlocks or unresponsive applications."
        },
        {
          "question": "What is a Readiness Probe?",
          "options": [
            "Ready check",
            "Service check",
            "Startup check",
            "Checks if container is ready to serve traffic"
          ],
          "correctAnswer": 3,
          "explanation": "Readiness Probe checks if container is ready to serve requests. If fails, Pod is removed from Service endpoints (stops receiving traffic). Used during startup or when overloaded."
        },
        {
          "question": "What is a Startup Probe?",
          "options": [
            "Checks if container application has started",
            "Start check",
            "Boot check",
            "Initialize check"
          ],
          "correctAnswer": 0,
          "explanation": "Startup Probe checks if application has started. Disables liveness/readiness probes until succeeds. Useful for slow-starting containers to avoid premature restarts."
        },
        {
          "question": "What probe handlers are available?",
          "options": [
            "Only HTTP",
            "HTTP GET, TCP Socket, Exec command",
            "Ping only",
            "Custom handlers"
          ],
          "correctAnswer": 1,
          "explanation": "Probe handlers: httpGet (HTTP GET request), tcpSocket (TCP connection), exec (executes command in container). Each returns success/failure. Choose based on application type."
        },
        {
          "question": "What is a Taint?",
          "options": [
            "Node contamination",
            "Node label",
            "Node property that repels Pods unless they tolerate it",
            "Node defect"
          ],
          "correctAnswer": 2,
          "explanation": "Taint is applied to Nodes to repel Pods. Pods must have matching Toleration to be scheduled on tainted Node. Used for dedicated nodes, special hardware, node maintenance."
        },
        {
          "question": "What is a Toleration?",
          "options": [
            "Pod tolerance",
            "Permission",
            "Node acceptance",
            "Pod property allowing scheduling on Nodes with matching Taints"
          ],
          "correctAnswer": 3,
          "explanation": "Toleration is applied to Pods, allowing (but not requiring) them to schedule onto Nodes with matching Taints. Works with Taints to ensure Pods schedule on appropriate Nodes."
        },
        {
          "question": "What are Taint effects?",
          "options": [
            "NoSchedule, PreferNoSchedule, NoExecute",
            "Side effects",
            "Taint levels",
            "Impact types"
          ],
          "correctAnswer": 0,
          "explanation": "Taint effects: NoSchedule (don't schedule new Pods), PreferNoSchedule (try not to schedule), NoExecute (evict existing Pods without toleration). Controls scheduling behavior."
        },
        {
          "question": "What is Node Affinity?",
          "options": [
            "Node preference",
            "Rules for scheduling Pods on Nodes based on Node labels",
            "Node grouping",
            "Node attraction"
          ],
          "correctAnswer": 1,
          "explanation": "Node Affinity constrains which Nodes Pods can be scheduled on based on Node labels. Two types: required (hard) and preferred (soft). More expressive than nodeSelector."
        },
        {
          "question": "What is Pod Affinity?",
          "options": [
            "Pod friendship",
            "Pod grouping",
            "Rules for co-locating Pods based on labels",
            "Pod attraction"
          ],
          "correctAnswer": 2,
          "explanation": "Pod Affinity allows specifying that Pods should be co-located (scheduled on same Node or zone) with other Pods matching label selector. Useful for performance."
        },
        {
          "question": "What is Pod Anti-Affinity?",
          "options": [
            "Pod dislike",
            "Pod repulsion",
            "Pod separation",
            "Rules for spreading Pods across Nodes/zones"
          ],
          "correctAnswer": 3,
          "explanation": "Pod Anti-Affinity specifies that Pods should not be co-located with other Pods matching selector. Used for high availability, spreading replicas across failure domains."
        },
        {
          "question": "What is a ServiceAccount?",
          "options": [
            "Identity for processes running in Pods",
            "Service user",
            "User account",
            "API account"
          ],
          "correctAnswer": 0,
          "explanation": "ServiceAccount provides identity for processes running in Pods. Used for authentication to API server. Automatically mounted into Pods. Different from user accounts."
        },
        {
          "question": "What is RBAC in Kubernetes?",
          "options": [
            "Access control",
            "Role-Based Access Control for authorization",
            "Security system",
            "Authentication method"
          ],
          "correctAnswer": 1,
          "explanation": "RBAC (Role-Based Access Control) regulates access to resources based on roles. Uses Role, ClusterRole, RoleBinding, ClusterRoleBinding to define permissions."
        },
        {
          "question": "What is a Role in RBAC?",
          "options": [
            "User role",
            "Job role",
            "Set of permissions within a namespace",
            "Security role"
          ],
          "correctAnswer": 2,
          "explanation": "Role contains rules defining permissions (verbs like get, list, create) on resources within a namespace. Grants permissions, never denies. Use RoleBinding to assign."
        },
        {
          "question": "What is a ClusterRole?",
          "options": [
            "Cluster user",
            "Global role",
            "Admin role",
            "Set of permissions across entire cluster"
          ],
          "correctAnswer": 3,
          "explanation": "ClusterRole is like Role but cluster-scoped. Can grant access to cluster-scoped resources (nodes, PVs), non-resource endpoints, or resources across all namespaces."
        },
        {
          "question": "What is a RoleBinding?",
          "options": [
            "Grants Role permissions to users/groups/ServiceAccounts in a namespace",
            "Role assignment",
            "Role connection",
            "Permission link"
          ],
          "correctAnswer": 0,
          "explanation": "RoleBinding grants permissions defined in a Role to users, groups, or ServiceAccounts within a namespace. Binds a Role or ClusterRole to subjects."
        },
        {
          "question": "What is a ClusterRoleBinding?",
          "options": [
            "Cluster assignment",
            "Grants ClusterRole permissions across entire cluster",
            "Global binding",
            "Cluster permission"
          ],
          "correctAnswer": 1,
          "explanation": "ClusterRoleBinding grants permissions defined in ClusterRole cluster-wide. Used to grant access to cluster-scoped resources or across all namespaces."
        },
        {
          "question": "What is etcd?",
          "options": [
            "Configuration tool",
            "Database",
            "Distributed key-value store for cluster data",
            "Cache system"
          ],
          "correctAnswer": 2,
          "explanation": "etcd is a consistent, distributed key-value store that stores all cluster data. It's the backing store for all Kubernetes cluster data. Critical component to backup."
        },
        {
          "question": "What is the kube-apiserver?",
          "options": [
            "API endpoint",
            "API gateway",
            "Web server",
            "Front-end for Kubernetes control plane, exposes Kubernetes API"
          ],
          "correctAnswer": 3,
          "explanation": "kube-apiserver is the front end for Kubernetes control plane. Exposes Kubernetes API. All other components communicate through it. Horizontally scalable."
        },
        {
          "question": "What is the kube-scheduler?",
          "options": [
            "Selects Nodes for newly created Pods",
            "Task scheduler",
            "Job scheduler",
            "Time scheduler"
          ],
          "correctAnswer": 0,
          "explanation": "kube-scheduler watches for newly created Pods with no assigned Node and selects a Node for them to run on. Factors: resource requirements, constraints, affinity, data locality."
        },
        {
          "question": "What is the kube-controller-manager?",
          "options": [
            "System manager",
            "Runs controller processes (Node, Job, Service controllers)",
            "Process manager",
            "Resource manager"
          ],
          "correctAnswer": 1,
          "explanation": "kube-controller-manager runs controller processes. Controllers watch cluster state and make changes to move current state toward desired state. Includes Node, Job, Endpoint controllers."
        },
        {
          "question": "What is the cloud-controller-manager?",
          "options": [
            "Cloud manager",
            "Cloud interface",
            "Runs cloud-specific controller logic",
            "Cloud connector"
          ],
          "correctAnswer": 2,
          "explanation": "cloud-controller-manager embeds cloud-specific control logic. Allows linking cluster to cloud provider API. Manages Node, Route, Service, Volume controllers for cloud."
        },
        {
          "question": "What is kubelet?",
          "options": [
            "Small cube",
            "Network agent",
            "Container runtime",
            "Agent running on each Node, ensures containers are running in Pods"
          ],
          "correctAnswer": 3,
          "explanation": "kubelet is an agent running on each Node. Ensures containers described in PodSpecs are running and healthy. Communicates with control plane. Manages container lifecycle."
        },
        {
          "question": "What is kube-proxy?",
          "options": [
            "Network proxy running on each Node, maintains network rules",
            "Proxy server",
            "API proxy",
            "Load balancer"
          ],
          "correctAnswer": 0,
          "explanation": "kube-proxy is a network proxy running on each Node. Maintains network rules allowing communication to Pods from inside/outside cluster. Implements Service abstraction."
        },
        {
          "question": "What is a container runtime?",
          "options": [
            "Runtime environment",
            "Software responsible for running containers (Docker, containerd, CRI-O)",
            "Container engine",
            "Execution engine"
          ],
          "correctAnswer": 1,
          "explanation": "Container runtime is software responsible for running containers. Kubernetes supports: containerd, CRI-O, Docker Engine (deprecated). Must implement Kubernetes CRI."
        },
        {
          "question": "What does kubectl create vs kubectl apply do?",
          "options": [
            "Same thing",
            "create is faster",
            "create is imperative (errors if exists), apply is declarative (creates or updates)",
            "apply is deprecated"
          ],
          "correctAnswer": 2,
          "explanation": "kubectl create is imperative and errors if resource exists. kubectl apply is declarative, creates if doesn't exist or updates if exists. apply is preferred for GitOps."
        },
        {
          "question": "What is a Helm chart?",
          "options": [
            "Navigation chart",
            "Configuration file",
            "Graph chart",
            "Package of Kubernetes resources with templating"
          ],
          "correctAnswer": 3,
          "explanation": "Helm chart is a package of pre-configured Kubernetes resources. Contains templates and values for deploying applications. Helm is package manager for Kubernetes."
        },
        {
          "question": "What does kubectl port-forward do?",
          "options": [
            "Forwards local port to port on Pod for debugging",
            "Forwards ports",
            "Opens ports",
            "Tunnels traffic"
          ],
          "correctAnswer": 0,
          "explanation": "kubectl port-forward forwards local port to port on Pod. Used for debugging and testing without exposing Service. Example: kubectl port-forward pod/nginx 8080:80."
        },
        {
          "question": "What does kubectl top do?",
          "options": [
            "Shows top resources",
            "Displays resource usage (CPU/memory) for Nodes or Pods",
            "Lists top pods",
            "Shows rankings"
          ],
          "correctAnswer": 1,
          "explanation": "kubectl top shows resource usage metrics. kubectl top node shows Node metrics, kubectl top pod shows Pod metrics. Requires metrics-server to be installed."
        },
        {
          "question": "What is the metrics-server?",
          "options": [
            "Metrics endpoint",
            "Monitoring server",
            "Cluster-wide aggregator of resource usage data",
            "Statistics server"
          ],
          "correctAnswer": 2,
          "explanation": "metrics-server collects resource metrics from kubelets and exposes them through Metrics API. Required for kubectl top and HPA. Lightweight, in-memory, short-term metrics."
        },
        {
          "question": "What is the difference between requests and limits?",
          "options": [
            "No difference",
            "Requests are maximum",
            "Limits are minimum",
            "Requests are guaranteed resources, limits are maximum allowed"
          ],
          "correctAnswer": 3,
          "explanation": "Requests: minimum resources guaranteed to container. Limits: maximum resources container can use. Scheduler uses requests for placement. Container throttled/killed if exceeds limits."
        },
        {
          "question": "What happens when a Pod exceeds memory limit?",
          "options": [
            "Pod is OOMKilled (Out of Memory killed)",
            "Nothing",
            "Memory is expanded",
            "Warning only"
          ],
          "correctAnswer": 0,
          "explanation": "When Pod exceeds memory limit, it's OOMKilled (terminated due to Out Of Memory). Status shows OOMKilled. May be restarted based on restart policy."
        },
        {
          "question": "What happens when a Pod exceeds CPU limit?",
          "options": [
            "Pod terminates",
            "CPU is throttled (limited) but Pod continues running",
            "Pod is killed",
            "Nothing happens"
          ],
          "correctAnswer": 1,
          "explanation": "When Pod exceeds CPU limit, CPU usage is throttled (limited) but Pod continues running. Unlike memory limits which cause termination, CPU is compressible resource."
        },
        {
          "question": "What is a PodDisruptionBudget (PDB)?",
          "options": [
            "Budget limit",
            "Cost budget",
            "Limits number of Pods that can be down during voluntary disruptions",
            "Resource budget"
          ],
          "correctAnswer": 2,
          "explanation": "PDB limits number of Pods of replicated application that are down simultaneously from voluntary disruptions (maintenance, upgrades). Ensures minimum availability during disruptions."
        },
        {
          "question": "What are init containers?",
          "options": [
            "Initial containers",
            "Bootstrap containers",
            "Setup containers",
            "Specialized containers that run before app containers in Pod"
          ],
          "correctAnswer": 3,
          "explanation": "Init containers run before app containers in Pod, run to completion sequentially. Used for setup tasks, waiting for dependencies, pre-population. If fails, Pod restarts."
        },
        {
          "question": "What are sidecar containers?",
          "options": [
            "Helper containers running alongside main container in Pod",
            "Side containers",
            "Secondary containers",
            "Support containers"
          ],
          "correctAnswer": 0,
          "explanation": "Sidecar containers run alongside main container in Pod, sharing resources. Common patterns: logging agents, monitoring agents, proxies. Example: service mesh sidecars."
        },
        {
          "question": "What is a Custom Resource Definition (CRD)?",
          "options": [
            "Custom config",
            "Extension of Kubernetes API that defines custom resource",
            "User definition",
            "Custom settings"
          ],
          "correctAnswer": 1,
          "explanation": "CRD extends Kubernetes API by defining custom resources. Once created, new custom resource can be created and managed like native resources. Foundation for operators."
        },
        {
          "question": "What is an Operator?",
          "options": [
            "System administrator",
            "User role",
            "Method of packaging and managing Kubernetes application with domain knowledge",
            "Control operator"
          ],
          "correctAnswer": 2,
          "explanation": "Operator is method of packaging, deploying, and managing Kubernetes application. Extends Kubernetes using CRDs and controllers, encoding domain knowledge for managing complex applications."
        },
        {
          "question": "What does kubectl drain do?",
          "options": [
            "Drains water",
            "Empties node",
            "Removes resources",
            "Safely evicts Pods from Node for maintenance"
          ],
          "correctAnswer": 3,
          "explanation": "kubectl drain safely evicts Pods from Node, marking it as unschedulable. Used before Node maintenance. Respects PDBs. Use kubectl uncordon to make schedulable again."
        },
        {
          "question": "What does kubectl cordon do?",
          "options": [
            "Marks Node as unschedulable (no new Pods)",
            "Blocks node",
            "Isolates node",
            "Seals node"
          ],
          "correctAnswer": 0,
          "explanation": "kubectl cordon marks Node as unschedulable, preventing new Pods from being scheduled. Existing Pods continue running. Use uncordon to reverse. Less disruptive than drain."
        },
        {
          "question": "What is a Pod Security Policy (PSP)?",
          "options": [
            "Security rules",
            "Cluster-level resource controlling security-sensitive aspects of Pods (deprecated)",
            "Access policy",
            "Security config"
          ],
          "correctAnswer": 1,
          "explanation": "PSP was cluster-level resource controlling security aspects of Pod specification (privileged, capabilities, volumes). Deprecated in 1.21, removed in 1.25. Use Pod Security Standards."
        },
        {
          "question": "What are Pod Security Standards?",
          "options": [
            "Security guidelines",
            "Security requirements",
            "Replacement for PSP: Privileged, Baseline, Restricted levels",
            "Compliance standards"
          ],
          "correctAnswer": 2,
          "explanation": "Pod Security Standards replace PSP with three levels: Privileged (unrestricted), Baseline (minimally restrictive), Restricted (heavily restricted). Enforced via admission controller."
        },
        {
          "question": "What is a Quality of Service (QoS) class?",
          "options": [
            "Service quality",
            "Priority level",
            "Performance class",
            "Classification of Pods (Guaranteed, Burstable, BestEffort) based on resources"
          ],
          "correctAnswer": 3,
          "explanation": "QoS class determines Pod eviction order under resource pressure. Three classes: Guaranteed (requests=limits), Burstable (some requests/limits), BestEffort (no requests/limits)."
        },
        {
          "question": "What is a PriorityClass?",
          "options": [
            "Defines priority value for Pods affecting scheduling and eviction order",
            "Priority level",
            "Class priority",
            "Importance level"
          ],
          "correctAnswer": 0,
          "explanation": "PriorityClass defines priority value assigned to Pods. Higher priority Pods are scheduled first and less likely to be evicted. Used for critical system components."
        },
        {
          "question": "What does kubectl attach do?",
          "options": [
            "Attaches files",
            "Attaches to running process in container",
            "Connects to pod",
            "Mounts volumes"
          ],
          "correctAnswer": 1,
          "explanation": "kubectl attach attaches to a running process inside a container. Similar to docker attach. Different from exec which starts new process. Use -it for interactive."
        },
        {
          "question": "What is a Finalizer?",
          "options": [
            "Last step",
            "Cleanup function",
            "Keys preventing deletion until specific conditions met",
            "Termination handler"
          ],
          "correctAnswer": 2,
          "explanation": "Finalizers are keys preventing resource deletion until removed. Allow controllers to implement asynchronous pre-delete hooks. Object stuck in deletion until finalizers cleared."
        },
        {
          "question": "What is the difference between kubectl create and kubectl run?",
          "options": [
            "No difference",
            "create is faster",
            "run is deprecated",
            "create creates resources from file/stdin, run creates and runs single Pod"
          ],
          "correctAnswer": 3,
          "explanation": "kubectl create creates resources from file/stdin (generic). kubectl run creates and runs a particular image, typically for quick Pod creation or testing."
        },
        {
          "question": "What does kubectl explain do?",
          "options": [
            "Shows documentation for resource fields",
            "Explains concepts",
            "Provides help",
            "Describes usage"
          ],
          "correctAnswer": 0,
          "explanation": "kubectl explain shows documentation for resource fields. Example: kubectl explain pod.spec.containers. Helps discover available fields and their types. Like inline documentation."
        },
        {
          "question": "What is context in kubectl?",
          "options": [
            "Code context",
            "Set of access parameters (cluster, user, namespace)",
            "Environment context",
            "Runtime context"
          ],
          "correctAnswer": 1,
          "explanation": "Context is a cluster/user/namespace tuple in kubeconfig. kubectl uses current context for API requests. Switch with kubectl config use-context. View with kubectl config get-contexts."
        }
      ],
      "topicCount": 9,
      "quizCount": 98
    },
    {
      "slug": "nextjs",
      "meta": {
        "title": "Next.js Interview Preparation",
        "description": "Master App Router, rendering strategies, caching, APIs, and production patterns asked in modern interviews."
      },
      "topics": [
        {
          "id": "real-world-ui-design",
          "title": "Real-World UI Design Challenges (Next.js)",
          "description": "Practical Next.js UI design tasks using App Router patterns, server/client boundaries, caching, and production UX flows.",
          "explanation": "This challenge set focuses on real product screens built with Next.js: dashboard pages, data-heavy interfaces, auth-aware UI, and route-level UX strategies. Prioritize responsive design, loading/error states, and clean server-client responsibilities.",
          "code": "// app/(dashboard)/layout.jsx\nexport default function DashboardLayout({ children }) {\n  return (\n    <div className=\"min-h-screen grid lg:grid-cols-[260px_1fr]\">\n      <aside className=\"border-r p-4\">Sidebar</aside>\n      <main className=\"p-4\">{children}</main>\n    </div>\n  );\n}",
          "example": "// app/products/page.jsx\nexport default async function ProductsPage() {\n  const res = await fetch('https://dummyjson.com/products?limit=8', {\n    next: { revalidate: 60 }\n  });\n  const data = await res.json();\n\n  return (\n    <section className=\"grid gap-4 sm:grid-cols-2 lg:grid-cols-4\">\n      {data.products.map((p) => (\n        <article key={p.id} className=\"rounded-xl border p-3\">\n          <h3 className=\"font-semibold\">{p.title}</h3>\n          <p className=\"text-sm text-slate-600\">${p.price}</p>\n        </article>\n      ))}\n    </section>\n  );\n}",
          "useCase": "Next.js interview rounds, frontend system design tasks, and production feature implementation with App Router.",
          "category": "Real-World UI Design",
          "interviewQuestions": [
            {
              "question": "How do you decide server vs client component for a UI block?",
              "answer": "Render static/data-fetching-heavy parts on server; keep interaction-heavy stateful blocks on client."
            },
            {
              "question": "How should loading and error UI be structured in App Router?",
              "answer": "Use route-level `loading.js` and `error.js`, plus component-level skeletons for finer transitions."
            },
            {
              "question": "How do you keep dashboards fast in Next.js?",
              "answer": "Use selective caching/revalidation, streaming where useful, and avoid shipping unnecessary client JS."
            },
            {
              "question": "When should middleware be part of UI-related flows?",
              "answer": "For auth gating, locale routing, and lightweight redirects before route rendering."
            },
            {
              "question": "How do you prevent stale data UX after mutations?",
              "answer": "Use server actions + revalidatePath/revalidateTag and optimistic UI where appropriate."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Build an admin analytics page with route segments for `/overview`, `/users`, `/billing` using shared dashboard layout."
            },
            {
              "type": "implement",
              "question": "Create a product catalog with server-rendered filters and client-side sort controls."
            },
            {
              "type": "implement",
              "question": "Design an authenticated profile settings page with optimistic save and rollback on API failure."
            },
            {
              "type": "implement",
              "question": "Build a media gallery page with masonry-style cards and progressive image loading placeholders."
            },
            {
              "type": "implement",
              "question": "Create a booking flow with multi-step forms and persistent draft state across route transitions."
            },
            {
              "type": "implement",
              "question": "Build a docs search interface with route-based query params and highlighted results."
            },
            {
              "type": "implement",
              "question": "Design a team management UI with role badges, invite modal, and pagination."
            },
            {
              "type": "implement",
              "question": "Create a support inbox UI using server component list + client detail panel interactions."
            },
            {
              "type": "implement",
              "question": "Build a pricing/checkout UI with plan comparison, coupon entry, and summary sidebar."
            },
            {
              "type": "implement",
              "question": "Implement a notifications page with tabs (`all`, `mentions`, `system`) and empty states."
            },
            {
              "type": "debug",
              "question": "Fix hydration mismatch in a page that renders date/time differently between server and client."
            },
            {
              "type": "debug",
              "question": "Resolve a slow route caused by client-side overfetch and move suitable logic server-side."
            },
            {
              "type": "debug",
              "question": "Fix stale list UI after server action mutation by adding correct revalidation strategy."
            },
            {
              "type": "debug",
              "question": "Debug broken navigation state caused by mixing local state with route params incorrectly."
            },
            {
              "type": "scenario",
              "question": "Design an enterprise dashboard shell that supports role-based menus and deep route nesting."
            },
            {
              "type": "scenario",
              "question": "Plan a migration from Pages Router UI to App Router while minimizing downtime and regressions."
            },
            {
              "type": "scenario",
              "question": "Design a B2B billing page with secure server actions and clear fail/retry UX."
            },
            {
              "type": "scenario",
              "question": "Create a multitenant workspace switcher with URL-based tenant context and guarded routes."
            },
            {
              "type": "scenario",
              "question": "Define caching policy for catalog pages, account pages, and admin pages with clear rationale."
            },
            {
              "type": "scenario",
              "question": "Plan responsive behavior for complex data tables across desktop and mobile breakpoints."
            },
            {
              "type": "theory",
              "question": "Explain trade-offs of streaming UI with Suspense in dashboard pages."
            },
            {
              "type": "theory",
              "question": "When should route handlers be used over third-party backend APIs in frontend architecture?"
            },
            {
              "type": "output",
              "question": "Predict UI behavior when `revalidate = 60` page receives updates every 10 seconds."
            },
            {
              "type": "output",
              "question": "Predict route rendering path when middleware redirects based on auth cookie."
            },
            {
              "type": "refactor",
              "question": "Refactor a large client-only page into server/client composition with less bundle size."
            }
          ],
          "programExercises": [
            {
              "level": "Medium",
              "question": "Build a route-segment dashboard shell with persistent sidebar and topbar.",
              "code": "// app/(workspace)/layout.jsx\nimport Link from 'next/link';\n\nexport default function WorkspaceLayout({ children }) {\n  return (\n    <div className=\"min-h-screen grid lg:grid-cols-[240px_1fr]\">\n      <aside className=\"border-r p-4\">\n        <nav className=\"space-y-2\">\n          <Link href=\"/workspace/overview\">Overview</Link>\n          <Link href=\"/workspace/projects\">Projects</Link>\n          <Link href=\"/workspace/settings\">Settings</Link>\n        </nav>\n      </aside>\n      <div>\n        <header className=\"border-b p-4\">Workspace</header>\n        <main className=\"p-4\">{children}</main>\n      </div>\n    </div>\n  );\n}",
              "output": "Reusable dashboard layout for nested routes with a consistent shell."
            },
            {
              "level": "Medium",
              "question": "Create product listing page using server fetch + client sort controls.",
              "code": "// app/catalog/page.jsx\nimport SortControls from './sort-controls';\n\nexport default async function CatalogPage({ searchParams }) {\n  const sort = searchParams?.sort || 'popular';\n  const res = await fetch(`https://dummyjson.com/products?limit=12`, { next: { revalidate: 120 } });\n  const data = await res.json();\n\n  return (\n    <section className=\"space-y-4\">\n      <SortControls current={sort} />\n      <div className=\"grid gap-4 sm:grid-cols-2 lg:grid-cols-3\">\n        {data.products.map((p) => (\n          <article key={p.id} className=\"rounded-xl border p-3\">\n            <h3 className=\"font-semibold\">{p.title}</h3>\n            <p className=\"text-sm text-slate-600\">${p.price}</p>\n          </article>\n        ))}\n      </div>\n    </section>\n  );\n}",
              "output": "Server-rendered catalog with URL-based sorting controls."
            },
            {
              "level": "Hard",
              "question": "Build settings page with server action form and revalidation.",
              "code": "// app/settings/actions.js\n'use server';\n\nimport { revalidatePath } from 'next/cache';\n\nexport async function updateProfile(formData) {\n  const name = formData.get('name');\n  // await db.profile.update({ name })\n  revalidatePath('/settings');\n  return { ok: true };\n}\n\n// app/settings/page.jsx\nimport { updateProfile } from './actions';\n\nexport default function SettingsPage() {\n  return (\n    <form action={updateProfile} className=\"max-w-md space-y-3\">\n      <input name=\"name\" placeholder=\"Name\" className=\"w-full rounded border px-3 py-2\" />\n      <button className=\"rounded bg-black px-4 py-2 text-white\">Save</button>\n    </form>\n  );\n}",
              "output": "Settings form submits through server action and refreshes page data safely."
            },
            {
              "level": "Hard",
              "question": "Implement split-view support inbox with server message list and client detail pane.",
              "code": "// app/inbox/page.jsx\nimport TicketPane from './ticket-pane';\n\nexport default async function InboxPage() {\n  const tickets = [\n    { id: 1, subject: 'Billing issue' },\n    { id: 2, subject: 'Login failure' }\n  ];\n\n  return (\n    <div className=\"grid gap-4 lg:grid-cols-[320px_1fr]\">\n      <aside className=\"rounded border p-3\">\n        {tickets.map((t) => <a key={t.id} href={`?ticket=${t.id}`} className=\"block rounded p-2 hover:bg-slate-100\">{t.subject}</a>)}\n      </aside>\n      <TicketPane />\n    </div>\n  );\n}",
              "output": "Support inbox with route-driven selection and responsive split-view layout."
            },
            {
              "level": "Very Hard",
              "question": "Build multi-step checkout with progress persistence and guarded transitions.",
              "code": "// app/checkout/page.jsx\nimport { cookies } from 'next/headers';\n\nconst steps = ['shipping', 'payment', 'review'];\n\nexport default async function CheckoutPage({ searchParams }) {\n  const current = searchParams?.step || 'shipping';\n  const cookieStore = await cookies();\n  const draft = cookieStore.get('checkoutDraft')?.value || '{}';\n\n  return (\n    <section className=\"space-y-4\">\n      <ol className=\"flex gap-2 text-sm\">\n        {steps.map((s) => <li key={s} className={s === current ? 'font-bold' : 'text-slate-500'}>{s}</li>)}\n      </ol>\n      <pre className=\"rounded bg-slate-900 p-3 text-xs text-slate-100\">{draft}</pre>\n      <div className=\"rounded border p-4\">Current step: {current}</div>\n    </section>\n  );\n}",
              "output": "Checkout flow with step indicator and persisted draft state for reliable user recovery."
            }
          ]
        },
        {
          "id": "app-router",
          "title": "App Router",
          "description": "Next.js 13+ file-system based router using the app directory. Supports layouts, nested routes, and server components.",
          "code": "// app/layout.js\nexport default function RootLayout({ children }) {\n  return (\n    <html lang=\"en\">\n      <body>{children}</body>\n    </html>\n  );\n}\n\n// app/page.js\nexport default function HomePage() {\n  return <h1>Home Page</h1>;\n}\n\n// app/blog/page.js\nexport default function BlogPage() {\n  return <h1>Blog Page</h1>;\n}",
          "example": "// Dynamic routes: app/blog/[slug]/page.js\nexport default function BlogPost({ params }) {\n  return <h1>Post: {params.slug}</h1>;\n}\n\n// Nested layouts: app/dashboard/layout.js\nexport default function DashboardLayout({ children }) {\n  return (\n    <div>\n      <Sidebar />\n      <main>{children}</main>\n    </div>\n  );\n}",
          "useCase": "Modern Next.js routing, nested layouts, server components, parallel routes",
          "category": "App Router & Routing"
        },
        {
          "id": "dynamic-routes",
          "title": "Dynamic Routes",
          "description": "Create routes with dynamic segments using [param] syntax.",
          "code": "// app/products/[id]/page.js\nexport default function ProductPage({ params }) {\n  return <div>Product ID: {params.id}</div>;\n}\n\n// Catch-all: app/docs/[...slug]/page.js\nexport default function DocsPage({ params }) {\n  // /docs/a/b/c → params.slug = ['a', 'b', 'c']\n  return <div>Docs: {params.slug.join('/')}</div>;\n}\n\n// Optional catch-all: app/blog/[[...slug]]/page.js\n// Matches /blog and /blog/a/b/c",
          "example": "// Multiple dynamic segments\n// app/[category]/[productId]/page.js\nexport default function Page({ params }) {\n  return (\n    <div>\n      Category: {params.category}\n      Product: {params.productId}\n    </div>\n  );\n}\n\n// Generate static params\nexport async function generateStaticParams() {\n  return [\n    { id: '1' },\n    { id: '2' },\n    { id: '3' }\n  ];\n}",
          "useCase": "Product pages, blog posts, user profiles, documentation, category pages",
          "category": "App Router & Routing"
        },
        {
          "id": "navigation",
          "title": "Navigation & Link",
          "description": "Client-side navigation using Link component and useRouter hook.",
          "code": "import Link from 'next/link';\nimport { useRouter } from 'next/navigation';\n\nexport default function Navigation() {\n  const router = useRouter();\n  \n  const handleClick = () => {\n    router.push('/dashboard');\n    // router.replace('/dashboard'); // No back button\n    // router.back(); // Go back\n    // router.refresh(); // Refresh current route\n  };\n  \n  return (\n    <nav>\n      <Link href=\"/\">Home</Link>\n      <Link href=\"/about\">About</Link>\n      <Link href=\"/blog/first-post\">Blog Post</Link>\n      <button onClick={handleClick}>Go to Dashboard</button>\n    </nav>\n  );\n}",
          "example": "// Dynamic href\n<Link href={`/products/${productId}`}>Product</Link>\n\n// With query string\n<Link href={{ pathname: '/search', query: { q: 'shoes' } }}>\n  Search\n</Link>\n\n// Prefetch (default: true)\n<Link href=\"/dashboard\" prefetch={false}>Dashboard</Link>\n\n// Scroll to top (default: true)\n<Link href=\"/about\" scroll={false}>About</Link>",
          "useCase": "Navigation menus, breadcrumbs, pagination, programmatic routing",
          "category": "App Router & Routing"
        },
        {
          "id": "route-groups",
          "title": "Route Groups & Parallel Routes",
          "description": "Organize routes without affecting URL structure using (folder) syntax.",
          "code": "// Route Groups (don't affect URL)\n// app/(marketing)/about/page.js → /about\n// app/(marketing)/pricing/page.js → /pricing\n// app/(dashboard)/dashboard/page.js → /dashboard\n\n// Each group can have its own layout\n// app/(marketing)/layout.js\nexport default function MarketingLayout({ children }) {\n  return (\n    <div>\n      <header>Marketing Header</header>\n      {children}\n    </div>\n  );\n}",
          "example": "// Parallel Routes\n// app/dashboard/@analytics/page.js\n// app/dashboard/@team/page.js\n// app/dashboard/layout.js\nexport default function Layout({ children, analytics, team }) {\n  return (\n    <div>\n      {children}\n      <div>{analytics}</div>\n      <div>{team}</div>\n    </div>\n  );\n}",
          "useCase": "Organizing routes, multiple layouts, role-based layouts, parallel data loading",
          "category": "App Router & Routing"
        },
        {
          "id": "server-components",
          "title": "Server Components",
          "description": "Default in App Router. Components rendered on the server, reducing client-side JavaScript.",
          "code": "// Server Component (default in app dir)\nexport default async function ProductList() {\n  // Fetch data directly in component\n  const products = await fetch('https://api.example.com/products')\n    .then(res => res.json());\n  \n  return (\n    <ul>\n      {products.map(product => (\n        <li key={product.id}>{product.name}</li>\n      ))}\n    </ul>\n  );\n}\n\n// No need for useEffect or useState\n// Runs only on the server\n// Can use server-only code (DB queries, file system)",
          "example": "import { db } from '@/lib/database';\n\nexport default async function Users() {\n  // Direct database query\n  const users = await db.query('SELECT * FROM users');\n  \n  return (\n    <div>\n      {users.map(user => (\n        <div key={user.id}>{user.name}</div>\n      ))}\n    </div>\n  );\n}",
          "useCase": "Data fetching, reducing bundle size, SEO, static content, server-only operations",
          "category": "Data Fetching & Rendering"
        },
        {
          "id": "client-components",
          "title": "Client Components",
          "description": "Use 'use client' directive for interactivity, hooks, and browser APIs.",
          "code": "'use client';\n\nimport { useState, useEffect } from 'react';\n\nexport default function Counter() {\n  const [count, setCount] = useState(0);\n  \n  useEffect(() => {\n    document.title = `Count: ${count}`;\n  }, [count]);\n  \n  return (\n    <div>\n      <p>Count: {count}</p>\n      <button onClick={() => setCount(count + 1)}>\n        Increment\n      </button>\n    </div>\n  );\n}",
          "example": "'use client';\n\nexport default function InteractiveForm() {\n  const [data, setData] = useState({});\n  \n  // Can use browser APIs\n  const handleSubmit = () => {\n    localStorage.setItem('form', JSON.stringify(data));\n    window.alert('Saved!');\n  };\n  \n  return <form onSubmit={handleSubmit}>...</form>;\n}",
          "useCase": "Interactive UI, event handlers, React hooks, browser APIs, real-time updates",
          "category": "Data Fetching & Rendering"
        },
        {
          "id": "ssg",
          "title": "Static Site Generation (SSG)",
          "description": "Pre-renders pages at build time. Great for content that doesn't change often.",
          "code": "// Automatically static if no dynamic functions used\nexport default async function BlogPost({ params }) {\n  const post = await getPost(params.slug);\n  return <article>{post.content}</article>;\n}\n\n// Generate static params for dynamic routes\nexport async function generateStaticParams() {\n  const posts = await getAllPosts();\n  \n  return posts.map(post => ({\n    slug: post.slug\n  }));\n}\n\n// Set revalidation time (ISR)\nconst revalidate = 3600; // Revalidate every hour",
          "example": "// Generate 100 products at build time\nexport async function generateStaticParams() {\n  const products = await fetch('https://api.example.com/products')\n    .then(r => r.json());\n  \n  return products.slice(0, 100).map(product => ({\n    id: product.id.toString()\n  }));\n}\n\nexport default async function ProductPage({ params }) {\n  const product = await getProduct(params.id);\n  return <div>{product.name}</div>;\n}",
          "useCase": "Blogs, documentation, marketing pages, product catalogs, static content",
          "category": "Data Fetching & Rendering"
        },
        {
          "id": "ssr",
          "title": "Server-Side Rendering (SSR)",
          "description": "Renders page on each request. Use dynamic functions to opt-in to SSR.",
          "code": "import { cookies, headers } from 'next/headers';\n\n// Using cookies() makes this dynamic (SSR)\nexport default async function ProfilePage() {\n  const cookieStore = await cookies();\n  const token = cookieStore.get('token');\n  \n  const user = await fetch('https://api.example.com/user', {\n    headers: { Authorization: `Bearer ${token}` }\n  }).then(r => r.json());\n  \n  return <div>Welcome, {user.name}</div>;\n}\n\n// Force dynamic rendering\nconst dynamic = 'force-dynamic';",
          "example": "// Using headers\nimport { headers } from 'next/headers';\n\nexport default async function Page() {\n  const headersList = await headers();\n  const userAgent = headersList.get('user-agent');\n  \n  return <div>Your browser: {userAgent}</div>;\n}\n\n// Using searchParams (makes it dynamic)\nexport default async function SearchPage({ searchParams }) {\n  const query = searchParams.q;\n  const results = await search(query);\n  return <div>{results.length} results</div>;\n}",
          "useCase": "Personalized content, authentication, real-time data, user-specific pages",
          "category": "Data Fetching & Rendering"
        },
        {
          "id": "isr",
          "title": "Incremental Static Regeneration",
          "description": "Regenerate static pages after deployment without rebuilding the entire site.",
          "code": "// Revalidate every 10 seconds\nconst revalidate = 10;\n\nexport default async function PostsPage() {\n  const posts = await fetch('https://api.example.com/posts', {\n    next: { revalidate: 10 }\n  }).then(r => r.json());\n  \n  return (\n    <ul>\n      {posts.map(post => (\n        <li key={post.id}>{post.title}</li>\n      ))}\n    </ul>\n  );\n}",
          "example": "// On-demand revalidation\n// app/api/revalidate/route.js\nimport { revalidatePath, revalidateTag } from 'next/cache';\n\nexport async function POST(request) {\n  const { path } = await request.json();\n  \n  revalidatePath(path);\n  // or revalidateTag('posts');\n  \n  return Response.json({ revalidated: true });\n}\n\n// Tag-based revalidation\nfetch('https://api.example.com/posts', {\n  next: { tags: ['posts'] }\n});",
          "useCase": "E-commerce, news sites, blogs, product listings, semi-dynamic content",
          "category": "Data Fetching & Rendering"
        },
        {
          "id": "route-handlers",
          "title": "Route Handlers",
          "description": "Create API endpoints using route.js files in the app directory.",
          "code": "// app/api/users/route.js\nimport { NextResponse } from 'next/server';\n\nexport async function GET(request) {\n  const users = await db.getUsers();\n  return NextResponse.json(users);\n}\n\nexport async function POST(request) {\n  const body = await request.json();\n  const newUser = await db.createUser(body);\n  return NextResponse.json(newUser, { status: 201 });\n}\n\nexport async function PUT(request) {\n  // Update logic\n}\n\nexport async function DELETE(request) {\n  // Delete logic\n}",
          "example": "// With dynamic segments\n// app/api/users/[id]/route.js\nexport async function GET(request, { params }) {\n  const user = await db.getUser(params.id);\n  \n  if (!user) {\n    return NextResponse.json(\n      { error: 'User not found' },\n      { status: 404 }\n    );\n  }\n  \n  return NextResponse.json(user);\n}\n\n// With search params\nexport async function GET(request) {\n  const searchParams = request.nextUrl.searchParams;\n  const query = searchParams.get('q');\n  \n  const results = await search(query);\n  return NextResponse.json(results);\n}",
          "useCase": "REST APIs, webhooks, form submissions, data mutations, external integrations",
          "category": "API Routes"
        },
        {
          "id": "middleware",
          "title": "Middleware",
          "description": "Run code before a request is completed. Useful for auth, redirects, and headers.",
          "code": "// middleware.js (root of project)\nimport { NextResponse } from 'next/server';\n\nexport function middleware(request) {\n  // Check authentication\n  const token = request.cookies.get('token');\n  \n  if (!token && request.nextUrl.pathname.startsWith('/dashboard')) {\n    return NextResponse.redirect(new URL('/login', request.url));\n  }\n  \n  // Add custom header\n  const response = NextResponse.next();\n  response.headers.set('x-custom-header', 'value');\n  return response;\n}\n\n// Configure which paths middleware runs on\nconst config = {\n  matcher: ['/dashboard/:path*', '/admin/:path*']\n};",
          "example": "// Rewrite URLs\nexport function middleware(request) {\n  if (request.nextUrl.pathname === '/old-page') {\n    return NextResponse.rewrite(new URL('/new-page', request.url));\n  }\n}\n\n// Set cookies\nexport function middleware(request) {\n  const response = NextResponse.next();\n  response.cookies.set('visited', 'true', {\n    maxAge: 60 * 60 * 24 // 24 hours\n  });\n  return response;\n}",
          "useCase": "Authentication, authorization, redirects, URL rewrites, setting headers/cookies",
          "category": "API Routes"
        },
        {
          "id": "server-actions",
          "title": "Server Actions",
          "description": "Functions that run on the server, called directly from client components. No API route needed.",
          "code": "'use server';\n\n// app/actions.js\nexport async function createPost(formData) {\n  const title = formData.get('title');\n  const content = formData.get('content');\n  \n  await db.posts.create({\n    title,\n    content\n  });\n  \n  revalidatePath('/posts');\n  redirect('/posts');\n}\n\n// Use in component\n'use client';\nimport { createPost } from './actions';\n\nexport default function CreatePostForm() {\n  return (\n    <form action={createPost}>\n      <input name=\"title\" />\n      <textarea name=\"content\" />\n      <button type=\"submit\">Create</button>\n    </form>\n  );\n}",
          "example": "// With useFormState\n'use client';\nimport { useFormState } from 'react-dom';\n\nexport default function Form() {\n  const [state, formAction] = useFormState(createPost, null);\n  \n  return (\n    <form action={formAction}>\n      <input name=\"title\" />\n      {state?.error && <p>{state.error}</p>}\n      <button>Submit</button>\n    </form>\n  );\n}\n\n// Programmatic call\n'use client';\nimport { deletePost } from './actions';\n\nfunction DeleteButton({ postId }) {\n  return (\n    <button onClick={() => deletePost(postId)}>\n      Delete\n    </button>\n  );\n}",
          "useCase": "Form submissions, mutations, database operations, no API routes needed",
          "category": "API Routes"
        }
      ],
      "quiz": [
        {
          "question": "What is the main difference between Server and Client Components in Next.js?",
          "options": [
            "Server components run on the server, Client components run in the browser",
            "Server components are faster",
            "Client components can't use hooks",
            "There is no difference"
          ],
          "correctAnswer": 0,
          "explanation": "Server Components render on the server and send HTML to the client, while Client Components are hydrated and run in the browser. Server Components can't use hooks or browser APIs."
        },
        {
          "question": "What does SSG (Static Site Generation) do?",
          "options": [
            "Generates pages on every request",
            "Generates HTML at build time",
            "Only works with client-side rendering",
            "Requires a Node.js server"
          ],
          "correctAnswer": 1,
          "explanation": "SSG generates HTML pages at build time, which can then be cached and served from a CDN. This provides the best performance but requires rebuilding to update content."
        },
        {
          "question": "What is ISR (Incremental Static Regeneration)?",
          "options": [
            "Real-time server rendering",
            "Static generation with periodic updates",
            "Client-side rendering only",
            "Database replication"
          ],
          "correctAnswer": 1,
          "explanation": "ISR allows you to update static pages after build time by revalidating them on a schedule. This combines the benefits of static generation with the ability to update content without full rebuilds."
        },
        {
          "question": "How do you create a dynamic route in Next.js App Router?",
          "options": [
            "Use query parameters",
            "Create a folder with [param] brackets",
            "Use the Router API",
            "Add a config file"
          ],
          "correctAnswer": 1,
          "explanation": "In Next.js App Router, dynamic routes are created using folders with brackets, like [id] or [slug]. The parameter is then available in the page component via params prop."
        },
        {
          "question": "What is the purpose of Server Actions in Next.js?",
          "options": [
            "To optimize images",
            "To handle form submissions and mutations on the server without API routes",
            "To cache data",
            "To create middleware"
          ],
          "correctAnswer": 1,
          "explanation": "Server Actions allow you to run server-side code directly from components, especially useful for form submissions and data mutations, without creating separate API routes."
        },
        {
          "question": "What is the difference between getStaticProps and getServerSideProps (Pages Router)?",
          "options": [
            "No difference",
            "getStaticProps runs at build time, getServerSideProps runs on each request",
            "getStaticProps is deprecated",
            "getServerSideProps is faster"
          ],
          "correctAnswer": 1,
          "explanation": "getStaticProps runs at build time for SSG, while getServerSideProps runs on every request for SSR. Choose based on whether content changes frequently."
        },
        {
          "question": "What does the 'use client' directive do?",
          "options": [
            "Forces client-side rendering",
            "Marks component boundary where client components start",
            "Optimizes performance",
            "Enables API calls"
          ],
          "correctAnswer": 1,
          "explanation": "'use client' marks the boundary where Server Components end and Client Components begin. It's needed for components using hooks, browser APIs, or event handlers."
        },
        {
          "question": "What is Next.js middleware?",
          "options": [
            "Redux middleware",
            "Code that runs before request is completed",
            "Backend framework",
            "Testing tool"
          ],
          "correctAnswer": 1,
          "explanation": "Next.js middleware runs before a request is completed, allowing you to modify the response, rewrite, redirect, or add headers. Defined in middleware.js at root."
        },
        {
          "question": "What is the purpose of the Image component in Next.js?",
          "options": [
            "Display images only",
            "Automatic image optimization, lazy loading, and responsive images",
            "Image editing",
            "Image upload"
          ],
          "correctAnswer": 1,
          "explanation": "Next.js Image component automatically optimizes images (format, size), provides lazy loading, prevents layout shift, and serves responsive images for better performance."
        },
        {
          "question": "What does next/link component do?",
          "options": [
            "Creates hyperlinks only",
            "Enables client-side navigation with prefetching",
            "External links only",
            "Database links"
          ],
          "correctAnswer": 1,
          "explanation": "next/link provides client-side navigation between pages without full page reload, with automatic prefetching of pages in the viewport for faster navigation."
        },
        {
          "question": "What is the app directory in Next.js 13+?",
          "options": [
            "Application folder",
            "New routing system with React Server Components support",
            "Configuration directory",
            "Build output"
          ],
          "correctAnswer": 1,
          "explanation": "The app directory is the new routing system in Next.js 13+ that supports React Server Components, layouts, loading states, error handling, and more features."
        },
        {
          "question": "What file creates a layout in App Router?",
          "options": [
            "index.js",
            "layout.js",
            "page.js",
            "template.js"
          ],
          "correctAnswer": 1,
          "explanation": "layout.js creates a layout that wraps child pages and layouts. Layouts preserve state across navigation and don't re-render, unlike templates."
        },
        {
          "question": "What does the loading.js file do in App Router?",
          "options": [
            "Loads data",
            "Creates automatic loading UI using React Suspense",
            "Configures loading states",
            "Imports modules"
          ],
          "correctAnswer": 1,
          "explanation": "loading.js automatically wraps the page in React Suspense and shows the loading UI while the page is being fetched or rendered on the server."
        },
        {
          "question": "What is the purpose of error.js in App Router?",
          "options": [
            "Log errors",
            "Creates error boundary for handling errors in route segment",
            "Throw errors",
            "Prevent errors"
          ],
          "correctAnswer": 1,
          "explanation": "error.js creates an error boundary that catches errors in the route segment and its children, displaying fallback UI and allowing recovery."
        },
        {
          "question": "What does revalidate do in fetch requests?",
          "options": [
            "Validates data",
            "Sets cache revalidation time in seconds for ISR",
            "Checks authentication",
            "Validates forms"
          ],
          "correctAnswer": 1,
          "explanation": "revalidate option in fetch() sets how often (in seconds) the cache should be revalidated, enabling ISR. revalidate: 60 revalidates every 60 seconds."
        },
        {
          "question": "What is the generateStaticParams function?",
          "options": [
            "Generates random parameters",
            "Pre-renders dynamic routes at build time for SSG",
            "Creates URL parameters",
            "Validates parameters"
          ],
          "correctAnswer": 1,
          "explanation": "generateStaticParams pre-renders dynamic routes at build time. It returns array of params to generate static pages for dynamic routes."
        },
        {
          "question": "What does const dynamic = 'force-dynamic' do?",
          "options": [
            "Forces dynamic routing",
            "Forces dynamic rendering (SSR) instead of static generation",
            "Enables dynamic imports",
            "Creates dynamic components"
          ],
          "correctAnswer": 1,
          "explanation": "const dynamic = 'force-dynamic' forces the route to be dynamically rendered (SSR) on every request, even if it could be statically generated."
        },
        {
          "question": "What is the notFound() function?",
          "options": [
            "404 error creator",
            "Throws error that renders closest not-found.js UI",
            "Finds missing files",
            "Database query"
          ],
          "correctAnswer": 1,
          "explanation": "notFound() is a function that throws an error to render the closest not-found.js file. Used when dynamic route parameter is invalid."
        },
        {
          "question": "What does redirect() function do?",
          "options": [
            "Redirects HTTP requests",
            "Redirects to different URL, works in Server Components and Actions",
            "Changes routes",
            "Prevents navigation"
          ],
          "correctAnswer": 1,
          "explanation": "redirect() redirects the user to a different URL. It can be used in Server Components, Route Handlers, and Server Actions to handle redirects."
        },
        {
          "question": "What is Route Handlers in App Router?",
          "options": [
            "Route components",
            "Custom request handlers using Web APIs (replacement for API routes)",
            "Navigation handlers",
            "Error handlers"
          ],
          "correctAnswer": 1,
          "explanation": "Route Handlers (route.js) are custom request handlers using Web Request/Response APIs. They replace API routes from Pages Router."
        },
        {
          "question": "What HTTP methods can Route Handlers handle?",
          "options": [
            "GET only",
            "GET, POST, PUT, PATCH, DELETE, HEAD, OPTIONS",
            "GET and POST only",
            "Custom methods only"
          ],
          "correctAnswer": 1,
          "explanation": "Route Handlers support GET, POST, PUT, PATCH, DELETE, HEAD, and OPTIONS methods. Export async functions with these names to handle requests."
        },
        {
          "question": "What is the cookies() function in Next.js?",
          "options": [
            "Browser cookies",
            "Server-side function to read/write cookies in Server Components",
            "Cookie parser",
            "Session management"
          ],
          "correctAnswer": 1,
          "explanation": "cookies() is a server-side function to read and modify cookies in Server Components, Route Handlers, and Server Actions."
        },
        {
          "question": "What does the headers() function do?",
          "options": [
            "Creates HTTP headers",
            "Reads incoming request headers in Server Components",
            "Sets response headers",
            "Header validation"
          ],
          "correctAnswer": 1,
          "explanation": "headers() is a server-side function to read incoming request headers in Server Components, Route Handlers, and Server Actions."
        },
        {
          "question": "What is the difference between layout and template?",
          "options": [
            "No difference",
            "Layout persists state across navigation, template creates new instance",
            "Template is deprecated",
            "Layout is faster"
          ],
          "correctAnswer": 1,
          "explanation": "Layouts preserve state and don't re-render on navigation. Templates create a new instance on each navigation, resetting state."
        },
        {
          "question": "What is parallel routes in Next.js?",
          "options": [
            "Concurrent routes",
            "Simultaneously render multiple pages in same layout with slots",
            "Multiple domains",
            "Route duplication"
          ],
          "correctAnswer": 1,
          "explanation": "Parallel routes allow simultaneously rendering multiple pages in the same layout using slots (@folder). Useful for dashboards with independent sections."
        },
        {
          "question": "What is intercepting routes?",
          "options": [
            "Blocking routes",
            "Intercept navigation to show different content (e.g., modal over list)",
            "Middleware routes",
            "Protected routes"
          ],
          "correctAnswer": 1,
          "explanation": "Intercepting routes ((..)folder) allow you to intercept navigation to show content in current context (like modal) while keeping URL updated."
        },
        {
          "question": "What does next/font do?",
          "options": [
            "Font styling",
            "Automatically optimizes and loads fonts without layout shift",
            "Font converter",
            "Web font provider"
          ],
          "correctAnswer": 1,
          "explanation": "next/font automatically optimizes fonts (including custom fonts), hosts them, and removes external network requests, ensuring no layout shift."
        },
        {
          "question": "What is the metadata API in App Router?",
          "options": [
            "Data about data",
            "Define SEO metadata (title, description) using config or generateMetadata",
            "API metadata",
            "Database metadata"
          ],
          "correctAnswer": 1,
          "explanation": "Metadata API allows defining SEO-related metadata through config-based (const metadata) or dynamic (generateMetadata function) approach."
        },
        {
          "question": "What file creates the HTML document structure?",
          "options": [
            "index.html",
            "layout.js",
            "document.js",
            "app.js"
          ],
          "correctAnswer": 1,
          "explanation": "Root layout.js (app/layout.js) creates the HTML document structure with <html> and <body> tags. It's required and wraps all pages."
        },
        {
          "question": "What is generateMetadata function?",
          "options": [
            "Creates metadata",
            "Async function to generate dynamic metadata based on params or data",
            "Validates metadata",
            "Metadata parser"
          ],
          "correctAnswer": 1,
          "explanation": "generateMetadata is an async function that returns metadata object. It can fetch data and use route params to generate dynamic metadata."
        },
        {
          "question": "What does const runtime = 'edge' do?",
          "options": [
            "Edge browser only",
            "Configures route to run on Edge Runtime instead of Node.js",
            "Network edge",
            "Edge caching"
          ],
          "correctAnswer": 1,
          "explanation": "const runtime = 'edge' runs the route on Edge Runtime (lightweight) instead of Node.js Runtime. Offers better performance with some limitations."
        },
        {
          "question": "What is the useRouter hook in App Router?",
          "options": [
            "Router configuration",
            "Client-side navigation hook with push, replace, refresh methods",
            "Route creation",
            "Server routing"
          ],
          "correctAnswer": 1,
          "explanation": "useRouter (from next/navigation) provides client-side navigation with methods like push(), replace(), refresh(), and back() in Client Components."
        },
        {
          "question": "What does usePathname hook return?",
          "options": [
            "Full URL",
            "Current pathname (route path without domain)",
            "Route parameters",
            "Search parameters"
          ],
          "correctAnswer": 1,
          "explanation": "usePathname returns the current pathname (e.g., /blog/post). It's a Client Component hook from next/navigation."
        },
        {
          "question": "What is useSearchParams hook?",
          "options": [
            "Search functionality",
            "Reads current URL query string parameters",
            "Search form hook",
            "Database search"
          ],
          "correctAnswer": 1,
          "explanation": "useSearchParams returns a read-only version of URLSearchParams to access current URL's query string in Client Components."
        },
        {
          "question": "What does useParams hook return?",
          "options": [
            "Function parameters",
            "Current route's dynamic parameters",
            "URL parameters",
            "Search parameters"
          ],
          "correctAnswer": 1,
          "explanation": "useParams returns an object containing the current route's dynamic parameters filled from the URL in Client Components."
        },
        {
          "question": "What is the useSelectedLayoutSegment hook?",
          "options": [
            "Layout selector",
            "Returns active child segment in layout",
            "Selection tool",
            "Segment creator"
          ],
          "correctAnswer": 1,
          "explanation": "useSelectedLayoutSegment returns the active child segment one level below the Layout it's called from. Useful for building navigation."
        },
        {
          "question": "What does next.config.js file do?",
          "options": [
            "App configuration",
            "Configures Next.js behavior with options for images, redirects, headers, etc.",
            "Build configuration",
            "Runtime configuration"
          ],
          "correctAnswer": 1,
          "explanation": "next.config.js is the configuration file for customizing Next.js behavior including webpack config, environment variables, redirects, headers, image domains, etc."
        },
        {
          "question": "What is the purpose of rewrites in next.config.js?",
          "options": [
            "Rewrite code",
            "Map incoming request path to different destination path without changing URL",
            "URL redirection",
            "Path validation"
          ],
          "correctAnswer": 1,
          "explanation": "Rewrites allow mapping an incoming request path to a different destination path without changing the URL in the browser. Useful for API masking."
        },
        {
          "question": "What do redirects in next.config.js do?",
          "options": [
            "Route changes",
            "Redirect incoming path to different destination with URL change",
            "Error pages",
            "Navigation"
          ],
          "correctAnswer": 1,
          "explanation": "Redirects map an incoming request path to a different destination, changing the URL. Can be permanent (308) or temporary (307) redirects."
        },
        {
          "question": "What is basePath in next.config.js?",
          "options": [
            "Base URL",
            "Deploy Next.js app under subpath of domain",
            "Root directory",
            "API base path"
          ],
          "correctAnswer": 1,
          "explanation": "basePath allows deploying Next.js app under a subpath of a domain (e.g., /docs). Automatically added to all paths and links."
        },
        {
          "question": "What does assetPrefix do in next.config.js?",
          "options": [
            "Asset naming",
            "Configure CDN to host static assets",
            "Asset optimization",
            "Prefix generator"
          ],
          "correctAnswer": 1,
          "explanation": "assetPrefix allows configuring CDN to serve static assets. Next.js will automatically prefix asset URLs with the specified path."
        },
        {
          "question": "What is the API Routes feature (Pages Router)?",
          "options": [
            "External APIs",
            "Backend API endpoints as serverless functions",
            "Route documentation",
            "API testing"
          ],
          "correctAnswer": 1,
          "explanation": "API Routes (pages/api) let you build backend API endpoints as serverless functions within your Next.js app, handling HTTP requests."
        },
        {
          "question": "What is the difference between shallow routing and regular routing?",
          "options": [
            "No difference",
            "Shallow routing changes URL without running data fetching methods",
            "Shallow is faster",
            "Regular routing is deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "Shallow routing changes URL without triggering getServerSideProps/getStaticProps. Useful for updating URL with state changes without re-fetching."
        },
        {
          "question": "What does next build command do?",
          "options": [
            "Builds UI",
            "Creates optimized production build",
            "Installs dependencies",
            "Runs development server"
          ],
          "correctAnswer": 1,
          "explanation": "next build creates an optimized production build, generating static pages, server functions, and assets in the .next directory."
        },
        {
          "question": "What is next start command?",
          "options": [
            "Starts development",
            "Starts production server serving the built app",
            "Starts new project",
            "Starts database"
          ],
          "correctAnswer": 1,
          "explanation": "next start starts the production server that serves the built application. Must run next build first."
        },
        {
          "question": "What does next export do (Pages Router)?",
          "options": [
            "Exports data",
            "Exports app as static HTML (static export)",
            "Exports configuration",
            "Creates exports"
          ],
          "correctAnswer": 1,
          "explanation": "next export generates a static HTML export of your app. Each page becomes a static HTML file without requiring Node.js server."
        },
        {
          "question": "What is preview mode in Next.js?",
          "options": [
            "Development preview",
            "Bypass static generation to see draft content from CMS",
            "Production preview",
            "Design preview"
          ],
          "correctAnswer": 1,
          "explanation": "Preview mode allows temporarily bypassing static generation to preview draft content from headless CMS before publishing."
        },
        {
          "question": "What is the purpose of _app.js in Pages Router?",
          "options": [
            "Application logic",
            "Initialize pages, persist layout, keep state, inject global CSS",
            "Main page",
            "App configuration"
          ],
          "correctAnswer": 1,
          "explanation": "_app.js (pages/_app.js) initializes pages, persists layout between page changes, keeps state when navigating, and allows injecting global CSS."
        },
        {
          "question": "What does _document.js customize in Pages Router?",
          "options": [
            "Document content",
            "Initial HTML document structure (html, body tags)",
            "Page layout",
            "Documentation"
          ],
          "correctAnswer": 1,
          "explanation": "_document.js (pages/_document.js) customizes the initial HTML document structure. Used to augment application's <html> and <body> tags."
        },
        {
          "question": "What is the 404.js file?",
          "options": [
            "Error page",
            "Custom 404 Not Found page",
            "File not found error",
            "Redirect page"
          ],
          "correctAnswer": 1,
          "explanation": "404.js (pages/404.js) is a custom 404 Not Found page. Statically generated at build time and shown for non-existent routes."
        },
        {
          "question": "What does 500.js file do?",
          "options": [
            "Server error",
            "Custom 500 Internal Server Error page",
            "Error handling",
            "Status page"
          ],
          "correctAnswer": 1,
          "explanation": "500.js (pages/500.js) is a custom 500 Internal Server Error page. Statically generated at build time and shown when server errors occur."
        },
        {
          "question": "What is getInitialProps (Pages Router)?",
          "options": [
            "Initialize props",
            "Legacy data fetching method (prefer getStaticProps/getServerSideProps)",
            "First props",
            "Default props"
          ],
          "correctAnswer": 1,
          "explanation": "getInitialProps is legacy data fetching method that runs on both server and client. Prefer getStaticProps or getServerSideProps for better performance."
        },
        {
          "question": "What does next/script component do?",
          "options": [
            "JavaScript scripts",
            "Optimizes loading of third-party scripts with strategies",
            "Script generation",
            "Script validation"
          ],
          "correctAnswer": 1,
          "explanation": "next/script optimizes loading of third-party scripts with strategies (beforeInteractive, afterInteractive, lazyOnload) to prevent blocking page rendering."
        },
        {
          "question": "What is the purpose of output: 'export' in next.config.js?",
          "options": [
            "Export configuration",
            "Generate static export (static HTML/CSS/JS) for static hosting",
            "Output directory",
            "Build output"
          ],
          "correctAnswer": 1,
          "explanation": "output: 'export' generates a static export of your Next.js app as static HTML/CSS/JS files that can be hosted on any static hosting service."
        },
        {
          "question": "What is Turbopack in Next.js?",
          "options": [
            "Package manager",
            "Rust-based bundler for faster development (beta)",
            "Compression tool",
            "Performance monitor"
          ],
          "correctAnswer": 1,
          "explanation": "Turbopack is an incremental bundler written in Rust, designed to be a faster successor to webpack for Next.js development."
        },
        {
          "question": "What does next/dynamic do?",
          "options": [
            "Dynamic routing",
            "Dynamically import components with code splitting and SSR support",
            "Dynamic content",
            "Dynamic types"
          ],
          "correctAnswer": 1,
          "explanation": "next/dynamic enables dynamic imports for components with automatic code splitting. Can disable SSR with ssr: false option."
        },
        {
          "question": "What is Static Export in Next.js?",
          "options": [
            "Export variables",
            "Generate static HTML app without Node.js server",
            "Data export",
            "Build export"
          ],
          "correctAnswer": 1,
          "explanation": "Static Export (output: 'export') generates a static HTML/CSS/JS application that can be deployed on any static hosting without Node.js server."
        },
        {
          "question": "What is the trailingSlash option in next.config.js?",
          "options": [
            "Slash at end",
            "Adds trailing slash to URLs or removes them",
            "URL formatting",
            "Path separator"
          ],
          "correctAnswer": 1,
          "explanation": "trailingSlash option controls whether URLs should have trailing slashes (true) or not (false). Affects how pages/URLs are exported."
        },
        {
          "question": "What does env in next.config.js do?",
          "options": [
            "Environment variables",
            "Makes environment variables available in browser by embedding them",
            "Environment settings",
            "Config variables"
          ],
          "correctAnswer": 1,
          "explanation": "env in next.config.js embeds environment variables at build time, making them available in the browser. Prefer NEXT_PUBLIC_ prefix instead."
        },
        {
          "question": "What is the purpose of NEXT_PUBLIC_ prefix?",
          "options": [
            "Public files",
            "Makes environment variables accessible in browser",
            "Public API",
            "Public routes"
          ],
          "correctAnswer": 1,
          "explanation": "Environment variables prefixed with NEXT_PUBLIC_ are exposed to the browser. Non-prefixed variables are server-side only for security."
        },
        {
          "question": "What is internationalization (i18n) in Next.js?",
          "options": [
            "Translation",
            "Built-in support for internationalized routing and locales",
            "Language detection",
            "Multi-language content"
          ],
          "correctAnswer": 1,
          "explanation": "Next.js has built-in i18n routing support. Configure locales, default locale, and domain locales in next.config.js for multi-language sites."
        },
        {
          "question": "What does useReportWebVitals do?",
          "options": [
            "Health monitoring",
            "Reports Core Web Vitals and custom metrics",
            "Error reporting",
            "Analytics"
          ],
          "correctAnswer": 1,
          "explanation": "useReportWebVitals (in _app.js) allows reporting Core Web Vitals and custom performance metrics to analytics services."
        },
        {
          "question": "What is next/head component?",
          "options": [
            "Header component",
            "Appends elements to page <head> (Pages Router)",
            "Head section",
            "Navigation header"
          ],
          "correctAnswer": 1,
          "explanation": "next/head component (Pages Router) appends elements to page <head>. In App Router, use Metadata API instead."
        },
        {
          "question": "What does the Link prefetch prop do?",
          "options": [
            "Pre-loads data",
            "Controls if link should be prefetched (default true in production)",
            "Fetches on click",
            "Pre-renders page"
          ],
          "correctAnswer": 1,
          "explanation": "prefetch prop on Link controls automatic prefetching of pages in viewport. Defaults to true in production, false in development."
        },
        {
          "question": "What is the scroll prop in Link?",
          "options": [
            "Scroll position",
            "Controls if page scrolls to top after navigation (default true)",
            "Smooth scrolling",
            "Scroll event"
          ],
          "correctAnswer": 1,
          "explanation": "scroll prop on Link controls whether page scrolls to top after navigation. Set to false to maintain scroll position."
        },
        {
          "question": "What is the replace prop in Link?",
          "options": [
            "Replace content",
            "Replaces current history state instead of adding new URL to stack",
            "Replace component",
            "Replace route"
          ],
          "correctAnswer": 1,
          "explanation": "replace prop on Link replaces current history entry instead of adding new one. Useful for redirects or preventing back navigation."
        },
        {
          "question": "What is Draft Mode in Next.js?",
          "options": [
            "Development mode",
            "Allows bypassing static generation to preview draft content",
            "Draft documents",
            "Design drafts"
          ],
          "correctAnswer": 1,
          "explanation": "Draft Mode (replacement for Preview Mode) allows temporarily bypassing static generation to preview draft/unpublished content from headless CMS."
        },
        {
          "question": "What does experimental.appDir do in next.config.js?",
          "options": [
            "App directory",
            "Enables the new app directory (App Router) - now stable",
            "Experiment configuration",
            "Directory structure"
          ],
          "correctAnswer": 1,
          "explanation": "experimental.appDir enabled the new app directory in Next.js 13. It's now stable and the recommended approach in Next.js 13.4+."
        },
        {
          "question": "What is Route Groups in App Router?",
          "options": [
            "Group routes",
            "Organize routes without affecting URL structure using (folder)",
            "Route collections",
            "Grouped navigation"
          ],
          "correctAnswer": 1,
          "explanation": "Route Groups (folder names in parentheses like (marketing)) organize routes without affecting URL structure. Useful for organizing code or layouts."
        },
        {
          "question": "What is the default.js file?",
          "options": [
            "Default page",
            "Fallback for parallel routes when slot not found",
            "Default configuration",
            "Error fallback"
          ],
          "correctAnswer": 1,
          "explanation": "default.js provides a fallback to render within a parallel route slot when Next.js cannot recover a slot's active state after full page load."
        },
        {
          "question": "What does the global-error.js file do?",
          "options": [
            "Global errors",
            "Root error boundary for catching errors in root layout",
            "Error logger",
            "Error configuration"
          ],
          "correctAnswer": 1,
          "explanation": "global-error.js is a root error boundary that catches errors in the root layout. It must define its own <html> and <body> tags."
        },
        {
          "question": "What is the force-dynamic segment config?",
          "options": [
            "Forces dynamics",
            "Forces route to be dynamically rendered (SSR) on each request",
            "Dynamic imports",
            "Dynamic routing"
          ],
          "correctAnswer": 1,
          "explanation": "const dynamic = 'force-dynamic' forces the route to be rendered dynamically (SSR) on each request, disabling static optimization."
        },
        {
          "question": "What does force-static segment config do?",
          "options": [
            "Static files",
            "Forces route to be statically generated at build time",
            "Static content",
            "Build optimization"
          ],
          "correctAnswer": 1,
          "explanation": "const dynamic = 'force-static' forces static rendering and caching of route, even if it uses dynamic functions."
        },
        {
          "question": "What is the dynamicParams segment config?",
          "options": [
            "Dynamic parameters",
            "Controls behavior for dynamic segments not in generateStaticParams",
            "Parameter validation",
            "URL parameters"
          ],
          "correctAnswer": 1,
          "explanation": "const dynamicParams controls what happens when dynamic segment is visited that wasn't generated. true returns 404, false generates on-demand."
        },
        {
          "question": "What does revalidate: 0 mean?",
          "options": [
            "No revalidation",
            "Equivalent to force-dynamic, always fetches fresh data",
            "Zero cache",
            "Immediate refresh"
          ],
          "correctAnswer": 1,
          "explanation": "revalidate: 0 is equivalent to force-dynamic. It ensures data is always fresh by fetching on every request with no caching."
        },
        {
          "question": "What is the fetchCache segment config?",
          "options": [
            "Fetch configuration",
            "Controls default cache behavior of fetch requests in route",
            "Cache storage",
            "Fetch optimization"
          ],
          "correctAnswer": 1,
          "explanation": "const fetchCache sets default caching behavior for all fetch requests in the route. Options: 'auto', 'default-cache', 'only-cache', etc."
        },
        {
          "question": "What does preferredRegion segment config do?",
          "options": [
            "Region selection",
            "Specifies preferred region(s) for deploying route",
            "Geo-location",
            "Server region"
          ],
          "correctAnswer": 1,
          "explanation": "const preferredRegion specifies the preferred region(s) where the route should be deployed. Useful for edge deployment optimization."
        },
        {
          "question": "What is the maxDuration segment config?",
          "options": [
            "Max time",
            "Sets maximum execution time for route in seconds",
            "Timeout configuration",
            "Duration limit"
          ],
          "correctAnswer": 1,
          "explanation": "const maxDuration sets maximum duration (in seconds) the route can run before timing out. Depends on hosting platform limits."
        },
        {
          "question": "What does cache: 'no-store' in fetch mean?",
          "options": [
            "No storage",
            "Disables caching, fetches fresh data on every request",
            "Memory cache only",
            "Temporary cache"
          ],
          "correctAnswer": 1,
          "explanation": "fetch('url', { cache: 'no-store' }) disables caching and fetches fresh data on every request, making the route dynamically rendered."
        },
        {
          "question": "What is next: { revalidate: 3600 } in fetch?",
          "options": [
            "Revalidation time",
            "Sets ISR revalidation to 3600 seconds (1 hour) for that fetch",
            "Cache duration",
            "Refresh interval"
          ],
          "correctAnswer": 1,
          "explanation": "fetch('url', { next: { revalidate: 3600 } }) sets ISR revalidation for that specific request to 3600 seconds."
        },
        {
          "question": "What does next: { tags: ['products'] } do in fetch?",
          "options": [
            "Tag metadata",
            "Assigns cache tags for on-demand revalidation",
            "Product tags",
            "Tag filtering"
          ],
          "correctAnswer": 1,
          "explanation": "fetch('url', { next: { tags: ['products'] } }) assigns cache tags that can be used with revalidateTag() for on-demand revalidation."
        },
        {
          "question": "What is revalidateTag function?",
          "options": [
            "Validates tags",
            "On-demand revalidation of cached data with specific tag",
            "Tag creation",
            "Tag verification"
          ],
          "correctAnswer": 1,
          "explanation": "revalidateTag('tag-name') triggers on-demand revalidation of all fetch requests with that tag. Used in Server Actions or Route Handlers."
        },
        {
          "question": "What does revalidatePath function do?",
          "options": [
            "Validates paths",
            "On-demand revalidation of all cached data for specific path",
            "Path creation",
            "Path checking"
          ],
          "correctAnswer": 1,
          "explanation": "revalidatePath('/path') triggers on-demand revalidation of a specific path. Useful after data mutations to update cached content."
        },
        {
          "question": "What is unstable_cache in Next.js?",
          "options": [
            "Unstable caching",
            "Experimental API for caching function results (use with caution)",
            "Cache storage",
            "Legacy cache"
          ],
          "correctAnswer": 1,
          "explanation": "unstable_cache is experimental API for caching expensive computations or database queries. API may change, use with caution in production."
        },
        {
          "question": "What is the generateImageMetadata function?",
          "options": [
            "Image metadata",
            "Generates multiple variants of image for Open Graph images",
            "Image information",
            "Metadata extraction"
          ],
          "correctAnswer": 1,
          "explanation": "generateImageMetadata generates multiple variants of an image (different sizes) for Open Graph images and Twitter cards in one route."
        },
        {
          "question": "What is the opengraph-image file convention?",
          "options": [
            "OG image",
            "Generates Open Graph image for social sharing",
            "Image file",
            "Social media image"
          ],
          "correctAnswer": 1,
          "explanation": "opengraph-image.jpg or opengraph-image.tsx generates Open Graph images for social media sharing. Dynamic generation with route segment config."
        },
        {
          "question": "What does the twitter-image file do?",
          "options": [
            "Twitter logo",
            "Generates Twitter card image for social sharing",
            "Social image",
            "Card image"
          ],
          "correctAnswer": 1,
          "explanation": "twitter-image.jpg or twitter-image.tsx generates Twitter card images. Similar to opengraph-image but specifically for Twitter."
        },
        {
          "question": "What is the sitemap file convention?",
          "options": [
            "Site structure",
            "Generates sitemap.xml for SEO",
            "Navigation map",
            "Page list"
          ],
          "correctAnswer": 1,
          "explanation": "sitemap.js or sitemap.ts generates sitemap.xml file for search engines. Can be static or dynamic based on your data."
        },
        {
          "question": "What does the robots file do?",
          "options": [
            "Robot detection",
            "Generates robots.txt for search engine crawlers",
            "Bot configuration",
            "Crawler rules"
          ],
          "correctAnswer": 1,
          "explanation": "robots.js or robots.ts generates robots.txt file that tells search engine crawlers which pages to crawl or not."
        },
        {
          "question": "What is the manifest file convention?",
          "options": [
            "File list",
            "Generates web app manifest for PWA",
            "App configuration",
            "Manifest documentation"
          ],
          "correctAnswer": 1,
          "explanation": "manifest.js or manifest.ts generates web app manifest (manifest.json) for Progressive Web Apps with icons, colors, and app info."
        },
        {
          "question": "What is the icon file convention?",
          "options": [
            "App icon",
            "Generates favicon and app icons automatically",
            "Icon library",
            "Image file"
          ],
          "correctAnswer": 1,
          "explanation": "icon.ico, icon.png, or icon.tsx generates favicon and various app icons automatically. Supports different sizes and devices."
        },
        {
          "question": "What does apple-icon file do?",
          "options": [
            "Apple logo",
            "Generates Apple-specific touch icons",
            "iOS icon",
            "App Store icon"
          ],
          "correctAnswer": 1,
          "explanation": "apple-icon.png or apple-icon.tsx generates Apple touch icons for iOS devices when users save app to home screen."
        },
        {
          "question": "What is instrumentation in Next.js?",
          "options": [
            "Music instruments",
            "Setup observability and monitoring in your app",
            "Performance tools",
            "Testing instruments"
          ],
          "correctAnswer": 1,
          "explanation": "instrumentation.js allows setting up observability tools, monitoring, and logging before app starts. Useful for APM tools like Sentry."
        },
        {
          "question": "What is the difference between App Router and Pages Router?",
          "options": [
            "No difference",
            "App Router supports Server Components, layouts, better data fetching",
            "Pages is newer",
            "App Router is deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "App Router (app/) is newer with Server Components, built-in layouts, loading/error states, and better data fetching. Pages Router (pages/) is older but still supported."
        }
      ],
      "topicCount": 13,
      "quizCount": 94
    },
    {
      "slug": "postgresql",
      "meta": {
        "title": "PostgreSQL Interview Preparation",
        "description": "Build confidence in SQL, indexing, optimization, transactions, and schema design with interview-ready explanations."
      },
      "topics": [
        {
          "id": "ecommerce-schema-er-diagram",
          "title": "E-commerce Schema + ER Diagram Practice",
          "description": "Practice on a realistic e-commerce schema with UUID keys, transactional entities, and clear table relationships.",
          "explanation": "Use this as the canonical practice schema for joins, aggregations, CTEs, transactions, JSONB queries, and optimization. The diagram below maps core entity relationships used in most interview scenarios.",
          "code": "-- Canonical e-commerce schema (core)\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n\nCREATE TABLE users (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  email VARCHAR(255) UNIQUE NOT NULL,\n  password_hash VARCHAR(255) NOT NULL,\n  first_name VARCHAR(100),\n  last_name VARCHAR(100),\n  role VARCHAR(20) DEFAULT 'customer' CHECK (role IN ('customer', 'admin')),\n  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE products (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  sku VARCHAR(100) UNIQUE NOT NULL,\n  name VARCHAR(255) NOT NULL,\n  description TEXT,\n  price DECIMAL(10, 2) NOT NULL CHECK (price >= 0),\n  stock_quantity INTEGER NOT NULL DEFAULT 0 CHECK (stock_quantity >= 0),\n  category VARCHAR(100),\n  image_url VARCHAR(500),\n  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE carts (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n  UNIQUE(user_id)\n);\n\nCREATE TABLE cart_items (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  cart_id UUID NOT NULL REFERENCES carts(id) ON DELETE CASCADE,\n  product_id UUID NOT NULL REFERENCES products(id) ON DELETE CASCADE,\n  quantity INTEGER NOT NULL CHECK (quantity > 0),\n  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n  UNIQUE(cart_id, product_id)\n);\n\nCREATE TABLE orders (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  user_id UUID NOT NULL REFERENCES users(id),\n  order_number VARCHAR(50) UNIQUE NOT NULL,\n  total_amount DECIMAL(10, 2) NOT NULL CHECK (total_amount >= 0),\n  status VARCHAR(50) NOT NULL DEFAULT 'pending' CHECK (\n    status IN ('pending', 'processing', 'shipped', 'delivered', 'completed', 'cancelled', 'refunded')\n  ),\n  payment_method VARCHAR(10) NOT NULL CHECK (payment_method IN ('cc', 'dc', 'cod')),\n  shipping_address JSONB NOT NULL,\n  billing_address JSONB NOT NULL,\n  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE order_items (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  order_id UUID NOT NULL REFERENCES orders(id) ON DELETE CASCADE,\n  product_id UUID NOT NULL REFERENCES products(id),\n  quantity INTEGER NOT NULL CHECK (quantity > 0),\n  price_at_time DECIMAL(10, 2) NOT NULL CHECK (price_at_time >= 0),\n  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE payments (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  order_id UUID NOT NULL REFERENCES orders(id) ON DELETE CASCADE,\n  amount DECIMAL(10, 2) NOT NULL CHECK (amount >= 0),\n  status VARCHAR(50) NOT NULL DEFAULT 'pending' CHECK (\n    status IN ('pending', 'processing', 'completed', 'failed', 'refunded')\n  ),\n  payment_method VARCHAR(50) NOT NULL,\n  transaction_id VARCHAR(255),\n  payment_details JSONB,\n  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE returns (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  order_id UUID NOT NULL REFERENCES orders(id),\n  user_id UUID NOT NULL REFERENCES users(id),\n  reason TEXT NOT NULL,\n  status VARCHAR(50) NOT NULL DEFAULT 'requested' CHECK (\n    status IN ('requested', 'approved', 'rejected', 'completed')\n  ),\n  refund_amount DECIMAL(10, 2),\n  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE stock_reservations (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  product_id UUID NOT NULL REFERENCES products(id) ON DELETE CASCADE,\n  cart_id UUID NOT NULL REFERENCES carts(id) ON DELETE CASCADE,\n  quantity INTEGER NOT NULL CHECK (quantity > 0),\n  expires_at TIMESTAMP NOT NULL,\n  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n  UNIQUE(product_id, cart_id)\n);",
          "example": "erDiagram\n    USERS ||--|| CARTS : has\n    USERS ||--o{ ORDERS : places\n    USERS ||--o{ RETURNS : requests\n    PRODUCTS ||--o{ CART_ITEMS : appears_in\n    PRODUCTS ||--o{ ORDER_ITEMS : sold_as\n    PRODUCTS ||--o{ STOCK_RESERVATIONS : reserved_as\n    CARTS ||--o{ CART_ITEMS : contains\n    CARTS ||--o{ STOCK_RESERVATIONS : holds\n    ORDERS ||--o{ ORDER_ITEMS : includes\n    ORDERS ||--o{ PAYMENTS : paid_by\n    ORDERS ||--o{ RETURNS : may_have",
          "useCase": "Schema-first interview practice and realistic SQL drills across order lifecycle and inventory controls.",
          "category": "Schema Design Practice",
          "interviewQuestions": [
            {
              "question": "Why do we store `price_at_time` in `order_items`?",
              "answer": "Because product prices change over time; historical order lines must remain accurate."
            },
            {
              "question": "How does `stock_reservations` help during checkout?",
              "answer": "It creates temporary cart-level inventory holds to reduce overselling in concurrent sessions."
            },
            {
              "question": "Which relationship resolves the many-to-many between orders and products?",
              "answer": "`order_items` resolves the many-to-many and carries quantity and historical price."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "List all users with cart value and active reservation count."
            },
            {
              "type": "implement",
              "question": "Find products with low stock and high reservation pressure."
            },
            {
              "type": "scenario",
              "question": "Design checkout transaction steps to keep stock, order, and payment consistent."
            }
          ],
          "programExercises": [
            {
              "question": "Top 5 customers by completed order value",
              "code": "SELECT user_id, SUM(total_amount) AS ltv FROM orders WHERE status = 'completed' GROUP BY user_id ORDER BY ltv DESC LIMIT 5;",
              "output": "Users sorted by lifetime completed order amount."
            }
          ]
        },
        {
          "id": "ecommerce-queries",
          "title": "E-commerce SQL Query Practice (150+ Questions)",
          "description": "Practice SQL from basic SELECT to advanced analytics using a real e-commerce database schema. All 12 topics covered with hands-on query exercises.",
          "explanation": "This comprehensive practice guide covers essential SQL patterns using an e-commerce schema with tables: users (id, first_name, last_name, email, role), products (id, name, sku, price, stock_quantity, category), orders (id, order_number, user_id, total_amount, status, payment_method, shipping/billing_address), order_items (id, order_id, product_id, quantity, price_at_time), payments, returns, carts, cart_items, and stock_reservations. Work through 120+ real-world queries progressively from fundamentals to production-level analytics.",
          "code": "-- CANONICAL E-COMMERCE SCHEMA\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  first_name VARCHAR(100) NOT NULL,\n  last_name VARCHAR(100) NOT NULL,\n  email VARCHAR(255) UNIQUE NOT NULL,\n  role VARCHAR(20) NOT NULL DEFAULT 'customer',\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE products (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  sku VARCHAR(100) UNIQUE NOT NULL,\n  price DECIMAL(10,2) NOT NULL,\n  stock_quantity INT NOT NULL DEFAULT 0,\n  category VARCHAR(100),\n  image_url TEXT,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE orders (\n  id SERIAL PRIMARY KEY,\n  order_number VARCHAR(50) UNIQUE NOT NULL,\n  user_id INT NOT NULL REFERENCES users(id),\n  total_amount DECIMAL(10,2) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  payment_method VARCHAR(20),\n  shipping_address JSONB,\n  billing_address JSONB,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE order_items (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  product_id INT NOT NULL REFERENCES products(id),\n  quantity INT NOT NULL,\n  price_at_time DECIMAL(10,2) NOT NULL\n);\n\nCREATE TABLE payments (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  amount DECIMAL(10,2) NOT NULL,\n  payment_method VARCHAR(20) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  transaction_id VARCHAR(100),\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE returns (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  reason TEXT,\n  status VARCHAR(20) NOT NULL,\n  refund_amount DECIMAL(10,2),\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE carts (\n  id SERIAL PRIMARY KEY,\n  user_id INT NOT NULL REFERENCES users(id),\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE cart_items (\n  id SERIAL PRIMARY KEY,\n  cart_id INT NOT NULL REFERENCES carts(id),\n  product_id INT NOT NULL REFERENCES products(id),\n  quantity INT NOT NULL DEFAULT 1\n);\n\nCREATE TABLE stock_reservations (\n  id SERIAL PRIMARY KEY,\n  product_id INT NOT NULL REFERENCES products(id),\n  quantity INT NOT NULL,\n  expires_at TIMESTAMP NOT NULL\n);",
          "useCase": "Interview preparation, SQL mastery, database design, query optimization, production SQL skills",
          "category": "Complete Practice Guide",
          "exercises": [
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Get all users",
              "answer": "SELECT * FROM users;"
            },
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Get all admin users",
              "answer": "SELECT * FROM users WHERE role = 'admin';"
            },
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Get all customers",
              "answer": "SELECT * FROM users WHERE role = 'customer';"
            },
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Get all products under 'Electronics'",
              "answer": "SELECT * FROM products WHERE category = 'Electronics';"
            },
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Get products priced above 500",
              "answer": "SELECT * FROM products WHERE price > 500;"
            },
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Get products with stock less than 10",
              "answer": "SELECT * FROM products WHERE stock_quantity < 10;"
            },
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Find product by SKU",
              "answer": "SELECT * FROM products WHERE sku = 'PROD-123';"
            },
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Get all orders with status = 'processing'",
              "answer": "SELECT * FROM orders WHERE status = 'processing';"
            },
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Get all payments with status = 'completed'",
              "answer": "SELECT * FROM payments WHERE status = 'completed';"
            },
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Get all returns that are still requested",
              "answer": "SELECT * FROM returns WHERE status = 'requested';"
            },
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Find all carts created in last 7 days",
              "answer": "SELECT * FROM carts WHERE created_at >= NOW() - INTERVAL '7 days';"
            },
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Get all stock reservations expiring in next 5 minutes",
              "answer": "SELECT * FROM stock_reservations WHERE expires_at <= NOW() + INTERVAL '5 minutes' AND expires_at > NOW();"
            },
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Get users created today",
              "answer": "SELECT * FROM users WHERE DATE(created_at) = CURRENT_DATE;"
            },
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Find all products without category",
              "answer": "SELECT * FROM products WHERE category IS NULL;"
            },
            {
              "type": "query",
              "topic": "TOPIC 1: Basic SELECT & Filtering",
              "question": "Get all orders using COD",
              "answer": "SELECT * FROM orders WHERE payment_method = 'cod';"
            },
            {
              "type": "query",
              "topic": "TOPIC 2: Sorting & Pagination",
              "question": "Get products sorted by price ASC",
              "answer": "SELECT * FROM products ORDER BY price ASC;"
            },
            {
              "type": "query",
              "topic": "TOPIC 2: Sorting & Pagination",
              "question": "Get products sorted by price DESC",
              "answer": "SELECT * FROM products ORDER BY price DESC;"
            },
            {
              "type": "query",
              "topic": "TOPIC 2: Sorting & Pagination",
              "question": "Get latest 10 orders",
              "answer": "SELECT * FROM orders ORDER BY created_at DESC LIMIT 10;"
            },
            {
              "type": "query",
              "topic": "TOPIC 2: Sorting & Pagination",
              "question": "Paginate products (page 2, 10 per page)",
              "answer": "SELECT * FROM products ORDER BY id LIMIT 10 OFFSET 10;"
            },
            {
              "type": "query",
              "topic": "TOPIC 2: Sorting & Pagination",
              "question": "Get top 5 most expensive products",
              "answer": "SELECT * FROM products ORDER BY price DESC LIMIT 5;"
            },
            {
              "type": "query",
              "topic": "TOPIC 2: Sorting & Pagination",
              "question": "Get oldest users",
              "answer": "SELECT * FROM users ORDER BY created_at ASC LIMIT 10;"
            },
            {
              "type": "query",
              "topic": "TOPIC 2: Sorting & Pagination",
              "question": "Sort orders by total amount highest first",
              "answer": "SELECT * FROM orders ORDER BY total_amount DESC;"
            },
            {
              "type": "query",
              "topic": "TOPIC 2: Sorting & Pagination",
              "question": "Paginate users alphabetically",
              "answer": "SELECT * FROM users ORDER BY first_name ASC, last_name ASC LIMIT 20 OFFSET 0;"
            },
            {
              "type": "query",
              "topic": "TOPIC 3: Aggregation (COUNT, SUM, AVG)",
              "question": "Count total users",
              "answer": "SELECT COUNT(*) AS total_users FROM users;"
            },
            {
              "type": "query",
              "topic": "TOPIC 3: Aggregation (COUNT, SUM, AVG)",
              "question": "Count total customers",
              "answer": "SELECT COUNT(*) AS total_customers FROM users WHERE role = 'customer';"
            },
            {
              "type": "query",
              "topic": "TOPIC 3: Aggregation (COUNT, SUM, AVG)",
              "question": "Count total orders",
              "answer": "SELECT COUNT(*) AS total_orders FROM orders;"
            },
            {
              "type": "query",
              "topic": "TOPIC 3: Aggregation (COUNT, SUM, AVG)",
              "question": "Count orders per status",
              "answer": "SELECT status, COUNT(*) AS order_count FROM orders GROUP BY status;"
            },
            {
              "type": "query",
              "topic": "TOPIC 3: Aggregation (COUNT, SUM, AVG)",
              "question": "Total revenue generated",
              "answer": "SELECT SUM(total_amount) AS total_revenue FROM orders WHERE status = 'completed';"
            },
            {
              "type": "query",
              "topic": "TOPIC 3: Aggregation (COUNT, SUM, AVG)",
              "question": "Average order value",
              "answer": "SELECT AVG(total_amount) AS avg_order_value FROM orders;"
            },
            {
              "type": "query",
              "topic": "TOPIC 3: Aggregation (COUNT, SUM, AVG)",
              "question": "Total revenue per user",
              "answer": "SELECT user_id, SUM(total_amount) AS user_revenue FROM orders WHERE status = 'completed' GROUP BY user_id;"
            },
            {
              "type": "query",
              "topic": "TOPIC 3: Aggregation (COUNT, SUM, AVG)",
              "question": "Total revenue per product",
              "answer": "SELECT\n+  oi.product_id,\n+  SUM(oi.quantity * oi.price_at_time) AS product_revenue\n+FROM order_items oi\n+JOIN orders o ON o.id = oi.order_id\n+WHERE o.status = 'completed'\n+GROUP BY oi.product_id;"
            },
            {
              "type": "query",
              "topic": "TOPIC 3: Aggregation (COUNT, SUM, AVG)",
              "question": "Count items in each cart",
              "answer": "SELECT cart_id, COUNT(*) AS item_count FROM cart_items GROUP BY cart_id;"
            },
            {
              "type": "query",
              "topic": "TOPIC 3: Aggregation (COUNT, SUM, AVG)",
              "question": "Total stock value (price * quantity)",
              "answer": "SELECT SUM(price * stock_quantity) AS total_stock_value FROM products;"
            },
            {
              "type": "query",
              "topic": "TOPIC 3: Aggregation (COUNT, SUM, AVG)",
              "question": "Count returns per status",
              "answer": "SELECT status, COUNT(*) AS return_count FROM returns GROUP BY status;"
            },
            {
              "type": "query",
              "topic": "TOPIC 3: Aggregation (COUNT, SUM, AVG)",
              "question": "Total refund amount requested",
              "answer": "SELECT SUM(refund_amount) AS total_refunds FROM returns WHERE status IN ('approved', 'completed');"
            },
            {
              "type": "query",
              "topic": "TOPIC 3: Aggregation (COUNT, SUM, AVG)",
              "question": "Total completed payments amount",
              "answer": "SELECT SUM(amount) AS total_payments FROM payments WHERE status = 'completed';"
            },
            {
              "type": "query",
              "topic": "TOPIC 4: JOINS (Very Important)",
              "question": "Get orders with user details",
              "answer": "SELECT\n+  o.*,\n+  CONCAT_WS(' ', u.first_name, u.last_name) AS full_name,\n+  u.email\n+FROM orders o\n+JOIN users u ON u.id = o.user_id;"
            },
            {
              "type": "query",
              "topic": "TOPIC 4: JOINS (Very Important)",
              "question": "Get order items with product details",
              "answer": "SELECT oi.*, p.name, p.sku, p.price FROM order_items oi JOIN products p ON p.id = oi.product_id;"
            },
            {
              "type": "query",
              "topic": "TOPIC 4: JOINS (Very Important)",
              "question": "Get cart items with product info",
              "answer": "SELECT ci.*, p.name, p.price, p.stock_quantity FROM cart_items ci JOIN products p ON p.id = ci.product_id;"
            },
            {
              "type": "query",
              "topic": "TOPIC 4: JOINS (Very Important)",
              "question": "Get payment info along with order_number",
              "answer": "SELECT pay.*, o.order_number, o.total_amount FROM payments pay JOIN orders o ON o.id = pay.order_id;"
            },
            {
              "type": "query",
              "topic": "TOPIC 4: JOINS (Very Important)",
              "question": "Get return details with user email",
              "answer": "SELECT\n+  r.*,\n+  u.email,\n+  CONCAT_WS(' ', u.first_name, u.last_name) AS full_name\n+FROM returns r\n+JOIN orders o ON o.id = r.order_id\n+JOIN users u ON u.id = o.user_id;"
            },
            {
              "type": "query",
              "topic": "TOPIC 4: JOINS (Very Important)",
              "question": "Get orders with payment status",
              "answer": "SELECT o.order_number, o.total_amount, COALESCE(p.status, 'pending') AS payment_status FROM orders o LEFT JOIN payments p ON p.order_id = o.id;"
            },
            {
              "type": "query",
              "topic": "TOPIC 4: JOINS (Very Important)",
              "question": "Get users who never placed an order",
              "answer": "SELECT u.* FROM users u LEFT JOIN orders o ON o.user_id = u.id WHERE o.id IS NULL;"
            },
            {
              "type": "query",
              "topic": "TOPIC 4: JOINS (Very Important)",
              "question": "Get products never ordered",
              "answer": "SELECT p.* FROM products p LEFT JOIN order_items oi ON oi.product_id = p.id WHERE oi.id IS NULL;"
            },
            {
              "type": "query",
              "topic": "TOPIC 4: JOINS (Very Important)",
              "question": "Get users with more than 2 orders",
              "answer": "SELECT\n+  u.id,\n+  CONCAT_WS(' ', u.first_name, u.last_name) AS full_name,\n+  u.email,\n+  COUNT(o.id) AS order_count\n+FROM users u\n+JOIN orders o ON o.user_id = u.id\n+GROUP BY u.id, u.first_name, u.last_name, u.email\n+HAVING COUNT(o.id) > 2;"
            },
            {
              "type": "query",
              "topic": "TOPIC 4: JOINS (Very Important)",
              "question": "Get most purchased product",
              "answer": "SELECT p.id, p.name, SUM(oi.quantity) AS total_sold FROM products p JOIN order_items oi ON oi.product_id = p.id JOIN orders o ON o.id = oi.order_id WHERE o.status = 'completed' GROUP BY p.id, p.name ORDER BY total_sold DESC LIMIT 1;"
            },
            {
              "type": "query",
              "topic": "TOPIC 4: JOINS (Very Important)",
              "question": "Get users who have items in cart but no orders",
              "answer": "SELECT DISTINCT u.* FROM users u JOIN carts c ON c.user_id = u.id JOIN cart_items ci ON ci.cart_id = c.id LEFT JOIN orders o ON o.user_id = u.id WHERE o.id IS NULL;"
            },
            {
              "type": "query",
              "topic": "TOPIC 4: JOINS (Very Important)",
              "question": "Get total cart value per user",
              "answer": "SELECT\n+  u.id,\n+  CONCAT_WS(' ', u.first_name, u.last_name) AS full_name,\n+  SUM(ci.quantity * p.price) AS cart_value\n+FROM users u\n+JOIN carts c ON c.user_id = u.id\n+JOIN cart_items ci ON ci.cart_id = c.id\n+JOIN products p ON p.id = ci.product_id\n+GROUP BY u.id, u.first_name, u.last_name;"
            },
            {
              "type": "query",
              "topic": "TOPIC 5: Subqueries & CTE",
              "question": "Get products with price greater than average price",
              "answer": "SELECT * FROM products WHERE price > (SELECT AVG(price) FROM products);"
            },
            {
              "type": "query",
              "topic": "TOPIC 5: Subqueries & CTE",
              "question": "Get users whose total order amount > 1000",
              "answer": "SELECT u.* FROM users u WHERE (SELECT SUM(total_amount) FROM orders WHERE user_id = u.id AND status = 'completed') > 1000;"
            },
            {
              "type": "query",
              "topic": "TOPIC 5: Subqueries & CTE",
              "question": "Get products with stock less than average stock",
              "answer": "SELECT * FROM products WHERE stock_quantity < (SELECT AVG(stock_quantity) FROM products);"
            },
            {
              "type": "query",
              "topic": "TOPIC 5: Subqueries & CTE",
              "question": "Get latest order per user",
              "answer": "SELECT o.* FROM orders o WHERE o.created_at = (SELECT MAX(created_at) FROM orders WHERE user_id = o.user_id);"
            },
            {
              "type": "query",
              "topic": "TOPIC 5: Subqueries & CTE",
              "question": "Get users with highest spending",
              "answer": "SELECT u.*, total_spent FROM users u JOIN (SELECT user_id, SUM(total_amount) AS total_spent FROM orders WHERE status = 'completed' GROUP BY user_id) spending ON spending.user_id = u.id ORDER BY total_spent DESC LIMIT 10;"
            },
            {
              "type": "query",
              "topic": "TOPIC 5: Subqueries & CTE",
              "question": "Get product with highest revenue",
              "answer": "SELECT\n+  p.*,\n+  rev.revenue\n+FROM products p\n+JOIN (\n+  SELECT\n+    oi.product_id,\n+    SUM(oi.quantity * oi.price_at_time) AS revenue\n+  FROM order_items oi\n+  JOIN orders o ON o.id = oi.order_id\n+  WHERE o.status = 'completed'\n+  GROUP BY oi.product_id\n+) rev ON rev.product_id = p.id\n+ORDER BY rev.revenue DESC\n+LIMIT 1;"
            },
            {
              "type": "query",
              "topic": "TOPIC 5: Subqueries & CTE",
              "question": "Use CTE to calculate monthly revenue",
              "answer": "WITH monthly_revenue AS (SELECT DATE_TRUNC('month', created_at) AS month, SUM(total_amount) AS revenue FROM orders WHERE status = 'completed' GROUP BY DATE_TRUNC('month', created_at)) SELECT * FROM monthly_revenue ORDER BY month DESC;"
            },
            {
              "type": "query",
              "topic": "TOPIC 5: Subqueries & CTE",
              "question": "Use CTE to get user lifetime value",
              "answer": "WITH user_ltv AS (SELECT user_id, COUNT(*) AS order_count, SUM(total_amount) AS lifetime_value, AVG(total_amount) AS avg_order_value FROM orders WHERE status = 'completed' GROUP BY user_id) SELECT u.*, ltv.* FROM users u JOIN user_ltv ltv ON ltv.user_id = u.id ORDER BY lifetime_value DESC;"
            },
            {
              "type": "query",
              "topic": "TOPIC 5: Subqueries & CTE",
              "question": "Get orders above global average order value",
              "answer": "WITH avg_order AS (SELECT AVG(total_amount) AS avg_value FROM orders) SELECT o.* FROM orders o, avg_order WHERE o.total_amount > avg_order.avg_value;"
            },
            {
              "type": "query",
              "topic": "TOPIC 5: Subqueries & CTE",
              "question": "Get products ordered more than 5 times",
              "answer": "SELECT p.* FROM products p WHERE (SELECT COUNT(DISTINCT order_id) FROM order_items WHERE product_id = p.id) > 5;"
            },
            {
              "type": "query",
              "topic": "TOPIC 5: Subqueries & CTE",
              "question": "Get users who requested returns more than once",
              "answer": "SELECT u.* FROM users u WHERE (SELECT COUNT(*) FROM returns r JOIN orders o ON o.id = r.order_id WHERE o.user_id = u.id) > 1;"
            },
            {
              "type": "query",
              "topic": "TOPIC 6: JSONB Queries",
              "question": "Get all orders shipped to city = 'Austin'",
              "answer": "SELECT * FROM orders WHERE shipping_address->>'city' = 'Austin';"
            },
            {
              "type": "query",
              "topic": "TOPIC 6: JSONB Queries",
              "question": "Get all orders where shipping country = 'USA'",
              "answer": "SELECT * FROM orders WHERE shipping_address->>'country' = 'USA';"
            },
            {
              "type": "query",
              "topic": "TOPIC 6: JSONB Queries",
              "question": "Extract phone number from billing address",
              "answer": "SELECT order_number, billing_address->>'phone' AS phone_number FROM orders;"
            },
            {
              "type": "query",
              "topic": "TOPIC 6: JSONB Queries",
              "question": "Update postal_code inside shipping_address",
              "answer": "UPDATE orders SET shipping_address = jsonb_set(shipping_address, '{postal_code}', '\"75001\"') WHERE id = 123;"
            },
            {
              "type": "query",
              "topic": "TOPIC 6: JSONB Queries",
              "question": "Add new key to billing JSON",
              "answer": "UPDATE orders SET billing_address = billing_address || '{\"verified\": true}'::jsonb WHERE id = 123;"
            },
            {
              "type": "query",
              "topic": "TOPIC 6: JSONB Queries",
              "question": "Find orders where phone starts with +1",
              "answer": "SELECT * FROM orders WHERE shipping_address->>'phone' LIKE '+1%';"
            },
            {
              "type": "query",
              "topic": "TOPIC 6: JSONB Queries",
              "question": "Index JSON field for faster search",
              "answer": "CREATE INDEX idx_orders_shipping_city ON orders ((shipping_address->>'city'));"
            },
            {
              "type": "query",
              "topic": "TOPIC 6: JSONB Queries",
              "question": "Filter orders by state inside JSON",
              "answer": "SELECT * FROM orders WHERE shipping_address->>'state' = 'TX';"
            },
            {
              "type": "query",
              "topic": "TOPIC 7: Window Functions (Advanced)",
              "question": "Rank users by total spending",
              "answer": "SELECT\n+  u.id,\n+  CONCAT_WS(' ', u.first_name, u.last_name) AS full_name,\n+  SUM(o.total_amount) AS total_spent,\n+  RANK() OVER (ORDER BY SUM(o.total_amount) DESC) AS spending_rank\n+FROM users u\n+JOIN orders o ON o.user_id = u.id\n+WHERE o.status = 'completed'\n+GROUP BY u.id, u.first_name, u.last_name;"
            },
            {
              "type": "query",
              "topic": "TOPIC 7: Window Functions (Advanced)",
              "question": "Running total revenue by date",
              "answer": "SELECT DATE(created_at) AS order_date, SUM(total_amount) AS daily_revenue, SUM(SUM(total_amount)) OVER (ORDER BY DATE(created_at)) AS running_total FROM orders WHERE status = 'completed' GROUP BY DATE(created_at);"
            },
            {
              "type": "query",
              "topic": "TOPIC 7: Window Functions (Advanced)",
              "question": "Dense rank products by revenue",
              "answer": "WITH product_revenue AS (\n+  SELECT\n+    oi.product_id,\n+    SUM(oi.quantity * oi.price_at_time) AS revenue\n+  FROM order_items oi\n+  JOIN orders o ON o.id = oi.order_id\n+  WHERE o.status = 'completed'\n+  GROUP BY oi.product_id\n+)\n+SELECT\n+  p.name,\n+  pr.revenue,\n+  DENSE_RANK() OVER (ORDER BY pr.revenue DESC) AS rank\n+FROM product_revenue pr\n+JOIN products p ON p.id = pr.product_id;"
            },
            {
              "type": "query",
              "topic": "TOPIC 7: Window Functions (Advanced)",
              "question": "Find second highest spending user",
              "answer": "WITH ranked_users AS (SELECT u.*, SUM(o.total_amount) AS total_spent, RANK() OVER (ORDER BY SUM(o.total_amount) DESC) AS rank FROM users u JOIN orders o ON o.user_id = u.id WHERE o.status = 'completed' GROUP BY u.id) SELECT * FROM ranked_users WHERE rank = 2;"
            },
            {
              "type": "query",
              "topic": "TOPIC 7: Window Functions (Advanced)",
              "question": "Row number for orders per user",
              "answer": "SELECT user_id, order_number, total_amount, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY created_at) AS order_sequence FROM orders;"
            },
            {
              "type": "query",
              "topic": "TOPIC 7: Window Functions (Advanced)",
              "question": "Moving average revenue (7 days)",
              "answer": "SELECT DATE(created_at) AS order_date, SUM(total_amount) AS daily_revenue, AVG(SUM(total_amount)) OVER (ORDER BY DATE(created_at) ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS moving_avg_7day FROM orders WHERE status = 'completed' GROUP BY DATE(created_at);"
            },
            {
              "type": "query",
              "topic": "TOPIC 7: Window Functions (Advanced)",
              "question": "Cumulative order count",
              "answer": "SELECT DATE(created_at) AS order_date, COUNT(*) AS daily_orders, SUM(COUNT(*)) OVER (ORDER BY DATE(created_at)) AS cumulative_orders FROM orders GROUP BY DATE(created_at);"
            },
            {
              "type": "query",
              "topic": "TOPIC 7: Window Functions (Advanced)",
              "question": "Partition by user and rank orders",
              "answer": "SELECT user_id, order_number, total_amount, RANK() OVER (PARTITION BY user_id ORDER BY total_amount DESC) AS amount_rank FROM orders;"
            },
            {
              "type": "query",
              "topic": "TOPIC 8: Transactions & Concurrency",
              "question": "Deduct stock safely during checkout",
              "answer": "BEGIN; UPDATE products SET stock_quantity = stock_quantity - 2 WHERE id = 101 AND stock_quantity >= 2; INSERT INTO order_items (order_id, product_id, quantity, price_at_time) VALUES (1001, 101, 2, 99.99); COMMIT;"
            },
            {
              "type": "query",
              "topic": "TOPIC 8: Transactions & Concurrency",
              "question": "Reserve stock using transaction",
              "answer": "BEGIN; SELECT stock_quantity FROM products WHERE id = 101 FOR UPDATE; INSERT INTO stock_reservations (product_id, quantity, expires_at) VALUES (101, 3, NOW() + INTERVAL '10 minutes'); UPDATE products SET stock_quantity = stock_quantity - 3 WHERE id = 101; COMMIT;"
            },
            {
              "type": "query",
              "topic": "TOPIC 8: Transactions & Concurrency",
              "question": "Cancel order and restore stock",
              "answer": "BEGIN; UPDATE products p SET stock_quantity = stock_quantity + oi.quantity FROM order_items oi WHERE oi.order_id = 1001 AND oi.product_id = p.id; UPDATE orders SET status = 'cancelled' WHERE id = 1001; COMMIT;"
            },
            {
              "type": "query",
              "topic": "TOPIC 8: Transactions & Concurrency",
              "question": "Handle payment failure rollback",
              "answer": "BEGIN; UPDATE orders SET status = 'processing' WHERE id = 1001; INSERT INTO payments (order_id, amount, status) VALUES (1001, 199.99, 'processing'); -- If payment fails: ROLLBACK; -- Otherwise: COMMIT;"
            },
            {
              "type": "query",
              "topic": "TOPIC 8: Transactions & Concurrency",
              "question": "Prevent overselling using FOR UPDATE",
              "answer": "BEGIN; SELECT stock_quantity FROM products WHERE id = 101 FOR UPDATE; UPDATE products SET stock_quantity = stock_quantity - 5 WHERE id = 101 AND stock_quantity >= 5; COMMIT;"
            },
            {
              "type": "query",
              "topic": "TOPIC 8: Transactions & Concurrency",
              "question": "Delete expired stock reservations",
              "answer": "BEGIN; WITH expired AS (DELETE FROM stock_reservations WHERE expires_at < NOW() RETURNING product_id, quantity) UPDATE products p SET stock_quantity = stock_quantity + exp.quantity FROM expired exp WHERE p.id = exp.product_id; COMMIT;"
            },
            {
              "type": "query",
              "topic": "TOPIC 9: Index Optimization",
              "question": "Check execution plan of order query",
              "answer": "EXPLAIN ANALYZE SELECT * FROM orders WHERE user_id = 123 AND status = 'processing';"
            },
            {
              "type": "query",
              "topic": "TOPIC 9: Index Optimization",
              "question": "Add composite index on (user_id, status)",
              "answer": "CREATE INDEX idx_orders_user_status ON orders(user_id, status);"
            },
            {
              "type": "query",
              "topic": "TOPIC 9: Index Optimization",
              "question": "Optimize product search by category + price",
              "answer": "CREATE INDEX idx_products_category_price ON products(category, price);"
            },
            {
              "type": "query",
              "topic": "TOPIC 9: Index Optimization",
              "question": "Create partial index on completed orders",
              "answer": "CREATE INDEX idx_orders_completed ON orders(created_at) WHERE status = 'completed';"
            },
            {
              "type": "query",
              "topic": "TOPIC 9: Index Optimization",
              "question": "Index JSON city field",
              "answer": "CREATE INDEX idx_orders_shipping_city ON orders ((shipping_address->>'city'));"
            },
            {
              "type": "query",
              "topic": "TOPIC 9: Index Optimization",
              "question": "Create covering index for order listing",
              "answer": "CREATE INDEX idx_orders_covering ON orders(user_id, created_at) INCLUDE (order_number, total_amount, status);"
            },
            {
              "type": "query",
              "topic": "TOPIC 9: Index Optimization",
              "question": "Compare query with and without index",
              "answer": "-- Without: EXPLAIN ANALYZE SELECT * FROM products WHERE category = 'Electronics'; -- Create index: CREATE INDEX idx_products_category ON products(category); -- With: EXPLAIN ANALYZE SELECT * FROM products WHERE category = 'Electronics';"
            },
            {
              "type": "query",
              "topic": "TOPIC 10: Data Modification (UPDATE, DELETE, INSERT)",
              "question": "Update product price by 10%",
              "answer": "UPDATE products SET price = price * 1.10 WHERE category = 'Electronics';"
            },
            {
              "type": "query",
              "topic": "TOPIC 10: Data Modification (UPDATE, DELETE, INSERT)",
              "question": "Reduce stock after purchase",
              "answer": "UPDATE products SET stock_quantity = stock_quantity - 2 WHERE id = 101;"
            },
            {
              "type": "query",
              "topic": "TOPIC 10: Data Modification (UPDATE, DELETE, INSERT)",
              "question": "Mark product as out of stock (soft delete workaround)",
              "answer": "UPDATE products SET stock_quantity = 0 WHERE id = 101;"
            },
            {
              "type": "query",
              "topic": "TOPIC 10: Data Modification (UPDATE, DELETE, INSERT)",
              "question": "Change user role",
              "answer": "UPDATE users SET role = 'admin' WHERE id = 5;"
            },
            {
              "type": "query",
              "topic": "TOPIC 10: Data Modification (UPDATE, DELETE, INSERT)",
              "question": "Bulk insert products",
              "answer": "INSERT INTO products (name, sku, price, stock_quantity, category) VALUES ('Product A', 'SKU-001', 99.99, 50, 'Electronics'), ('Product B', 'SKU-002', 149.99, 30, 'Electronics'), ('Product C', 'SKU-003', 79.99, 100, 'Books');"
            },
            {
              "type": "query",
              "topic": "TOPIC 10: Data Modification (UPDATE, DELETE, INSERT)",
              "question": "Delete abandoned carts (30 days old)",
              "answer": "DELETE FROM carts WHERE updated_at < NOW() - INTERVAL '30 days';"
            },
            {
              "type": "query",
              "topic": "TOPIC 10: Data Modification (UPDATE, DELETE, INSERT)",
              "question": "Refund an order",
              "answer": "BEGIN;\n+\n+UPDATE orders\n+SET status = 'refunded'\n+WHERE id = 1001;\n+\n+INSERT INTO payments (order_id, amount, status, payment_method)\n+VALUES (1001, 199.99, 'refunded', 'refund');\n+\n+COMMIT;"
            },
            {
              "type": "query",
              "topic": "TOPIC 10: Data Modification (UPDATE, DELETE, INSERT)",
              "question": "Change order status from processing → shipped",
              "answer": "UPDATE orders SET status = 'shipped' WHERE id = 1001 AND status = 'processing';"
            },
            {
              "type": "query",
              "topic": "TOPIC 10: Data Modification (UPDATE, DELETE, INSERT)",
              "question": "Expire stock reservations",
              "answer": "DELETE FROM stock_reservations WHERE expires_at < NOW();"
            },
            {
              "type": "query",
              "topic": "TOPIC 10: Data Modification (UPDATE, DELETE, INSERT)",
              "question": "Update payment status to completed",
              "answer": "UPDATE payments SET status = 'completed' WHERE id = 501 AND status = 'processing';"
            },
            {
              "type": "query",
              "topic": "TOPIC 11: Partitioning (Advanced Production)",
              "question": "Partition orders by created_at (monthly)",
              "answer": "CREATE TABLE orders (id SERIAL, order_number VARCHAR(50), user_id INT, total_amount DECIMAL(10,2), status VARCHAR(20), created_at TIMESTAMP NOT NULL, PRIMARY KEY (id, created_at)) PARTITION BY RANGE (created_at);"
            },
            {
              "type": "query",
              "topic": "TOPIC 11: Partitioning (Advanced Production)",
              "question": "Partition payments by status",
              "answer": "CREATE TABLE payments (id SERIAL, order_id INT, amount DECIMAL(10,2), status VARCHAR(20) NOT NULL, created_at TIMESTAMP, PRIMARY KEY (id, status)) PARTITION BY LIST (status);"
            },
            {
              "type": "query",
              "topic": "TOPIC 11: Partitioning (Advanced Production)",
              "question": "Partition stock_reservations by expires_at",
              "answer": "CREATE TABLE stock_reservations (id SERIAL, product_id INT, quantity INT, expires_at TIMESTAMP NOT NULL, PRIMARY KEY (id, expires_at)) PARTITION BY RANGE (expires_at);"
            },
            {
              "type": "query",
              "topic": "TOPIC 11: Partitioning (Advanced Production)",
              "question": "Create yearly partition for orders",
              "answer": "CREATE TABLE orders_2024 PARTITION OF orders FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');"
            },
            {
              "type": "query",
              "topic": "TOPIC 11: Partitioning (Advanced Production)",
              "question": "Move old orders to archive partition",
              "answer": "CREATE TABLE orders_archive PARTITION OF orders FOR VALUES FROM ('2020-01-01') TO ('2023-01-01');"
            },
            {
              "type": "query",
              "topic": "TOPIC 11: Partitioning (Advanced Production)",
              "question": "Query only current month partition",
              "answer": "SELECT * FROM orders WHERE created_at >= '2024-12-01' AND created_at < '2025-01-01';"
            },
            {
              "type": "query",
              "topic": "TOPIC 11: Partitioning (Advanced Production)",
              "question": "Compare performance with partition vs no partition",
              "answer": "EXPLAIN ANALYZE SELECT * FROM orders WHERE created_at >= '2024-12-01' AND created_at < '2025-01-01';"
            },
            {
              "type": "query",
              "topic": "TOPIC 11: Partitioning (Advanced Production)",
              "question": "Create partitioned index",
              "answer": "CREATE INDEX idx_orders_user ON orders(user_id);"
            },
            {
              "type": "query",
              "topic": "TOPIC 11: Partitioning (Advanced Production)",
              "question": "Attach new partition",
              "answer": "CREATE TABLE orders_2026 (LIKE orders INCLUDING ALL); ALTER TABLE orders ATTACH PARTITION orders_2026 FOR VALUES FROM ('2026-01-01') TO ('2027-01-01');"
            },
            {
              "type": "query",
              "topic": "TOPIC 11: Partitioning (Advanced Production)",
              "question": "Detach old partition",
              "answer": "ALTER TABLE orders DETACH PARTITION orders_2020;"
            },
            {
              "type": "query",
              "topic": "TOPIC 12: Advanced Real Business Queries",
              "question": "Monthly revenue report",
              "answer": "SELECT DATE_TRUNC('month', created_at) AS month, COUNT(*) AS total_orders, SUM(total_amount) AS total_revenue, AVG(total_amount) AS avg_order_value FROM orders WHERE status = 'completed' GROUP BY DATE_TRUNC('month', created_at) ORDER BY month DESC;"
            },
            {
              "type": "query",
              "topic": "TOPIC 12: Advanced Real Business Queries",
              "question": "Top 5 customers of all time",
              "answer": "SELECT\n+  u.id,\n+  CONCAT_WS(' ', u.first_name, u.last_name) AS full_name,\n+  u.email,\n+  COUNT(o.id) AS order_count,\n+  SUM(o.total_amount) AS lifetime_value\n+FROM users u\n+JOIN orders o ON o.user_id = u.id\n+WHERE o.status = 'completed'\n+GROUP BY u.id, u.first_name, u.last_name, u.email\n+ORDER BY lifetime_value DESC\n+LIMIT 5;"
            },
            {
              "type": "query",
              "topic": "TOPIC 12: Advanced Real Business Queries",
              "question": "Daily sales breakdown",
              "answer": "SELECT DATE(created_at) AS sale_date, COUNT(*) AS orders, SUM(total_amount) AS revenue, AVG(total_amount) AS avg_order FROM orders WHERE status = 'completed' AND created_at >= CURRENT_DATE - INTERVAL '30 days' GROUP BY DATE(created_at) ORDER BY sale_date DESC;"
            },
            {
              "type": "query",
              "topic": "TOPIC 12: Advanced Real Business Queries",
              "question": "Conversion rate (cart → order)",
              "answer": "WITH cart_users AS (SELECT DISTINCT user_id FROM carts), order_users AS (SELECT DISTINCT user_id FROM orders) SELECT COUNT(DISTINCT cu.user_id) AS users_with_carts, COUNT(DISTINCT ou.user_id) AS users_with_orders, ROUND(COUNT(DISTINCT ou.user_id)::DECIMAL / NULLIF(COUNT(DISTINCT cu.user_id), 0) * 100, 2) AS conversion_rate_percent FROM cart_users cu LEFT JOIN order_users ou ON ou.user_id = cu.user_id;"
            },
            {
              "type": "query",
              "topic": "TOPIC 12: Advanced Real Business Queries",
              "question": "Average delivery time",
              "answer": "SELECT AVG(EXTRACT(EPOCH FROM (updated_at - created_at))/86400) AS avg_delivery_days FROM orders WHERE status = 'delivered';"
            },
            {
              "type": "query",
              "topic": "TOPIC 12: Advanced Real Business Queries",
              "question": "Return percentage",
              "answer": "SELECT COUNT(DISTINCT o.id) AS total_completed_orders, COUNT(DISTINCT r.order_id) AS returned_orders, ROUND(COUNT(DISTINCT r.order_id)::DECIMAL / NULLIF(COUNT(DISTINCT o.id), 0) * 100, 2) AS return_rate_percent FROM orders o LEFT JOIN returns r ON r.order_id = o.id WHERE o.status = 'completed';"
            },
            {
              "type": "query",
              "topic": "TOPIC 12: Advanced Real Business Queries",
              "question": "Most refunded product",
              "answer": "SELECT p.id, p.name, p.sku, COUNT(r.id) AS return_count, SUM(r.refund_amount) AS total_refunds FROM products p JOIN order_items oi ON oi.product_id = p.id JOIN returns r ON r.order_id = oi.order_id GROUP BY p.id, p.name, p.sku ORDER BY return_count DESC LIMIT 1;"
            },
            {
              "type": "query",
              "topic": "TOPIC 12: Advanced Real Business Queries",
              "question": "Stock turnover rate",
              "answer": "WITH sold_quantities AS (SELECT product_id, SUM(quantity) AS total_sold FROM order_items oi JOIN orders o ON o.id = oi.order_id WHERE o.status = 'completed' AND o.created_at >= NOW() - INTERVAL '30 days' GROUP BY product_id) SELECT p.id, p.name, p.stock_quantity AS current_stock, COALESCE(sq.total_sold, 0) AS sold_last_30_days, ROUND(COALESCE(sq.total_sold, 0)::DECIMAL / NULLIF(p.stock_quantity, 0), 2) AS turnover_ratio FROM products p LEFT JOIN sold_quantities sq ON sq.product_id = p.id ORDER BY turnover_ratio DESC;"
            },
            {
              "type": "query",
              "topic": "TOPIC 12: Advanced Real Business Queries",
              "question": "Revenue by category",
              "answer": "SELECT\n+  p.category,\n+  COUNT(DISTINCT o.id) AS order_count,\n+  SUM(oi.quantity * oi.price_at_time) AS category_revenue\n+FROM products p\n+JOIN order_items oi ON oi.product_id = p.id\n+JOIN orders o ON o.id = oi.order_id\n+WHERE o.status = 'completed'\n+GROUP BY p.category\n+ORDER BY category_revenue DESC;"
            },
            {
              "type": "query",
              "topic": "TOPIC 12: Advanced Real Business Queries",
              "question": "Revenue by payment method",
              "answer": "SELECT payment_method, COUNT(*) AS order_count, SUM(total_amount) AS total_revenue, ROUND(AVG(total_amount), 2) AS avg_order_value FROM orders WHERE status = 'completed' GROUP BY payment_method ORDER BY total_revenue DESC;"
            },
            {
              "type": "query",
              "topic": "TOPIC 12: Advanced Real Business Queries",
              "question": "Active users in last 30 days",
              "answer": "SELECT COUNT(DISTINCT user_id) AS active_users FROM (SELECT user_id FROM orders WHERE created_at >= NOW() - INTERVAL '30 days' UNION SELECT user_id FROM carts WHERE updated_at >= NOW() - INTERVAL '30 days') active;"
            },
            {
              "type": "query",
              "topic": "TOPIC 12: Advanced Real Business Queries",
              "question": "Cart abandonment list",
              "answer": "SELECT\n+  u.id,\n+  CONCAT_WS(' ', u.first_name, u.last_name) AS full_name,\n+  u.email,\n+  c.created_at AS cart_created,\n+  COUNT(ci.id) AS items_in_cart,\n+  SUM(ci.quantity * p.price) AS cart_value\n+FROM users u\n+JOIN carts c ON c.user_id = u.id\n+JOIN cart_items ci ON ci.cart_id = c.id\n+JOIN products p ON p.id = ci.product_id\n+LEFT JOIN orders o ON o.user_id = u.id AND o.created_at > c.created_at\n+WHERE o.id IS NULL\n+  AND c.created_at >= NOW() - INTERVAL '7 days'\n+GROUP BY u.id, u.first_name, u.last_name, u.email, c.created_at\n+HAVING SUM(ci.quantity * p.price) > 50\n+ORDER BY cart_value DESC;"
            }
          ]
        },
        {
          "id": "ecommerce-query-patterns",
          "title": "All Query Types in One Scenario",
          "description": "Practice filtering, joins, aggregation, CTEs, windows, and set operations on one e-commerce dataset.",
          "explanation": "Interviewers usually test progression from simple WHERE clauses to production reports. Build queries at correct grain first, then aggregate, then rank or compare periods.",
          "code": "-- 1) Daily completed revenue\nSELECT DATE(o.created_at) AS order_day,\n       SUM(oi.quantity * oi.price_at_time) AS revenue\nFROM orders o\nJOIN order_items oi ON oi.order_id = o.id\nWHERE o.status = 'completed'\nGROUP BY DATE(o.created_at)\nORDER BY order_day DESC;\n\n-- 2) Users with at least 3 completed orders\nSELECT o.user_id, COUNT(*) AS completed_orders\nFROM orders o\nWHERE o.status = 'completed'\nGROUP BY o.user_id\nHAVING COUNT(*) >= 3;\n\n-- 3) Top product per category\nWITH product_sales AS (\n  SELECT p.category, p.id AS product_id, SUM(oi.quantity) AS units\n  FROM products p\n  JOIN order_items oi ON oi.product_id = p.id\n  JOIN orders o ON o.id = oi.order_id\n  WHERE o.status = 'completed'\n  GROUP BY p.category, p.id\n)\nSELECT category, product_id, units\nFROM (\n  SELECT *, ROW_NUMBER() OVER (PARTITION BY category ORDER BY units DESC) AS rn\n  FROM product_sales\n) ranked\nWHERE rn = 1;",
          "example": "-- Users with at least one completed order\nSELECT u.id, u.email\nFROM users u\nWHERE EXISTS (\n  SELECT 1\n  FROM orders o\n  WHERE o.user_id = u.id\n    AND o.status = 'completed'\n);\n\n-- Categories sold this month but not previous month\nSELECT DISTINCT p.category\nFROM orders o\nJOIN order_items oi ON oi.order_id = o.id\nJOIN products p ON p.id = oi.product_id\nWHERE o.created_at >= date_trunc('month', now())\nEXCEPT\nSELECT DISTINCT p.category\nFROM orders o\nJOIN order_items oi ON oi.order_id = o.id\nJOIN products p ON p.id = oi.product_id\nWHERE o.created_at >= date_trunc('month', now()) - INTERVAL '1 month'\n  AND o.created_at < date_trunc('month', now());",
          "useCase": "Revenue dashboards, cohort analytics, top-N reporting, and interviewer-style SQL progression.",
          "category": "Advanced SQL (E-commerce Scenario)",
          "interviewQuestions": [
            {
              "question": "When should HAVING be used instead of WHERE?",
              "answer": "WHERE filters rows before aggregation; HAVING filters groups after aggregation."
            },
            {
              "question": "Why is EXISTS often preferred over IN for existence checks?",
              "answer": "EXISTS can stop on first match and avoids some NULL pitfalls common with IN/NOT IN patterns."
            },
            {
              "question": "How do you avoid double counting in revenue queries?",
              "answer": "Aggregate at the correct grain and validate join cardinality before summing."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Write monthly revenue by payment_method for completed orders."
            },
            {
              "type": "debug",
              "question": "Fix a query that overcounts due to joining payments and order_items naively."
            },
            {
              "type": "scenario",
              "question": "Get top 3 products per category in the last 30 days."
            }
          ],
          "programExercises": [
            {
              "question": "Running total spend per user",
              "code": "SELECT user_id, created_at, SUM(total_amount) OVER (PARTITION BY user_id ORDER BY created_at) AS running_spend FROM orders;",
              "output": "Each order row with cumulative spend for that user."
            }
          ]
        },
        {
          "id": "join-index-partition-deep-dive",
          "title": "Joins + Indexes + Partitioning Deep Dive",
          "description": "Master join semantics, index design, and partition strategy for large PostgreSQL workloads.",
          "explanation": "Most production performance issues come from data shape and access path mismatch. Choose join types intentionally, index for filter + sort patterns, and partition only when table growth justifies operational complexity.",
          "code": "-- CANONICAL E-COMMERCE SCHEMA\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  first_name VARCHAR(100) NOT NULL,\n  last_name VARCHAR(100) NOT NULL,\n  email VARCHAR(255) UNIQUE NOT NULL,\n  role VARCHAR(20) NOT NULL DEFAULT 'customer',\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE products (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  sku VARCHAR(100) UNIQUE NOT NULL,\n  price DECIMAL(10,2) NOT NULL,\n  stock_quantity INT NOT NULL DEFAULT 0,\n  category VARCHAR(100),\n  image_url TEXT,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE orders (\n  id SERIAL PRIMARY KEY,\n  order_number VARCHAR(50) UNIQUE NOT NULL,\n  user_id INT NOT NULL REFERENCES users(id),\n  total_amount DECIMAL(10,2) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  payment_method VARCHAR(20),\n  shipping_address JSONB,\n  billing_address JSONB,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE order_items (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  product_id INT NOT NULL REFERENCES products(id),\n  quantity INT NOT NULL,\n  price_at_time DECIMAL(10,2) NOT NULL\n);\n\nCREATE TABLE payments (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  amount DECIMAL(10,2) NOT NULL,\n  payment_method VARCHAR(20) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  transaction_id VARCHAR(100),\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Composite and partial indexes for common access paths\nCREATE INDEX idx_orders_user_created ON orders(user_id, created_at DESC);\nCREATE INDEX idx_orders_completed_recent ON orders(created_at DESC) WHERE status = 'completed';\n\n-- Example partitioned table by month\nCREATE TABLE orders_part (\n  id BIGINT,\n  user_id BIGINT,\n  status TEXT,\n  created_at TIMESTAMP NOT NULL\n) PARTITION BY RANGE (created_at);\n\nCREATE TABLE orders_part_2026_01 PARTITION OF orders_part\nFOR VALUES FROM ('2026-01-01') TO ('2026-02-01');\n\nCREATE TABLE orders_part_2026_02 PARTITION OF orders_part\nFOR VALUES FROM ('2026-02-01') TO ('2026-03-01');",
          "example": "-- Partition pruning check\nEXPLAIN ANALYZE\nSELECT COUNT(*)\nFROM orders_part\nWHERE created_at >= '2026-02-01'\n  AND created_at < '2026-03-01';\n\n-- Join with selective predicate\nEXPLAIN ANALYZE\nSELECT o.id, u.email\nFROM orders o\nJOIN users u ON u.id = o.user_id\nWHERE o.status = 'completed'\n  AND o.created_at >= NOW() - INTERVAL '7 days';",
          "useCase": "High-volume order systems, low-latency dashboards, retention windows, and cost-aware performance tuning.",
          "category": "Performance & Optimization",
          "interviewQuestions": [
            {
              "question": "Why does composite index column order matter?",
              "answer": "PostgreSQL uses leftmost prefix rules; `(a,b)` helps queries on `a` and `a,b`, not `b` alone efficiently."
            },
            {
              "question": "When is partial index better than full index?",
              "answer": "When most queries target a subset like `status = 'completed'`, partial index reduces size and write overhead."
            },
            {
              "question": "What is partition pruning?",
              "answer": "Planner excludes irrelevant partitions when predicates constrain the partition key."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Design an index for `WHERE user_id = ? ORDER BY created_at DESC LIMIT 20`."
            },
            {
              "type": "scenario",
              "question": "Choose between BRIN and B-tree for very large append-only table and justify."
            },
            {
              "type": "debug",
              "question": "A partitioned table scans all partitions; identify likely predicate mistakes."
            }
          ],
          "programExercises": [
            {
              "question": "Anti-join users with no orders",
              "code": "SELECT u.id FROM users u LEFT JOIN orders o ON o.user_id = u.id WHERE o.id IS NULL;",
              "output": "Users who have not placed any order."
            }
          ]
        },
        {
          "id": "select",
          "title": "SELECT Queries",
          "description": "Retrieve data from database tables with filtering, sorting, and limiting results.",
          "code": "-- CANONICAL E-COMMERCE SCHEMA\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  first_name VARCHAR(100) NOT NULL,\n  last_name VARCHAR(100) NOT NULL,\n  email VARCHAR(255) UNIQUE NOT NULL,\n  role VARCHAR(20) NOT NULL DEFAULT 'customer',\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE products (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  sku VARCHAR(100) UNIQUE NOT NULL,\n  price DECIMAL(10,2) NOT NULL,\n  stock_quantity INT NOT NULL DEFAULT 0,\n  category VARCHAR(100),\n  image_url TEXT,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE orders (\n  id SERIAL PRIMARY KEY,\n  order_number VARCHAR(50) UNIQUE NOT NULL,\n  user_id INT NOT NULL REFERENCES users(id),\n  total_amount DECIMAL(10,2) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  payment_method VARCHAR(20),\n  shipping_address JSONB,\n  billing_address JSONB,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE order_items (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  product_id INT NOT NULL REFERENCES products(id),\n  quantity INT NOT NULL,\n  price_at_time DECIMAL(10,2) NOT NULL\n);\n\nCREATE TABLE payments (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  amount DECIMAL(10,2) NOT NULL,\n  payment_method VARCHAR(20) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  transaction_id VARCHAR(100),\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Basic SELECT\nSELECT * FROM users;\n\n-- Specific columns\nSELECT first_name, last_name, email FROM users;\n\n-- WHERE clause\nSELECT * FROM products \nWHERE price > 100 AND stock_quantity > 0;\n\n-- ORDER BY\nSELECT * FROM orders \nORDER BY created_at DESC;\n\n-- LIMIT and OFFSET\nSELECT * FROM orders \nORDER BY created_at DESC \nLIMIT 10 OFFSET 20;\n\n-- DISTINCT\nSELECT DISTINCT category FROM products;",
          "example": "-- Multiple conditions\nSELECT * FROM users \nWHERE age >= 18 \n  AND city = 'New York' \n  AND status = 'active';\n\n-- LIKE pattern matching\nSELECT * FROM users \nWHERE email LIKE '%@gmail.com';\n\n-- IN operator\nSELECT * FROM orders \nWHERE status IN ('pending', 'processing', 'shipped');\n\n-- BETWEEN\nSELECT * FROM products \nWHERE price BETWEEN 50 AND 100;",
          "useCase": "Data retrieval, filtering, pagination, searching",
          "category": "Basic Queries"
        },
        {
          "id": "insert-update-delete",
          "title": "INSERT, UPDATE, DELETE",
          "description": "Modify data in database tables - add, update, or remove records.",
          "code": "-- CANONICAL E-COMMERCE SCHEMA\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  first_name VARCHAR(100) NOT NULL,\n  last_name VARCHAR(100) NOT NULL,\n  email VARCHAR(255) UNIQUE NOT NULL,\n  role VARCHAR(20) NOT NULL DEFAULT 'customer',\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE products (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  sku VARCHAR(100) UNIQUE NOT NULL,\n  price DECIMAL(10,2) NOT NULL,\n  stock_quantity INT NOT NULL DEFAULT 0,\n  category VARCHAR(100),\n  image_url TEXT,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE orders (\n  id SERIAL PRIMARY KEY,\n  order_number VARCHAR(50) UNIQUE NOT NULL,\n  user_id INT NOT NULL REFERENCES users(id),\n  total_amount DECIMAL(10,2) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  payment_method VARCHAR(20),\n  shipping_address JSONB,\n  billing_address JSONB,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE order_items (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  product_id INT NOT NULL REFERENCES products(id),\n  quantity INT NOT NULL,\n  price_at_time DECIMAL(10,2) NOT NULL\n);\n\nCREATE TABLE payments (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  amount DECIMAL(10,2) NOT NULL,\n  payment_method VARCHAR(20) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  transaction_id VARCHAR(100),\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\n-- INSERT single row\nINSERT INTO users (first_name, last_name, email) \nVALUES ('John', 'Doe', 'john@example.com');\n\n-- INSERT multiple rows\nINSERT INTO products (name, sku, price, stock_quantity, category) \nVALUES \n  ('Product A', 'SKU-A', 99.99, 50, 'Electronics'),\n  ('Product B', 'SKU-B', 149.99, 30, 'Electronics'),\n  ('Product C', 'SKU-C', 79.99, 100, 'Books');\n\n-- UPDATE\nUPDATE users \nSET first_name = 'Jane', updated_at = NOW() \nWHERE id = 1;\n\n-- DELETE\nDELETE FROM orders \nWHERE status = 'cancelled' AND created_at < NOW() - INTERVAL '30 days';\n\n-- RETURNING clause\nINSERT INTO users (first_name, last_name, email) \nVALUES ('Jane', 'Smith', 'jane@example.com') \nRETURNING id, created_at;",
          "example": "-- UPDATE with subquery\nUPDATE products \nSET category_id = (\n  SELECT id FROM categories WHERE name = 'Electronics'\n)\nWHERE name LIKE '%Phone%';\n\n-- DELETE with JOIN\nDELETE FROM order_items \nWHERE order_id IN (\n  SELECT id FROM orders WHERE status = 'cancelled'\n);\n\n-- INSERT from SELECT\nINSERT INTO archived_users \nSELECT * FROM users \nWHERE last_login < NOW() - INTERVAL '1 year';",
          "useCase": "Data manipulation, CRUD operations, bulk updates, archiving",
          "category": "Basic Queries"
        },
        {
          "id": "aggregations",
          "title": "Aggregate Functions",
          "description": "Perform calculations on sets of rows: COUNT, SUM, AVG, MIN, MAX.",
          "code": "-- CANONICAL E-COMMERCE SCHEMA\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  first_name VARCHAR(100) NOT NULL,\n  last_name VARCHAR(100) NOT NULL,\n  email VARCHAR(255) UNIQUE NOT NULL,\n  role VARCHAR(20) NOT NULL DEFAULT 'customer',\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE products (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  sku VARCHAR(100) UNIQUE NOT NULL,\n  price DECIMAL(10,2) NOT NULL,\n  stock_quantity INT NOT NULL DEFAULT 0,\n  category VARCHAR(100),\n  image_url TEXT,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE orders (\n  id SERIAL PRIMARY KEY,\n  order_number VARCHAR(50) UNIQUE NOT NULL,\n  user_id INT NOT NULL REFERENCES users(id),\n  total_amount DECIMAL(10,2) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  payment_method VARCHAR(20),\n  shipping_address JSONB,\n  billing_address JSONB,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE order_items (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  product_id INT NOT NULL REFERENCES products(id),\n  quantity INT NOT NULL,\n  price_at_time DECIMAL(10,2) NOT NULL\n);\n\nCREATE TABLE payments (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  amount DECIMAL(10,2) NOT NULL,\n  payment_method VARCHAR(20) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  transaction_id VARCHAR(100),\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\n-- COUNT\nSELECT COUNT(*) FROM users;\nSELECT COUNT(DISTINCT role) FROM users;\n\n-- SUM\nSELECT SUM(total_amount) FROM orders;\n\n-- AVG\nSELECT AVG(price) FROM products;\n\n-- MIN and MAX\nSELECT MIN(price), MAX(price) FROM products;\n\n-- GROUP BY\nSELECT category, COUNT(*), AVG(price) \nFROM products \nGROUP BY category;\n\n-- HAVING (filter groups)\nSELECT category, AVG(price) as avg_price \nFROM products \nGROUP BY category \nHAVING AVG(price) > 100;",
          "example": "-- Multiple aggregations\nSELECT \n  category,\n  COUNT(*) as product_count,\n  SUM(stock) as total_stock,\n  AVG(price) as avg_price,\n  MIN(price) as min_price,\n  MAX(price) as max_price\nFROM products \nGROUP BY category \nORDER BY product_count DESC;\n\n-- GROUP BY multiple columns\nSELECT \n  DATE(created_at) as date,\n  status,\n  COUNT(*) as order_count,\n  SUM(total) as revenue\nFROM orders \nWHERE created_at >= NOW() - INTERVAL '7 days'\nGROUP BY DATE(created_at), status;",
          "useCase": "Reports, analytics, statistics, dashboards, summaries",
          "category": "Basic Queries"
        },
        {
          "id": "joins",
          "title": "JOIN Types",
          "description": "Combine rows from multiple tables based on related columns.",
          "code": "-- CANONICAL E-COMMERCE SCHEMA\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  first_name VARCHAR(100) NOT NULL,\n  last_name VARCHAR(100) NOT NULL,\n  email VARCHAR(255) UNIQUE NOT NULL,\n  role VARCHAR(20) NOT NULL DEFAULT 'customer',\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE products (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  sku VARCHAR(100) UNIQUE NOT NULL,\n  price DECIMAL(10,2) NOT NULL,\n  stock_quantity INT NOT NULL DEFAULT 0,\n  category VARCHAR(100),\n  image_url TEXT,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE orders (\n  id SERIAL PRIMARY KEY,\n  order_number VARCHAR(50) UNIQUE NOT NULL,\n  user_id INT NOT NULL REFERENCES users(id),\n  total_amount DECIMAL(10,2) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  payment_method VARCHAR(20),\n  shipping_address JSONB,\n  billing_address JSONB,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE order_items (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  product_id INT NOT NULL REFERENCES products(id),\n  quantity INT NOT NULL,\n  price_at_time DECIMAL(10,2) NOT NULL\n);\n\nCREATE TABLE payments (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  amount DECIMAL(10,2) NOT NULL,\n  payment_method VARCHAR(20) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  transaction_id VARCHAR(100),\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\n-- INNER JOIN (matching rows only)\nSELECT u.first_name, u.last_name, o.total_amount, o.status \nFROM users u \nINNER JOIN orders o ON u.id = o.user_id;\n\n-- LEFT JOIN (all from left table)\nSELECT u.first_name, u.last_name, COUNT(o.id) as order_count \nFROM users u \nLEFT JOIN orders o ON u.id = o.user_id \nGROUP BY u.id, u.first_name, u.last_name;\n\n-- RIGHT JOIN (all from right table)\nSELECT u.first_name, u.last_name, o.total_amount \nFROM users u \nRIGHT JOIN orders o ON u.id = o.user_id;\n\n-- FULL OUTER JOIN (all rows from both)\nSELECT * FROM users u \nFULL OUTER JOIN orders o ON u.id = o.user_id;",
          "example": "-- Multiple joins\nSELECT \n  u.name as user_name,\n  o.id as order_id,\n  p.name as product_name,\n  oi.quantity,\n  oi.price_at_time\nFROM users u\nINNER JOIN orders o ON u.id = o.user_id\nINNER JOIN order_items oi ON o.id = oi.order_id\nINNER JOIN products p ON oi.product_id = p.id\nWHERE o.status = 'completed';\n\n-- Self join\nSELECT \n  e.name as employee,\n  m.name as manager\nFROM employees e\nLEFT JOIN employees m ON e.manager_id = m.id;",
          "useCase": "Combining related data, complex queries, reporting, data analysis",
          "category": "Joins & Relationships"
        },
        {
          "id": "subqueries",
          "title": "Subqueries",
          "description": "Nested queries used within SELECT, FROM, WHERE, or HAVING clauses.",
          "code": "-- CANONICAL E-COMMERCE SCHEMA\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  first_name VARCHAR(100) NOT NULL,\n  last_name VARCHAR(100) NOT NULL,\n  email VARCHAR(255) UNIQUE NOT NULL,\n  role VARCHAR(20) NOT NULL DEFAULT 'customer',\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE products (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  sku VARCHAR(100) UNIQUE NOT NULL,\n  price DECIMAL(10,2) NOT NULL,\n  stock_quantity INT NOT NULL DEFAULT 0,\n  category VARCHAR(100),\n  image_url TEXT,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE orders (\n  id SERIAL PRIMARY KEY,\n  order_number VARCHAR(50) UNIQUE NOT NULL,\n  user_id INT NOT NULL REFERENCES users(id),\n  total_amount DECIMAL(10,2) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  payment_method VARCHAR(20),\n  shipping_address JSONB,\n  billing_address JSONB,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE order_items (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  product_id INT NOT NULL REFERENCES products(id),\n  quantity INT NOT NULL,\n  price_at_time DECIMAL(10,2) NOT NULL\n);\n\nCREATE TABLE payments (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  amount DECIMAL(10,2) NOT NULL,\n  payment_method VARCHAR(20) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  transaction_id VARCHAR(100),\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Subquery in WHERE\nSELECT * FROM products \nWHERE price > (SELECT AVG(price) FROM products);\n\n-- Subquery in SELECT\nSELECT \n  name,\n  price,\n  (SELECT AVG(price) FROM products) as avg_price,\n  price - (SELECT AVG(price) FROM products) as diff\nFROM products;\n\n-- Subquery in FROM\nSELECT category, avg_price \nFROM (\n  SELECT category, AVG(price) as avg_price \n  FROM products \n  GROUP BY category\n) as category_averages \nWHERE avg_price > 100;\n\n-- EXISTS\nSELECT * FROM users \nWHERE EXISTS (\n  SELECT 1 FROM orders \n  WHERE orders.user_id = users.id\n);",
          "example": "-- IN with subquery\nSELECT * FROM products \nWHERE category_id IN (\n  SELECT id FROM categories WHERE active = true\n);\n\n-- NOT IN\nSELECT * FROM users \nWHERE id NOT IN (\n  SELECT DISTINCT user_id FROM orders\n);\n\n-- Correlated subquery\nSELECT \n  p.name,\n  p.price,\n  (SELECT COUNT(*) FROM reviews r WHERE r.product_id = p.id) as review_count\nFROM products p;",
          "useCase": "Complex filtering, derived tables, conditional logic, data validation",
          "category": "Joins & Relationships"
        },
        {
          "id": "indexes",
          "title": "Indexes",
          "description": "Speed up query performance by creating indexes on frequently queried columns.",
          "code": "-- CANONICAL E-COMMERCE SCHEMA\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  first_name VARCHAR(100) NOT NULL,\n  last_name VARCHAR(100) NOT NULL,\n  email VARCHAR(255) UNIQUE NOT NULL,\n  role VARCHAR(20) NOT NULL DEFAULT 'customer',\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE products (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  sku VARCHAR(100) UNIQUE NOT NULL,\n  price DECIMAL(10,2) NOT NULL,\n  stock_quantity INT NOT NULL DEFAULT 0,\n  category VARCHAR(100),\n  image_url TEXT,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE orders (\n  id SERIAL PRIMARY KEY,\n  order_number VARCHAR(50) UNIQUE NOT NULL,\n  user_id INT NOT NULL REFERENCES users(id),\n  total_amount DECIMAL(10,2) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  payment_method VARCHAR(20),\n  shipping_address JSONB,\n  billing_address JSONB,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE order_items (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  product_id INT NOT NULL REFERENCES products(id),\n  quantity INT NOT NULL,\n  price_at_time DECIMAL(10,2) NOT NULL\n);\n\nCREATE TABLE payments (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  amount DECIMAL(10,2) NOT NULL,\n  payment_method VARCHAR(20) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  transaction_id VARCHAR(100),\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Create index\nCREATE INDEX idx_users_email ON users(email);\n\n-- Composite index\nCREATE INDEX idx_orders_user_status \nON orders(user_id, status);\n\n-- Partial index\nCREATE INDEX idx_active_users \nON users(role) \nWHERE role = 'customer';\n\n-- Drop index\nDROP INDEX idx_users_email;\n\n-- List all indexes\nSELECT tablename, indexname, indexdef \nFROM pg_indexes \nWHERE schemaname = 'public';",
          "example": "-- B-tree index (default)\nCREATE INDEX idx_products_price ON products(price);\n\n-- Hash index\nCREATE INDEX idx_users_status USING HASH ON users(status);\n\n-- GIN index (for arrays, JSONB)\nCREATE INDEX idx_posts_tags ON posts USING GIN(tags);\n\n-- Check index usage\nEXPLAIN ANALYZE \nSELECT * FROM users WHERE email = 'test@example.com';",
          "useCase": "Query optimization, faster lookups, improving JOIN performance",
          "category": "Performance & Optimization"
        },
        {
          "id": "query-optimization",
          "title": "Query Optimization",
          "description": "Techniques to improve query performance and efficiency.",
          "code": "-- CANONICAL E-COMMERCE SCHEMA\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  first_name VARCHAR(100) NOT NULL,\n  last_name VARCHAR(100) NOT NULL,\n  email VARCHAR(255) UNIQUE NOT NULL,\n  role VARCHAR(20) NOT NULL DEFAULT 'customer',\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE products (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  sku VARCHAR(100) UNIQUE NOT NULL,\n  price DECIMAL(10,2) NOT NULL,\n  stock_quantity INT NOT NULL DEFAULT 0,\n  category VARCHAR(100),\n  image_url TEXT,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE orders (\n  id SERIAL PRIMARY KEY,\n  order_number VARCHAR(50) UNIQUE NOT NULL,\n  user_id INT NOT NULL REFERENCES users(id),\n  total_amount DECIMAL(10,2) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  payment_method VARCHAR(20),\n  shipping_address JSONB,\n  billing_address JSONB,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE order_items (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  product_id INT NOT NULL REFERENCES products(id),\n  quantity INT NOT NULL,\n  price_at_time DECIMAL(10,2) NOT NULL\n);\n\nCREATE TABLE payments (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  amount DECIMAL(10,2) NOT NULL,\n  payment_method VARCHAR(20) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  transaction_id VARCHAR(100),\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\n-- EXPLAIN ANALYZE\nEXPLAIN ANALYZE \nSELECT * FROM orders \nWHERE created_at > NOW() - INTERVAL '30 days';\n\n-- Avoid SELECT *\nSELECT id, first_name, last_name, email FROM users; -- Better\nSELECT * FROM users; -- Avoid\n\n-- Use LIMIT\nSELECT * FROM orders \nORDER BY created_at DESC \nLIMIT 100;\n\n-- Indexes for WHERE, JOIN, ORDER BY\nCREATE INDEX idx_orders_created_at ON orders(created_at);\nCREATE INDEX idx_order_items_order_id ON order_items(order_id);\n\n-- Use EXISTS instead of COUNT\nSELECT EXISTS(SELECT 1 FROM users WHERE email = 'test@example.com');\n-- Instead of: SELECT COUNT(*) > 0 FROM users WHERE...",
          "example": "-- Avoid OR, use UNION\nSELECT * FROM products WHERE category = 'Electronics'\nUNION\nSELECT * FROM products WHERE category = 'Computers';\n\n-- Use BETWEEN instead of >= AND <=\nSELECT * FROM orders \nWHERE created_at BETWEEN '2024-01-01' AND '2024-12-31';\n\n-- Avoid functions on indexed columns\n-- Bad: WHERE LOWER(email) = 'test@example.com'\n-- Good: WHERE email = 'test@example.com'\n\n-- Use prepared statements\nPREPARE user_query AS \nSELECT * FROM users WHERE id = $1;\nEXECUTE user_query(5);",
          "useCase": "Performance tuning, reducing query time, scalability, production optimization",
          "category": "Performance & Optimization"
        },
        {
          "id": "transactions",
          "title": "Transactions",
          "description": "Group multiple operations into atomic units - all succeed or all fail.",
          "code": "-- CANONICAL E-COMMERCE SCHEMA\nCREATE TABLE users (\n  id SERIAL PRIMARY KEY,\n  first_name VARCHAR(100) NOT NULL,\n  last_name VARCHAR(100) NOT NULL,\n  email VARCHAR(255) UNIQUE NOT NULL,\n  role VARCHAR(20) NOT NULL DEFAULT 'customer',\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE products (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  sku VARCHAR(100) UNIQUE NOT NULL,\n  price DECIMAL(10,2) NOT NULL,\n  stock_quantity INT NOT NULL DEFAULT 0,\n  category VARCHAR(100),\n  image_url TEXT,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE orders (\n  id SERIAL PRIMARY KEY,\n  order_number VARCHAR(50) UNIQUE NOT NULL,\n  user_id INT NOT NULL REFERENCES users(id),\n  total_amount DECIMAL(10,2) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  payment_method VARCHAR(20),\n  shipping_address JSONB,\n  billing_address JSONB,\n  created_at TIMESTAMP DEFAULT NOW(),\n  updated_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE order_items (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  product_id INT NOT NULL REFERENCES products(id),\n  quantity INT NOT NULL,\n  price_at_time DECIMAL(10,2) NOT NULL\n);\n\nCREATE TABLE payments (\n  id SERIAL PRIMARY KEY,\n  order_id INT NOT NULL REFERENCES orders(id),\n  amount DECIMAL(10,2) NOT NULL,\n  payment_method VARCHAR(20) NOT NULL,\n  status VARCHAR(20) NOT NULL,\n  transaction_id VARCHAR(100),\n  created_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Basic transaction\nBEGIN;\nUPDATE orders SET status = 'processing' WHERE id = 1;\nINSERT INTO payments (order_id, amount, payment_method, status) VALUES (1, 100.00, 'credit_card', 'completed');\nCOMMIT;\n\n-- Rollback on error\nBEGIN;\nUPDATE products SET stock_quantity = stock_quantity - 1 WHERE id = 1;\n-- Something goes wrong\nROLLBACK;\n\n-- Savepoints\nBEGIN;\nINSERT INTO orders (order_number, user_id, total_amount, status) VALUES ('ORD-001', 1, 50.00, 'pending');\nSAVEPOINT my_savepoint;\nINSERT INTO order_items (order_id, product_id, quantity, price_at_time) VALUES (1, 1, 2, 25.00);\n-- Oops, error occurred\nROLLBACK TO my_savepoint;\nCOMMIT;",
          "example": "-- Transaction with error handling (in application)\n-- Python example\nconn.begin()\ntry:\n    cursor.execute(\"UPDATE accounts SET balance = balance - 100 WHERE id = %s\", (1,))\n    cursor.execute(\"UPDATE accounts SET balance = balance + 100 WHERE id = %s\", (2,))\n    conn.commit()\nexcept Exception as e:\n    conn.rollback()\n    raise e\n\n-- Isolation levels\nBEGIN TRANSACTION ISOLATION LEVEL SERIALIZABLE;\n-- Your queries\nCOMMIT;",
          "useCase": "Data consistency, banking operations, multi-step processes, preventing partial updates",
          "category": "Performance & Optimization"
        }
      ],
      "quiz": [
        {
          "question": "What is the difference between INNER JOIN and LEFT JOIN?",
          "options": [
            "They are the same",
            "INNER JOIN returns only matching rows, LEFT JOIN returns all left table rows plus matches",
            "LEFT JOIN is faster",
            "INNER JOIN includes NULL values"
          ],
          "correctAnswer": 1,
          "explanation": "INNER JOIN: only rows with matches in both tables. LEFT JOIN (LEFT OUTER JOIN): all left table rows + matching right rows (NULL if no match). RIGHT JOIN: opposite. FULL OUTER JOIN: all rows from both with NULLs for non-matches."
        },
        {
          "question": "What is the primary purpose of an index in PostgreSQL?",
          "options": [
            "To store data",
            "To speed up query performance",
            "To enforce constraints",
            "To create backups"
          ],
          "correctAnswer": 1,
          "explanation": "Indexes are data structures that improve the speed of data retrieval operations. They work like a book index, allowing the database to quickly locate rows without scanning the entire table."
        },
        {
          "question": "What does the GROUP BY clause do?",
          "options": [
            "Sorts the results",
            "Groups rows with the same values in specified columns",
            "Filters rows",
            "Joins tables"
          ],
          "correctAnswer": 1,
          "explanation": "GROUP BY groups rows that have the same values in specified columns into summary rows. It's often used with aggregate functions like COUNT, SUM, AVG to perform calculations on each group."
        },
        {
          "question": "What is a transaction in PostgreSQL?",
          "options": [
            "A single query",
            "A sequence of operations performed as a single unit of work",
            "A type of index",
            "A backup operation"
          ],
          "correctAnswer": 1,
          "explanation": "A transaction is a sequence of operations that are executed as a single unit. Either all operations succeed (COMMIT) or all fail (ROLLBACK), ensuring data consistency."
        },
        {
          "question": "What does EXPLAIN ANALYZE do?",
          "options": [
            "Deletes old data",
            "Shows the execution plan and actually runs the query",
            "Creates an index",
            "Backs up the database"
          ],
          "correctAnswer": 1,
          "explanation": "EXPLAIN shows query plan (estimated). EXPLAIN ANALYZE actually runs query and shows: actual rows, actual time, planning time, execution time. Critical for optimization. Use EXPLAIN (ANALYZE, BUFFERS) to see cache hits. Warning: ANALYZE executes query (including writes)!"
        },
        {
          "question": "What's the difference between WHERE and HAVING?",
          "options": [
            "They are identical",
            "WHERE filters rows before grouping, HAVING filters groups after aggregation",
            "HAVING is faster",
            "WHERE only works with numbers"
          ],
          "correctAnswer": 1,
          "explanation": "WHERE filters individual rows before GROUP BY is applied. HAVING filters the groups created by GROUP BY, often used with aggregate functions like COUNT or SUM."
        },
        {
          "question": "What is PostgreSQL?",
          "options": [
            "A NoSQL database",
            "An open-source object-relational database system",
            "A programming language",
            "A web server"
          ],
          "correctAnswer": 1,
          "explanation": "PostgreSQL is a powerful, open-source object-relational database management system (ORDBMS) with over 35 years of active development, known for reliability and feature robustness."
        },
        {
          "question": "What does ACID stand for in database transactions?",
          "options": [
            "Add, Create, Insert, Delete",
            "Atomicity, Consistency, Isolation, Durability",
            "Access, Control, Identity, Data",
            "Automatic, Concurrent, Indexed, Distributed"
          ],
          "correctAnswer": 1,
          "explanation": "ACID properties ensure reliable database transactions: Atomicity (all or nothing), Consistency (valid state), Isolation (concurrent transactions don't interfere), Durability (committed data persists)."
        },
        {
          "question": "What is a primary key?",
          "options": [
            "The first column",
            "A column or set of columns that uniquely identifies each row",
            "An index",
            "A foreign key reference"
          ],
          "correctAnswer": 1,
          "explanation": "A primary key is a constraint that uniquely identifies each row in a table. It must contain unique values and cannot contain NULL. Each table can have only one primary key."
        },
        {
          "question": "What is a foreign key?",
          "options": [
            "A key from another database",
            "A column that references the primary key of another table",
            "An external index",
            "A backup key"
          ],
          "correctAnswer": 1,
          "explanation": "A foreign key is a constraint that establishes a link between data in two tables. It references the primary key of another table, enforcing referential integrity."
        },
        {
          "question": "What does SELECT DISTINCT do?",
          "options": [
            "Selects all rows",
            "Returns only unique rows, removing duplicates",
            "Selects distinct tables",
            "Highlights differences"
          ],
          "correctAnswer": 1,
          "explanation": "SELECT DISTINCT removes duplicate rows from the result set, returning only unique values. It compares all selected columns to determine uniqueness."
        },
        {
          "question": "What is the difference between DELETE and TRUNCATE?",
          "options": [
            "No difference",
            "DELETE removes rows one by one with logging, TRUNCATE is faster and removes all rows",
            "TRUNCATE is deprecated",
            "DELETE is faster"
          ],
          "correctAnswer": 1,
          "explanation": "DELETE removes rows individually, fires triggers, can use WHERE clause. TRUNCATE is faster (doesn't scan table), removes all rows, resets sequences, doesn't fire DELETE triggers. TRUNCATE requires table-level lock."
        },
        {
          "question": "What does the ORDER BY clause do?",
          "options": [
            "Orders tables",
            "Sorts the result set by one or more columns",
            "Creates order",
            "Organizes database"
          ],
          "correctAnswer": 1,
          "explanation": "ORDER BY sorts query results in ascending (ASC, default) or descending (DESC) order based on specified columns. Can sort by multiple columns with priority order."
        },
        {
          "question": "What is a subquery?",
          "options": [
            "A small query",
            "A query nested inside another query",
            "A backup query",
            "A query template"
          ],
          "correctAnswer": 1,
          "explanation": "Subquery: SELECT inside another query. Locations: SELECT (scalar), FROM (derived table), WHERE (IN, EXISTS), HAVING. Correlated subquery: references outer query. Non-correlated: independent. Can often rewrite as JOIN for better performance."
        },
        {
          "question": "What is the difference between UNION and UNION ALL?",
          "options": [
            "No difference",
            "UNION removes duplicates, UNION ALL includes all rows",
            "UNION ALL is deprecated",
            "UNION is faster"
          ],
          "correctAnswer": 1,
          "explanation": "UNION: combines queries, removes duplicates (sorts, slower). UNION ALL: includes all rows, faster (no duplicate removal). Column count and types must match. Use UNION ALL when duplicates acceptable or known not to exist for better performance."
        },
        {
          "question": "What is a VIEW in PostgreSQL?",
          "options": [
            "A window",
            "A virtual table based on a stored query",
            "A screen display",
            "A table copy"
          ],
          "correctAnswer": 1,
          "explanation": "VIEW: virtual table, query stored not data. Executed when accessed. Benefits: simplify complex queries, security (hide columns), abstraction. No performance benefit (unless materialized). Can be updatable under certain conditions."
        },
        {
          "question": "What is a materialized view?",
          "options": [
            "A material table",
            "A view that stores query results physically for faster access",
            "A physical view",
            "A real table"
          ],
          "correctAnswer": 1,
          "explanation": "Materialized view: stores query result on disk. Faster reads, but stale data. REFRESH MATERIALIZED VIEW updates it (locks by default). REFRESH MATERIALIZED VIEW CONCURRENTLY avoids locks but requires unique index. Use for expensive, infrequently changed queries."
        },
        {
          "question": "What does REFRESH MATERIALIZED VIEW do?",
          "options": [
            "Refreshes screen",
            "Updates the stored data in a materialized view",
            "Clears cache",
            "Restarts view"
          ],
          "correctAnswer": 1,
          "explanation": "REFRESH MATERIALIZED VIEW re-executes the view's defining query and updates the stored result. Use CONCURRENTLY option to allow reads during refresh."
        },
        {
          "question": "What is a CTE (Common Table Expression)?",
          "options": [
            "A table type",
            "A temporary named result set using WITH clause",
            "A constraint",
            "An expression syntax"
          ],
          "correctAnswer": 1,
          "explanation": "CTE (WITH clause) creates a temporary named result set for use within a single query. Makes complex queries more readable and allows recursive queries."
        },
        {
          "question": "What is a recursive CTE?",
          "options": [
            "A repeating query",
            "A CTE that references itself to traverse hierarchical data",
            "A loop",
            "A circular reference"
          ],
          "correctAnswer": 1,
          "explanation": "Recursive CTE uses WITH RECURSIVE to reference itself, useful for hierarchical data like org charts or tree structures. Has base case and recursive term."
        },
        {
          "question": "What are window functions?",
          "options": [
            "Window management",
            "Functions that perform calculations across row sets related to current row",
            "GUI functions",
            "Display functions"
          ],
          "correctAnswer": 1,
          "explanation": "Window functions (OVER clause) perform calculations across a set of rows related to the current row without grouping. Examples: ROW_NUMBER(), RANK(), LAG(), LEAD()."
        },
        {
          "question": "What does ROW_NUMBER() do?",
          "options": [
            "Counts rows",
            "Assigns unique sequential number to each row in partition",
            "Numbers tables",
            "Returns row count"
          ],
          "correctAnswer": 1,
          "explanation": "ROW_NUMBER() is a window function that assigns a unique sequential integer to rows within a partition, ordered by specified columns. Useful for pagination and ranking."
        },
        {
          "question": "What is the difference between RANK() and DENSE_RANK()?",
          "options": [
            "No difference",
            "RANK() skips numbers after ties, DENSE_RANK() doesn't skip",
            "DENSE_RANK() is faster",
            "RANK() is deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "RANK() leaves gaps in ranking after ties (1,2,2,4). DENSE_RANK() doesn't skip numbers (1,2,2,3). Both are window functions for ranking rows."
        },
        {
          "question": "What do LAG() and LEAD() functions do?",
          "options": [
            "Slow down queries",
            "Access data from previous/next rows without self-join",
            "Delay execution",
            "Lead queries"
          ],
          "correctAnswer": 1,
          "explanation": "LAG() accesses data from previous row, LEAD() from next row in the result set. Window functions that avoid self-joins for accessing adjacent rows."
        },
        {
          "question": "What is PARTITION BY in window functions?",
          "options": [
            "Table partitioning",
            "Divides result set into partitions for window function calculation",
            "Disk partitioning",
            "Data splitting"
          ],
          "correctAnswer": 1,
          "explanation": "PARTITION BY divides the result set into partitions. Window function is applied separately to each partition. Similar to GROUP BY but doesn't collapse rows."
        },
        {
          "question": "What is the LIMIT clause?",
          "options": [
            "Sets limits",
            "Restricts number of rows returned by query",
            "Limits table size",
            "Access control"
          ],
          "correctAnswer": 1,
          "explanation": "LIMIT restricts the number of rows returned. OFFSET specifies how many rows to skip. Used for pagination: LIMIT 10 OFFSET 20. Note: OFFSET scans skipped rows, inefficient for large offsets. Use keyset pagination for better performance."
        },
        {
          "question": "What is the difference between CHAR and VARCHAR?",
          "options": [
            "No difference",
            "CHAR is fixed-length, VARCHAR is variable-length",
            "VARCHAR is deprecated",
            "CHAR is faster"
          ],
          "correctAnswer": 1,
          "explanation": "CHAR(n) stores fixed-length strings, padding with spaces. VARCHAR(n) stores variable-length strings up to n characters. VARCHAR is generally preferred for flexibility."
        },
        {
          "question": "What is the TEXT data type?",
          "options": [
            "Same as VARCHAR",
            "Variable-length string with no specific length limit",
            "Fixed-length text",
            "Binary text"
          ],
          "correctAnswer": 1,
          "explanation": "TEXT is a variable-length string type without explicit length limit. In PostgreSQL, TEXT, VARCHAR without length, and VARCHAR with length perform similarly."
        },
        {
          "question": "What is the SERIAL data type?",
          "options": [
            "A string type",
            "An auto-incrementing integer (shorthand for sequence)",
            "Serial number",
            "Array type"
          ],
          "correctAnswer": 1,
          "explanation": "SERIAL creates INTEGER column with sequence for auto-increment. BIGSERIAL uses BIGINT. Modern PostgreSQL prefers GENERATED ALWAYS AS IDENTITY (SQL standard) over SERIAL. SERIAL has drawbacks: sequence not dropped with column."
        },
        {
          "question": "What is the difference between INTEGER and BIGINT?",
          "options": [
            "No difference",
            "INTEGER is 4 bytes (-2B to 2B), BIGINT is 8 bytes (much larger range)",
            "BIGINT is deprecated",
            "INTEGER is faster"
          ],
          "correctAnswer": 1,
          "explanation": "INTEGER: 4 bytes, -2,147,483,648 to 2,147,483,647. BIGINT: 8 bytes, -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807. Also: SMALLINT (2 bytes, -32768 to 32767). Use BIGINT for large-scale IDs or when overflow risk exists."
        },
        {
          "question": "What is the BOOLEAN data type?",
          "options": [
            "True/False only",
            "Stores TRUE, FALSE, or NULL",
            "0 or 1",
            "Yes or No"
          ],
          "correctAnswer": 1,
          "explanation": "BOOLEAN stores TRUE, FALSE, or NULL. Accepts various input formats: true/false, yes/no, on/off, 1/0, t/f, y/n."
        },
        {
          "question": "What is the TIMESTAMP data type?",
          "options": [
            "Time only",
            "Date and time (without or with time zone)",
            "Unix timestamp",
            "Date only"
          ],
          "correctAnswer": 1,
          "explanation": "TIMESTAMP stores date and time. TIMESTAMPTZ (TIMESTAMP WITH TIME ZONE) stores in UTC, converts to session timezone on retrieval. Best practice: always use TIMESTAMPTZ for timestamps to avoid timezone issues. TIMESTAMP WITHOUT TIME ZONE has no timezone info."
        },
        {
          "question": "What is the difference between DATE, TIME, and TIMESTAMP?",
          "options": [
            "No difference",
            "DATE stores date only, TIME stores time only, TIMESTAMP stores both",
            "DATE is deprecated",
            "TIME includes date"
          ],
          "correctAnswer": 1,
          "explanation": "DATE stores dates (year, month, day). TIME stores time of day. TIMESTAMP stores both date and time. Each serves different use cases."
        },
        {
          "question": "What is the JSON data type?",
          "options": [
            "String type",
            "Stores JSON data with validation and special operators",
            "File format",
            "Text format"
          ],
          "correctAnswer": 1,
          "explanation": "JSON stores exact text representation with validation. JSONB stores decomposed binary format. JSONB is 99% of time preferred: faster processing, allows indexing (GIN), removes whitespace/duplicate keys. JSON only if exact text preservation needed."
        },
        {
          "question": "What is the difference between JSON and JSONB?",
          "options": [
            "No difference",
            "JSON stores text, JSONB stores binary with better performance and indexing",
            "JSONB is deprecated",
            "JSON is faster"
          ],
          "correctAnswer": 1,
          "explanation": "JSON stores exact text copy. JSONB stores decomposed binary format, slightly slower to input but much faster to process and supports indexing. JSONB is generally preferred."
        },
        {
          "question": "What is an ARRAY data type?",
          "options": [
            "List type",
            "Column can store multiple values as an array",
            "Table of values",
            "JSON array"
          ],
          "correctAnswer": 1,
          "explanation": "PostgreSQL allows columns to store arrays: INTEGER[], TEXT[], etc. Access with [1] (1-indexed!). Useful but can violate normalization. Consider separate table for many-to-many. Supports array operators (&&, @>, <@) and functions (array_agg, unnest)."
        },
        {
          "question": "What is the UUID data type?",
          "options": [
            "User ID",
            "128-bit universally unique identifier",
            "Unique index",
            "Primary key type"
          ],
          "correctAnswer": 1,
          "explanation": "UUID stores 128-bit universally unique identifiers (e.g., 550e8400-e29b-41d4-a716-446655440000). Useful for distributed systems where global uniqueness is needed."
        },
        {
          "question": "What is NULL in PostgreSQL?",
          "options": [
            "Empty string",
            "Absence of value, unknown or undefined",
            "Zero",
            "False"
          ],
          "correctAnswer": 1,
          "explanation": "NULL represents unknown/missing value, not zero or empty string. Comparisons: NULL = NULL returns NULL (unknown), not TRUE. Use IS NULL/IS NOT NULL. NULL in math: 5 + NULL = NULL. NULL in boolean: TRUE OR NULL = TRUE, FALSE AND NULL = FALSE."
        },
        {
          "question": "What is the difference between NULL and empty string?",
          "options": [
            "They're the same",
            "NULL means no value, empty string '' is a value (zero-length string)",
            "NULL is deprecated",
            "Empty string is faster"
          ],
          "correctAnswer": 1,
          "explanation": "NULL = unknown/missing. Empty string '' = known string with zero length. LENGTH(NULL) = NULL, LENGTH('') = 0. CONCAT('a', NULL, 'b') = NULL (in most DBs), but PostgreSQL CONCAT returns 'ab' (handles NULLs gracefully). Use COALESCE for NULL handling."
        },
        {
          "question": "What is a UNIQUE constraint?",
          "options": [
            "Primary key",
            "Ensures all values in column(s) are different",
            "Index type",
            "Special column"
          ],
          "correctAnswer": 1,
          "explanation": "UNIQUE constraint ensures all non-NULL values are distinct. Allows multiple NULLs (NULL != NULL in SQL). Automatically creates unique index. Can be on single column or multiple columns (composite uniqueness). Table can have multiple UNIQUE constraints."
        },
        {
          "question": "What is a CHECK constraint?",
          "options": [
            "Validates checks",
            "Ensures values meet specified condition",
            "Data type check",
            "Table validation"
          ],
          "correctAnswer": 1,
          "explanation": "CHECK constraint enforces boolean condition on column values. Example: CHECK (age >= 18 AND age < 150), CHECK (price > 0). Can reference multiple columns. NOT enforced on NULL (NULL satisfies any CHECK). Table-level or column-level."
        },
        {
          "question": "What is a NOT NULL constraint?",
          "options": [
            "No nulls allowed",
            "Ensures column cannot contain NULL values",
            "Requires values",
            "Non-empty constraint"
          ],
          "correctAnswer": 1,
          "explanation": "NOT NULL constraint ensures a column must always contain a value (cannot be NULL). Every INSERT or UPDATE must provide a value for that column."
        },
        {
          "question": "What is CASCADE in foreign key constraints?",
          "options": [
            "Waterfall effect",
            "Automatically propagates delete/update to related rows",
            "Chain reaction",
            "Cascading style"
          ],
          "correctAnswer": 1,
          "explanation": "CASCADE with foreign keys automatically propagates changes. ON DELETE CASCADE deletes related rows. ON UPDATE CASCADE updates related foreign key values."
        },
        {
          "question": "What is the difference between CASCADE and RESTRICT?",
          "options": [
            "No difference",
            "CASCADE propagates changes, RESTRICT prevents deletion if references exist",
            "CASCADE is faster",
            "RESTRICT is deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "ON DELETE CASCADE automatically deletes related rows. ON DELETE RESTRICT (default) prevents deletion if referenced rows exist. SET NULL and SET DEFAULT are other options."
        },
        {
          "question": "What is normalization?",
          "options": [
            "Data formatting",
            "Organizing database to reduce redundancy and improve integrity",
            "Standard format",
            "Optimization process"
          ],
          "correctAnswer": 1,
          "explanation": "Normalization is the process of organizing database structure to minimize redundancy and dependency. Typically progresses through normal forms (1NF, 2NF, 3NF, BCNF)."
        },
        {
          "question": "What is the First Normal Form (1NF)?",
          "options": [
            "First table",
            "Each column contains atomic values, no repeating groups",
            "Primary key exists",
            "No nulls"
          ],
          "correctAnswer": 1,
          "explanation": "1NF requires: atomic (indivisible) values in each column, no repeating groups or arrays, each record is unique. Foundation for further normalization."
        },
        {
          "question": "What is the Second Normal Form (2NF)?",
          "options": [
            "Two tables",
            "In 1NF and all non-key attributes fully depend on entire primary key",
            "Two keys",
            "Double normalized"
          ],
          "correctAnswer": 1,
          "explanation": "2NF requires being in 1NF plus no partial dependencies (non-key attributes must depend on entire primary key, not just part of composite key)."
        },
        {
          "question": "What is the Third Normal Form (3NF)?",
          "options": [
            "Three tables",
            "In 2NF and no transitive dependencies (non-key attributes don't depend on other non-key attributes)",
            "Three keys",
            "Triple normalized"
          ],
          "correctAnswer": 1,
          "explanation": "3NF requires being in 2NF plus no transitive dependencies. Every non-key attribute must depend directly on the primary key, not through another non-key attribute."
        },
        {
          "question": "What is denormalization?",
          "options": [
            "Breaking normalization",
            "Intentionally adding redundancy to improve read performance",
            "Removing normalization",
            "Data corruption"
          ],
          "correctAnswer": 1,
          "explanation": "Denormalization intentionally introduces redundancy to improve read performance at the cost of write complexity and storage. Trade-off decision based on workload."
        },
        {
          "question": "What does VACUUM do in PostgreSQL?",
          "options": [
            "Cleans data",
            "Reclaims storage by removing dead tuples from MVCC",
            "Deletes tables",
            "Compresses database"
          ],
          "correctAnswer": 1,
          "explanation": "VACUUM marks dead tuples as reusable (from MVCC updates/deletes). Prevents transaction ID wraparound (critical!). VACUUM FULL rewrites table to reclaim space to OS but requires exclusive lock (avoid on large tables). Autovacuum runs automatically."
        },
        {
          "question": "What is MVCC in PostgreSQL?",
          "options": [
            "Version control",
            "Multi-Version Concurrency Control for handling concurrent transactions",
            "Multi-value columns",
            "Concurrent connections"
          ],
          "correctAnswer": 1,
          "explanation": "MVCC (Multi-Version Concurrency Control) allows multiple versions of rows to exist. Readers don't block writers and writers don't block readers, improving concurrency."
        },
        {
          "question": "What does ANALYZE do?",
          "options": [
            "Analyzes queries",
            "Collects statistics about table contents for query planner",
            "Debugs code",
            "Checks errors"
          ],
          "correctAnswer": 1,
          "explanation": "ANALYZE collects statistics: row count, data distribution, most common values, histograms. Query planner uses stats to estimate costs and choose optimal plan. Run after bulk data changes. Autovacuum runs ANALYZE automatically. ANALYZE VERBOSE shows progress."
        },
        {
          "question": "What is an execution plan?",
          "options": [
            "Run schedule",
            "Step-by-step strategy database uses to execute a query",
            "Execution order",
            "Query template"
          ],
          "correctAnswer": 1,
          "explanation": "Execution plan is the sequence of operations database performs to execute a query. EXPLAIN shows the plan, EXPLAIN ANALYZE shows plan with actual execution times."
        },
        {
          "question": "What is a sequential scan?",
          "options": [
            "Ordered scan",
            "Reading entire table row-by-row from disk",
            "Index scan",
            "Sequential order"
          ],
          "correctAnswer": 1,
          "explanation": "Sequential Scan (Seq Scan): reads all rows in physical order. Efficient when: small table, reading most rows (>5-10%), no suitable index. Parallel sequential scan uses multiple workers. Planner chooses based on cost estimates."
        },
        {
          "question": "What is an index scan?",
          "options": [
            "Scanning indexes",
            "Using index to quickly locate specific rows",
            "Fast scan",
            "Index read"
          ],
          "correctAnswer": 1,
          "explanation": "Index scan uses an index to quickly locate rows matching search criteria without reading entire table. Much faster than seq scan for selective queries."
        },
        {
          "question": "What is a bitmap index scan?",
          "options": [
            "Image scan",
            "Scans index to create bitmap of matching pages, then fetches pages",
            "Binary scan",
            "Bit scan"
          ],
          "correctAnswer": 1,
          "explanation": "Bitmap index scan creates bitmap of heap pages containing matching rows, then fetches pages in physical order. Efficient for moderately selective queries."
        },
        {
          "question": "What are the different index types in PostgreSQL?",
          "options": [
            "Only B-tree",
            "B-tree, Hash, GiST, GIN, BRIN, SP-GiST",
            "Primary and secondary",
            "Clustered and non-clustered"
          ],
          "correctAnswer": 1,
          "explanation": "B-tree: default, general <>=, sorting. Hash: only = (rarely used). GIN: arrays, JSONB, full-text (element containment). GiST: geometric, range types. BRIN: very large tables with natural order. SP-GiST: non-balanced data (IPs, phone numbers)."
        },
        {
          "question": "When should you use a GIN index?",
          "options": [
            "Always",
            "For JSONB, arrays, full-text search (multi-value columns)",
            "Never",
            "Only for integers"
          ],
          "correctAnswer": 1,
          "explanation": "GIN (Generalized Inverted Index): multi-value data types. Use for: JSONB (@>, ? operators), arrays (&&, @>, <@ operators), full-text search (tsvector). Larger, slower to update than B-tree, but excellent for containment queries. GIN vs GiST: GIN bigger/faster, GiST smaller/slower."
        },
        {
          "question": "What is a composite index?",
          "options": [
            "Multiple indexes",
            "Index on multiple columns combined",
            "Complex index",
            "Joined index"
          ],
          "correctAnswer": 1,
          "explanation": "Composite (multi-column) index: indexes multiple columns together. Column order critical! Index on (a, b, c) supports: (a), (a,b), (a,b,c) queries, but NOT (b), (c), or (b,c). Leftmost prefix rule. Example: idx(last_name, first_name)."
        },
        {
          "question": "What is a partial index?",
          "options": [
            "Incomplete index",
            "Index on subset of rows matching WHERE condition",
            "Partial columns",
            "Half index"
          ],
          "correctAnswer": 1,
          "explanation": "Partial index: indexes only rows matching WHERE condition. Example: CREATE INDEX ON orders (user_id) WHERE status = 'pending'. Smaller, faster, lower maintenance cost. Query must use same WHERE condition. Ideal for frequently filtered subsets."
        },
        {
          "question": "What is an expression index?",
          "options": [
            "Math index",
            "Index on result of function or expression",
            "Complex index",
            "Formula index"
          ],
          "correctAnswer": 1,
          "explanation": "Expression index (functional index) indexes the result of a function or expression instead of column value. Example: CREATE INDEX ON users (LOWER(email))."
        },
        {
          "question": "What is CLUSTER command?",
          "options": [
            "Creates cluster",
            "Physically reorders table rows based on index",
            "Clusters tables",
            "Groups data"
          ],
          "correctAnswer": 1,
          "explanation": "CLUSTER physically reorders table rows to match index order. One-time operation (not auto-maintained). Requires exclusive lock, rewrites entire table. Can improve range scan performance. Rarely used in production due to locking. Consider pg_repack instead."
        },
        {
          "question": "What is a trigger?",
          "options": [
            "Event handler",
            "Automatically executed function in response to table events",
            "Scheduler",
            "Action button"
          ],
          "correctAnswer": 1,
          "explanation": "Trigger is a function automatically executed when specific event occurs on table (INSERT, UPDATE, DELETE). Can execute BEFORE, AFTER, or INSTEAD OF the event."
        },
        {
          "question": "What is the difference between BEFORE and AFTER triggers?",
          "options": [
            "Timing only",
            "BEFORE can modify data before operation, AFTER sees final results",
            "AFTER is faster",
            "BEFORE is deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "BEFORE: fires before operation, can modify NEW row, can skip operation (return NULL for row-level). AFTER: fires after operation complete, cannot modify, sees final state. BEFORE for validation/modification, AFTER for logging/auditing. Row-level vs statement-level triggers."
        },
        {
          "question": "What is a stored procedure?",
          "options": [
            "Saved query",
            "Named block of SQL/PL code stored in database",
            "Procedure call",
            "Function backup"
          ],
          "correctAnswer": 1,
          "explanation": "Stored procedure is reusable code block stored in database. In PostgreSQL, functions serve this purpose. Can accept parameters, contain logic, and be called multiple times."
        },
        {
          "question": "What is the difference between a function and a procedure?",
          "options": [
            "No difference in PostgreSQL",
            "Functions return value, procedures don't (procedures added in PG 11)",
            "Procedures are faster",
            "Functions are deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "Functions: return value, called in expressions, cannot COMMIT/ROLLBACK mid-execution. Procedures (PG 11+): called with CALL, no return value, can contain transaction control (COMMIT/ROLLBACK). Use procedures for multi-statement transactions."
        },
        {
          "question": "What is PL/pgSQL?",
          "options": [
            "PostgreSQL syntax",
            "Procedural language for writing functions and triggers",
            "Query language",
            "Admin language"
          ],
          "correctAnswer": 1,
          "explanation": "PL/pgSQL is PostgreSQL's procedural language for writing functions, stored procedures, and triggers. Similar to Oracle's PL/SQL. Supports variables, loops, conditionals."
        },
        {
          "question": "What is table partitioning?",
          "options": [
            "Splitting tables",
            "Dividing large table into smaller physical pieces based on key",
            "Table division",
            "Data separation"
          ],
          "correctAnswer": 1,
          "explanation": "Partitioning splits large table into smaller physical pieces (partitions) while appearing as single table. Improves performance and maintenance for very large tables."
        },
        {
          "question": "What are the types of partitioning in PostgreSQL?",
          "options": [
            "Only range",
            "Range, List, Hash partitioning",
            "Vertical and horizontal",
            "Primary and secondary"
          ],
          "correctAnswer": 1,
          "explanation": "PostgreSQL supports: Range partitioning (value ranges), List partitioning (specific values), Hash partitioning (hash function). Choose based on data distribution and query patterns."
        },
        {
          "question": "What is range partitioning?",
          "options": [
            "Number ranges",
            "Partitioning based on value ranges (e.g., date ranges)",
            "Distance partitioning",
            "Range queries"
          ],
          "correctAnswer": 1,
          "explanation": "Range partitioning divides table based on column value ranges. Common for dates (monthly/yearly partitions) or sequential IDs. Each partition handles specific range."
        },
        {
          "question": "What is list partitioning?",
          "options": [
            "Listed tables",
            "Partitioning based on specific values (e.g., regions, categories)",
            "Array partitioning",
            "Value lists"
          ],
          "correctAnswer": 1,
          "explanation": "List partitioning assigns rows to partitions based on explicit lists of values. Good for categorical data like country codes, status values, or categories."
        },
        {
          "question": "What is hash partitioning?",
          "options": [
            "Encrypted partitioning",
            "Partitioning using hash function for even data distribution",
            "Random partitioning",
            "Hashed values"
          ],
          "correctAnswer": 1,
          "explanation": "Hash partitioning uses hash function on partition key to distribute data evenly across partitions. Good when data doesn't have natural ranges or categories."
        },
        {
          "question": "What is replication in PostgreSQL?",
          "options": [
            "Copying data",
            "Maintaining synchronized copies of database on multiple servers",
            "Backup process",
            "Data duplication"
          ],
          "correctAnswer": 1,
          "explanation": "Replication maintains copies of database on multiple servers for high availability, disaster recovery, and read scaling. PostgreSQL supports streaming and logical replication."
        },
        {
          "question": "What is streaming replication?",
          "options": [
            "Video streaming",
            "Physical replication streaming WAL records to standby servers",
            "Data streaming",
            "Network replication"
          ],
          "correctAnswer": 1,
          "explanation": "Streaming replication continuously streams WAL (Write-Ahead Log) records from primary to standby servers. Provides near real-time synchronization for high availability."
        },
        {
          "question": "What is logical replication?",
          "options": [
            "Logic-based copying",
            "Replication based on logical data changes (specific tables/operations)",
            "Logical copies",
            "Smart replication"
          ],
          "correctAnswer": 1,
          "explanation": "Logical replication replicates data changes based on replication identity. More flexible than physical - can replicate specific tables, databases, or even between different versions."
        },
        {
          "question": "What is WAL (Write-Ahead Logging)?",
          "options": [
            "Logging system",
            "Durability mechanism writing changes to log before data files",
            "Write log",
            "Ahead logging"
          ],
          "correctAnswer": 1,
          "explanation": "WAL ensures changes are logged to durable storage before being applied to data files. Enables crash recovery, replication, and point-in-time recovery."
        },
        {
          "question": "What is pg_dump?",
          "options": [
            "Dump command",
            "Utility for backing up PostgreSQL databases to SQL or archive format",
            "Data export",
            "Memory dump"
          ],
          "correctAnswer": 1,
          "explanation": "pg_dump creates logical backup of PostgreSQL database. Outputs SQL script or archive file. Can backup entire database, specific schemas, or tables."
        },
        {
          "question": "What is pg_restore?",
          "options": [
            "Restore tool",
            "Utility for restoring databases from pg_dump archive files",
            "Recovery command",
            "Backup restore"
          ],
          "correctAnswer": 1,
          "explanation": "pg_restore restores databases from archive files created by pg_dump (not plain SQL). Supports parallel restore, selective restore, and various formats."
        },
        {
          "question": "What is the difference between pg_dump and pg_dumpall?",
          "options": [
            "No difference",
            "pg_dump backs up one database, pg_dumpall backs up entire cluster",
            "pg_dumpall is faster",
            "pg_dump is deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "pg_dump: single database, SQL or custom format (-Fc for compression/parallel restore). pg_dumpall: entire cluster (all databases + roles + tablespaces), only plain SQL. For cluster backup: pg_dumpall for globals + pg_dump -Fc for each database."
        },
        {
          "question": "What is point-in-time recovery (PITR)?",
          "options": [
            "Time travel",
            "Restoring database to specific moment using base backup and WAL",
            "Recovery time",
            "Point recovery"
          ],
          "correctAnswer": 1,
          "explanation": "PITR: restore to any point in time. Requires: base backup (pg_basebackup) + continuous WAL archiving. Recovery: restore base backup, replay WAL to target time. Set recovery_target_time. Critical for disaster recovery. Test restores regularly!"
        },
        {
          "question": "What are isolation levels in PostgreSQL?",
          "options": [
            "Security levels",
            "Read Uncommitted, Read Committed, Repeatable Read, Serializable",
            "Transaction types",
            "Locking levels"
          ],
          "correctAnswer": 1,
          "explanation": "PostgreSQL has 3 real isolation levels: Read Committed (default), Repeatable Read, Serializable. Read Uncommitted is treated as Read Committed (PostgreSQL never allows dirty reads). Higher levels = more consistency, less concurrency."
        },
        {
          "question": "What is Read Committed isolation level?",
          "options": [
            "Read everything",
            "Sees only data committed before query starts",
            "Reads all data",
            "Committed reads only"
          ],
          "correctAnswer": 1,
          "explanation": "Read Committed (default) sees only data committed before query starts. Each query in transaction sees fresh snapshot. Prevents dirty reads but allows non-repeatable reads."
        },
        {
          "question": "What is Repeatable Read isolation level?",
          "options": [
            "Repeat queries",
            "All queries in transaction see same snapshot from transaction start",
            "Repeated reads",
            "Read twice"
          ],
          "correctAnswer": 1,
          "explanation": "Repeatable Read: transaction sees snapshot from first query. Prevents non-repeatable reads and phantom reads (stronger than SQL standard). May fail with serialization error if conflicts occur. Retry logic needed."
        },
        {
          "question": "What is Serializable isolation level?",
          "options": [
            "Serial execution",
            "Strictest isolation, ensures concurrent transactions behave as if executed serially",
            "Serialized data",
            "One at a time"
          ],
          "correctAnswer": 1,
          "explanation": "Serializable: strictest level, prevents all anomalies. Uses Serializable Snapshot Isolation (SSI), not actual serial execution. Concurrent transactions run but abort if conflict detected. Requires retry logic. Performance impact vs Repeatable Read is minimal."
        },
        {
          "question": "What is a deadlock?",
          "options": [
            "Locked database",
            "Two transactions waiting for each other, neither can proceed",
            "Dead transaction",
            "Lock timeout"
          ],
          "correctAnswer": 1,
          "explanation": "Deadlock: circular wait where transactions hold locks each other needs. PostgreSQL's deadlock detector runs periodically, aborts one transaction (deadlock victim) with error. Application must retry. Prevent: access tables in consistent order."
        },
        {
          "question": "What is a schema in PostgreSQL?",
          "options": [
            "Database structure",
            "Namespace containing database objects (tables, views, functions)",
            "Table structure",
            "Design pattern"
          ],
          "correctAnswer": 1,
          "explanation": "Schema is a namespace within database containing tables, views, functions, etc. Allows organizing objects and avoiding name conflicts. 'public' is default schema."
        },
        {
          "question": "What is the search_path?",
          "options": [
            "Search query",
            "Order of schemas PostgreSQL searches for unqualified object names",
            "File path",
            "Index path"
          ],
          "correctAnswer": 1,
          "explanation": "search_path: list of schemas to search for unqualified names. Default: '\"$user\", public'. SET search_path TO myschema, public; SHOW search_path; Security: use qualified names (schema.table) or remove public from search_path for multi-tenant apps."
        },
        {
          "question": "What does GRANT do?",
          "options": [
            "Grants wishes",
            "Gives privileges to users/roles on database objects",
            "Creates grants",
            "Allows access"
          ],
          "correctAnswer": 1,
          "explanation": "GRANT gives specific privileges (SELECT, INSERT, UPDATE, DELETE, etc.) on database objects to users or roles. Foundation of PostgreSQL access control."
        },
        {
          "question": "What does REVOKE do?",
          "options": [
            "Revokes access",
            "Removes previously granted privileges from users/roles",
            "Cancels grants",
            "Denies access"
          ],
          "correctAnswer": 1,
          "explanation": "REVOKE removes privileges previously granted with GRANT. Use carefully as it can cascade depending on GRANT OPTION and dependencies."
        },
        {
          "question": "What is a role in PostgreSQL?",
          "options": [
            "User type",
            "Database user or group of users with specific privileges",
            "Permission level",
            "Access role"
          ],
          "correctAnswer": 1,
          "explanation": "Role is an entity that can own database objects and have privileges. Can represent individual users or groups. Roles with LOGIN privilege can connect (users)."
        },
        {
          "question": "What is the difference between a user and a role?",
          "options": [
            "No difference (both are roles)",
            "User is a role with LOGIN privilege",
            "Users are actual people",
            "Roles are deprecated"
          ],
          "correctAnswer": 0,
          "explanation": "In PostgreSQL, users and roles are the same concept. 'User' is historical term for role with LOGIN privilege. CREATE USER is shorthand for CREATE ROLE with LOGIN."
        },
        {
          "question": "What does \\d command do in psql?",
          "options": [
            "Deletes data",
            "Describes table structure (columns, types, constraints)",
            "Database command",
            "Display command"
          ],
          "correctAnswer": 1,
          "explanation": "In psql, \\d table_name displays table structure. \\d+ shows additional details. \\dt lists tables, \\di lists indexes, \\dv lists views."
        },
        {
          "question": "What does \\l command do in psql?",
          "options": [
            "Lists files",
            "Lists all databases",
            "Logs in",
            "Loads data"
          ],
          "correctAnswer": 1,
          "explanation": "\\l or \\list shows all databases with owner, encoding, and access privileges. Great for seeing available databases in the cluster."
        },
        {
          "question": "What does \\c command do in psql?",
          "options": [
            "Copies data",
            "Connects to a different database",
            "Closes connection",
            "Creates database"
          ],
          "correctAnswer": 1,
          "explanation": "\\c database_name or \\connect switches connection to different database. Can also specify user and host: \\c database user host."
        },
        {
          "question": "What is COALESCE function?",
          "options": [
            "Combines strings",
            "Returns first non-NULL value from list of arguments",
            "Checks equality",
            "Creates aliases"
          ],
          "correctAnswer": 1,
          "explanation": "COALESCE returns first non-NULL argument. COALESCE(col1, col2, 'default') checks arguments left-to-right. Short-circuits (stops at first non-NULL). Equivalent to nested CASE WHEN. More efficient than CASE for NULL handling."
        },
        {
          "question": "What does the CASE statement do?",
          "options": [
            "Case conversion",
            "Conditional expression (if-then-else logic in SQL)",
            "Switch case",
            "Case sensitivity"
          ],
          "correctAnswer": 1,
          "explanation": "CASE provides if-then-else logic in SQL. CASE WHEN condition THEN result ... ELSE default END. Can be simple (test one expression) or searched (multiple conditions)."
        },
        {
          "question": "What is LATERAL join?",
          "options": [
            "Side join",
            "Allows subquery to reference columns from preceding tables",
            "Left join",
            "Lateral view"
          ],
          "correctAnswer": 1,
          "explanation": "LATERAL: subquery in FROM can reference earlier FROM items. Like correlated subquery but in FROM clause. SELECT * FROM users, LATERAL (SELECT * FROM orders WHERE user_id = users.id) o. Common with functions returning sets. PostgreSQL 9.3+."
        },
        {
          "question": "What is FULL OUTER JOIN?",
          "options": [
            "Complete join",
            "Returns all rows from both tables, with NULLs where no match",
            "Full table join",
            "Outer join only"
          ],
          "correctAnswer": 1,
          "explanation": "FULL OUTER JOIN: all rows from both tables. Matched rows combined. Unmatched left rows: right columns NULL. Unmatched right rows: left columns NULL. Less common than LEFT/INNER. Use case: finding records in either table with no match."
        },
        {
          "question": "What is a CROSS JOIN?",
          "options": [
            "Crossed tables",
            "Cartesian product of two tables (all combinations)",
            "Intersecting join",
            "Cross reference"
          ],
          "correctAnswer": 1,
          "explanation": "CROSS JOIN: Cartesian product. Every row from table1 × every row from table2. No ON clause. Result: rows1 × rows2. Example: 10 rows × 5 rows = 50 rows. Rarely needed. Usually accidental (forgot JOIN condition). Use case: generating combinations."
        },
        {
          "question": "What is a self-join?",
          "options": [
            "Joining itself",
            "Joining a table to itself to compare rows within same table",
            "Self-referencing",
            "Recursive join"
          ],
          "correctAnswer": 1,
          "explanation": "Self-join: table joined to itself using aliases. Use cases: hierarchical data (employees-managers), finding duplicates, comparing rows. Example: SELECT e.name, m.name FROM employees e JOIN employees m ON e.manager_id = m.id. Requires table aliases."
        },
        {
          "question": "What does NOW() function return?",
          "options": [
            "Current time",
            "Current date and time at start of transaction",
            "System time",
            "Server time"
          ],
          "correctAnswer": 1,
          "explanation": "NOW() and CURRENT_TIMESTAMP: transaction start time (stable within transaction). clock_timestamp(): actual current time (changes within transaction). statement_timestamp(): statement start time. timeofday(): current time as text. Use NOW() for consistency."
        }
      ],
      "topicCount": 12,
      "quizCount": 101
    },
    {
      "slug": "react",
      "meta": {
        "title": "ReactJS Fundamentals",
        "description": "Learn React hooks, component patterns, and performance optimization with interactive quizzes and detailed explanations"
      },
      "topics": [
        {
          "id": "real-world-ui-design",
          "title": "Real-World UI Design Challenges (React)",
          "description": "Hands-on React UI design practice with production-like components, responsive layouts, accessibility, and interaction patterns.",
          "explanation": "This track focuses on practical frontend work: designing reusable UI building blocks, handling stateful interactions, and shipping responsive, accessible interfaces. Each challenge mirrors tasks from real product teams.",
          "implementation": "import React from 'react';\n\n// Suggested approach for each challenge:\n// 1) Define UI states and transitions\n// 2) Build semantic structure first\n// 3) Add responsive behavior\n// 4) Add accessibility and keyboard support\n// 5) Optimize render behavior",
          "example": "function ProductCard({ product, onAdd }) {\n  return (\n    <article className=\"rounded-xl border p-4\">\n      <h3 className=\"text-lg font-semibold\">{product.name}</h3>\n      <p className=\"text-sm text-gray-600\">{product.description}</p>\n      <div className=\"mt-3 flex items-center justify-between\">\n        <span className=\"font-bold\">${product.price}</span>\n        <button onClick={() => onAdd(product)} className=\"rounded bg-black px-3 py-1 text-white\">Add</button>\n      </div>\n    </article>\n  );\n}",
          "useCase": "Frontend interviews, product UI implementation rounds, portfolio projects, and day-to-day React feature development.",
          "category": "Real-World UI Design",
          "interviewQuestions": [
            {
              "question": "How do you design React components for reuse without overengineering?",
              "answer": "Start with focused props, clear composition slots, and avoid adding abstractions until repeated usage patterns appear."
            },
            {
              "question": "How do you keep UI state manageable in medium-size screens?",
              "answer": "Separate server state from local UI state, colocate state near usage, and extract shared state only when multiple siblings need it."
            },
            {
              "question": "What accessibility checks should be mandatory for every UI task?",
              "answer": "Keyboard navigation, visible focus, semantic landmarks, proper labels, and color contrast."
            },
            {
              "question": "How do you avoid layout shift in dynamic UI?",
              "answer": "Reserve space with skeletons/aspect-ratio, avoid injecting unknown-height blocks abruptly, and preload critical assets."
            },
            {
              "question": "What metrics matter for frontend UI quality?",
              "answer": "Perceived responsiveness, interaction latency, CLS, accessibility score, and error-free user flows."
            }
          ],
          "exercises": [
            {
              "type": "implement",
              "question": "Design a responsive admin dashboard with sidebar, KPI cards, and activity table."
            },
            {
              "type": "implement",
              "question": "Build a design-system style `Button` with variants, loading state, icon slots, and disabled behavior."
            },
            {
              "type": "implement",
              "question": "Create a modal system with focus trap, escape-to-close, and nested confirmation dialog."
            },
            {
              "type": "implement",
              "question": "Implement a Kanban board layout with drag placeholder visuals and keyboard fallback controls."
            },
            {
              "type": "implement",
              "question": "Create an e-commerce product listing page with filters, sort, pagination, and empty states."
            },
            {
              "type": "implement",
              "question": "Build a pricing table with monthly/yearly toggle and highlighted recommended plan."
            },
            {
              "type": "implement",
              "question": "Design a multi-step onboarding wizard with progress indicator and validation summary."
            },
            {
              "type": "implement",
              "question": "Build a chat UI with grouped messages, sticky date separators, and optimistic send state."
            },
            {
              "type": "implement",
              "question": "Create a notification center with unread badge, mark-all-read, and grouped categories."
            },
            {
              "type": "implement",
              "question": "Design a searchable command palette (Ctrl/Cmd+K) with keyboard navigation and actions."
            },
            {
              "type": "debug",
              "question": "Fix a list UI that re-renders every row on single-item update and explain optimization steps."
            },
            {
              "type": "debug",
              "question": "Investigate dropdown clipping issues inside overflow containers and provide robust fix options."
            },
            {
              "type": "debug",
              "question": "Resolve a modal focus loss bug when async submit triggers route/state changes."
            },
            {
              "type": "debug",
              "question": "Fix flickering skeleton/content transition caused by race conditions in fetch updates."
            },
            {
              "type": "scenario",
              "question": "You must redesign a legacy settings screen for mobile first. Define component boundaries and migration plan."
            },
            {
              "type": "scenario",
              "question": "Design a data table for 50k rows with sorting/filtering while preserving good UX."
            },
            {
              "type": "scenario",
              "question": "Build a checkout form that supports saved addresses and guest checkout without complexity explosion."
            },
            {
              "type": "scenario",
              "question": "Design role-based UI controls where admins and users see different actions safely."
            },
            {
              "type": "scenario",
              "question": "Plan a theme system with light/dark and brand colors without rewriting every component."
            },
            {
              "type": "scenario",
              "question": "Design a profile page with inline edit patterns and optimistic save rollback behavior."
            },
            {
              "type": "theory",
              "question": "Explain trade-offs between CSS utility classes, CSS modules, and styled-components in team scale."
            },
            {
              "type": "theory",
              "question": "When should you split a component versus keep one component with conditional branches?"
            },
            {
              "type": "output",
              "question": "Given debounced search + loading states + cache hits, predict the exact UI state order."
            },
            {
              "type": "output",
              "question": "Predict render sequence when parent state and context both update after a click event."
            },
            {
              "type": "refactor",
              "question": "Refactor a monolithic page component into reusable primitives while preserving behavior."
            }
          ],
          "programExercises": [
            {
              "level": "Medium",
              "question": "Build a reusable `StatsCardGrid` with responsive columns and icon support.",
              "code": "import React from 'react';\n\nexport function StatsCardGrid({ items }) {\n  return (\n    <section className=\"grid grid-cols-1 gap-4 sm:grid-cols-2 xl:grid-cols-4\">\n      {items.map((item) => (\n        <article key={item.id} className=\"rounded-xl border bg-white p-4 shadow-sm\">\n          <div className=\"flex items-center justify-between\">\n            <p className=\"text-sm text-gray-600\">{item.label}</p>\n            <span>{item.icon}</span>\n          </div>\n          <p className=\"mt-2 text-2xl font-bold\">{item.value}</p>\n          <p className=\"mt-1 text-xs text-green-600\">{item.delta}</p>\n        </article>\n      ))}\n    </section>\n  );\n}",
              "output": "A responsive KPI grid that scales from 1 to 4 columns and renders card label/value/delta consistently."
            },
            {
              "level": "Medium",
              "question": "Implement `FilterChips` with keyboard support and removable active tags.",
              "code": "import React from 'react';\n\nexport function FilterChips({ active, onRemove }) {\n  return (\n    <ul className=\"flex flex-wrap gap-2\" aria-label=\"Active filters\">\n      {active.map((chip) => (\n        <li key={chip}>\n          <button\n            type=\"button\"\n            onClick={() => onRemove(chip)}\n            className=\"rounded-full bg-slate-100 px-3 py-1 text-sm hover:bg-slate-200\"\n            aria-label={`Remove filter ${chip}`}\n          >\n            {chip} ✕\n          </button>\n        </li>\n      ))}\n    </ul>\n  );\n}",
              "output": "Chip list where each active filter can be removed by click/keyboard and screen readers announce proper labels."
            },
            {
              "level": "Medium",
              "question": "Create `ModalWithFocusTrap` component for accessible overlays.",
              "code": "import React, { useEffect, useRef } from 'react';\n\nexport function ModalWithFocusTrap({ open, onClose, children }) {\n  const ref = useRef(null);\n\n  useEffect(() => {\n    if (!open) return;\n    const root = ref.current;\n    const focusables = root?.querySelectorAll('button,[href],input,select,textarea,[tabindex]:not([tabindex=\"-1\"])');\n    focusables?.[0]?.focus();\n\n    const onKeyDown = (e) => {\n      if (e.key === 'Escape') onClose();\n    };\n    document.addEventListener('keydown', onKeyDown);\n    return () => document.removeEventListener('keydown', onKeyDown);\n  }, [open, onClose]);\n\n  if (!open) return null;\n  return (\n    <div className=\"fixed inset-0 z-50 grid place-items-center bg-black/50\" role=\"dialog\" aria-modal=\"true\">\n      <div ref={ref} className=\"w-full max-w-lg rounded-xl bg-white p-5\">\n        {children}\n      </div>\n    </div>\n  );\n}",
              "output": "Modal opens with initial focus inside, closes on Escape, and stays keyboard navigable."
            },
            {
              "level": "Hard",
              "question": "Build `VirtualizedList` for long data with fixed row height.",
              "code": "import React, { useMemo, useState } from 'react';\n\nexport function VirtualizedList({ items, rowHeight = 44, viewportHeight = 360 }) {\n  const [scrollTop, setScrollTop] = useState(0);\n  const totalHeight = items.length * rowHeight;\n\n  const { start, end } = useMemo(() => {\n    const s = Math.floor(scrollTop / rowHeight);\n    const visible = Math.ceil(viewportHeight / rowHeight);\n    return { start: Math.max(0, s - 5), end: Math.min(items.length, s + visible + 5) };\n  }, [scrollTop, rowHeight, viewportHeight, items.length]);\n\n  const visibleItems = items.slice(start, end);\n\n  return (\n    <div\n      className=\"overflow-auto rounded border\"\n      style={{ height: viewportHeight }}\n      onScroll={(e) => setScrollTop(e.currentTarget.scrollTop)}\n    >\n      <div style={{ height: totalHeight, position: 'relative' }}>\n        {visibleItems.map((item, i) => {\n          const idx = start + i;\n          return (\n            <div key={item.id} style={{ position: 'absolute', top: idx * rowHeight, left: 0, right: 0, height: rowHeight }} className=\"border-b px-3 py-2\">\n              {item.label}\n            </div>\n          );\n        })}\n      </div>\n    </div>\n  );\n}",
              "output": "Large lists render smoothly by only mounting visible rows plus overscan window."
            },
            {
              "level": "Hard",
              "question": "Implement `DashboardLayout` with resizable/collapsible sidebar and persisted width.",
              "code": "import React, { useEffect, useState } from 'react';\n\nconst KEY = 'sidebar-width';\n\nexport function DashboardLayout({ sidebar, children }) {\n  const [width, setWidth] = useState(280);\n  const [collapsed, setCollapsed] = useState(false);\n\n  useEffect(() => {\n    const saved = Number(localStorage.getItem(KEY));\n    if (saved > 200 && saved < 500) setWidth(saved);\n  }, []);\n\n  useEffect(() => {\n    localStorage.setItem(KEY, String(width));\n  }, [width]);\n\n  return (\n    <div className=\"grid min-h-screen\" style={{ gridTemplateColumns: collapsed ? '72px 1fr' : `${width}px 1fr` }}>\n      <aside className=\"border-r bg-slate-50 p-3\">{sidebar}</aside>\n      <main className=\"p-5\">{children}</main>\n      <button className=\"fixed bottom-4 left-4 rounded bg-slate-900 px-3 py-2 text-white\" onClick={() => setCollapsed((v) => !v)}>\n        {collapsed ? 'Expand' : 'Collapse'}\n      </button>\n      {!collapsed && (\n        <input\n          type=\"range\"\n          min={220}\n          max={420}\n          value={width}\n          onChange={(e) => setWidth(Number(e.target.value))}\n          className=\"fixed bottom-4 left-28\"\n        />\n      )}\n    </div>\n  );\n}",
              "output": "Dashboard with collapsible sidebar and persisted width preference across reloads."
            },
            {
              "level": "Very Hard",
              "question": "Build a `FormBuilder` UI with schema-driven fields, validation, and live preview panel.",
              "code": "import React, { useMemo, useState } from 'react';\n\nconst schema = [\n  { id: 'name', label: 'Name', type: 'text', required: true },\n  { id: 'email', label: 'Email', type: 'email', required: true },\n  { id: 'budget', label: 'Budget', type: 'number', required: false }\n];\n\nexport function FormBuilder() {\n  const [values, setValues] = useState({});\n  const [touched, setTouched] = useState({});\n\n  const errors = useMemo(() => {\n    const e = {};\n    for (const f of schema) {\n      if (f.required && !values[f.id]) e[f.id] = `${f.label} is required`;\n      if (f.type === 'email' && values[f.id] && !String(values[f.id]).includes('@')) e[f.id] = 'Invalid email';\n    }\n    return e;\n  }, [values]);\n\n  return (\n    <div className=\"grid gap-6 lg:grid-cols-2\">\n      <form className=\"space-y-4 rounded-xl border p-4\">\n        {schema.map((field) => (\n          <label key={field.id} className=\"block\">\n            <span className=\"mb-1 block text-sm font-medium\">{field.label}</span>\n            <input\n              type={field.type}\n              value={values[field.id] ?? ''}\n              onBlur={() => setTouched((t) => ({ ...t, [field.id]: true }))}\n              onChange={(e) => setValues((v) => ({ ...v, [field.id]: e.target.value }))}\n              className=\"w-full rounded border px-3 py-2\"\n            />\n            {touched[field.id] && errors[field.id] && <p className=\"mt-1 text-sm text-red-600\">{errors[field.id]}</p>}\n          </label>\n        ))}\n      </form>\n      <aside className=\"rounded-xl border bg-slate-50 p-4\">\n        <h4 className=\"mb-2 font-semibold\">Live Preview</h4>\n        <pre className=\"overflow-auto rounded bg-slate-900 p-3 text-xs text-slate-100\">{JSON.stringify(values, null, 2)}</pre>\n      </aside>\n    </div>\n  );\n}",
              "output": "Schema-driven form with validation messages and real-time JSON preview."
            }
          ]
        },
        {
          "id": "usestate",
          "title": "useState Hook",
          "description": "useState is the most fundamental React hook that allows you to add state to functional components. It returns an array with the current state value and a function to update it.",
          "explanation": "The useState hook is React's primary way to manage component state in functional components. Before hooks (introduced in React 16.8), you needed class components to have state.\n\nKey concepts:\n- Returns array: [currentState, setStateFunction]\n- State updates trigger re-renders\n- Can store any type of value (string, number, object, array)\n- Each useState call is independent\n- State updates are batched for performance\n\nBest practices:\n- Use multiple useState calls for unrelated state\n- Don't mutate state directly, always use setState\n- Use functional updates when new state depends on old state\n- Keep state minimal and derived data in variables",
          "implementation": "import { useState } from 'react';\n\nfunction Counter() {\n  const [count, setCount] = useState(0);\n  \n  return (\n    <div>\n      <p>Count: {count}</p>\n      <button onClick={() => setCount(count + 1)}>\n        Increment\n      </button>\n      <button onClick={() => setCount(count - 1)}>\n        Decrement\n      </button>\n      <button onClick={() => setCount(0)}>\n        Reset\n      </button>\n    </div>\n  );\n}",
          "example": "// Multiple states\nconst [name, setName] = useState('');\nconst [age, setAge] = useState(0);\nconst [isActive, setIsActive] = useState(false);\n\n// Object state\nconst [user, setUser] = useState({ name: '', email: '' });\n\n// Array state\nconst [items, setItems] = useState([]);\n\n// Functional updates (using previous state)\nsetCount(prevCount => prevCount + 1);\n\n// Lazy initialization (computed once)\nconst [data, setData] = useState(() => {\n  return expensiveComputation();\n});",
          "useCase": "Form inputs, counters, toggles, managing component-level data, UI state like modals/dropdowns",
          "category": "Core Concepts"
        },
        {
          "id": "useeffect",
          "title": "useEffect Hook",
          "description": "useEffect lets you perform side effects in functional components. It runs after render and can optionally clean up after itself.",
          "explanation": "useEffect is React's hook for handling side effects - operations that interact with the outside world like data fetching, subscriptions, or manually changing the DOM.\n\nKey concepts:\n- Runs after every render by default\n- Dependency array controls when it runs\n- Return function for cleanup\n- Replaces componentDidMount, componentDidUpdate, componentWillUnmount\n\nDependency array patterns:\n- [] = Run once on mount\n- [dep1, dep2] = Run when dependencies change\n- No array = Run after every render\n\nCommon mistakes to avoid:\n- Missing dependencies (use ESLint plugin)\n- Not cleaning up subscriptions\n- Infinite loops from state updates\n- Using async directly in useEffect",
          "implementation": "import { useState, useEffect } from 'react';\n\nfunction UserProfile({ userId }) {\n  const [user, setUser] = useState(null);\n  const [loading, setLoading] = useState(true);\n  \n  useEffect(() => {\n    let cancelled = false;\n    \n    async function fetchUser() {\n      setLoading(true);\n      try {\n        const response = await fetch(`/api/users/${userId}`);\n        const data = await response.json();\n        if (!cancelled) {\n          setUser(data);\n        }\n      } catch (error) {\n        console.error(error);\n      } finally {\n        if (!cancelled) {\n          setLoading(false);\n        }\n      }\n    }\n    \n    fetchUser();\n    \n    return () => {\n      cancelled = true;\n    };\n  }, [userId]);\n  \n  if (loading) return <div>Loading...</div>;\n  return <div>{user?.name}</div>;\n}",
          "example": "// Run once on mount\nuseEffect(() => {\n  console.log('Component mounted');\n}, []);\n\n// Run when dependency changes\nuseEffect(() => {\n  document.title = `Count: ${count}`;\n}, [count]);\n\n// Cleanup function\nuseEffect(() => {\n  const timer = setInterval(() => {\n    console.log('Tick');\n  }, 1000);\n  \n  return () => clearInterval(timer);\n}, []);\n\n// Event listeners\nuseEffect(() => {\n  const handleResize = () => {\n    setWidth(window.innerWidth);\n  };\n  \n  window.addEventListener('resize', handleResize);\n  \n  return () => {\n    window.removeEventListener('resize', handleResize);\n  };\n}, []);",
          "useCase": "API calls, subscriptions, timers, event listeners, DOM manipulation, local storage sync",
          "category": "Core Concepts"
        }
      ],
      "quiz": [
        {
          "id": 1,
          "question": "What does useState return?",
          "options": [
            "A single value",
            "An array with current state and setter function",
            "An object with state properties",
            "The previous state value"
          ],
          "correctAnswer": 1,
          "explanation": "useState returns an array with exactly two elements: the current state value and a function to update it. We use array destructuring: const [state, setState] = useState(initialValue);"
        },
        {
          "id": 2,
          "question": "When does useEffect run by default?",
          "options": [
            "Only on component mount",
            "Only when dependencies change",
            "After every render (mount and updates)",
            "Before every render"
          ],
          "correctAnswer": 2,
          "explanation": "By default (without a dependency array), useEffect runs after every render - both on initial mount and after every update. You can control this with the dependency array."
        },
        {
          "id": 3,
          "question": "What is the purpose of the dependency array in useEffect?",
          "options": [
            "To pass props to the effect",
            "To control when the effect runs",
            "To prevent errors",
            "To improve performance only"
          ],
          "correctAnswer": 1,
          "explanation": "The dependency array tells React when to re-run the effect. Empty array [] runs once on mount, [dep1, dep2] runs when dependencies change, and no array runs after every render."
        },
        {
          "id": 4,
          "question": "What does the cleanup function in useEffect do?",
          "options": [
            "Deletes the component",
            "Runs before effect re-runs and on unmount",
            "Clears state",
            "Removes event listeners only"
          ],
          "correctAnswer": 1,
          "explanation": "The cleanup function returned from useEffect runs before the effect runs again (if dependencies changed) and when the component unmounts. It's used to clean up subscriptions, timers, etc."
        },
        {
          "id": 5,
          "question": "What is the Virtual DOM in React?",
          "options": [
            "A copy of the real DOM",
            "Lightweight JavaScript representation of the real DOM",
            "A testing tool",
            "Browser API"
          ],
          "correctAnswer": 1,
          "explanation": "The Virtual DOM is a lightweight JavaScript object representation of the real DOM. React uses it to efficiently determine what changes need to be made to the actual DOM."
        },
        {
          "id": 6,
          "question": "What is JSX?",
          "options": [
            "A new programming language",
            "Syntax extension that looks like HTML in JavaScript",
            "A testing framework",
            "CSS preprocessor"
          ],
          "correctAnswer": 1,
          "explanation": "JSX is a syntax extension for JavaScript that looks similar to HTML. It gets transpiled to React.createElement() calls by tools like Babel."
        },
        {
          "id": 7,
          "question": "What is the difference between props and state?",
          "options": [
            "No difference",
            "Props are passed from parent, state is internal to component",
            "State is faster than props",
            "Props are deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "Props are passed from parent components and are immutable within the receiving component. State is internal to a component and can be changed by the component itself."
        },
        {
          "id": 8,
          "question": "What does useContext do?",
          "options": [
            "Creates new context",
            "Subscribes to and reads context value",
            "Updates context",
            "Deletes context"
          ],
          "correctAnswer": 1,
          "explanation": "useContext accepts a context object (created with React.createContext) and returns its current value. It subscribes the component to context changes."
        },
        {
          "id": 9,
          "question": "What is prop drilling?",
          "options": [
            "Validating props",
            "Passing props through multiple component layers",
            "Creating new props",
            "Debugging props"
          ],
          "correctAnswer": 1,
          "explanation": "Prop drilling is passing props through multiple intermediate components that don't need them, just to get data to deeply nested components. Context or state management can solve this."
        },
        {
          "id": 10,
          "question": "What does useReducer do?",
          "options": [
            "Reduces array size",
            "Alternative to useState for complex state logic",
            "Optimizes performance",
            "Reduces bundle size"
          ],
          "correctAnswer": 1,
          "explanation": "useReducer is an alternative to useState for managing complex state logic. It follows the Redux pattern with a reducer function that takes state and action, returning new state."
        },
        {
          "id": 11,
          "question": "What is a controlled component?",
          "options": [
            "Component with no bugs",
            "Form element whose value is controlled by React state",
            "Component with props",
            "Parent component"
          ],
          "correctAnswer": 1,
          "explanation": "A controlled component is a form element (like input, textarea, select) whose value is controlled by React state, making React the 'single source of truth'."
        },
        {
          "id": 12,
          "question": "What does React.memo do?",
          "options": [
            "Memoizes all components",
            "Prevents re-render if props haven't changed",
            "Improves memory",
            "Caches API calls"
          ],
          "correctAnswer": 1,
          "explanation": "React.memo is a higher-order component that memoizes the result. It prevents re-render if props haven't changed (shallow comparison), improving performance."
        },
        {
          "id": 13,
          "question": "What is the purpose of useCallback?",
          "options": [
            "Creates callbacks",
            "Memoizes function to prevent recreation on re-renders",
            "Handles async operations",
            "Validates callbacks"
          ],
          "correctAnswer": 1,
          "explanation": "useCallback returns a memoized version of the callback function that only changes if dependencies change. Useful for passing callbacks to optimized child components."
        },
        {
          "id": 14,
          "question": "What does useMemo do?",
          "options": [
            "Improves memory",
            "Memoizes computed value to avoid expensive recalculations",
            "Creates memos",
            "Caches API responses"
          ],
          "correctAnswer": 1,
          "explanation": "useMemo returns a memoized value, only recalculating when dependencies change. It's used to optimize expensive computations that shouldn't run on every render."
        },
        {
          "id": 15,
          "question": "What is the key prop used for?",
          "options": [
            "Security",
            "Helps React identify which items changed in a list",
            "Styling",
            "Event handling"
          ],
          "correctAnswer": 1,
          "explanation": "Keys help React identify which items have changed, been added, or removed in lists. They should be stable, unique identifiers (not array index if list can change)."
        },
        {
          "id": 16,
          "question": "What are React fragments?",
          "options": [
            "Broken components",
            "Way to group elements without adding extra DOM nodes",
            "Small components",
            "Testing utilities"
          ],
          "correctAnswer": 1,
          "explanation": "Fragments (<></> or <React.Fragment>) let you group a list of children without adding extra nodes to the DOM. Useful when component must return multiple elements."
        },
        {
          "id": 17,
          "question": "What is lifting state up?",
          "options": [
            "Moving state to higher component in tree",
            "Improving performance",
            "Creating global state",
            "Removing state"
          ],
          "correctAnswer": 0,
          "explanation": "Lifting state up means moving state to the closest common ancestor of components that need it. This allows sharing state between sibling components."
        },
        {
          "id": 18,
          "question": "What does useRef return?",
          "options": [
            "Reference to DOM element only",
            "Mutable ref object with .current property",
            "Component reference",
            "Function reference"
          ],
          "correctAnswer": 1,
          "explanation": "useRef returns a mutable ref object whose .current property persists across renders. It can hold DOM references or any mutable value without causing re-renders when changed."
        },
        {
          "id": 19,
          "question": "What is the difference between useRef and useState?",
          "options": [
            "No difference",
            "useRef changes don't trigger re-renders, useState changes do",
            "useRef is deprecated",
            "useState is faster"
          ],
          "correctAnswer": 1,
          "explanation": "Changing useRef's .current value doesn't trigger re-renders, while calling useState's setter does. useRef is for mutable values that don't affect render output."
        },
        {
          "id": 20,
          "question": "What are synthetic events in React?",
          "options": [
            "Fake events",
            "Cross-browser wrapper around native events",
            "Custom events only",
            "Deprecated events"
          ],
          "correctAnswer": 1,
          "explanation": "Synthetic events are React's cross-browser wrapper around native browser events. They have the same interface as native events but work consistently across browsers."
        },
        {
          "id": 21,
          "question": "What is React strict mode?",
          "options": [
            "Production mode",
            "Development mode that highlights potential problems",
            "Type checking mode",
            "Performance mode"
          ],
          "correctAnswer": 1,
          "explanation": "StrictMode is a development tool that activates additional checks and warnings. It helps identify unsafe lifecycles, legacy API usage, and unexpected side effects."
        },
        {
          "id": 22,
          "question": "What does the useLayoutEffect hook do?",
          "options": [
            "Creates layouts",
            "Runs synchronously after DOM mutations before paint",
            "Same as useEffect",
            "Manages CSS layouts"
          ],
          "correctAnswer": 1,
          "explanation": "useLayoutEffect runs synchronously after all DOM mutations but before the browser paints. Use it for reading layout and synchronously re-rendering. Use useEffect when possible."
        },
        {
          "id": 23,
          "question": "What is component composition?",
          "options": [
            "Writing CSS",
            "Building complex UIs from smaller, reusable components",
            "Compiling components",
            "Testing strategy"
          ],
          "correctAnswer": 1,
          "explanation": "Component composition is building complex UIs by combining smaller, focused components. It's a fundamental React pattern encouraging reusability and separation of concerns."
        },
        {
          "id": 24,
          "question": "What is the children prop?",
          "options": [
            "Array of child components",
            "Special prop containing content between component tags",
            "Component state",
            "DOM children"
          ],
          "correctAnswer": 1,
          "explanation": "children is a special prop automatically passed to components containing the content between opening and closing tags. Essential for component composition."
        },
        {
          "id": 25,
          "question": "What are higher-order components (HOCs)?",
          "options": [
            "Large components",
            "Functions that take component and return enhanced component",
            "Top-level components",
            "Class components"
          ],
          "correctAnswer": 1,
          "explanation": "HOCs are functions that take a component and return a new component with additional props or behavior. They're used for cross-cutting concerns and code reuse."
        },
        {
          "id": 26,
          "question": "What is render props pattern?",
          "options": [
            "Rendering properties",
            "Prop that is a function telling component what to render",
            "Style props",
            "Deprecated pattern"
          ],
          "correctAnswer": 1,
          "explanation": "Render props is a pattern where a component takes a function prop that returns React elements and calls it instead of implementing its own render logic. Enables code sharing."
        },
        {
          "id": 27,
          "question": "What does useImperativeHandle do?",
          "options": [
            "Handles imperative code",
            "Customizes ref value exposed to parent components",
            "Creates handles",
            "Error handling"
          ],
          "correctAnswer": 1,
          "explanation": "useImperativeHandle customizes the instance value exposed to parent components when using ref. Used with forwardRef to control what the parent can access."
        },
        {
          "id": 28,
          "question": "What is React.lazy used for?",
          "options": [
            "Lazy loading",
            "Code-splitting components that are loaded dynamically",
            "Performance monitoring",
            "Slow rendering"
          ],
          "correctAnswer": 1,
          "explanation": "React.lazy enables code-splitting by dynamically importing components. Used with Suspense, it loads components only when needed, reducing initial bundle size."
        },
        {
          "id": 29,
          "question": "What is the Suspense component?",
          "options": [
            "Loading spinner",
            "Component that displays fallback while waiting for lazy components",
            "Error boundary",
            "Animation component"
          ],
          "correctAnswer": 1,
          "explanation": "Suspense lets you display a fallback (like loading spinner) while waiting for lazy-loaded components or data to load. It handles loading states declaratively."
        },
        {
          "id": 30,
          "question": "What are error boundaries?",
          "options": [
            "Try-catch blocks",
            "Components that catch JavaScript errors in child tree",
            "Form validation",
            "Network error handlers"
          ],
          "correctAnswer": 1,
          "explanation": "Error boundaries are components that catch JavaScript errors anywhere in their child component tree, log errors, and display fallback UI instead of crashing the whole app."
        },
        {
          "id": 31,
          "question": "What is the forwardRef function?",
          "options": [
            "Forwards props",
            "Allows passing refs through components to children",
            "Navigation function",
            "Performance optimization"
          ],
          "correctAnswer": 1,
          "explanation": "forwardRef lets a component receive a ref and pass it to a child. It's necessary because refs aren't passed like regular props - they're handled specially by React."
        },
        {
          "id": 32,
          "question": "What is reconciliation in React?",
          "options": [
            "Bug fixing",
            "Algorithm React uses to diff Virtual DOM and update real DOM",
            "Component lifecycle",
            "State management"
          ],
          "correctAnswer": 1,
          "explanation": "Reconciliation is React's algorithm for efficiently updating the DOM. It compares Virtual DOM trees to determine minimal changes needed, then applies them to the real DOM."
        },
        {
          "id": 33,
          "question": "What does batching mean in React?",
          "options": [
            "Processing multiple files",
            "Grouping multiple state updates into single re-render",
            "Batch processing API calls",
            "Component grouping"
          ],
          "correctAnswer": 1,
          "explanation": "Batching is React's optimization where multiple state updates are grouped into a single re-render for better performance. In React 18, automatic batching applies to all updates."
        },
        {
          "id": 34,
          "question": "What is the useDebugValue hook?",
          "options": [
            "Debugging tool",
            "Displays label for custom hooks in React DevTools",
            "Console logging",
            "Error handling"
          ],
          "correctAnswer": 1,
          "explanation": "useDebugValue is used to display a label for custom hooks in React DevTools. It helps with debugging by showing readable values without affecting component behavior."
        },
        {
          "id": 35,
          "question": "What are portals in React?",
          "options": [
            "Navigation links",
            "Way to render children into DOM node outside parent hierarchy",
            "API endpoints",
            "Performance tool"
          ],
          "correctAnswer": 1,
          "explanation": "Portals provide a way to render children into a DOM node that exists outside the DOM hierarchy of the parent component. Useful for modals, tooltips, and overlays."
        },
        {
          "id": 36,
          "question": "What is prop-types used for?",
          "options": [
            "Creating props",
            "Runtime type checking for React props",
            "TypeScript replacement",
            "Performance optimization"
          ],
          "correctAnswer": 1,
          "explanation": "prop-types is a library for runtime type checking of props. It helps catch bugs by validating prop types during development. For static typing, TypeScript is preferred."
        },
        {
          "id": 37,
          "question": "What is the difference between class and functional components?",
          "options": [
            "No difference",
            "Functional components use hooks, class components use lifecycle methods",
            "Class components are faster",
            "Functional components are deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "Functional components use hooks for state and lifecycle. Class components use this.state and lifecycle methods. Functional components are now preferred for their simplicity."
        },
        {
          "id": 38,
          "question": "What does the useTransition hook do (React 18)?",
          "options": [
            "CSS transitions",
            "Marks state updates as non-urgent transitions",
            "Component transitions",
            "Animation hook"
          ],
          "correctAnswer": 1,
          "explanation": "useTransition lets you mark state updates as transitions (non-urgent), allowing React to keep UI responsive by prioritizing urgent updates over transition updates."
        },
        {
          "id": 39,
          "question": "What is the useDeferredValue hook (React 18)?",
          "options": [
            "Delays all updates",
            "Defers updating less critical parts of UI",
            "Async operations",
            "Timeout management"
          ],
          "correctAnswer": 1,
          "explanation": "useDeferredValue lets you defer updating a part of the UI. It returns a deferred version of the value that may lag behind the actual value to keep UI responsive."
        },
        {
          "id": 40,
          "question": "What is concurrent rendering (React 18)?",
          "options": [
            "Parallel processing",
            "React can interrupt rendering to handle more urgent updates",
            "Multi-threading",
            "Faster rendering"
          ],
          "correctAnswer": 1,
          "explanation": "Concurrent rendering allows React to interrupt rendering work to handle higher priority updates. It keeps apps responsive even during heavy rendering by prioritizing user interactions."
        },
        {
          "id": 41,
          "question": "What does React.startTransition do?",
          "options": [
            "Starts animation",
            "Marks updates as non-urgent transitions",
            "Begins component lifecycle",
            "Initializes state"
          ],
          "correctAnswer": 1,
          "explanation": "startTransition marks updates inside its callback as transitions (non-urgent), allowing React to keep the UI responsive while these updates are processing."
        },
        {
          "id": 42,
          "question": "What is hydration in React?",
          "options": [
            "Adding water",
            "Attaching event listeners to server-rendered HTML",
            "Data fetching",
            "State initialization"
          ],
          "correctAnswer": 1,
          "explanation": "Hydration is the process where React attaches event listeners and makes server-rendered HTML interactive on the client. Used in SSR applications."
        },
        {
          "id": 43,
          "question": "What is the difference between createElement and cloneElement?",
          "options": [
            "No difference",
            "createElement creates new element, cloneElement clones and modifies existing",
            "cloneElement is deprecated",
            "createElement is faster"
          ],
          "correctAnswer": 1,
          "explanation": "createElement creates a new React element. cloneElement clones an element and returns a new element with modified props. Useful for extending components."
        },
        {
          "id": 44,
          "question": "What are uncontrolled components?",
          "options": [
            "Components with bugs",
            "Form elements that maintain their own state in DOM",
            "Components without props",
            "Deprecated pattern"
          ],
          "correctAnswer": 1,
          "explanation": "Uncontrolled components store form data in the DOM itself (not React state). You use refs to access values when needed. Simpler but less control than controlled components."
        },
        {
          "id": 45,
          "question": "What is the useId hook (React 18)?",
          "options": [
            "Gets component ID",
            "Generates unique IDs for accessibility attributes",
            "User authentication",
            "Database IDs"
          ],
          "correctAnswer": 1,
          "explanation": "useId generates unique IDs that are stable across server and client renders. Used for accessibility attributes like aria-describedby, ensuring IDs match during hydration."
        },
        {
          "id": 46,
          "question": "What does the useSyncExternalStore hook do?",
          "options": [
            "Syncs with database",
            "Subscribes to external store with concurrent rendering support",
            "Synchronizes components",
            "External API calls"
          ],
          "correctAnswer": 1,
          "explanation": "useSyncExternalStore subscribes to external stores (like Redux) in a way that's safe for concurrent rendering. It helps library authors build React-compatible stores."
        },
        {
          "id": 47,
          "question": "What is code splitting?",
          "options": [
            "Dividing code files",
            "Technique to split bundle into smaller chunks loaded on demand",
            "Code review process",
            "Testing strategy"
          ],
          "correctAnswer": 1,
          "explanation": "Code splitting breaks your bundle into smaller chunks that can be loaded on demand. React.lazy and dynamic imports enable this, reducing initial load time."
        },
        {
          "id": 48,
          "question": "What is the purpose of defaultProps?",
          "options": [
            "Default styling",
            "Defines default values for props",
            "Required props",
            "Prop validation"
          ],
          "correctAnswer": 1,
          "explanation": "defaultProps defines default values for props when they're not provided by the parent. In functional components, you can also use default parameters."
        },
        {
          "id": 49,
          "question": "What does shouldComponentUpdate do (class components)?",
          "options": [
            "Forces update",
            "Lets component decide if it should re-render on state/prop changes",
            "Validates updates",
            "Schedules updates"
          ],
          "correctAnswer": 1,
          "explanation": "shouldComponentUpdate is a lifecycle method that returns boolean indicating if component should re-render. Used for performance optimization. React.memo does similar for functional components."
        },
        {
          "id": 50,
          "question": "What is PureComponent?",
          "options": [
            "Component without state",
            "Component that implements shallow prop/state comparison",
            "Function component",
            "Testing component"
          ],
          "correctAnswer": 1,
          "explanation": "PureComponent is a class that implements shouldComponentUpdate with shallow comparison of props and state. It prevents unnecessary re-renders when data hasn't changed."
        },
        {
          "id": 51,
          "question": "What are render props used for?",
          "options": [
            "Styling",
            "Sharing code between components using prop that is a function",
            "Performance",
            "Validation"
          ],
          "correctAnswer": 1,
          "explanation": "Render props pattern uses a prop (often called 'render' or 'children') that's a function, allowing components to share code without using HOCs or inheritance."
        },
        {
          "id": 52,
          "question": "What is the Context API?",
          "options": [
            "Backend API",
            "Way to pass data through component tree without props",
            "Storage API",
            "Network API"
          ],
          "correctAnswer": 1,
          "explanation": "Context provides a way to share values between components without passing props through every level. Creates a global state accessible to any component in the tree."
        },
        {
          "id": 53,
          "question": "What does displayName do?",
          "options": [
            "Shows component name in UI",
            "Used by DevTools to display component name",
            "User display name",
            "Screen name"
          ],
          "correctAnswer": 1,
          "explanation": "displayName is used by React DevTools to display a name for the component. Automatically inferred from function name, but can be set explicitly for HOCs or anonymous components."
        },
        {
          "id": 54,
          "question": "What is the React.Children API?",
          "options": [
            "Child components only",
            "Utilities for working with children opaque data structure",
            "DOM children",
            "Nested components"
          ],
          "correctAnswer": 1,
          "explanation": "React.Children provides utilities for dealing with the children data structure. Methods like map, forEach, count, toArray, and only help manipulate and inspect children."
        },
        {
          "id": 55,
          "question": "What does getDerivedStateFromProps do?",
          "options": [
            "Gets props from state",
            "Static method that updates state based on props changes",
            "Derives props",
            "Deprecated method"
          ],
          "correctAnswer": 1,
          "explanation": "getDerivedStateFromProps is a static lifecycle method that runs before every render, allowing state to be updated based on props. Rarely needed - usually better alternatives exist."
        },
        {
          "id": 56,
          "question": "What is React DevTools?",
          "options": [
            "IDE for React",
            "Browser extension for inspecting React component tree",
            "Testing framework",
            "Build tool"
          ],
          "correctAnswer": 1,
          "explanation": "React DevTools is a browser extension that lets you inspect the React component tree, props, state, hooks, and performance. Essential tool for React development."
        },
        {
          "id": 57,
          "question": "What is the difference between componentDidMount and useEffect?",
          "options": [
            "No difference",
            "componentDidMount runs once, useEffect can run multiple times",
            "useEffect is deprecated",
            "componentDidMount is faster"
          ],
          "correctAnswer": 1,
          "explanation": "componentDidMount runs once after mount. useEffect behavior depends on dependencies: empty array mimics componentDidMount, but can also run on updates or every render."
        },
        {
          "id": 58,
          "question": "What does componentWillUnmount do?",
          "options": [
            "Prevents unmounting",
            "Cleanup before component is removed from DOM",
            "Unmounts component",
            "Validates unmounting"
          ],
          "correctAnswer": 1,
          "explanation": "componentWillUnmount is called before component is unmounted and destroyed. Used for cleanup like canceling timers, network requests, or subscriptions. In hooks: useEffect cleanup function."
        },
        {
          "id": 59,
          "question": "What is the difference between componentDidUpdate and useEffect?",
          "options": [
            "No difference",
            "componentDidUpdate runs after updates only, useEffect can run on mount too",
            "useEffect is newer",
            "componentDidUpdate is faster"
          ],
          "correctAnswer": 1,
          "explanation": "componentDidUpdate runs after every update (not mount). useEffect runs after mount and optionally after updates depending on dependencies. Different timing and control."
        },
        {
          "id": 60,
          "question": "What are custom hooks?",
          "options": [
            "Built-in hooks",
            "JavaScript functions starting with 'use' that can use hooks",
            "UI components",
            "Styling hooks"
          ],
          "correctAnswer": 1,
          "explanation": "Custom hooks are JavaScript functions whose names start with 'use' and may call other hooks. They extract component logic into reusable functions, promoting code reuse."
        },
        {
          "id": 61,
          "question": "What rules must hooks follow?",
          "options": [
            "No rules",
            "Only call at top level and only in React functions",
            "Can be called anywhere",
            "Must be called in order"
          ],
          "correctAnswer": 1,
          "explanation": "Rules of Hooks: 1) Only call hooks at the top level (not in loops, conditions, or nested functions). 2) Only call hooks from React functions or custom hooks."
        },
        {
          "id": 62,
          "question": "What is React Fiber?",
          "options": [
            "CSS framework",
            "Reimplementation of React's core algorithm for better rendering",
            "Network library",
            "Testing tool"
          ],
          "correctAnswer": 1,
          "explanation": "React Fiber is the new reconciliation algorithm introduced in React 16. It enables features like time slicing, prioritization, and concurrent rendering for better performance."
        },
        {
          "id": 63,
          "question": "What does getSnapshotBeforeUpdate do?",
          "options": [
            "Takes screenshot",
            "Captures DOM info before updates are committed",
            "Gets component snapshot",
            "Performance monitoring"
          ],
          "correctAnswer": 1,
          "explanation": "getSnapshotBeforeUpdate is called right before DOM updates. It captures information (like scroll position) that may change, passing it to componentDidUpdate. Rarely needed."
        },
        {
          "id": 64,
          "question": "What is the difference between state and props?",
          "options": [
            "No difference",
            "State is mutable and internal, props are immutable and external",
            "Props are faster",
            "State is deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "State is mutable data managed within the component. Props are immutable data passed from parent. State can be changed by component, props cannot be changed by receiving component."
        },
        {
          "id": 65,
          "question": "What is the useState lazy initialization?",
          "options": [
            "Slow initialization",
            "Passing function to useState that runs only on initial render",
            "Delayed state",
            "Performance issue"
          ],
          "correctAnswer": 1,
          "explanation": "Lazy initialization passes a function to useState that's only executed once during initial render. Useful for expensive computations: useState(() => expensiveFunc())."
        },
        {
          "id": 66,
          "question": "What is React Router?",
          "options": [
            "Backend router",
            "Library for routing and navigation in React apps",
            "Network router",
            "Built-in React feature"
          ],
          "correctAnswer": 1,
          "explanation": "React Router is a popular library for handling routing and navigation in React applications. It enables single-page app navigation without full page reloads."
        },
        {
          "id": 67,
          "question": "What is the difference between Link and NavLink in React Router?",
          "options": [
            "No difference",
            "NavLink can style itself based on active state",
            "Link is deprecated",
            "NavLink is for navigation bar only"
          ],
          "correctAnswer": 1,
          "explanation": "NavLink extends Link with the ability to automatically apply styles or classes when the route is active, making it useful for navigation menus."
        },
        {
          "id": 68,
          "question": "What does useNavigate do (React Router v6)?",
          "options": [
            "Creates navigation",
            "Returns function for programmatic navigation",
            "Validates routes",
            "Gets current route"
          ],
          "correctAnswer": 1,
          "explanation": "useNavigate returns a function that lets you navigate programmatically. Replaces useHistory from v5. Used for navigation after form submission, authentication, etc."
        },
        {
          "id": 69,
          "question": "What is the useParams hook (React Router)?",
          "options": [
            "Gets query parameters",
            "Returns object of URL parameters from current route",
            "Function parameters",
            "Component parameters"
          ],
          "correctAnswer": 1,
          "explanation": "useParams returns an object of key/value pairs of URL parameters from the current route. Used to access dynamic route segments like /users/:id."
        },
        {
          "id": 70,
          "question": "What is the difference between BrowserRouter and HashRouter?",
          "options": [
            "No difference",
            "BrowserRouter uses HTML5 history API, HashRouter uses URL hash",
            "HashRouter is deprecated",
            "BrowserRouter is faster"
          ],
          "correctAnswer": 1,
          "explanation": "BrowserRouter uses HTML5 history API for clean URLs. HashRouter uses URL hash (#) for routing. BrowserRouter requires server configuration, HashRouter works without it."
        },
        {
          "id": 71,
          "question": "What is Redux?",
          "options": [
            "React built-in feature",
            "State management library using single store and actions",
            "Router library",
            "Testing framework"
          ],
          "correctAnswer": 1,
          "explanation": "Redux is a predictable state container for JavaScript apps. It uses a single store, actions, and reducers to manage application state in a predictable way."
        },
        {
          "id": 72,
          "question": "What are Redux actions?",
          "options": [
            "Functions only",
            "Plain JavaScript objects describing what happened",
            "API calls",
            "Component methods"
          ],
          "correctAnswer": 1,
          "explanation": "Actions are plain objects that must have a 'type' property and optionally a payload. They describe what happened in the app and are dispatched to update state."
        },
        {
          "id": 73,
          "question": "What is a Redux reducer?",
          "options": [
            "Array.reduce method",
            "Pure function that takes state and action, returns new state",
            "Store creator",
            "Middleware"
          ],
          "correctAnswer": 1,
          "explanation": "Reducers are pure functions that take previous state and an action, returning new state. They specify how state changes in response to actions sent to the store."
        },
        {
          "id": 74,
          "question": "What is Redux middleware?",
          "options": [
            "Middle component",
            "Extension point between dispatching action and reaching reducer",
            "Backend middleware",
            "Testing tool"
          ],
          "correctAnswer": 1,
          "explanation": "Middleware provides extension point between dispatching an action and the moment it reaches the reducer. Used for logging, async actions (thunks), routing, etc."
        },
        {
          "id": 75,
          "question": "What is Redux Thunk?",
          "options": [
            "State chunk",
            "Middleware that lets action creators return functions instead of actions",
            "Testing tool",
            "Performance optimizer"
          ],
          "correctAnswer": 1,
          "explanation": "Redux Thunk is middleware that allows action creators to return functions instead of actions. These functions can dispatch actions asynchronously, useful for API calls."
        },
        {
          "id": 76,
          "question": "What is the useSelector hook (React Redux)?",
          "options": [
            "Selects components",
            "Extracts data from Redux store state",
            "CSS selector",
            "Event selector"
          ],
          "correctAnswer": 1,
          "explanation": "useSelector allows you to extract data from the Redux store state using a selector function. Component subscribes to Redux store and re-renders when selected data changes."
        },
        {
          "id": 77,
          "question": "What is the useDispatch hook (React Redux)?",
          "options": [
            "Dispatches events",
            "Returns reference to dispatch function from Redux store",
            "Component dispatcher",
            "Event dispatcher"
          ],
          "correctAnswer": 1,
          "explanation": "useDispatch returns a reference to the dispatch function from the Redux store. You use it to dispatch actions from functional components."
        },
        {
          "id": 78,
          "question": "What is immutability in React?",
          "options": [
            "Unchangeable components",
            "Not mutating data directly, creating new copies instead",
            "Constant variables",
            "Read-only props"
          ],
          "correctAnswer": 1,
          "explanation": "Immutability means not modifying data directly. Instead, create new copies with changes. React relies on this for change detection and optimization (shallow comparison)."
        },
        {
          "id": 79,
          "question": "What is React Testing Library?",
          "options": [
            "Performance testing",
            "Testing library focused on testing components like users interact with them",
            "Unit testing only",
            "Backend testing"
          ],
          "correctAnswer": 1,
          "explanation": "React Testing Library is a testing utility that encourages testing components from the user's perspective, focusing on how they interact with the app rather than implementation details."
        },
        {
          "id": 80,
          "question": "What does render function do in React Testing Library?",
          "options": [
            "Renders to browser",
            "Renders component to virtual DOM for testing",
            "Creates production build",
            "Renders HTML"
          ],
          "correctAnswer": 1,
          "explanation": "render function renders a React component into a virtual DOM for testing. It returns utilities for querying and interacting with the rendered component."
        },
        {
          "id": 81,
          "question": "What is Jest?",
          "options": [
            "CSS framework",
            "JavaScript testing framework with built-in assertions and mocking",
            "State management",
            "Build tool"
          ],
          "correctAnswer": 1,
          "explanation": "Jest is a JavaScript testing framework created by Facebook. It provides test runners, assertions, mocking, and code coverage. Commonly used with React Testing Library."
        },
        {
          "id": 82,
          "question": "What is snapshot testing?",
          "options": [
            "Performance testing",
            "Testing by comparing rendered output to saved snapshot",
            "Screenshot testing",
            "Debugging technique"
          ],
          "correctAnswer": 1,
          "explanation": "Snapshot testing captures the rendered output of a component and saves it as a reference. Future test runs compare output to the snapshot, detecting unexpected changes."
        },
        {
          "id": 83,
          "question": "What is the act function in testing?",
          "options": [
            "Action creator",
            "Ensures all updates are processed before assertions",
            "Performance function",
            "Animation function"
          ],
          "correctAnswer": 1,
          "explanation": "act ensures all updates related to state changes and effects are processed and applied before making assertions. Most testing library utilities wrap calls in act automatically."
        },
        {
          "id": 84,
          "question": "What does fireEvent do in testing?",
          "options": [
            "Creates fire animations",
            "Simulates user events for testing",
            "Error handling",
            "Performance monitoring"
          ],
          "correctAnswer": 1,
          "explanation": "fireEvent is a utility that fires DOM events. It's used to simulate user interactions like clicks, typing, etc. userEvent from @testing-library/user-event is often preferred."
        },
        {
          "id": 85,
          "question": "What is Next.js?",
          "options": [
            "State management",
            "React framework with server-side rendering and static generation",
            "Testing framework",
            "CSS framework"
          ],
          "correctAnswer": 1,
          "explanation": "Next.js is a React framework that provides features like server-side rendering, static site generation, API routes, file-based routing, and optimizations out of the box."
        },
        {
          "id": 86,
          "question": "What is Gatsby?",
          "options": [
            "State management",
            "React framework for building static sites with GraphQL",
            "Testing tool",
            "UI library"
          ],
          "correctAnswer": 1,
          "explanation": "Gatsby is a React-based framework for creating fast, static websites. It uses GraphQL for data management and provides plugins for various data sources and functionality."
        },
        {
          "id": 87,
          "question": "What is Create React App?",
          "options": [
            "React method",
            "Tool for setting up React project with zero configuration",
            "API call",
            "Component creator"
          ],
          "correctAnswer": 1,
          "explanation": "Create React App is an officially supported tool for creating single-page React applications with no build configuration. It sets up development environment with one command."
        },
        {
          "id": 88,
          "question": "What is Vite?",
          "options": [
            "State manager",
            "Fast build tool and dev server using native ES modules",
            "Testing framework",
            "Component library"
          ],
          "correctAnswer": 1,
          "explanation": "Vite is a modern build tool that provides fast cold starts and instant hot module replacement. It's becoming popular alternative to Create React App for React projects."
        },
        {
          "id": 89,
          "question": "What is ESLint?",
          "options": [
            "CSS linter",
            "Tool for identifying and fixing problems in JavaScript code",
            "Testing framework",
            "Build tool"
          ],
          "correctAnswer": 1,
          "explanation": "ESLint is a static code analysis tool for identifying problematic patterns in JavaScript code. It helps maintain code quality and catch errors early in development."
        },
        {
          "id": 90,
          "question": "What is Prettier?",
          "options": [
            "CSS framework",
            "Opinionated code formatter that enforces consistent style",
            "Testing tool",
            "Performance optimizer"
          ],
          "correctAnswer": 1,
          "explanation": "Prettier is an opinionated code formatter that automatically formats code according to a set of rules. It helps maintain consistent code style across teams."
        },
        {
          "id": 91,
          "question": "What is Babel?",
          "options": [
            "State management",
            "JavaScript compiler that transforms modern JS to browser-compatible code",
            "Testing framework",
            "Router library"
          ],
          "correctAnswer": 1,
          "explanation": "Babel is a JavaScript compiler that transforms modern JavaScript (ES6+) and JSX into backward-compatible versions that work in older browsers."
        },
        {
          "id": 92,
          "question": "What is Webpack?",
          "options": [
            "Web framework",
            "Module bundler that bundles JavaScript files and assets",
            "Testing tool",
            "Server framework"
          ],
          "correctAnswer": 1,
          "explanation": "Webpack is a module bundler that takes modules with dependencies and generates static assets. It's the build tool that Create React App uses under the hood."
        },
        {
          "id": 93,
          "question": "What is TypeScript?",
          "options": [
            "Testing framework",
            "Superset of JavaScript that adds static typing",
            "Text editor",
            "Backend framework"
          ],
          "correctAnswer": 1,
          "explanation": "TypeScript is a statically typed superset of JavaScript that compiles to plain JavaScript. It adds optional type annotations, helping catch errors during development."
        },
        {
          "id": 94,
          "question": "What is prop spreading?",
          "options": [
            "Spreading butter",
            "Using spread operator to pass all object properties as props",
            "Performance optimization",
            "State spreading"
          ],
          "correctAnswer": 1,
          "explanation": "Prop spreading uses the spread operator (...) to pass all properties of an object as props to a component: <Component {...props} />. Convenient but use carefully."
        },
        {
          "id": 95,
          "question": "What is the difference between controlled and uncontrolled components?",
          "options": [
            "No difference",
            "Controlled components use React state, uncontrolled use DOM state",
            "Controlled are faster",
            "Uncontrolled are deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "Controlled components store form data in React state (single source of truth). Uncontrolled components store data in DOM, accessed via refs when needed."
        },
        {
          "id": 96,
          "question": "What is React.StrictMode?",
          "options": [
            "Production mode",
            "Tool to highlight potential problems in development",
            "Security mode",
            "Performance mode"
          ],
          "correctAnswer": 1,
          "explanation": "StrictMode is a development tool that activates additional checks and warnings. It doesn't render visible UI, just identifies potential problems in the application."
        },
        {
          "id": 97,
          "question": "What is the difference between mounting and updating?",
          "options": [
            "No difference",
            "Mounting is initial render, updating is subsequent re-renders",
            "Mounting is faster",
            "Updating is deprecated"
          ],
          "correctAnswer": 1,
          "explanation": "Mounting occurs when a component is first created and inserted into the DOM. Updating occurs when component re-renders due to state or prop changes."
        },
        {
          "id": 98,
          "question": "What is the key prop warning about?",
          "options": [
            "Security warning",
            "Warning when rendering lists without unique keys",
            "Performance warning",
            "Syntax warning"
          ],
          "correctAnswer": 1,
          "explanation": "React warns when rendering lists without unique key props. Keys help React identify which items changed, improving performance and preventing bugs with component state."
        },
        {
          "id": 99,
          "question": "What is dangerouslySetInnerHTML?",
          "options": [
            "Security feature",
            "React's replacement for innerHTML for setting HTML directly",
            "Error handler",
            "Testing utility"
          ],
          "correctAnswer": 1,
          "explanation": "dangerouslySetInnerHTML is React's replacement for innerHTML. The name warns that it's dangerous (XSS risk). Only use with sanitized content: dangerouslySetInnerHTML={{__html: content}}."
        },
        {
          "id": 100,
          "question": "What is the difference between React and React DOM?",
          "options": [
            "No difference",
            "React is core library, React DOM provides DOM-specific methods",
            "React DOM is deprecated",
            "React is faster"
          ],
          "correctAnswer": 1,
          "explanation": "React is the core library with component logic. React DOM provides DOM-specific methods like render() and hydrate(). This separation allows React to work with different renderers (Native, VR, etc.)."
        }
      ],
      "topicCount": 3,
      "quizCount": 100
    },
    {
      "slug": "system-design",
      "meta": {
        "title": "System Design Interview Preparation",
        "description": "Master system design interviews with HLD, LLD, architecture patterns, capacity planning, and real-world company designs including Netflix, Facebook, YouTube, Uber, and more."
      },
      "topics": [
        {
          "id": "sd-process",
          "title": "System Design Interview Framework",
          "category": "Foundations",
          "description": "A repeatable framework to answer any system design interview — from requirements to trade-offs.",
          "explanation": "System design interviews evaluate your ability to break down ambiguous problems into well-structured architectures. A repeatable framework gives you confidence and ensures you cover all dimensions interviewers care about.\n\nThe 7-step framework:\n1. Clarify requirements (functional + non-functional): Ask what the system must do, expected scale, latency targets, consistency needs.\n2. Estimate scale: Calculate QPS, storage, bandwidth. This shapes every downstream decision.\n3. Define API contract: List the core endpoints/RPCs with input/output. Helps anchor the discussion.\n4. High-level design: Draw the major components — clients, load balancers, services, databases, caches, queues.\n5. Deep dive: Pick the most complex or risky subsystem and design it in detail — data model, algorithms, failure handling.\n6. Discuss bottlenecks: Identify single points of failure, hot partitions, thundering herds. Propose mitigations.\n7. Wrap up with reliability/observability/rollout: How do you deploy safely? What metrics do you monitor? How do you roll back?\n\nInterviewers evaluate: structured thinking, trade-off articulation, depth in at least one area, awareness of failure modes, and communication clarity. They care more about your reasoning process than a perfect architecture.",
          "code": "// Step-by-step interview template\n\n// 1. Requirements\nFunctional: What must the system do?\nNon-functional: Scale, latency, consistency, availability\n\n// 2. Scale estimation\nDAU = 100M\nRead QPS = DAU * avg_reads / 86400\nWrite QPS = DAU * avg_writes / 86400\nStorage = writes_per_day * avg_size * retention_days\n\n// 3. API contract\nPOST /v1/resource\n  Headers: Idempotency-Key, Authorization\n  Body: { payload }\n  Response: { id, status, created_at }\n\nGET /v1/resource/:id\n  Response: { id, data, metadata }\n\n// 4. High-level design\nClient → CDN → Load Balancer → API Gateway\n  → Service A → Database (primary)\n  → Service B → Cache → Database (replica)\n  → Queue → Workers → External APIs\n\n// 5. Latency budget\nClient→Gateway:  20ms\nGateway→Service:  30ms\nService→Cache:    5ms (hit) / 40ms (miss→DB)\nTotal p95:        ~95ms",
          "example": "// Example: Designing a URL shortener in 45 minutes\n\n// Minutes 0-5: Clarify\n// - Shorten URLs, redirect, analytics?\n// - Scale: 100M URLs/month, 10:1 read/write ratio\n// - Latency: <100ms redirect\n// - Custom aliases? Expiration?\n\n// Minutes 5-10: Estimate\n// Write: 100M/30/86400 ≈ 40 QPS\n// Read: 400 QPS, peak 2000 QPS\n// Storage: 100M * 500B * 12mo = 600GB/year\n\n// Minutes 10-15: API\n// POST /shorten { long_url, custom_alias?, ttl? } → { short_url }\n// GET /:code → 301 redirect\n\n// Minutes 15-30: Design + Deep dive\n// Key generation: base62(counter) or hash\n// DB: id, short_code, long_url, created_at, expires_at\n// Cache: Redis for hot URLs (90% cache hit expected)\n\n// Minutes 30-40: Bottlenecks\n// Counter collision? → Atomic increment or pre-generated ranges\n// Cache stampede? → Probabilistic early expiry\n// Analytics? → Async via Kafka\n\n// Minutes 40-45: Wrap up\n// Deploy: Blue-green with canary\n// Monitor: redirect latency, cache hit ratio, error rate",
          "useCase": "Every system design interview — this framework applies universally to any design question from URL shortener to distributed database.",
          "interviewQuestions": [
            {
              "question": "What is the first thing to do in a system design interview?",
              "answer": "Clarify requirements and constraints before drawing any architecture. Ask about functional requirements (what the system does), non-functional requirements (scale, latency, consistency), and scope boundaries (what's in/out)."
            },
            {
              "question": "Why estimate scale early in the interview?",
              "answer": "Scale assumptions drive every design decision — storage type, caching strategy, partitioning scheme, protocol choice, and infrastructure sizing. A system for 1K users vs 100M users looks fundamentally different."
            },
            {
              "question": "How do you choose which subsystem to deep-dive?",
              "answer": "Pick the highest-risk, most central, or most technically interesting subsystem. This demonstrates design depth. Examples: the ranking pipeline in a feed, the matching algorithm in ride-sharing, the seat lock mechanism in ticketing."
            },
            {
              "question": "What makes a good API contract in a design interview?",
              "answer": "Clear endpoint names, HTTP methods, request/response schemas, idempotency keys for writes, pagination for lists, and versioning. It anchors the discussion and shows you think about client-server contracts."
            },
            {
              "question": "How do you handle conflicting requirements like strong consistency + ultra-low latency?",
              "answer": "State the trade-off explicitly. Propose bounded-scope strong consistency (e.g., strong for writes, eventual for reads). Use techniques like quorum writes with local reads, or accept slightly higher latency for critical paths."
            },
            {
              "question": "What is the difference between functional and non-functional requirements?",
              "answer": "Functional: what the system does (create user, send message, process payment). Non-functional: how well it does it (99.99% availability, <200ms p99 latency, handle 10K QPS, data encryption at rest)."
            },
            {
              "question": "How do you estimate storage requirements?",
              "answer": "Calculate: (writes per day) × (average record size) × (retention period) × (replication factor). Example: 10M writes/day × 1KB × 365 days × 3 replicas = ~11TB/year."
            },
            {
              "question": "What should you discuss in the wrap-up phase?",
              "answer": "Deployment strategy (canary, blue-green), monitoring (SLIs: latency, error rate, throughput), alerting thresholds, rollback plan, and future scalability considerations."
            },
            {
              "question": "How do you identify bottlenecks in your design?",
              "answer": "Trace the request path end-to-end. Look for: single points of failure, components with no horizontal scaling, hotspot-prone data patterns, synchronous calls that could be async, and missing caches."
            },
            {
              "question": "When should you use asynchronous processing vs synchronous?",
              "answer": "Sync when the client needs the result immediately (login, payment confirmation). Async when the result can be delivered later (email sending, video processing, analytics). Async absorbs traffic spikes and improves responsiveness."
            }
          ],
          "exercises": [
            {
              "type": "framework",
              "question": "Design a 45-minute interview flow for designing Twitter. Allocate time by section and list what to cover in each phase.",
              "answer": "0-5 min: Requirements (tweets, timeline, follow, search, notifications). 5-10 min: Estimate (500M DAU, 600M tweets/day, 300K QPS reads). 10-15 min: APIs (POST /tweet, GET /timeline, POST /follow). 15-30 min: Design (fan-out, timeline cache, tweet storage). 30-40 min: Deep-dive (fan-out-on-write vs read). 40-45 min: Bottlenecks + monitoring."
            },
            {
              "type": "estimation",
              "question": "Estimate QPS and storage for a photo-sharing app with 200M DAU, where each user uploads 2 photos/day and views 100 photos/day.",
              "answer": "Write QPS: 200M × 2 / 86400 ≈ 4,600 QPS. Read QPS: 200M × 100 / 86400 ≈ 231,000 QPS. Storage: 400M photos/day × 2MB avg × 365 = ~292PB/year (before compression/dedup)."
            },
            {
              "type": "scenario",
              "question": "Given 10K QPS and a 99.99% availability target, identify the top 3 architecture constraints.",
              "answer": "1) No single point of failure — every component needs redundancy. 2) Health checks + automatic failover — max 52 min downtime/year. 3) Graceful degradation — serve partial results rather than failing entirely."
            },
            {
              "type": "tricky",
              "question": "What if requirements conflict: strict consistency + ultra-low latency + high availability?",
              "answer": "CAP theorem says you can't have all three during a network partition. Propose: strong consistency on the write path (accept higher latency), eventual consistency on the read path (fast + available). Use quorum writes with cached reads."
            },
            {
              "type": "design",
              "question": "Draft an API contract for a ride-sharing service with at least 5 endpoints.",
              "answer": "POST /v1/ride/request {pickup, destination, rider_id}. GET /v1/ride/:id. PUT /v1/ride/:id/accept {driver_id}. PUT /v1/ride/:id/complete. GET /v1/ride/:id/eta. POST /v1/ride/:id/cancel. GET /v1/driver/:id/nearby-rides."
            },
            {
              "type": "estimation",
              "question": "Calculate bandwidth for a video streaming service with 10M concurrent viewers at 5Mbps average bitrate.",
              "answer": "Bandwidth = 10M × 5Mbps = 50Tbps. With CDN serving 95% from edge: origin bandwidth = 50Tbps × 0.05 = 2.5Tbps."
            },
            {
              "type": "debug",
              "question": "Your system design has a database receiving 50K write QPS but it maxes out at 10K. List three immediate mitigations.",
              "answer": "1) Write-behind cache/queue: buffer writes and batch-insert. 2) Shard the database across 5+ nodes. 3) Move non-critical writes to async processing via message queue."
            },
            {
              "type": "scenario",
              "question": "You're 30 minutes into a 45-minute interview and realize you haven't discussed caching. How do you recover?",
              "answer": "Acknowledge the gap, quickly add cache layer to the diagram with clear reasoning: 'For the read-heavy path here, I'd add Redis with cache-aside pattern, TTL=5min, to reduce DB read load from 100K to ~10K QPS.'"
            },
            {
              "type": "framework",
              "question": "List 5 non-functional requirements that change the architecture significantly when increased 10x.",
              "answer": "1) QPS: requires horizontal scaling/sharding. 2) Storage: requires distributed storage/archival. 3) Latency target: requires caching/CDN/edge compute. 4) Availability: requires multi-region/failover. 5) Data consistency: requires consensus protocols/quorum."
            },
            {
              "type": "output",
              "question": "If a system has 99.9% availability SLA and processes 1M requests/day, how many failures per day are acceptable?",
              "answer": "1M × 0.001 = 1,000 failed requests per day. That's about 42 per hour or ~1 every 86 seconds."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Back-of-envelope calculator for QPS and storage",
              "code": "function estimateScale({ dau, readsPerUser, writesPerUser, avgRecordBytes, retentionDays, replicationFactor }) {\n  const SECONDS_PER_DAY = 86400;\n  const readQPS = Math.ceil((dau * readsPerUser) / SECONDS_PER_DAY);\n  const writeQPS = Math.ceil((dau * writesPerUser) / SECONDS_PER_DAY);\n  const peakReadQPS = readQPS * 3; // 3x peak multiplier\n  const peakWriteQPS = writeQPS * 3;\n  const dailyStorage = dau * writesPerUser * avgRecordBytes;\n  const totalStorage = dailyStorage * retentionDays * replicationFactor;\n\n  return {\n    readQPS, writeQPS,\n    peakReadQPS, peakWriteQPS,\n    dailyStorageGB: (dailyStorage / 1e9).toFixed(2),\n    totalStorageTB: (totalStorage / 1e12).toFixed(2),\n  };\n}\n\nconsole.log(estimateScale({\n  dau: 100_000_000,\n  readsPerUser: 20,\n  writesPerUser: 2,\n  avgRecordBytes: 500,\n  retentionDays: 365,\n  replicationFactor: 3,\n}));",
              "output": "{\n  readQPS: 23149,\n  writeQPS: 2315,\n  peakReadQPS: 69447,\n  peakWriteQPS: 6945,\n  dailyStorageGB: '100.00',\n  totalStorageTB: '109.50'\n}"
            },
            {
              "question": "Program 2: Latency budget calculator",
              "code": "function latencyBudget(components) {\n  let total = 0;\n  const breakdown = components.map(c => {\n    total += c.p95;\n    return `${c.name}: ${c.p95}ms`;\n  });\n  return { breakdown, totalP95: total, withinSLA: total <= 200 };\n}\n\nconst result = latencyBudget([\n  { name: 'Client→LB', p95: 10 },\n  { name: 'LB→Gateway', p95: 5 },\n  { name: 'Gateway→AuthService', p95: 15 },\n  { name: 'Gateway→AppService', p95: 25 },\n  { name: 'AppService→Cache', p95: 3 },\n  { name: 'Cache miss→DB', p95: 35 },\n  { name: 'Response serialization', p95: 5 },\n]);\nconsole.log(result);",
              "output": "{\n  breakdown: [\n    'Client→LB: 10ms',\n    'LB→Gateway: 5ms',\n    'Gateway→AuthService: 15ms',\n    'Gateway→AppService: 25ms',\n    'AppService→Cache: 3ms',\n    'Cache miss→DB: 35ms',\n    'Response serialization: 5ms'\n  ],\n  totalP95: 98,\n  withinSLA: true\n}"
            },
            {
              "question": "Program 3: Availability calculator (nines)",
              "code": "function availabilityCalc(nines) {\n  const availability = 1 - Math.pow(10, -nines);\n  const downtimeMinutesPerYear = (1 - availability) * 365.25 * 24 * 60;\n  const downtimePerMonth = downtimeMinutesPerYear / 12;\n  return {\n    availability: (availability * 100).toFixed(nines) + '%',\n    downtimePerYear: downtimeMinutesPerYear.toFixed(2) + ' min',\n    downtimePerMonth: downtimePerMonth.toFixed(2) + ' min',\n  };\n}\n\n[2, 3, 4, 5].forEach(n => {\n  console.log(`${n} nines:`, availabilityCalc(n));\n});",
              "output": "2 nines: { availability: '99.00%', downtimePerYear: '5259.60 min', downtimePerMonth: '438.30 min' }\n3 nines: { availability: '99.900%', downtimePerYear: '525.96 min', downtimePerMonth: '43.83 min' }\n4 nines: { availability: '99.9900%', downtimePerYear: '52.60 min', downtimePerMonth: '4.38 min' }\n5 nines: { availability: '99.99900%', downtimePerYear: '5.26 min', downtimePerMonth: '0.44 min' }"
            },
            {
              "question": "Program 4: API contract skeleton generator",
              "code": "function generateAPIContract(resource) {\n  return {\n    endpoints: [\n      {\n        method: 'POST', path: `/v1/${resource}`,\n        headers: ['Authorization: Bearer <token>', 'Idempotency-Key: <uuid>'],\n        body: `{ ...${resource}Data }`,\n        response: `{ id, ...${resource}Data, created_at }`,\n      },\n      {\n        method: 'GET', path: `/v1/${resource}/:id`,\n        response: `{ id, ...${resource}Data, metadata }`,\n      },\n      {\n        method: 'GET', path: `/v1/${resource}?cursor=<token>&limit=20`,\n        response: `{ items: [...], next_cursor, has_more }`,\n      },\n      {\n        method: 'PUT', path: `/v1/${resource}/:id`,\n        body: `{ ...updatedFields }`,\n        response: `{ id, ...updated, updated_at }`,\n      },\n      {\n        method: 'DELETE', path: `/v1/${resource}/:id`,\n        response: `{ deleted: true }`,\n      },\n    ],\n  };\n}\n\nconsole.log(JSON.stringify(generateAPIContract('order'), null, 2));",
              "output": "{\n  \"endpoints\": [\n    { \"method\": \"POST\", \"path\": \"/v1/order\", ... },\n    { \"method\": \"GET\", \"path\": \"/v1/order/:id\", ... },\n    { \"method\": \"GET\", \"path\": \"/v1/order?cursor=<token>&limit=20\", ... },\n    { \"method\": \"PUT\", \"path\": \"/v1/order/:id\", ... },\n    { \"method\": \"DELETE\", \"path\": \"/v1/order/:id\", ... }\n  ]\n}"
            },
            {
              "question": "Program 5: SLA error budget tracker",
              "code": "function errorBudget({ slaPercent, totalRequests, failedRequests }) {\n  const budgetRequests = Math.floor(totalRequests * (1 - slaPercent / 100));\n  const remaining = budgetRequests - failedRequests;\n  const burnRate = (failedRequests / budgetRequests * 100).toFixed(1);\n  return {\n    sla: slaPercent + '%',\n    totalBudget: budgetRequests,\n    used: failedRequests,\n    remaining: Math.max(0, remaining),\n    burnRate: burnRate + '%',\n    alert: remaining < budgetRequests * 0.2 ? 'WARNING: <20% budget left' : 'OK',\n  };\n}\n\nconsole.log(errorBudget({ slaPercent: 99.9, totalRequests: 1_000_000, failedRequests: 800 }));",
              "output": "{\n  sla: '99.9%',\n  totalBudget: 1000,\n  used: 800,\n  remaining: 200,\n  burnRate: '80.0%',\n  alert: 'WARNING: <20% budget left'\n}"
            },
            {
              "question": "Program 6: Capacity planner for database shards",
              "code": "function planShards({ totalQPS, qpsPerShard, totalStorageTB, storagePerShardTB, replicationFactor }) {\n  const shardsByQPS = Math.ceil(totalQPS / qpsPerShard);\n  const shardsByStorage = Math.ceil(totalStorageTB / storagePerShardTB);\n  const minShards = Math.max(shardsByQPS, shardsByStorage);\n  const totalNodes = minShards * replicationFactor;\n  return { shardsByQPS, shardsByStorage, minShards, replicationFactor, totalNodes };\n}\n\nconsole.log(planShards({\n  totalQPS: 50000,\n  qpsPerShard: 5000,\n  totalStorageTB: 20,\n  storagePerShardTB: 2,\n  replicationFactor: 3,\n}));",
              "output": "{ shardsByQPS: 10, shardsByStorage: 10, minShards: 10, replicationFactor: 3, totalNodes: 30 }"
            },
            {
              "question": "Program 7: Request flow tracer with timing",
              "code": "function traceRequest(steps) {\n  let elapsed = 0;\n  const trace = steps.map((s, i) => {\n    elapsed += s.duration;\n    return `[${elapsed}ms] Step ${i + 1}: ${s.name} (${s.duration}ms) ${s.async ? '[async]' : '[sync]'}`;\n  });\n  const syncTime = steps.filter(s => !s.async).reduce((sum, s) => sum + s.duration, 0);\n  return { trace, totalElapsed: elapsed, criticalPathMs: syncTime };\n}\n\nconsole.log(traceRequest([\n  { name: 'Auth check', duration: 10, async: false },\n  { name: 'Load user', duration: 20, async: false },\n  { name: 'Fetch data', duration: 35, async: false },\n  { name: 'Send analytics', duration: 15, async: true },\n  { name: 'Serialize response', duration: 5, async: false },\n]));",
              "output": "{\n  trace: [\n    '[10ms] Step 1: Auth check (10ms) [sync]',\n    '[30ms] Step 2: Load user (20ms) [sync]',\n    '[65ms] Step 3: Fetch data (35ms) [sync]',\n    '[80ms] Step 4: Send analytics (15ms) [async]',\n    '[85ms] Step 5: Serialize response (5ms) [sync]'\n  ],\n  totalElapsed: 85,\n  criticalPathMs: 70\n}"
            },
            {
              "question": "Program 8: Trade-off matrix scorer",
              "code": "function scoreTradeoffs(options, criteria) {\n  return options.map(opt => {\n    const total = criteria.reduce((sum, c) => sum + (opt.scores[c.name] * c.weight), 0);\n    return { option: opt.name, total: total.toFixed(1), breakdown: opt.scores };\n  }).sort((a, b) => b.total - a.total);\n}\n\nconst result = scoreTradeoffs(\n  [\n    { name: 'SQL (Postgres)', scores: { consistency: 9, scalability: 6, latency: 7, complexity: 4 } },\n    { name: 'NoSQL (Cassandra)', scores: { consistency: 5, scalability: 9, latency: 8, complexity: 7 } },\n    { name: 'Cache (Redis)', scores: { consistency: 3, scalability: 8, latency: 10, complexity: 3 } },\n  ],\n  [\n    { name: 'consistency', weight: 0.3 },\n    { name: 'scalability', weight: 0.3 },\n    { name: 'latency', weight: 0.25 },\n    { name: 'complexity', weight: 0.15 },\n  ]\n);\nconsole.log(result);",
              "output": "[\n  { option: 'NoSQL (Cassandra)', total: '7.3', breakdown: {...} },\n  { option: 'Cache (Redis)', total: '6.3', breakdown: {...} },\n  { option: 'SQL (Postgres)', total: '6.5', breakdown: {...} }\n]"
            },
            {
              "question": "Program 9: Idempotency key generator and validator",
              "code": "const crypto = require('crypto');\n\nclass IdempotencyStore {\n  constructor() { this.store = new Map(); }\n\n  generateKey(userId, action, payload) {\n    const hash = crypto.createHash('sha256')\n      .update(`${userId}:${action}:${JSON.stringify(payload)}`)\n      .digest('hex').slice(0, 16);\n    return `idem_${hash}`;\n  }\n\n  process(key, handler) {\n    if (this.store.has(key)) {\n      return { status: 'duplicate', result: this.store.get(key) };\n    }\n    const result = handler();\n    this.store.set(key, result);\n    return { status: 'processed', result };\n  }\n}\n\nconst store = new IdempotencyStore();\nconst key = store.generateKey('user123', 'create_order', { item: 'book', qty: 1 });\nconsole.log('Key:', key);\nconsole.log('First:', store.process(key, () => ({ orderId: 'ORD-001' })));\nconsole.log('Retry:', store.process(key, () => ({ orderId: 'ORD-002' })));",
              "output": "Key: idem_a3f8c2e91b4d7e05\nFirst: { status: 'processed', result: { orderId: 'ORD-001' } }\nRetry: { status: 'duplicate', result: { orderId: 'ORD-001' } }"
            },
            {
              "question": "Program 10: System design checklist validator",
              "code": "function validateDesign(design) {\n  const checklist = [\n    { item: 'Requirements clarified', check: () => design.requirements?.length > 0 },\n    { item: 'Scale estimated', check: () => design.qps > 0 && design.storage > 0 },\n    { item: 'APIs defined', check: () => design.apis?.length >= 3 },\n    { item: 'Database chosen', check: () => !!design.database },\n    { item: 'Caching discussed', check: () => !!design.cache },\n    { item: 'Failure handling', check: () => design.failureModes?.length > 0 },\n    { item: 'Monitoring plan', check: () => design.metrics?.length > 0 },\n  ];\n  const results = checklist.map(c => ({ ...c, passed: c.check() }));\n  const score = results.filter(r => r.passed).length;\n  return { score: `${score}/${checklist.length}`, results: results.map(r => `${r.passed ? '✅' : '❌'} ${r.item}`) };\n}\n\nconsole.log(validateDesign({\n  requirements: ['shorten URLs', 'redirect', 'analytics'],\n  qps: 1000, storage: 500,\n  apis: ['POST /shorten', 'GET /:code', 'GET /stats/:code'],\n  database: 'PostgreSQL',\n  cache: 'Redis',\n  failureModes: ['DB down', 'cache miss storm'],\n  metrics: ['latency_p99', 'error_rate', 'cache_hit_ratio'],\n}));",
              "output": "{\n  score: '7/7',\n  results: [\n    '✅ Requirements clarified',\n    '✅ Scale estimated',\n    '✅ APIs defined',\n    '✅ Database chosen',\n    '✅ Caching discussed',\n    '✅ Failure handling',\n    '✅ Monitoring plan'\n  ]\n}"
            }
          ]
        },
        {
          "id": "capacity-consistency",
          "title": "Capacity Planning, Consistency & Trade-offs",
          "category": "Foundations",
          "description": "Convert traffic assumptions into storage/throughput design and choose the right consistency model.",
          "explanation": "Capacity planning quantifies the resources your system needs. Start with DAU, estimate read/write QPS, apply peak multipliers (2-5x), and calculate storage with retention and replication. Then choose a consistency model by business semantics.\n\nCapacity planning steps:\n1. Estimate DAU and actions per user per day\n2. Calculate average and peak QPS (reads and writes separately)\n3. Estimate storage: records/day × avg size × retention × replication\n4. Estimate bandwidth: QPS × avg payload size\n5. Derive infrastructure needs: number of servers, DB shards, cache nodes\n\nConsistency models:\n- Strong consistency: All reads see the latest write. Use for money movement, seat booking, inventory. Cost: higher latency, lower availability during partitions.\n- Eventual consistency: Reads may see stale data temporarily. Use for feeds, counters, notifications. Benefit: higher availability and lower latency.\n- Causal consistency: Preserves cause-effect ordering. Good for chat messages, comment threads.\n- Read-your-writes: User always sees their own updates. Common compromise for user-facing apps.\n\nCAP theorem: During a network partition, you must choose between Consistency and Availability. In practice, most systems are AP (available + partition-tolerant) with eventual consistency, using strong consistency only for critical paths.",
          "code": "// Capacity estimation worksheet\n\n// Input assumptions\nconst DAU = 200_000_000;        // 200M daily active users\nconst readsPerUser = 50;         // feed views, searches\nconst writesPerUser = 3;         // posts, messages\nconst avgReadPayload = 2_000;    // 2KB response\nconst avgWritePayload = 500;     // 500B request\nconst retentionDays = 365;\nconst replicationFactor = 3;\n\n// QPS\nconst avgReadQPS = (DAU * readsPerUser) / 86400;   // ~115,741\nconst avgWriteQPS = (DAU * writesPerUser) / 86400;  // ~6,944\nconst peakReadQPS = avgReadQPS * 3;                  // ~347,222\nconst peakWriteQPS = avgWriteQPS * 5;                // ~34,722\n\n// Storage\nconst dailyNewData = DAU * writesPerUser * avgWritePayload; // ~300GB/day\nconst totalStorage = dailyNewData * retentionDays * replicationFactor;\n// ~328TB total\n\n// Bandwidth\nconst ingressBandwidth = peakWriteQPS * avgWritePayload; // ~17MB/s\nconst egressBandwidth = peakReadQPS * avgReadPayload;    // ~694MB/s",
          "example": "// Example: Consistency choice for different features\n\n// Feature 1: Wallet balance\n// Consistency: STRONG\n// Reason: Cannot show stale balance — user might double-spend\n// Implementation: Single-leader DB with serializable transactions\n\n// Feature 2: Feed like count\n// Consistency: EVENTUAL\n// Reason: Showing 1,002 vs 1,005 likes is acceptable\n// Implementation: Async counter with periodic materialization\n\n// Feature 3: Chat messages\n// Consistency: CAUSAL\n// Reason: Messages must appear in order within a conversation\n// Implementation: Per-conversation sequence numbers\n\n// Feature 4: User profile edit\n// Consistency: READ-YOUR-WRITES\n// Reason: User sees own changes immediately, others can lag\n// Implementation: Read from primary after write, replicas for others\n\n// Anti-pattern: Using strong consistency for everything\n// Problem: High latency, low throughput, poor availability\n// Fix: Classify each feature by consistency need",
          "useCase": "Every system design interview starts with capacity estimation. Consistency trade-offs come up in database selection, caching strategy, and replication design for any distributed system.",
          "interviewQuestions": [
            {
              "question": "When do you choose eventual consistency over strong consistency?",
              "answer": "For user-facing non-critical data where low latency and high availability matter more than strict freshness — feeds, like counts, recommendations, notifications. The brief staleness window is acceptable."
            },
            {
              "question": "What is a bad shard key and why?",
              "answer": "A key with skewed distribution (e.g., user_country) causes hotspots — one shard gets 80% of traffic while others are idle. Good shard keys distribute evenly (user_id hash, UUID)."
            },
            {
              "question": "How do you handle sudden 10x traffic spikes?",
              "answer": "1) Autoscale stateless tiers. 2) Rate limit to protect backends. 3) Queue burst writes for async processing. 4) Serve from cache/CDN for reads. 5) Degrade gracefully (partial results, reduced features)."
            },
            {
              "question": "Explain the CAP theorem with a practical example.",
              "answer": "During a network partition between two data centers: CP system (like ZooKeeper) rejects writes to maintain consistency. AP system (like Cassandra) accepts writes on both sides, resolving conflicts later. Most web apps choose AP with eventual consistency."
            },
            {
              "question": "How do you estimate if you need caching?",
              "answer": "Calculate read QPS vs DB capacity. If reads exceed DB throughput (e.g., 100K QPS vs 10K DB limit), add cache. Also consider: read/write ratio (>10:1 benefits from cache), latency requirements, and data access patterns (hot keys)."
            },
            {
              "question": "What is read-your-writes consistency?",
              "answer": "After a user writes data, their subsequent reads always reflect that write. Other users may see stale data. Implemented by routing the writing user's reads to the primary or using session-sticky connections."
            },
            {
              "question": "How do you plan for data growth over 3 years?",
              "answer": "Calculate daily data generation, apply retention policy, multiply by replication factor, and project 3 years. Add 50% buffer for indexes, metadata, and unexpected growth. Plan re-sharding strategy before hitting capacity."
            },
            {
              "question": "What's the difference between horizontal and vertical scaling?",
              "answer": "Vertical: bigger machine (more CPU/RAM). Simple but has limits and is a single point of failure. Horizontal: more machines. Complex (needs load balancing, data partitioning) but scales linearly and provides redundancy."
            },
            {
              "question": "How do you handle hot partitions?",
              "answer": "1) Add random suffix to hot keys to spread across partitions. 2) Use a separate cache layer for hot keys. 3) Re-shard with more granular key. 4) Rate limit writes to hot partitions. 5) Monitor partition metrics."
            },
            {
              "question": "When would you choose a multi-leader replication setup?",
              "answer": "For multi-region deployments where each region needs low-latency writes. Trade-off: conflict resolution complexity. Use timestamp-based LWW (last-writer-wins) or application-level merge for conflicts."
            }
          ],
          "exercises": [
            {
              "type": "estimation",
              "question": "Estimate storage for 200M events/day retained for 180 days with 1.5KB/event and 3x replication.",
              "answer": "Daily: 200M × 1.5KB = 300GB. Total: 300GB × 180 days = 54TB. With replication: 54TB × 3 = 162TB."
            },
            {
              "type": "design",
              "question": "Pick strong vs eventual consistency for: wallet balance, feed likes, chat unread count, order status.",
              "answer": "Wallet: Strong (money). Feed likes: Eventual (cosmetic). Chat unread: Eventual with read-your-writes (user expects own reads to clear). Order status: Strong for transitions (PAID→SHIPPED), eventual for display."
            },
            {
              "type": "debug",
              "question": "A shard is 5x hotter than others. List three immediate mitigations.",
              "answer": "1) Move hot keys to a dedicated cache. 2) Split the hot shard into sub-shards. 3) Add read replicas for the hot shard. Long-term: re-evaluate shard key strategy."
            },
            {
              "type": "estimation",
              "question": "A service needs 99.99% availability. Calculate max downtime per year and per month.",
              "answer": "Per year: 365.25 × 24 × 60 × 0.0001 = 52.6 minutes. Per month: 52.6 / 12 = 4.38 minutes. This means any single incident must be resolved in under 4 minutes."
            },
            {
              "type": "scenario",
              "question": "Your database is at 80% capacity. You expect 2x data growth in 6 months. What is your plan?",
              "answer": "Immediate: Archive/compress old data, add read replicas. 30-day: Implement sharding or migrate to horizontally-scalable DB. 90-day: Test with 3x load and validate capacity headroom."
            },
            {
              "type": "tricky",
              "question": "Can you have strong consistency AND high availability? Under what conditions?",
              "answer": "Yes, when there is no network partition. CAP only forces a choice during partitions. In a single-region, well-connected setup, you can have both. Multi-region strong consistency is possible with quorum (e.g., Raft) but with higher latency."
            },
            {
              "type": "estimation",
              "question": "An image service stores 5M images/day, avg 3MB each. Estimate storage cost at $0.023/GB/month for 1 year.",
              "answer": "Daily: 5M × 3MB = 15TB. Yearly: 15TB × 365 = 5,475TB = 5,475,000GB. Monthly cost: 5,475,000 × $0.023 = $125,925/month (at full year's accumulation)."
            },
            {
              "type": "design",
              "question": "Design a replication strategy for a global e-commerce platform with users in US, EU, and Asia.",
              "answer": "Multi-region with regional replicas in each region. Write to nearest leader. Use async replication between regions (50-200ms lag acceptable). Strong consistency for orders/payments within the region, eventual for catalog/reviews."
            },
            {
              "type": "output",
              "question": "If peak QPS is 50K reads and each DB node handles 5K QPS, how many read replicas do you need with 50% headroom?",
              "answer": "Base: 50K / 5K = 10 nodes. With 50% headroom: 10 × 1.5 = 15 read replicas."
            },
            {
              "type": "debug",
              "question": "Latency spikes to 5s during peak hours. DB CPU is at 95%. Cache hit ratio dropped from 90% to 60%. Diagnose.",
              "answer": "Cache is expiring too many keys simultaneously (TTL thundering herd). Fix: Add jitter to TTL values (TTL ± random 10-20%). Pre-warm cache before peak. Add more cache nodes or increase memory."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Throughput planner",
              "code": "function planThroughput({ avgQPS, peakMultiplier, writeRatio }) {\n  const peakQPS = avgQPS * peakMultiplier;\n  const writeQPS = Math.ceil(peakQPS * writeRatio);\n  const readQPS = Math.ceil(peakQPS * (1 - writeRatio));\n  return { avgQPS, peakQPS, writeQPS, readQPS, ratio: `${Math.round((1 - writeRatio) / writeRatio)}:1 read:write` };\n}\nconsole.log(planThroughput({ avgQPS: 10000, peakMultiplier: 5, writeRatio: 0.3 }));",
              "output": "{ avgQPS: 10000, peakQPS: 50000, writeQPS: 15000, readQPS: 35000, ratio: '2:1 read:write' }"
            },
            {
              "question": "Program 2: Shard calculator",
              "code": "function calcShards({ totalDataTB, maxPerShardTB, peakQPS, maxQPSPerShard }) {\n  const byStorage = Math.ceil(totalDataTB / maxPerShardTB);\n  const byQPS = Math.ceil(peakQPS / maxQPSPerShard);\n  const recommended = Math.max(byStorage, byQPS);\n  return { byStorage, byQPS, recommended, bottleneck: byStorage > byQPS ? 'storage' : 'throughput' };\n}\nconsole.log(calcShards({ totalDataTB: 50, maxPerShardTB: 5, peakQPS: 80000, maxQPSPerShard: 10000 }));",
              "output": "{ byStorage: 10, byQPS: 8, recommended: 10, bottleneck: 'storage' }"
            },
            {
              "question": "Program 3: Consistency requirement classifier",
              "code": "function classifyConsistency(features) {\n  const rules = {\n    money: 'strong', payment: 'strong', booking: 'strong', inventory: 'strong',\n    feed: 'eventual', likes: 'eventual', views: 'eventual', recommendations: 'eventual',\n    chat: 'causal', comments: 'causal', profile: 'read-your-writes',\n  };\n  return features.map(f => {\n    const match = Object.keys(rules).find(k => f.toLowerCase().includes(k));\n    return { feature: f, consistency: match ? rules[match] : 'evaluate case-by-case' };\n  });\n}\nconsole.log(classifyConsistency(['Wallet Balance', 'Feed Likes', 'Chat Messages', 'Seat Booking', 'User Profile', 'View Counter']));",
              "output": "[\n  { feature: 'Wallet Balance', consistency: 'strong' },\n  { feature: 'Feed Likes', consistency: 'eventual' },\n  { feature: 'Chat Messages', consistency: 'causal' },\n  { feature: 'Seat Booking', consistency: 'strong' },\n  { feature: 'User Profile', consistency: 'read-your-writes' },\n  { feature: 'View Counter', consistency: 'eventual' }\n]"
            },
            {
              "question": "Program 4: Replication lag monitor",
              "code": "function monitorReplicationLag(replicas) {\n  const threshold = 100; // ms\n  return replicas.map(r => ({\n    replica: r.name,\n    lagMs: r.lagMs,\n    status: r.lagMs <= threshold ? 'healthy' : r.lagMs <= 500 ? 'warning' : 'critical',\n    action: r.lagMs > 500 ? 'Route reads to primary' : r.lagMs > threshold ? 'Monitor closely' : 'None',\n  }));\n}\nconsole.log(monitorReplicationLag([\n  { name: 'replica-us-east-1', lagMs: 15 },\n  { name: 'replica-eu-west-1', lagMs: 250 },\n  { name: 'replica-ap-south-1', lagMs: 800 },\n]));",
              "output": "[\n  { replica: 'replica-us-east-1', lagMs: 15, status: 'healthy', action: 'None' },\n  { replica: 'replica-eu-west-1', lagMs: 250, status: 'warning', action: 'Monitor closely' },\n  { replica: 'replica-ap-south-1', lagMs: 800, status: 'critical', action: 'Route reads to primary' }\n]"
            },
            {
              "question": "Program 5: Hot key detector",
              "code": "function detectHotKeys(accessLog, threshold) {\n  const counts = {};\n  accessLog.forEach(key => { counts[key] = (counts[key] || 0) + 1; });\n  const total = accessLog.length;\n  return Object.entries(counts)\n    .filter(([, count]) => (count / total) > threshold)\n    .map(([key, count]) => ({ key, count, percentage: (count / total * 100).toFixed(1) + '%' }))\n    .sort((a, b) => b.count - a.count);\n}\nconst log = Array(1000).fill(null).map((_, i) => i < 400 ? 'user:123' : i < 600 ? 'user:456' : `user:${i}`);\nconsole.log(detectHotKeys(log, 0.1));",
              "output": "[\n  { key: 'user:123', count: 400, percentage: '40.0%' },\n  { key: 'user:456', count: 200, percentage: '20.0%' }\n]"
            },
            {
              "question": "Program 6: TTL jitter generator to prevent thundering herd",
              "code": "function ttlWithJitter(baseTTLSeconds, jitterPercent = 0.2) {\n  const jitter = baseTTLSeconds * jitterPercent;\n  const min = baseTTLSeconds - jitter;\n  const max = baseTTLSeconds + jitter;\n  return Math.floor(min + Math.random() * (max - min));\n}\n\n// Generate 10 TTLs for 300s base\nconst ttls = Array.from({ length: 10 }, () => ttlWithJitter(300));\nconsole.log('Base TTL: 300s');\nconsole.log('Jittered TTLs:', ttls);\nconsole.log('Range:', Math.min(...ttls), '-', Math.max(...ttls));",
              "output": "Base TTL: 300s\nJittered TTLs: [287, 312, 245, 340, 298, 275, 321, 260, 330, 290]\nRange: 245 - 340"
            },
            {
              "question": "Program 7: Bandwidth estimator",
              "code": "function estimateBandwidth({ peakQPS, avgPayloadKB, direction }) {\n  const bwMBps = (peakQPS * avgPayloadKB) / 1024;\n  const bwGbps = (bwMBps * 8) / 1024;\n  return { direction, peakQPS, avgPayloadKB: avgPayloadKB + 'KB', bandwidthMBps: bwMBps.toFixed(1) + ' MB/s', bandwidthGbps: bwGbps.toFixed(2) + ' Gbps' };\n}\nconsole.log(estimateBandwidth({ peakQPS: 100000, avgPayloadKB: 5, direction: 'egress' }));\nconsole.log(estimateBandwidth({ peakQPS: 10000, avgPayloadKB: 2, direction: 'ingress' }));",
              "output": "{ direction: 'egress', peakQPS: 100000, avgPayloadKB: '5KB', bandwidthMBps: '488.3 MB/s', bandwidthGbps: '3.81 Gbps' }\n{ direction: 'ingress', peakQPS: 10000, avgPayloadKB: '2KB', bandwidthMBps: '19.5 MB/s', bandwidthGbps: '0.15 Gbps' }"
            },
            {
              "question": "Program 8: CAP theorem decision helper",
              "code": "function capDecision(requirements) {\n  const { needsStrongConsistency, needsHighAvailability, multiRegion } = requirements;\n  if (!multiRegion) return { type: 'CA', note: 'Single region — no partition risk. Can have both C and A.' };\n  if (needsStrongConsistency && needsHighAvailability) return { type: 'Impossible during partition', note: 'Must choose: CP for critical writes, AP for reads.' };\n  if (needsStrongConsistency) return { type: 'CP', note: 'Reject writes during partition. Use Raft/Paxos consensus.', examples: 'ZooKeeper, etcd, Spanner' };\n  return { type: 'AP', note: 'Accept writes on both sides, merge later.', examples: 'Cassandra, DynamoDB, CouchDB' };\n}\nconsole.log(capDecision({ needsStrongConsistency: true, needsHighAvailability: false, multiRegion: true }));\nconsole.log(capDecision({ needsStrongConsistency: false, needsHighAvailability: true, multiRegion: true }));",
              "output": "{ type: 'CP', note: 'Reject writes during partition. Use Raft/Paxos consensus.', examples: 'ZooKeeper, etcd, Spanner' }\n{ type: 'AP', note: 'Accept writes on both sides, merge later.', examples: 'Cassandra, DynamoDB, CouchDB' }"
            },
            {
              "question": "Program 9: Storage cost projection",
              "code": "function projectStorageCost({ dailyDataGB, retentionDays, replication, costPerGBMonth, months }) {\n  const projections = [];\n  for (let m = 1; m <= months; m++) {\n    const effectiveDays = Math.min(m * 30, retentionDays);\n    const totalGB = dailyDataGB * effectiveDays * replication;\n    const monthlyCost = totalGB * costPerGBMonth;\n    projections.push({ month: m, storageGB: Math.round(totalGB), cost: '$' + Math.round(monthlyCost) });\n  }\n  return projections;\n}\nconsole.log(projectStorageCost({ dailyDataGB: 100, retentionDays: 90, replication: 3, costPerGBMonth: 0.023, months: 6 }));",
              "output": "[\n  { month: 1, storageGB: 9000, cost: '$207' },\n  { month: 2, storageGB: 18000, cost: '$414' },\n  { month: 3, storageGB: 27000, cost: '$621' },\n  { month: 4, storageGB: 27000, cost: '$621' },\n  { month: 5, storageGB: 27000, cost: '$621' },\n  { month: 6, storageGB: 27000, cost: '$621' }\n]"
            },
            {
              "question": "Program 10: Read/write ratio analyzer",
              "code": "function analyzeRWRatio(logs) {\n  const reads = logs.filter(l => l.type === 'read').length;\n  const writes = logs.filter(l => l.type === 'write').length;\n  const total = logs.length;\n  const ratio = (reads / writes).toFixed(1);\n  let strategy;\n  if (reads / writes > 10) strategy = 'Heavy caching + read replicas';\n  else if (reads / writes > 3) strategy = 'Cache + single primary';\n  else if (reads / writes > 1) strategy = 'Balanced — consider write-behind cache';\n  else strategy = 'Write-heavy — use append-only log + async reads';\n  return { reads, writes, total, ratio: ratio + ':1', strategy };\n}\nconst mockLogs = [\n  ...Array(850).fill({ type: 'read' }),\n  ...Array(150).fill({ type: 'write' }),\n];\nconsole.log(analyzeRWRatio(mockLogs));",
              "output": "{ reads: 850, writes: 150, total: 1000, ratio: '5.7:1', strategy: 'Cache + single primary' }"
            }
          ]
        },
        {
          "id": "load-balancing",
          "title": "Load Balancing & Reverse Proxy",
          "category": "Foundations",
          "description": "Distribute traffic across servers using load balancers and reverse proxies for high availability and scalability.",
          "explanation": "A load balancer distributes incoming requests across multiple backend servers to prevent any single server from becoming a bottleneck. This improves throughput, reduces latency, and provides fault tolerance.\n\nLayer 4 (Transport) vs Layer 7 (Application):\n- L4 LB operates on TCP/UDP — fast, simple, no payload inspection. Routes by IP+port. Examples: AWS NLB, HAProxy TCP mode.\n- L7 LB operates on HTTP — can inspect headers, URLs, cookies. Enables content-based routing, SSL termination, compression. Examples: Nginx, AWS ALB, Envoy.\n\nCommon algorithms:\n- Round Robin: Requests distributed sequentially. Simple but ignores server load.\n- Weighted Round Robin: Assigns proportional traffic by server capacity.\n- Least Connections: Routes to server with fewest active connections. Best for variable request durations.\n- IP Hash: Same client always goes to same server (sticky sessions without cookies).\n- Consistent Hashing: Minimizes redistribution when servers are added/removed.\n\nReverse proxy sits in front of backends, hiding their identity. Provides SSL termination, compression, caching, rate limiting, and security filtering. All modern load balancers are also reverse proxies.\n\nHealth checks: Active (periodic HTTP/TCP probes) and passive (monitor response errors). Unhealthy servers are removed from the pool automatically.\n\nGlobal Server Load Balancing (GSLB): DNS-based routing to the nearest data center using GeoDNS or anycast. Enables multi-region deployments.",
          "code": "# Nginx reverse proxy + load balancer configuration\n\nupstream backend {\n    # Least connections algorithm\n    least_conn;\n    \n    server backend1:8080 weight=3;   # 3x traffic\n    server backend2:8080 weight=1;\n    server backend3:8080 weight=1;\n    server backend4:8080 backup;      # Only when others are down\n}\n\nserver {\n    listen 443 ssl;\n    server_name api.example.com;\n    \n    # SSL termination at LB\n    ssl_certificate /etc/ssl/cert.pem;\n    ssl_certificate_key /etc/ssl/key.pem;\n    \n    # Health check\n    location /health {\n        proxy_pass http://backend;\n        proxy_connect_timeout 2s;\n        proxy_read_timeout 5s;\n    }\n    \n    # Proxy with headers\n    location / {\n        proxy_pass http://backend;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        \n        # Timeouts\n        proxy_connect_timeout 5s;\n        proxy_read_timeout 30s;\n        proxy_send_timeout 30s;\n    }\n}",
          "example": "# HAProxy configuration with health checks\n\nfrontend http_front\n    bind *:80\n    bind *:443 ssl crt /etc/ssl/certs/\n    redirect scheme https if !{ ssl_fc }\n    default_backend app_servers\n\nbackend app_servers\n    balance roundrobin\n    option httpchk GET /health\n    http-check expect status 200\n    \n    server app1 10.0.1.1:8080 check inter 5s fall 3 rise 2\n    server app2 10.0.1.2:8080 check inter 5s fall 3 rise 2\n    server app3 10.0.1.3:8080 check inter 5s fall 3 rise 2\n\n# inter 5s = check every 5 seconds\n# fall 3   = mark unhealthy after 3 failures\n# rise 2   = mark healthy after 2 successes",
          "useCase": "Every production web application — API servers, microservices, static assets, WebSocket connections, database connection pooling.",
          "interviewQuestions": [
            {
              "question": "What is the difference between L4 and L7 load balancing?",
              "answer": "L4 operates at the transport layer (TCP/UDP) — fast, no payload inspection, routes by IP and port. L7 operates at the application layer (HTTP) — can inspect headers, URLs, cookies, enabling content-based routing, SSL termination, and caching."
            },
            {
              "question": "How does a load balancer detect unhealthy servers?",
              "answer": "Active health checks: periodic HTTP/TCP probes (e.g., GET /health every 5s). Passive health checks: monitor actual response errors. After N consecutive failures (fall threshold), the server is removed from the pool."
            },
            {
              "question": "When would you use sticky sessions?",
              "answer": "When server-side session state exists (shopping carts, WebSocket connections). Implemented via cookies or IP hash. Downside: uneven load distribution and failover complexity. Better approach: externalize state to Redis."
            },
            {
              "question": "What happens when a load balancer itself fails?",
              "answer": "Use active-passive or active-active LB pairs with floating IP (VRRP). Cloud-managed LBs (ALB, NLB) are inherently redundant across AZs. DNS failover provides another layer of redundancy."
            },
            {
              "question": "Explain consistent hashing in load balancing.",
              "answer": "Servers are placed on a hash ring. Requests are hashed to a position on the ring and routed to the nearest server clockwise. When a server is added/removed, only ~1/N of keys are redistributed. Virtual nodes improve uniformity."
            },
            {
              "question": "What is SSL termination and why do it at the load balancer?",
              "answer": "Decrypting SSL/TLS at the LB instead of backend servers. Benefits: centralizes certificate management, offloads CPU-intensive encryption from app servers, enables L7 inspection of decrypted traffic."
            },
            {
              "question": "How do you handle WebSocket connections with load balancers?",
              "answer": "Use L7 LB with connection upgrade support. Enable sticky sessions so the persistent connection stays with the same backend. Alternatively, use L4 LB which naturally maintains TCP connections."
            },
            {
              "question": "Compare round robin vs least connections algorithms.",
              "answer": "Round robin is simple and works well when requests have similar processing times. Least connections is better when request durations vary — it routes to the least loaded server, preventing slow requests from backing up one server."
            },
            {
              "question": "What is a reverse proxy and how does it differ from a load balancer?",
              "answer": "A reverse proxy sits between clients and servers, forwarding requests on behalf of clients. All load balancers are reverse proxies, but reverse proxies also provide caching, compression, SSL termination, and security filtering without load distribution."
            },
            {
              "question": "How does Global Server Load Balancing (GSLB) work?",
              "answer": "Uses DNS to route users to the nearest data center. GeoDNS resolves the domain to different IPs based on client location. Health-aware GSLB removes unhealthy regions from DNS. Anycast is another approach where the same IP is advertised from multiple locations."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design a load balancing strategy for a service with 10 servers where 3 are 2x more powerful than the others.",
              "answer": "Use weighted round robin or weighted least connections. Assign weight=2 to powerful servers. This gives them 2x traffic: powerful servers get ~22% each (66% total), regular servers get ~5% each (34% total)."
            },
            {
              "type": "scenario",
              "question": "Your LB health check interval is 30s and a server crashes. What's the worst-case impact and how to improve?",
              "answer": "Worst case: 30s of requests to a dead server. Reduce interval to 3-5s with fall=2. Use passive checks on actual traffic errors. Result: detection in 6-10s instead of 30s."
            },
            {
              "type": "debug",
              "question": "Users report intermittent 502 errors. LB logs show backend servers returning errors. What do you investigate?",
              "answer": "1) Check backend health: are servers overloaded or crashing? 2) Check connection limits: LB may be hitting max connections to backends. 3) Check timeouts: backend may be too slow. 4) Check if health checks are passing but actual requests fail."
            },
            {
              "type": "estimation",
              "question": "100K concurrent users, each makes 1 request every 10 seconds. How many app servers (8K QPS each) behind a load balancer?",
              "answer": "QPS = 100K / 10 = 10K QPS. Servers needed: 10K / 8K = 1.25 → 2 servers minimum. With headroom (2x): 4 servers."
            },
            {
              "type": "tricky",
              "question": "You deploy a new version behind the LB but some users see the old version. Why?",
              "answer": "Sticky sessions routing users to old servers, or CDN/browser caching. Fix: use rolling deployment (drain old servers), bust cache with versioned URLs, or use blue-green deployment with DNS switch."
            },
            {
              "type": "design",
              "question": "Design a multi-tier load balancing architecture for a global application.",
              "answer": "Tier 1: GSLB via GeoDNS routes to nearest region. Tier 2: L4 NLB distributes to availability zones. Tier 3: L7 ALB routes by URL path to different services. Each tier adds resilience."
            },
            {
              "type": "output",
              "question": "If you have 3 servers with weights 5, 3, 2 and 100 requests, how many go to each?",
              "answer": "Total weight = 10. Server 1: 100 × 5/10 = 50 requests. Server 2: 100 × 3/10 = 30 requests. Server 3: 100 × 2/10 = 20 requests."
            },
            {
              "type": "scenario",
              "question": "During deployment, you need zero-downtime. How does the LB help?",
              "answer": "Rolling update: remove one server from pool, update it, health check passes, add it back, repeat. Or blue-green: deploy new version on separate servers, switch LB target group atomically."
            },
            {
              "type": "explain",
              "question": "Why is the X-Forwarded-For header important in load-balanced setups?",
              "answer": "Without it, backend sees the LB's IP as the client IP. X-Forwarded-For preserves the original client IP through the proxy chain. Critical for rate limiting, geo-targeting, logging, and security."
            },
            {
              "type": "debug",
              "question": "One backend server receives 80% of traffic while others are idle. LB algorithm is round-robin. What's wrong?",
              "answer": "Possible causes: Sticky sessions enabled, persistent connections (one long connection gets all requests), health checks failing on other servers, or incorrect weight configuration."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Round-robin load balancer",
              "code": "class RoundRobinLB {\n  constructor(servers) {\n    this.servers = servers;\n    this.index = 0;\n  }\n  getServer() {\n    const server = this.servers[this.index];\n    this.index = (this.index + 1) % this.servers.length;\n    return server;\n  }\n}\n\nconst lb = new RoundRobinLB(['s1:8080', 's2:8080', 's3:8080']);\nfor (let i = 0; i < 7; i++) console.log(`Request ${i + 1} → ${lb.getServer()}`);",
              "output": "Request 1 → s1:8080\nRequest 2 → s2:8080\nRequest 3 → s3:8080\nRequest 4 → s1:8080\nRequest 5 → s2:8080\nRequest 6 → s3:8080\nRequest 7 → s1:8080"
            },
            {
              "question": "Program 2: Weighted round-robin load balancer",
              "code": "class WeightedRRLB {\n  constructor(servers) {\n    this.servers = [];\n    servers.forEach(s => {\n      for (let i = 0; i < s.weight; i++) this.servers.push(s.address);\n    });\n    this.index = 0;\n  }\n  getServer() {\n    const server = this.servers[this.index];\n    this.index = (this.index + 1) % this.servers.length;\n    return server;\n  }\n}\n\nconst lb = new WeightedRRLB([\n  { address: 's1', weight: 3 },\n  { address: 's2', weight: 1 },\n  { address: 's3', weight: 1 },\n]);\nconst counts = {};\nfor (let i = 0; i < 50; i++) {\n  const s = lb.getServer();\n  counts[s] = (counts[s] || 0) + 1;\n}\nconsole.log(counts);",
              "output": "{ s1: 30, s2: 10, s3: 10 }"
            },
            {
              "question": "Program 3: Least connections load balancer",
              "code": "class LeastConnectionsLB {\n  constructor(servers) {\n    this.servers = servers.map(s => ({ address: s, connections: 0 }));\n  }\n  getServer() {\n    const server = this.servers.reduce((min, s) => s.connections < min.connections ? s : min);\n    server.connections++;\n    return server.address;\n  }\n  release(address) {\n    const server = this.servers.find(s => s.address === address);\n    if (server) server.connections = Math.max(0, server.connections - 1);\n  }\n  status() {\n    return this.servers.map(s => `${s.address}: ${s.connections} conn`);\n  }\n}\n\nconst lb = new LeastConnectionsLB(['s1', 's2', 's3']);\nconsole.log(lb.getServer()); // s1 (all 0, picks first)\nconsole.log(lb.getServer()); // s2\nconsole.log(lb.getServer()); // s3\nconsole.log(lb.getServer()); // s1 (all have 1, picks first again)\nlb.release('s2');\nconsole.log(lb.getServer()); // s2 (now has 0)\nconsole.log(lb.status());",
              "output": "s1\ns2\ns3\ns1\ns2\n['s1: 2 conn', 's2: 1 conn', 's3: 1 conn']"
            },
            {
              "question": "Program 4: Health check simulator",
              "code": "class HealthChecker {\n  constructor(servers, { fall = 3, rise = 2 } = {}) {\n    this.servers = servers.map(s => ({ address: s, healthy: true, failCount: 0, passCount: 0 }));\n    this.fall = fall;\n    this.rise = rise;\n  }\n  check(address, success) {\n    const server = this.servers.find(s => s.address === address);\n    if (success) {\n      server.failCount = 0;\n      server.passCount++;\n      if (!server.healthy && server.passCount >= this.rise) {\n        server.healthy = true;\n        console.log(`[RECOVERED] ${address}`);\n      }\n    } else {\n      server.passCount = 0;\n      server.failCount++;\n      if (server.healthy && server.failCount >= this.fall) {\n        server.healthy = false;\n        console.log(`[DOWN] ${address}`);\n      }\n    }\n  }\n  getHealthy() { return this.servers.filter(s => s.healthy).map(s => s.address); }\n}\n\nconst hc = new HealthChecker(['s1', 's2', 's3']);\nhc.check('s2', false); hc.check('s2', false); hc.check('s2', false); // 3 fails\nconsole.log('Healthy:', hc.getHealthy());\nhc.check('s2', true); hc.check('s2', true); // 2 passes\nconsole.log('Healthy:', hc.getHealthy());",
              "output": "[DOWN] s2\nHealthy: ['s1', 's3']\n[RECOVERED] s2\nHealthy: ['s1', 's2', 's3']"
            },
            {
              "question": "Program 5: IP hash load balancer",
              "code": "function simpleHash(str) {\n  let hash = 0;\n  for (let i = 0; i < str.length; i++) {\n    hash = ((hash << 5) - hash) + str.charCodeAt(i);\n    hash |= 0;\n  }\n  return Math.abs(hash);\n}\n\nclass IPHashLB {\n  constructor(servers) { this.servers = servers; }\n  getServer(clientIP) {\n    const index = simpleHash(clientIP) % this.servers.length;\n    return this.servers[index];\n  }\n}\n\nconst lb = new IPHashLB(['s1', 's2', 's3']);\nconst ips = ['192.168.1.1', '10.0.0.5', '172.16.0.1', '192.168.1.1'];\nips.forEach(ip => console.log(`${ip} → ${lb.getServer(ip)}`));",
              "output": "192.168.1.1 → s2\n10.0.0.5 → s1\n172.16.0.1 → s3\n192.168.1.1 → s2  // Same IP always goes to same server"
            },
            {
              "question": "Program 6: Connection draining simulator",
              "code": "class DrainingLB {\n  constructor(servers) {\n    this.servers = servers.map(s => ({ addr: s, draining: false, active: 0 }));\n  }\n  drain(addr) {\n    const s = this.servers.find(s => s.addr === addr);\n    s.draining = true;\n    console.log(`[DRAINING] ${addr} (${s.active} active connections)`);\n  }\n  route() {\n    const available = this.servers.filter(s => !s.draining);\n    if (!available.length) return null;\n    const s = available.reduce((min, s) => s.active < min.active ? s : min);\n    s.active++;\n    return s.addr;\n  }\n  complete(addr) {\n    const s = this.servers.find(s => s.addr === addr);\n    s.active = Math.max(0, s.active - 1);\n    if (s.draining && s.active === 0) console.log(`[DRAINED] ${addr} — safe to remove`);\n  }\n}\n\nconst lb = new DrainingLB(['s1', 's2', 's3']);\nlb.route(); lb.route(); lb.route(); // 1 each\nlb.servers.find(s => s.addr === 's2').active = 2;\nlb.drain('s2');\nconsole.log('New routes go to:', lb.route(), lb.route());\nlb.complete('s2'); lb.complete('s2');",
              "output": "[DRAINING] s2 (2 active connections)\nNew routes go to: s1 s3\n[DRAINED] s2 — safe to remove"
            },
            {
              "question": "Program 7: Rate-limited load balancer",
              "code": "class RateLimitedLB {\n  constructor(servers, maxRPS) {\n    this.servers = servers;\n    this.maxRPS = maxRPS;\n    this.counts = new Map();\n    this.index = 0;\n  }\n  route(clientIP) {\n    const count = this.counts.get(clientIP) || 0;\n    if (count >= this.maxRPS) return { status: 429, message: 'Rate limited' };\n    this.counts.set(clientIP, count + 1);\n    const server = this.servers[this.index % this.servers.length];\n    this.index++;\n    return { status: 200, server };\n  }\n  resetWindow() { this.counts.clear(); }\n}\n\nconst lb = new RateLimitedLB(['s1', 's2'], 3);\nfor (let i = 0; i < 5; i++) {\n  console.log(`Req ${i + 1}:`, lb.route('client-1'));\n}",
              "output": "Req 1: { status: 200, server: 's1' }\nReq 2: { status: 200, server: 's2' }\nReq 3: { status: 200, server: 's1' }\nReq 4: { status: 429, message: 'Rate limited' }\nReq 5: { status: 429, message: 'Rate limited' }"
            },
            {
              "question": "Program 8: Multi-tier LB router",
              "code": "class MultiTierLB {\n  constructor(regions) { this.regions = regions; }\n  route(userRegion, path) {\n    const region = this.regions[userRegion] || this.regions['default'];\n    const service = path.startsWith('/api') ? 'api' : path.startsWith('/static') ? 'cdn' : 'web';\n    const servers = region[service] || region['web'];\n    const server = servers[Math.floor(Math.random() * servers.length)];\n    return { region: userRegion, service, server };\n  }\n}\n\nconst lb = new MultiTierLB({\n  'us-east': { api: ['api-us-1', 'api-us-2'], web: ['web-us-1'], cdn: ['cdn-us-1'] },\n  'eu-west': { api: ['api-eu-1'], web: ['web-eu-1'], cdn: ['cdn-eu-1'] },\n  'default': { api: ['api-us-1'], web: ['web-us-1'], cdn: ['cdn-us-1'] },\n});\nconsole.log(lb.route('us-east', '/api/users'));\nconsole.log(lb.route('eu-west', '/static/logo.png'));\nconsole.log(lb.route('ap-south', '/home'));",
              "output": "{ region: 'us-east', service: 'api', server: 'api-us-1' }\n{ region: 'eu-west', service: 'cdn', server: 'cdn-eu-1' }\n{ region: 'ap-south', service: 'web', server: 'web-us-1' }"
            },
            {
              "question": "Program 9: Server weight auto-adjuster based on response times",
              "code": "function adjustWeights(servers) {\n  const maxLatency = Math.max(...servers.map(s => s.avgLatencyMs));\n  return servers.map(s => {\n    const weight = Math.max(1, Math.round((maxLatency / s.avgLatencyMs) * 5));\n    return { ...s, weight, note: s.avgLatencyMs > 200 ? 'slow' : 'ok' };\n  });\n}\n\nconst servers = [\n  { name: 's1', avgLatencyMs: 50 },\n  { name: 's2', avgLatencyMs: 120 },\n  { name: 's3', avgLatencyMs: 300 },\n];\nconsole.log(adjustWeights(servers));",
              "output": "[\n  { name: 's1', avgLatencyMs: 50, weight: 30, note: 'ok' },\n  { name: 's2', avgLatencyMs: 120, weight: 13, note: 'ok' },\n  { name: 's3', avgLatencyMs: 300, weight: 5, note: 'slow' }\n]"
            },
            {
              "question": "Program 10: Load balancer stats dashboard",
              "code": "function lbStats(accessLog) {\n  const stats = {};\n  accessLog.forEach(({ server, latencyMs, status }) => {\n    if (!stats[server]) stats[server] = { requests: 0, errors: 0, totalLatency: 0 };\n    stats[server].requests++;\n    stats[server].totalLatency += latencyMs;\n    if (status >= 500) stats[server].errors++;\n  });\n  return Object.entries(stats).map(([server, s]) => ({\n    server,\n    requests: s.requests,\n    avgLatencyMs: Math.round(s.totalLatency / s.requests),\n    errorRate: (s.errors / s.requests * 100).toFixed(1) + '%',\n  }));\n}\n\nconst log = [\n  { server: 's1', latencyMs: 45, status: 200 },\n  { server: 's2', latencyMs: 120, status: 200 },\n  { server: 's1', latencyMs: 55, status: 200 },\n  { server: 's2', latencyMs: 500, status: 503 },\n  { server: 's3', latencyMs: 30, status: 200 },\n];\nconsole.log(lbStats(log));",
              "output": "[\n  { server: 's1', requests: 2, avgLatencyMs: 50, errorRate: '0.0%' },\n  { server: 's2', requests: 2, avgLatencyMs: 310, errorRate: '50.0%' },\n  { server: 's3', requests: 1, avgLatencyMs: 30, errorRate: '0.0%' }\n]"
            }
          ]
        },
        {
          "id": "caching",
          "title": "Caching Strategies",
          "category": "Foundations",
          "description": "Accelerate reads and reduce database load using caching patterns — cache-aside, write-through, write-behind, and multi-level caching.",
          "explanation": "Caching stores frequently accessed data in a fast storage layer (RAM) to reduce latency and database load. A well-designed cache can handle 100x the throughput of a database at 1/100th the latency.\n\nCaching patterns:\n- Cache-aside (Lazy loading): App checks cache first, on miss reads from DB and populates cache. Most common. Risk: cache miss stampede.\n- Read-through: Cache itself loads from DB on miss. Simplifies app code but cache must know about the data source.\n- Write-through: Write to cache and DB synchronously. Strong consistency but higher write latency.\n- Write-behind (Write-back): Write to cache, asynchronously flush to DB. Low write latency but data loss risk on cache failure.\n\nCache invalidation strategies:\n- TTL (Time-to-Live): Simple, eventual consistency. Set TTL based on data freshness needs.\n- Event-driven: Publish cache invalidation events on data change. Immediate consistency.\n- Version-based: Include version in cache key. New writes create new keys.\n\nCommon problems:\n- Thundering herd: Cache key expires, many requests hit DB simultaneously. Fix: lock on miss, probabilistic early expiry, or stale-while-revalidate.\n- Cache penetration: Queries for non-existent data bypass cache. Fix: cache null results or use Bloom filter.\n- Hot key: One key gets extreme traffic. Fix: local in-process cache, key replication, or request coalescing.\n\nRedis vs Memcached: Redis supports data structures (lists, sets, sorted sets), persistence, replication, Lua scripting. Memcached is simpler, multi-threaded, slightly faster for plain key-value.",
          "code": "// Cache-aside pattern implementation\nclass CacheAside {\n  constructor(cache, db) {\n    this.cache = cache; // Redis-like\n    this.db = db;\n    this.hits = 0;\n    this.misses = 0;\n  }\n\n  async get(key) {\n    // 1. Check cache first\n    const cached = await this.cache.get(key);\n    if (cached !== null) {\n      this.hits++;\n      return JSON.parse(cached);\n    }\n\n    // 2. Cache miss — read from DB\n    this.misses++;\n    const data = await this.db.findById(key);\n    if (data === null) {\n      // Cache null to prevent penetration\n      await this.cache.set(key, 'null', 'EX', 60);\n      return null;\n    }\n\n    // 3. Populate cache with TTL + jitter\n    const ttl = 300 + Math.floor(Math.random() * 60); // 300-360s\n    await this.cache.set(key, JSON.stringify(data), 'EX', ttl);\n    return data;\n  }\n\n  async update(key, newData) {\n    // Write to DB first, then invalidate cache\n    await this.db.update(key, newData);\n    await this.cache.del(key); // Invalidate, not update\n  }\n\n  hitRate() {\n    const total = this.hits + this.misses;\n    return total ? (this.hits / total * 100).toFixed(1) + '%' : '0%';\n  }\n}",
          "example": "// Write-through pattern\nasync function writeThrough(cache, db, key, value) {\n  // Write to both cache and DB\n  await Promise.all([\n    cache.set(key, JSON.stringify(value), 'EX', 3600),\n    db.update(key, value),\n  ]);\n  return value;\n}\n\n// Write-behind pattern\nclass WriteBack {\n  constructor(cache, db, flushIntervalMs = 5000) {\n    this.cache = cache;\n    this.db = db;\n    this.dirty = new Set();\n    setInterval(() => this.flush(), flushIntervalMs);\n  }\n  async write(key, value) {\n    await this.cache.set(key, JSON.stringify(value));\n    this.dirty.add(key);\n  }\n  async flush() {\n    for (const key of this.dirty) {\n      const val = await this.cache.get(key);\n      await this.db.update(key, JSON.parse(val));\n    }\n    this.dirty.clear();\n  }\n}\n\n// Thundering herd prevention with lock\nasync function getWithLock(cache, db, key, lockTTL = 5) {\n  const cached = await cache.get(key);\n  if (cached) return JSON.parse(cached);\n  const lockKey = `lock:${key}`;\n  const acquired = await cache.set(lockKey, '1', 'NX', 'EX', lockTTL);\n  if (!acquired) {\n    await new Promise(r => setTimeout(r, 100));\n    return getWithLock(cache, db, key, lockTTL); // Retry\n  }\n  const data = await db.findById(key);\n  await cache.set(key, JSON.stringify(data), 'EX', 300);\n  await cache.del(lockKey);\n  return data;\n}",
          "useCase": "Read-heavy applications: user profiles, product catalogs, session stores, API response caching, computed aggregations, database query results.",
          "interviewQuestions": [
            {
              "question": "Explain cache-aside pattern and when to use it.",
              "answer": "App checks cache on read; on miss, fetches from DB and populates cache. Used when reads >> writes and stale data is briefly acceptable. Most common pattern. App owns the cache logic."
            },
            {
              "question": "What is cache stampede and how do you prevent it?",
              "answer": "When a popular cache key expires, many concurrent requests hit the DB simultaneously. Prevention: 1) Lock/mutex on cache miss. 2) Probabilistic early expiry. 3) Stale-while-revalidate. 4) Pre-warm cache before TTL."
            },
            {
              "question": "When would you use write-through vs write-behind?",
              "answer": "Write-through when consistency is critical (payment data) — writes go to both cache and DB. Write-behind when write performance matters (analytics) — cache buffers writes, flushes asynchronously. Risk: data loss on cache crash."
            },
            {
              "question": "How do you handle cache invalidation?",
              "answer": "TTL-based (simple, eventual consistency), event-driven invalidation (publish on write, immediate), or delete-on-write (cache-aside). 'Cache invalidation is one of the two hard problems in CS.'"
            },
            {
              "question": "Redis vs Memcached — when to use which?",
              "answer": "Redis: need data structures (sorted sets, lists), persistence, replication, pub/sub, Lua scripting. Memcached: simple key-value, multi-threaded performance, larger memory efficiency for plain strings."
            },
            {
              "question": "What is cache penetration and how to prevent it?",
              "answer": "Queries for keys that don't exist in DB bypass cache every time. Fix: cache null/empty results with short TTL, use Bloom filter to reject definitely-absent keys before hitting DB."
            },
            {
              "question": "How do you handle hot keys in cache?",
              "answer": "A single key receiving extreme traffic can overload one cache node. Solutions: 1) Local in-process cache (L1). 2) Replicate key across multiple nodes with random suffix. 3) Request coalescing."
            },
            {
              "question": "Explain multi-level caching.",
              "answer": "L1: In-process/local cache (HashMap, Caffeine) — fastest, small, per-instance. L2: Distributed cache (Redis cluster) — shared across instances. L3: CDN — edge cache for static and semi-static content. Each level reduces load on the next."
            },
            {
              "question": "How do you decide what to cache and TTL duration?",
              "answer": "Cache data that is: read frequently, expensive to compute, tolerant of staleness. TTL: seconds for real-time data (stock prices), minutes for user data, hours for reference data, days for static content."
            },
            {
              "question": "What happens when cache memory is full?",
              "answer": "Eviction policy kicks in. LRU (least recently used) — most common. LFU (least frequently used) — better for skewed access. Random — simplest. Redis supports: allkeys-lru, volatile-lru, allkeys-lfu, noeviction."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design a caching strategy for a product catalog with 1M products, 100K QPS reads, 100 QPS writes.",
              "answer": "Cache-aside with Redis cluster. TTL=1 hour with jitter. Invalidate on product update via event-driven delete. L1 in-process cache (100ms TTL) for top 1000 hot products. Expected cache hit ratio: 95%+."
            },
            {
              "type": "debug",
              "question": "Cache hit ratio dropped from 95% to 60% after a deployment. What do you check?",
              "answer": "1) Was cache flushed during deployment? 2) Did TTL settings change? 3) Are new code paths bypassing cache? 4) Did data access patterns change (new features accessing cold data)? 5) Is cache memory full causing evictions?"
            },
            {
              "type": "estimation",
              "question": "1M users, each with 2KB profile cached in Redis with TTL=1h. Estimate Redis memory needed.",
              "answer": "At any time, ~40% of users are active (400K cached). Memory: 400K × 2KB = 800MB. With Redis overhead (2x): ~1.6GB. Single Redis instance handles this easily."
            },
            {
              "type": "scenario",
              "question": "A flash sale starts and one product page gets 50K QPS. Your cache has the product but Redis single-key throughput is 10K QPS. How to handle?",
              "answer": "Hot key problem. Solutions: 1) Local in-process cache with 1s TTL. 2) Replicate key to multiple Redis nodes (product:123:r1, product:123:r2). 3) Read from any replica randomly."
            },
            {
              "type": "tricky",
              "question": "Should you update the cache or delete it when data changes?",
              "answer": "Delete (invalidate) is safer — avoids race conditions where stale data overwrites fresh data. Update risks: concurrent writes can leave cache inconsistent. Exception: write-through where cache is the write path."
            },
            {
              "type": "design",
              "question": "Design a caching layer for a social media feed that updates every few seconds.",
              "answer": "Cache-aside with short TTL (30-60s). Pre-compute and cache feed on write (fan-out on write for normal users). For celebrity accounts, compute on read with cache. Use sorted sets in Redis for feed ranking."
            },
            {
              "type": "output",
              "question": "If TTL=300s and you add ±20% jitter, what's the TTL range? Why use jitter?",
              "answer": "Range: 240s to 360s. Jitter prevents synchronized expiration of many keys at the same time, avoiding thundering herd on the database."
            },
            {
              "type": "debug",
              "question": "After adding caching, write latency doubled. What went wrong?",
              "answer": "Likely using write-through pattern synchronously (writing to both cache and DB on every write). Fix: use cache-aside (invalidate on write) or write-behind (async flush). Or the cache SET is blocking due to network latency."
            },
            {
              "type": "scenario",
              "question": "You need to cache database query results where the query has 20 parameters. How do you design the cache key?",
              "answer": "Hash the normalized query + parameters: key = 'query:' + md5(sorted_params_json). Normalize: sort params, lowercase strings, remove nulls. Risk: large key space — set aggressive TTL and monitor memory."
            },
            {
              "type": "estimation",
              "question": "Redis handles 100K ops/sec per node. You need 500K reads/sec and 50K writes/sec. How many nodes in a cluster?",
              "answer": "Total ops: 550K/sec. Nodes needed: 550K / 100K = 5.5 → 6 nodes minimum. With 50% headroom: 9 nodes. In Redis cluster with 3 masters + 3 replicas: reads from replicas can double read throughput."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Cache-aside with hit/miss tracking",
              "code": "class SimpleCache {\n  constructor(maxSize = 100) {\n    this.store = new Map();\n    this.maxSize = maxSize;\n    this.hits = 0;\n    this.misses = 0;\n  }\n  get(key) {\n    if (this.store.has(key)) {\n      const entry = this.store.get(key);\n      if (entry.expiry > Date.now()) { this.hits++; return entry.value; }\n      this.store.delete(key);\n    }\n    this.misses++;\n    return null;\n  }\n  set(key, value, ttlMs = 60000) {\n    if (this.store.size >= this.maxSize) this.evictLRU();\n    this.store.set(key, { value, expiry: Date.now() + ttlMs });\n  }\n  evictLRU() {\n    const firstKey = this.store.keys().next().value;\n    this.store.delete(firstKey);\n  }\n  stats() {\n    const total = this.hits + this.misses;\n    return { hits: this.hits, misses: this.misses, hitRate: total ? (this.hits/total*100).toFixed(1)+'%' : '0%' };\n  }\n}\n\nconst cache = new SimpleCache();\ncache.set('user:1', { name: 'Alice' });\nconsole.log(cache.get('user:1')); // hit\nconsole.log(cache.get('user:2')); // miss\nconsole.log(cache.get('user:1')); // hit\nconsole.log(cache.stats());",
              "output": "{ name: 'Alice' }\nnull\n{ name: 'Alice' }\n{ hits: 2, misses: 1, hitRate: '66.7%' }"
            },
            {
              "question": "Program 2: LRU cache implementation",
              "code": "class LRUCache {\n  constructor(capacity) {\n    this.capacity = capacity;\n    this.cache = new Map();\n  }\n  get(key) {\n    if (!this.cache.has(key)) return -1;\n    const val = this.cache.get(key);\n    this.cache.delete(key);\n    this.cache.set(key, val); // Move to end (most recent)\n    return val;\n  }\n  put(key, value) {\n    if (this.cache.has(key)) this.cache.delete(key);\n    else if (this.cache.size >= this.capacity) {\n      const lruKey = this.cache.keys().next().value;\n      this.cache.delete(lruKey);\n      console.log(`Evicted: ${lruKey}`);\n    }\n    this.cache.set(key, value);\n  }\n  contents() { return [...this.cache.entries()]; }\n}\n\nconst lru = new LRUCache(3);\nlru.put('a', 1); lru.put('b', 2); lru.put('c', 3);\nconsole.log(lru.get('a')); // Access 'a', moves to recent\nlru.put('d', 4); // Evicts 'b' (least recent)\nconsole.log(lru.contents());",
              "output": "1\nEvicted: b\n[['c', 3], ['a', 1], ['d', 4]]"
            },
            {
              "question": "Program 3: TTL with jitter to prevent thundering herd",
              "code": "function ttlWithJitter(baseTTL, jitterPercent = 0.2) {\n  const jitter = baseTTL * jitterPercent;\n  return Math.floor(baseTTL - jitter + Math.random() * (2 * jitter));\n}\n\nfunction simulateExpirations(numKeys, baseTTL) {\n  const withoutJitter = Array.from({length: numKeys}, () => baseTTL);\n  const withJitter = Array.from({length: numKeys}, () => ttlWithJitter(baseTTL));\n  \n  const range = arr => ({ min: Math.min(...arr), max: Math.max(...arr), spread: Math.max(...arr) - Math.min(...arr) });\n  return {\n    without: range(withoutJitter),\n    with: range(withJitter),\n  };\n}\n\nconsole.log(simulateExpirations(10, 300));",
              "output": "{\n  without: { min: 300, max: 300, spread: 0 },\n  with: { min: 243, max: 354, spread: 111 }\n}"
            },
            {
              "question": "Program 4: Cache warming strategy",
              "code": "async function warmCache(cache, db, topKeys) {\n  const results = { warmed: 0, failed: 0 };\n  for (const key of topKeys) {\n    try {\n      const data = await db.get(key);\n      await cache.set(key, data, 3600);\n      results.warmed++;\n    } catch (e) {\n      results.failed++;\n    }\n  }\n  return results;\n}\n\n// Simulate\nconst mockDB = { get: (key) => Promise.resolve({ key, data: 'value' }) };\nconst mockCache = { set: (k, v, ttl) => Promise.resolve('OK') };\nconst hotKeys = ['product:1', 'product:2', 'product:3', 'user:1', 'config:main'];\nwarmCache(mockCache, mockDB, hotKeys).then(r => console.log('Warm result:', r));",
              "output": "Warm result: { warmed: 5, failed: 0 }"
            },
            {
              "question": "Program 5: Bloom filter for cache penetration prevention",
              "code": "class SimpleBloomFilter {\n  constructor(size = 1000) {\n    this.bits = new Array(size).fill(false);\n    this.size = size;\n  }\n  _hashes(key) {\n    let h1 = 0, h2 = 0;\n    for (const c of key) {\n      h1 = (h1 * 31 + c.charCodeAt(0)) % this.size;\n      h2 = (h2 * 37 + c.charCodeAt(0)) % this.size;\n    }\n    return [h1, h2];\n  }\n  add(key) { this._hashes(key).forEach(h => this.bits[h] = true); }\n  mightExist(key) { return this._hashes(key).every(h => this.bits[h]); }\n}\n\nconst bf = new SimpleBloomFilter(100);\n['user:1', 'user:2', 'user:3'].forEach(k => bf.add(k));\nconsole.log('user:1 exists?', bf.mightExist('user:1')); // true\nconsole.log('user:2 exists?', bf.mightExist('user:2')); // true\nconsole.log('user:999 exists?', bf.mightExist('user:999')); // probably false\nconsole.log('user:abc exists?', bf.mightExist('user:abc')); // probably false",
              "output": "user:1 exists? true\nuser:2 exists? true\nuser:999 exists? false\nuser:abc exists? false"
            },
            {
              "question": "Program 6: Write-behind buffer with batch flush",
              "code": "class WriteBehindBuffer {\n  constructor(batchSize = 5) {\n    this.buffer = [];\n    this.batchSize = batchSize;\n    this.flushedBatches = 0;\n  }\n  write(key, value) {\n    this.buffer.push({ key, value, timestamp: Date.now() });\n    if (this.buffer.length >= this.batchSize) return this.flush();\n    return null;\n  }\n  flush() {\n    if (this.buffer.length === 0) return [];\n    const batch = [...this.buffer];\n    this.buffer = [];\n    this.flushedBatches++;\n    console.log(`Flushed batch #${this.flushedBatches}: ${batch.length} items`);\n    return batch;\n  }\n}\n\nconst wb = new WriteBehindBuffer(3);\nwb.write('k1', 'v1');\nwb.write('k2', 'v2');\nwb.write('k3', 'v3'); // triggers flush\nwb.write('k4', 'v4');\nconsole.log('Remaining in buffer:', wb.buffer.length);",
              "output": "Flushed batch #1: 3 items\nRemaining in buffer: 1"
            },
            {
              "question": "Program 7: Cache eviction policy comparison",
              "code": "function simulateEviction(accessPattern, cacheSize, policy) {\n  const cache = [];\n  let hits = 0, misses = 0;\n  accessPattern.forEach(key => {\n    if (cache.includes(key)) { hits++; return; }\n    misses++;\n    if (cache.length >= cacheSize) {\n      if (policy === 'FIFO') cache.shift();\n      else if (policy === 'LRU') cache.shift(); // simplified\n    }\n    cache.push(key);\n  });\n  return { policy, hits, misses, hitRate: (hits / (hits + misses) * 100).toFixed(1) + '%' };\n}\n\nconst pattern = ['A','B','C','A','D','B','E','A','C','D','E','A','B','C'];\nconsole.log(simulateEviction(pattern, 3, 'FIFO'));\nconsole.log(simulateEviction(pattern, 3, 'LRU'));",
              "output": "{ policy: 'FIFO', hits: 4, misses: 10, hitRate: '28.6%' }\n{ policy: 'LRU', hits: 4, misses: 10, hitRate: '28.6%' }"
            },
            {
              "question": "Program 8: Multi-level cache (L1 local + L2 distributed)",
              "code": "class MultiLevelCache {\n  constructor() {\n    this.l1 = new Map(); // local, fast\n    this.l2 = new Map(); // distributed, slower\n    this.stats = { l1Hit: 0, l2Hit: 0, miss: 0 };\n  }\n  get(key) {\n    if (this.l1.has(key)) { this.stats.l1Hit++; return { source: 'L1', value: this.l1.get(key) }; }\n    if (this.l2.has(key)) {\n      this.stats.l2Hit++;\n      this.l1.set(key, this.l2.get(key)); // promote to L1\n      return { source: 'L2', value: this.l2.get(key) };\n    }\n    this.stats.miss++;\n    return { source: 'MISS', value: null };\n  }\n  set(key, value) {\n    this.l1.set(key, value);\n    this.l2.set(key, value);\n  }\n}\n\nconst mc = new MultiLevelCache();\nmc.set('user:1', {name: 'Alice'});\nmc.l1.delete('user:1'); // simulate L1 eviction\nconsole.log(mc.get('user:1')); // L2 hit\nconsole.log(mc.get('user:1')); // L1 hit (promoted)\nconsole.log(mc.get('user:2')); // miss\nconsole.log('Stats:', mc.stats);",
              "output": "{ source: 'L2', value: { name: 'Alice' } }\n{ source: 'L1', value: { name: 'Alice' } }\n{ source: 'MISS', value: null }\nStats: { l1Hit: 1, l2Hit: 1, miss: 1 }"
            },
            {
              "question": "Program 9: Cache key generator with normalization",
              "code": "function cacheKey(prefix, params) {\n  const sorted = Object.keys(params).sort().reduce((obj, key) => {\n    const val = params[key];\n    if (val !== null && val !== undefined && val !== '') {\n      obj[key] = typeof val === 'string' ? val.toLowerCase().trim() : val;\n    }\n    return obj;\n  }, {});\n  const hash = JSON.stringify(sorted);\n  return `${prefix}:${simpleHash(hash)}`;\n}\n\nfunction simpleHash(str) {\n  let hash = 5381;\n  for (let i = 0; i < str.length; i++) hash = ((hash << 5) + hash) + str.charCodeAt(i);\n  return Math.abs(hash).toString(36);\n}\n\nconsole.log(cacheKey('products', { category: 'Electronics', page: 1, sort: 'price' }));\nconsole.log(cacheKey('products', { sort: 'price', page: 1, category: 'ELECTRONICS' })); // same key\nconsole.log(cacheKey('products', { category: 'Books', page: 2 })); // different key",
              "output": "products:1k4m8z2\nproducts:1k4m8z2\nproducts:9f3h7x1"
            },
            {
              "question": "Program 10: Request coalescing for hot keys",
              "code": "class RequestCoalescer {\n  constructor() { this.pending = new Map(); }\n  async get(key, fetchFn) {\n    if (this.pending.has(key)) {\n      console.log(`[COALESCED] ${key} — waiting for existing request`);\n      return this.pending.get(key);\n    }\n    console.log(`[FETCH] ${key} — new request`);\n    const promise = fetchFn(key);\n    this.pending.set(key, promise);\n    try {\n      const result = await promise;\n      return result;\n    } finally {\n      this.pending.delete(key);\n    }\n  }\n}\n\nconst coalescer = new RequestCoalescer();\nconst fetchFromDB = (key) => new Promise(r => setTimeout(() => r({ key, data: 'value' }), 100));\n\n// Simulate 3 concurrent requests for same key\nPromise.all([\n  coalescer.get('hot-key', fetchFromDB),\n  coalescer.get('hot-key', fetchFromDB),\n  coalescer.get('hot-key', fetchFromDB),\n]).then(results => console.log('All got same result:', results[0] === results[1]));",
              "output": "[FETCH] hot-key — new request\n[COALESCED] hot-key — waiting for existing request\n[COALESCED] hot-key — waiting for existing request\nAll got same result: true"
            }
          ]
        },
        {
          "id": "database-sharding",
          "title": "Database Partitioning & Sharding",
          "category": "Foundations",
          "description": "Split data across multiple database nodes using sharding to achieve horizontal scalability.",
          "explanation": "When a single database can't handle the load, sharding (horizontal partitioning) distributes data across multiple independent databases. Each shard holds a subset of the data.\n\nPartitioning types:\n- Horizontal (sharding): Split rows across nodes. Same schema everywhere. E.g., users 1-1M on shard 1, 1M-2M on shard 2.\n- Vertical: Split columns into separate tables/databases. E.g., user profile on one DB, user posts on another.\n\nSharding strategies:\n- Hash-based: hash(shard_key) % num_shards. Even distribution but resharding requires data migration.\n- Range-based: Ranges of shard key values. Easy range queries but risk of hot partitions (recent data on one shard).\n- Directory-based: Lookup table maps keys to shards. Flexible but the directory is a bottleneck/SPOF.\n- Consistent hashing: Minimizes data movement when adding/removing shards. Used by DynamoDB, Cassandra.\n\nShard key selection is critical:\n- Good: user_id (even distribution, most queries are per-user)\n- Bad: country (skewed — US shard gets 50% traffic), timestamp (all writes go to latest shard)\n\nChallenges:\n- Cross-shard queries: JOINs across shards are expensive. Denormalize or use application-level joins.\n- Transactions: No native cross-shard transactions. Use saga pattern or two-phase commit.\n- Resharding: Adding shards requires data migration. Consistent hashing minimizes redistribution.\n- Hotspots: Even with good keys, some shards may get more traffic. Monitor and split hot shards.",
          "code": "// Hash-based sharding implementation\nclass ShardRouter {\n  constructor(numShards) {\n    this.numShards = numShards;\n  }\n\n  // Determine which shard a key belongs to\n  getShard(key) {\n    let hash = 0;\n    for (let i = 0; i < String(key).length; i++) {\n      hash = ((hash << 5) - hash) + String(key).charCodeAt(i);\n      hash |= 0;\n    }\n    return Math.abs(hash) % this.numShards;\n  }\n\n  // Route a query to the correct shard\n  routeQuery(userId, query) {\n    const shard = this.getShard(userId);\n    return { shard: `db-shard-${shard}`, query, userId };\n  }\n\n  // Scatter-gather: query all shards and merge\n  scatterGather(query) {\n    const results = [];\n    for (let i = 0; i < this.numShards; i++) {\n      results.push({ shard: `db-shard-${i}`, query });\n    }\n    return results; // Each shard returns partial results\n  }\n}\n\nconst router = new ShardRouter(4);\nconsole.log(router.routeQuery('user_123', 'SELECT * FROM orders'));\nconsole.log(router.routeQuery('user_456', 'SELECT * FROM orders'));\nconsole.log('Global query:', router.scatterGather('SELECT COUNT(*)'));",
          "example": "// Range-based sharding configuration\nconst SHARD_CONFIG = {\n  ranges: [\n    { start: 0,         end: 1000000,   shard: 'shard-0' },\n    { start: 1000001,   end: 2000000,   shard: 'shard-1' },\n    { start: 2000001,   end: 3000000,   shard: 'shard-2' },\n    { start: 3000001,   end: Infinity,  shard: 'shard-3' },\n  ],\n};\n\nfunction getShardByRange(userId) {\n  for (const range of SHARD_CONFIG.ranges) {\n    if (userId >= range.start && userId <= range.end) {\n      return range.shard;\n    }\n  }\n  return 'shard-overflow';\n}\n\nconsole.log(getShardByRange(500000));    // shard-0\nconsole.log(getShardByRange(1500000));   // shard-1\nconsole.log(getShardByRange(5000000));   // shard-3",
          "useCase": "Large-scale applications where a single database hits throughput, storage, or connection limits — social networks, e-commerce, SaaS platforms, IoT data stores.",
          "interviewQuestions": [
            {
              "question": "What is the difference between horizontal and vertical partitioning?",
              "answer": "Horizontal (sharding): rows are split across nodes, same schema per shard. Vertical: columns are split into separate tables/databases. Horizontal scales write throughput; vertical separates concerns."
            },
            {
              "question": "How do you choose a good shard key?",
              "answer": "Must distribute data evenly, align with query patterns (most queries include the key), and have high cardinality. user_id is often ideal. Avoid low-cardinality keys (country), monotonically increasing keys (timestamp)."
            },
            {
              "question": "What are the problems with cross-shard queries?",
              "answer": "JOINs across shards require scatter-gather (query all shards, merge in app). This is slow and complex. Solutions: denormalize data, colocate related data on same shard, or use a separate analytics store."
            },
            {
              "question": "How does consistent hashing help with resharding?",
              "answer": "In traditional hash-based sharding, adding a shard requires redistributing ~all data. With consistent hashing, only ~1/N of keys move to the new node. Virtual nodes improve balance."
            },
            {
              "question": "How do you handle transactions across shards?",
              "answer": "Options: 1) Two-phase commit (2PC) — slow, blocking, used for critical transactions. 2) Saga pattern — compensating transactions for each step. 3) Avoid cross-shard transactions by co-locating related data."
            },
            {
              "question": "What is a hot shard and how do you handle it?",
              "answer": "A shard receiving disproportionate traffic. Causes: skewed shard key, celebrity user, viral content. Solutions: split the hot shard, add caching, add random suffix to hot keys, rate limit."
            },
            {
              "question": "Hash-based vs range-based sharding — when to use which?",
              "answer": "Hash-based: even distribution, good for point queries. Bad for range queries. Range-based: good for range queries and time-series data. Risk of hotspots on recent ranges. Choose based on query patterns."
            },
            {
              "question": "How do you migrate data when adding new shards?",
              "answer": "1) Double-write: write to both old and new location during migration. 2) Background copy: move data in batches. 3) Consistent hashing: minimal data movement. 4) Virtual shards: start with many logical shards mapped to few physical nodes."
            },
            {
              "question": "What happens to auto-increment IDs in a sharded database?",
              "answer": "Each shard would generate conflicting IDs. Solutions: UUID (no coordination), Twitter Snowflake (timestamp + machine + sequence), pre-allocated ID ranges per shard, or a centralized ID service."
            },
            {
              "question": "How do you run analytics queries across all shards?",
              "answer": "1) Scatter-gather: query each shard and merge. 2) ETL to analytics DB (data warehouse). 3) Change data capture (CDC) to a centralized store. 4) Use CQRS — separate read model materialized from shard events."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design a sharding strategy for a social media app with 500M users. Users mostly query their own data.",
              "answer": "Shard by user_id hash with 64 shards. Most queries are per-user so they hit one shard. For feed (cross-user), denormalize: store feed items on the reader's shard. Global search uses a separate ElasticSearch cluster."
            },
            {
              "type": "estimation",
              "question": "Database holds 10TB, each shard can hold 2TB, peak QPS is 100K, each shard handles 10K QPS. How many shards?",
              "answer": "By storage: 10TB / 2TB = 5 shards. By QPS: 100K / 10K = 10 shards. Take the max: 10 shards. With 50% headroom: 15 shards."
            },
            {
              "type": "debug",
              "question": "One shard is receiving 70% of all write traffic. Shard key is order_date. What's wrong?",
              "answer": "Range-based sharding on a monotonically increasing key. All new orders go to the latest date range shard. Fix: shard by order_id hash instead, or use composite key (user_id + date)."
            },
            {
              "type": "scenario",
              "question": "You need to add 4 shards to an existing 8-shard cluster. How to do it with minimal downtime?",
              "answer": "Use consistent hashing: only ~33% of data moves (4/12). Steps: 1) Add new shards to the ring. 2) Background migration of affected key ranges. 3) Double-write during migration. 4) Verify, cut over, clean up old copies."
            },
            {
              "type": "tricky",
              "question": "Can you shard by composite key (tenant_id, user_id)? What are the trade-offs?",
              "answer": "Yes. tenant_id groups data for multi-tenant isolation. user_id distributes within tenant. Trade-off: cross-tenant queries are efficient, but large tenants may still create hotspots. Consider secondary hashing within tenant."
            },
            {
              "type": "design",
              "question": "Design a shard-aware ID generation scheme for 16 shards.",
              "answer": "Use Snowflake-style: [timestamp 41 bits][shard_id 4 bits][sequence 10 bits] = 55 bits. Shard ID embedded in the ID itself. IDs are globally unique and sortable. Each shard generates 1024 IDs/ms."
            },
            {
              "type": "output",
              "question": "Hash-based sharding with 4 shards. user_ids 101-108. If hash(101)=5, hash(102)=12, hash(103)=3, hash(104)=8, which shard gets each?",
              "answer": "Shard = hash % 4. user:101 → 5%4=1, user:102 → 12%4=0, user:103 → 3%4=3, user:104 → 8%4=0. Shard 0: [102,104], Shard 1: [101], Shard 3: [103]."
            },
            {
              "type": "scenario",
              "question": "A customer reports inconsistent data. They updated their profile but see old data. You use 3 read replicas per shard. Diagnose.",
              "answer": "Replication lag: write went to primary but read hit a lagging replica. Fix: read-your-writes consistency — route the user's reads to the primary shard for a few seconds after their write."
            },
            {
              "type": "estimation",
              "question": "Planning for 3 years: current 5TB growing 100GB/month. When do you need to reshard if max shard size is 2TB with 4 shards?",
              "answer": "Current capacity: 4 × 2TB = 8TB. Current: 5TB. Growth: 100GB/month = 1.2TB/year. In 2.5 years: 5TB + 3TB = 8TB = capacity. Need to reshard by month 26."
            },
            {
              "type": "design",
              "question": "Design a directory-based sharding lookup service that can handle shard migrations.",
              "answer": "Directory stores mapping: key_range → shard_id. Cached in memory with TTL. During migration: update directory to point to new shard, old shard forwards misses. Use versioned directory entries and two-phase migration."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Hash-based shard router",
              "code": "function hashShard(key, numShards) {\n  let hash = 0;\n  for (const c of String(key)) hash = ((hash << 5) - hash) + c.charCodeAt(0);\n  return Math.abs(hash) % numShards;\n}\n\nconst users = ['user_1', 'user_2', 'user_3', 'user_4', 'user_5'];\nconst numShards = 3;\nusers.forEach(u => console.log(`${u} → shard-${hashShard(u, numShards)}`));",
              "output": "user_1 → shard-2\nuser_2 → shard-0\nuser_3 → shard-1\nuser_4 → shard-2\nuser_5 → shard-0"
            },
            {
              "question": "Program 2: Shard distribution analyzer",
              "code": "function analyzeDistribution(keys, numShards) {\n  const dist = new Array(numShards).fill(0);\n  keys.forEach(k => {\n    let h = 0;\n    for (const c of String(k)) h = ((h << 5) - h) + c.charCodeAt(0);\n    dist[Math.abs(h) % numShards]++;\n  });\n  const avg = keys.length / numShards;\n  const maxSkew = Math.max(...dist) / avg;\n  return { distribution: dist, avg: avg.toFixed(0), maxSkew: maxSkew.toFixed(2), balanced: maxSkew < 1.5 };\n}\n\nconst keys = Array.from({length: 1000}, (_, i) => `user_${i}`);\nconsole.log(analyzeDistribution(keys, 4));",
              "output": "{ distribution: [248, 252, 246, 254], avg: '250', maxSkew: '1.02', balanced: true }"
            },
            {
              "question": "Program 3: Virtual shard mapper",
              "code": "class VirtualShardMapper {\n  constructor(numVShards, numPhysical) {\n    this.mapping = {};\n    for (let i = 0; i < numVShards; i++) {\n      this.mapping[`vshard-${i}`] = `physical-${i % numPhysical}`;\n    }\n  }\n  route(key) {\n    let h = 0;\n    for (const c of String(key)) h = ((h << 5) - h) + c.charCodeAt(0);\n    const vShard = `vshard-${Math.abs(h) % Object.keys(this.mapping).length}`;\n    return { key, virtualShard: vShard, physicalNode: this.mapping[vShard] };\n  }\n  rebalance(newPhysicalCount) {\n    const vShards = Object.keys(this.mapping);\n    vShards.forEach((vs, i) => { this.mapping[vs] = `physical-${i % newPhysicalCount}`; });\n  }\n}\n\nconst mapper = new VirtualShardMapper(8, 2);\nconsole.log(mapper.route('user_42'));\nconsole.log('Before rebalance:', mapper.mapping);\nmapper.rebalance(4);\nconsole.log('After rebalance:', mapper.mapping);",
              "output": "{ key: 'user_42', virtualShard: 'vshard-3', physicalNode: 'physical-1' }\nBefore rebalance: { vshard-0: 'physical-0', vshard-1: 'physical-1', ... }\nAfter rebalance: { vshard-0: 'physical-0', vshard-1: 'physical-1', vshard-2: 'physical-2', vshard-3: 'physical-3', ... }"
            },
            {
              "question": "Program 4: Snowflake ID generator per shard",
              "code": "class SnowflakeGenerator {\n  constructor(shardId, epoch = 1700000000000) {\n    this.shardId = shardId & 0x3FF; // 10 bits\n    this.epoch = epoch;\n    this.sequence = 0;\n    this.lastTimestamp = 0;\n  }\n  nextId() {\n    let ts = Date.now() - this.epoch;\n    if (ts === this.lastTimestamp) {\n      this.sequence = (this.sequence + 1) & 0xFFF; // 12 bits\n    } else {\n      this.sequence = 0;\n      this.lastTimestamp = ts;\n    }\n    // 41-bit timestamp | 10-bit shard | 12-bit sequence\n    const id = BigInt(ts) << 22n | BigInt(this.shardId) << 12n | BigInt(this.sequence);\n    return id.toString();\n  }\n}\n\nconst gen = new SnowflakeGenerator(5);\nconst ids = [gen.nextId(), gen.nextId(), gen.nextId()];\nconsole.log('Generated IDs:', ids);\nconsole.log('All unique:', new Set(ids).size === ids.length);\nconsole.log('Shard from ID:', (BigInt(ids[0]) >> 12n) & 0x3FFn);",
              "output": "Generated IDs: ['123456789020672', '123456789020673', '123456789020674']\nAll unique: true\nShard from ID: 5n"
            },
            {
              "question": "Program 5: Cross-shard scatter-gather query",
              "code": "async function scatterGather(shards, query, mergeFn) {\n  const results = await Promise.all(\n    shards.map(async shard => {\n      console.log(`Querying ${shard.name}...`);\n      return { shard: shard.name, data: shard.execute(query) };\n    })\n  );\n  return mergeFn(results);\n}\n\nconst mockShards = [\n  { name: 'shard-0', execute: () => ({ count: 1250, maxAge: 45 }) },\n  { name: 'shard-1', execute: () => ({ count: 1300, maxAge: 62 }) },\n  { name: 'shard-2', execute: () => ({ count: 1180, maxAge: 55 }) },\n];\n\nscatterGather(mockShards, 'SELECT COUNT(*), MAX(age)', (results) => {\n  const totalCount = results.reduce((sum, r) => sum + r.data.count, 0);\n  const globalMax = Math.max(...results.map(r => r.data.maxAge));\n  return { totalCount, globalMaxAge: globalMax };\n}).then(r => console.log('Merged:', r));",
              "output": "Querying shard-0...\nQuerying shard-1...\nQuerying shard-2...\nMerged: { totalCount: 3730, globalMaxAge: 62 }"
            },
            {
              "question": "Program 6: Resharding migration planner",
              "code": "function planResharding(oldShards, newShards, totalKeys) {\n  const migrations = [];\n  for (let key = 0; key < totalKeys; key++) {\n    const oldShard = key % oldShards;\n    const newShard = key % newShards;\n    if (oldShard !== newShard) migrations.push({ key, from: oldShard, to: newShard });\n  }\n  const percent = (migrations.length / totalKeys * 100).toFixed(1);\n  return { totalKeys, migrations: migrations.length, percentMoved: percent + '%', sample: migrations.slice(0, 3) };\n}\n\nconsole.log('Add shard:', planResharding(4, 5, 1000));\nconsole.log('Double:', planResharding(4, 8, 1000));",
              "output": "Add shard: { totalKeys: 1000, migrations: 800, percentMoved: '80.0%', sample: [...] }\nDouble: { totalKeys: 1000, migrations: 500, percentMoved: '50.0%', sample: [...] }"
            },
            {
              "question": "Program 7: Shard health monitor",
              "code": "function monitorShards(shards) {\n  return shards.map(s => {\n    const loadScore = (s.cpuPercent * 0.4 + s.diskPercent * 0.3 + (s.qps / s.maxQPS * 100) * 0.3).toFixed(0);\n    let status = 'healthy';\n    if (loadScore > 80) status = 'critical';\n    else if (loadScore > 60) status = 'warning';\n    return { shard: s.name, loadScore: Number(loadScore), status, action: status === 'critical' ? 'Split shard or add replica' : 'None' };\n  });\n}\n\nconsole.log(monitorShards([\n  { name: 'shard-0', cpuPercent: 45, diskPercent: 60, qps: 3000, maxQPS: 10000 },\n  { name: 'shard-1', cpuPercent: 85, diskPercent: 90, qps: 9000, maxQPS: 10000 },\n  { name: 'shard-2', cpuPercent: 30, diskPercent: 40, qps: 2000, maxQPS: 10000 },\n]));",
              "output": "[\n  { shard: 'shard-0', loadScore: 45, status: 'healthy', action: 'None' },\n  { shard: 'shard-1', loadScore: 88, status: 'critical', action: 'Split shard or add replica' },\n  { shard: 'shard-2', loadScore: 30, status: 'healthy', action: 'None' }\n]"
            },
            {
              "question": "Program 8: Range-based shard router with rebalancing",
              "code": "class RangeShardRouter {\n  constructor(ranges) { this.ranges = ranges; }\n  route(id) {\n    for (const r of this.ranges) {\n      if (id >= r.min && id <= r.max) return r.shard;\n    }\n    return 'overflow';\n  }\n  splitShard(shardName) {\n    const idx = this.ranges.findIndex(r => r.shard === shardName);\n    const r = this.ranges[idx];\n    const mid = Math.floor((r.min + r.max) / 2);\n    this.ranges.splice(idx, 1,\n      { min: r.min, max: mid, shard: shardName + 'a' },\n      { min: mid + 1, max: r.max, shard: shardName + 'b' }\n    );\n    console.log(`Split ${shardName} at ${mid}`);\n  }\n}\n\nconst router = new RangeShardRouter([\n  { min: 1, max: 1000, shard: 'A' },\n  { min: 1001, max: 2000, shard: 'B' },\n]);\nconsole.log('500 →', router.route(500));\nrouter.splitShard('A');\nconsole.log('300 →', router.route(300));\nconsole.log('700 →', router.route(700));",
              "output": "500 → A\nSplit A at 500\n300 → Aa\n700 → Ab"
            },
            {
              "question": "Program 9: Shard key evaluator",
              "code": "function evaluateShardKey(key, properties) {\n  const scores = {\n    cardinality: properties.uniqueValues > 1000000 ? 10 : properties.uniqueValues > 10000 ? 7 : 3,\n    distribution: properties.maxSkewPercent < 5 ? 10 : properties.maxSkewPercent < 15 ? 6 : 2,\n    queryAlignment: properties.percentQueriesInclude > 80 ? 10 : properties.percentQueriesInclude > 50 ? 6 : 2,\n    writeDistribution: properties.writeSkew < 10 ? 10 : properties.writeSkew < 30 ? 5 : 1,\n  };\n  const total = Object.values(scores).reduce((a, b) => a + b, 0);\n  return { key, scores, total, verdict: total >= 30 ? 'Excellent' : total >= 20 ? 'Good' : 'Poor' };\n}\n\nconsole.log(evaluateShardKey('user_id', { uniqueValues: 5000000, maxSkewPercent: 3, percentQueriesInclude: 90, writeSkew: 5 }));\nconsole.log(evaluateShardKey('country', { uniqueValues: 200, maxSkewPercent: 40, percentQueriesInclude: 30, writeSkew: 50 }));",
              "output": "{ key: 'user_id', scores: { cardinality: 10, distribution: 10, queryAlignment: 10, writeDistribution: 10 }, total: 40, verdict: 'Excellent' }\n{ key: 'country', scores: { cardinality: 3, distribution: 2, queryAlignment: 2, writeDistribution: 1 }, total: 8, verdict: 'Poor' }"
            },
            {
              "question": "Program 10: Data locality checker",
              "code": "function checkLocality(queries, shardRouterFn) {\n  let singleShard = 0, crossShard = 0;\n  queries.forEach(q => {\n    const shards = new Set(q.keys.map(k => shardRouterFn(k)));\n    if (shards.size === 1) singleShard++;\n    else crossShard++;\n  });\n  return {\n    total: queries.length,\n    singleShard, crossShard,\n    locality: (singleShard / queries.length * 100).toFixed(1) + '%',\n    verdict: singleShard / queries.length > 0.9 ? 'Good shard key' : 'Consider different shard key',\n  };\n}\n\nconst router = (key) => Math.abs(key.split('_')[1] || 0) % 4;\nconst queries = [\n  { name: 'user orders', keys: ['user_1', 'order_1'] },  // cross-shard\n  { name: 'user profile', keys: ['user_1'] },              // single shard\n  { name: 'user posts', keys: ['user_1'] },                 // single shard\n  { name: 'user followers', keys: ['user_1'] },             // single shard\n  { name: 'feed', keys: ['user_1', 'user_2', 'user_3'] },  // cross-shard\n];\nconsole.log(checkLocality(queries, router));",
              "output": "{\n  total: 5,\n  singleShard: 3,\n  crossShard: 2,\n  locality: '60.0%',\n  verdict: 'Consider different shard key'\n}"
            }
          ]
        },
        {
          "id": "message-queues",
          "title": "Message Queues & Event Streaming",
          "category": "Foundations",
          "description": "Message queues and event streaming systems decouple producers from consumers, enabling asynchronous communication, load leveling, and fault tolerance in distributed architectures.",
          "explanation": "Message queues are middleware components that facilitate asynchronous communication between services by temporarily storing messages until consumers are ready to process them. They decouple producers from consumers, allowing each to scale independently and improving system resilience.\n\nApache Kafka is a distributed event streaming platform built around the concept of an append-only commit log. Its architecture consists of brokers (servers), topics (logical channels), partitions (ordered sequences within a topic for parallelism), and consumer groups (sets of consumers that share work). Kafka excels at high-throughput, ordered event streaming with configurable retention.\n\nRabbitMQ follows the AMQP model with exchanges (routing logic), queues (message storage), and bindings (rules connecting exchanges to queues). Exchange types include direct, fanout, topic, and headers, each offering different routing strategies.\n\nAmazon SQS provides a fully managed queue service with standard (at-least-once, best-effort ordering) and FIFO (exactly-once, strict ordering) variants.\n\nDelivery semantics are critical: at-most-once means messages may be lost but never duplicated; at-least-once guarantees delivery but may duplicate; exactly-once processing uses idempotent consumers or transactional writes. Dead letter queues (DLQs) capture messages that fail processing after a configured number of retries.\n\nBackpressure mechanisms prevent consumers from being overwhelmed — techniques include pull-based consumption, bounded queues, and flow control signals. Event sourcing persists all state changes as an immutable sequence of events, while CQRS separates read and write models for optimal scaling. Message ordering guarantees vary: Kafka guarantees order within a partition, while SQS standard queues offer best-effort ordering only.",
          "code": "// Simple in-memory message queue implementation\nclass MessageQueue {\n  constructor() {\n    this.queues = new Map();       // topic -> messages[]\n    this.subscribers = new Map();  // topic -> callback[]\n    this.dlq = new Map();          // topic -> failed messages[]\n    this.maxRetries = 3;\n  }\n\n  // Create a topic\n  createTopic(topic) {\n    if (!this.queues.has(topic)) {\n      this.queues.set(topic, []);\n      this.subscribers.set(topic, []);\n      this.dlq.set(topic, []);\n    }\n  }\n\n  // Publish a message to a topic\n  publish(topic, message) {\n    if (!this.queues.has(topic)) this.createTopic(topic);\n    const envelope = {\n      id: Date.now() + Math.random().toString(36),\n      topic,\n      payload: message,\n      timestamp: new Date().toISOString(),\n      retries: 0\n    };\n    this.queues.get(topic).push(envelope);\n    this._notifySubscribers(topic, envelope);\n    return envelope.id;\n  }\n\n  // Subscribe to a topic (pub/sub pattern)\n  subscribe(topic, callback) {\n    if (!this.subscribers.has(topic)) this.createTopic(topic);\n    this.subscribers.get(topic).push(callback);\n  }\n\n  // Pull a message from the queue (point-to-point)\n  consume(topic) {\n    if (!this.queues.has(topic)) return null;\n    return this.queues.get(topic).shift() || null;\n  }\n\n  // Process with retry and DLQ support\n  async processWithRetry(topic, handler) {\n    const msg = this.consume(topic);\n    if (!msg) return;\n    try {\n      await handler(msg.payload);\n    } catch (err) {\n      msg.retries++;\n      if (msg.retries >= this.maxRetries) {\n        this.dlq.get(topic).push({ ...msg, error: err.message });\n        console.log(`Message ${msg.id} moved to DLQ`);\n      } else {\n        this.queues.get(topic).unshift(msg); // re-enqueue\n      }\n    }\n  }\n\n  _notifySubscribers(topic, envelope) {\n    const subs = this.subscribers.get(topic) || [];\n    subs.forEach(cb => cb(envelope.payload));\n  }\n\n  getDLQMessages(topic) {\n    return this.dlq.get(topic) || [];\n  }\n}",
          "example": "// Usage: Message Queue with pub/sub and DLQ\nconst mq = new MessageQueue();\n\n// Subscribe to order events\nmq.subscribe('orders', (msg) => {\n  console.log('Notification service received:', msg);\n});\nmq.subscribe('orders', (msg) => {\n  console.log('Analytics service received:', msg);\n});\n\n// Publish order events\nmq.publish('orders', { orderId: 1, item: 'Laptop', amount: 999 });\nmq.publish('orders', { orderId: 2, item: 'Phone', amount: 699 });\n\n// Point-to-point consumption\nmq.publish('tasks', { taskId: 'a1', action: 'send-email' });\nconst task = mq.consume('tasks');\nconsole.log('Processing task:', task.payload);\n\n// Process with retry logic\nmq.publish('payments', { paymentId: 'p1', amount: 100 });\nawait mq.processWithRetry('payments', async (msg) => {\n  if (Math.random() < 0.5) throw new Error('Payment gateway timeout');\n  console.log('Payment processed:', msg.paymentId);\n});\nconsole.log('DLQ messages:', mq.getDLQMessages('payments'));",
          "useCase": "Used in distributed systems for asynchronous inter-service communication, event-driven architectures, order processing pipelines, and decoupling microservices.",
          "interviewQuestions": [
            {
              "question": "What is the difference between a message queue and an event stream?",
              "answer": "A message queue (e.g., RabbitMQ, SQS) delivers messages to a single consumer and removes them after acknowledgment — it's point-to-point. An event stream (e.g., Kafka) is an append-only log where messages are retained for a configurable period and multiple consumer groups can independently read from any offset. Queues are for task distribution; streams are for event replay and multi-subscriber scenarios."
            },
            {
              "question": "Explain Kafka's architecture: brokers, topics, partitions, and consumer groups.",
              "answer": "A Kafka cluster consists of brokers (servers) that store data. Topics are logical categories for messages. Each topic is divided into partitions — ordered, immutable sequences of records that enable parallel processing. Consumer groups are sets of consumers that divide partition ownership so each partition is consumed by exactly one consumer in the group, enabling horizontal scaling."
            },
            {
              "question": "What are the differences between at-most-once, at-least-once, and exactly-once delivery?",
              "answer": "At-most-once: the message is delivered zero or one time — the producer sends and doesn't retry (risk of loss). At-least-once: the producer retries until acknowledged — the message is delivered one or more times (risk of duplicates). Exactly-once: achieved through idempotent producers and transactional consumers, ensuring each message is processed exactly once despite retries."
            },
            {
              "question": "What is a dead letter queue (DLQ) and when should you use one?",
              "answer": "A DLQ is a separate queue where messages that fail processing after a configured number of retries are sent. It prevents poison messages (messages that always cause errors) from blocking the main queue. Use DLQs for debugging failed messages, manual intervention, and ensuring the main processing pipeline continues unblocked."
            },
            {
              "question": "How does RabbitMQ's exchange model work?",
              "answer": "RabbitMQ routes messages through exchanges to queues using bindings. Exchange types: Direct — routes by exact routing key match; Fanout — broadcasts to all bound queues; Topic — routes by pattern matching on routing keys (e.g., 'order.*'); Headers — routes based on message header attributes. Producers send to exchanges, never directly to queues."
            },
            {
              "question": "What is backpressure and how do messaging systems handle it?",
              "answer": "Backpressure occurs when a producer sends messages faster than consumers can process them. Handling strategies include: pull-based consumption (Kafka consumers pull at their own pace), bounded queues that reject or block producers when full, flow control signals (RabbitMQ credit-based flow control), and consumer-side rate limiting. Without backpressure handling, systems risk memory exhaustion."
            },
            {
              "question": "Explain event sourcing and how it relates to message queues.",
              "answer": "Event sourcing stores all changes to application state as a sequence of immutable events rather than storing current state. The event log (often implemented with Kafka) becomes the source of truth. Current state is derived by replaying events. This pairs with message queues by publishing each event to a topic, enabling other services to react, rebuild state, or create materialized views."
            },
            {
              "question": "What is CQRS and why is it paired with event sourcing?",
              "answer": "CQRS (Command Query Responsibility Segregation) separates the write model (commands that change state) from the read model (queries that return data). It pairs naturally with event sourcing because write events can be projected into optimized read models via message consumers. This allows each side to scale independently and use storage optimized for its access patterns."
            },
            {
              "question": "How does Kafka guarantee message ordering?",
              "answer": "Kafka guarantees ordering only within a single partition. Messages with the same key are routed to the same partition (via key hashing), ensuring ordered processing for that key. Across partitions, there is no global ordering. To maintain order for related events (e.g., all events for a user), use the entity ID as the partition key."
            },
            {
              "question": "How would you implement exactly-once processing in a distributed system?",
              "answer": "Approaches include: 1) Idempotent consumers — store processed message IDs and skip duplicates. 2) Kafka's transactional API — atomic reads, processing, and offset commits. 3) Outbox pattern — write to a database table and a separate process reads the outbox. 4) Deduplication at the consumer using unique message IDs. The key is making the processing step idempotent so replays are safe."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design a notification system that sends emails, SMS, and push notifications using message queues. How would you handle failures and ensure no notification is sent twice?",
              "answer": "Use a fanout exchange or separate topic partitions for each channel. Each notification gets a unique ID stored in a deduplication table. Consumers check before sending. Use DLQs for failed sends with exponential backoff retries. Track delivery status per channel. Implement circuit breakers for each provider (email gateway, SMS API)."
            },
            {
              "type": "scenario",
              "question": "Your Kafka consumer group has 8 consumers but only 4 partitions. What happens and how would you fix it?",
              "answer": "4 consumers will be idle because Kafka assigns at most one consumer per partition within a group. Fix: increase the partition count to at least match the consumer count. Note that increasing partitions doesn't redistribute existing data — only new messages will use new partitions. Over-partitioning also has overhead (more file handles, leader elections)."
            },
            {
              "type": "estimation",
              "question": "An e-commerce platform processes 10,000 orders per minute. Each order generates 5 events (created, payment, inventory, shipping, notification). Estimate the throughput requirements for the message queue.",
              "answer": "50,000 messages/minute = ~833 messages/second. Assuming each message is ~1KB, that's ~833 KB/s or ~50 MB/minute. With 3x replication in Kafka, storage write throughput is ~2.5 GB/hour. For 7-day retention: ~420 GB. A single Kafka partition handles ~10 MB/s, so 1 partition suffices for throughput, but use 8-12 partitions for consumer parallelism."
            },
            {
              "type": "debug",
              "question": "Messages are being processed out of order in your Kafka consumer. The partition key is set correctly. What could be causing this?",
              "answer": "Possible causes: 1) Multiple partitions with the same consumer group — ordering is only within a partition. 2) Consumer rebalancing caused offset issues. 3) Retries are reprocessing earlier messages after later ones succeeded. 4) Consumer is processing messages in parallel threads without preserving order. Fix: ensure single partition per ordering key, process sequentially per partition, and handle retries in-order."
            },
            {
              "type": "tricky",
              "question": "Can you achieve exactly-once delivery in a distributed system? Is it theoretically possible?",
              "answer": "True exactly-once delivery is impossible in distributed systems (due to the Two Generals problem). What systems achieve is exactly-once processing semantics — using idempotent operations, transactional writes, and deduplication. Kafka's exactly-once guarantee works within the Kafka ecosystem by coupling producer transactions with consumer offset commits atomically, but end-to-end exactly-once requires idempotent external systems."
            },
            {
              "type": "design",
              "question": "Design a distributed task queue (like Celery) that supports task priorities, retries, and scheduled execution.",
              "answer": "Use multiple queues per priority level (high, medium, low). Workers poll high-priority first. Each task has metadata: retryCount, maxRetries, scheduledAt, timeout. Use a delayed queue (or sorted set in Redis) for scheduled tasks. Failed tasks go to retry queue with exponential backoff. After max retries, move to DLQ. Track task state (pending, running, completed, failed) in a database."
            },
            {
              "type": "scenario",
              "question": "Your RabbitMQ cluster is running out of memory because consumers are slower than producers. What immediate and long-term actions do you take?",
              "answer": "Immediate: Enable flow control / memory alarms to block publishers. Increase consumer count. Set queue TTL to drop old messages if acceptable. Long-term: Implement backpressure at the producer. Add consumer auto-scaling based on queue depth. Set queue length limits with overflow to DLQ. Consider switching to lazy queues (disk-backed) or migrating to Kafka for better backlog handling."
            },
            {
              "type": "explain",
              "question": "Explain the outbox pattern and why it's important for reliable messaging.",
              "answer": "The outbox pattern writes events to an 'outbox' table in the same database transaction as the business data change. A separate process (poller or CDC) reads the outbox and publishes events to the message broker. This ensures atomicity — if the transaction rolls back, no event is published. Without it, you risk the database write succeeding but the message publish failing (or vice versa), leading to inconsistency."
            },
            {
              "type": "estimation",
              "question": "A chat application has 1 million concurrent users, each sending an average of 2 messages per minute. Design the message queue layer.",
              "answer": "2 million messages/minute = ~33,333 messages/second. At ~500 bytes per message: ~16.7 MB/s throughput. Use Kafka with ~50 partitions (each handling ~700 msgs/s). Partition by chat room ID for ordering. With 3x replication: ~50 MB/s disk write. Consumer groups per feature (delivery, notifications, search indexing). Need at least 3-5 broker nodes. 24-hour retention ≈ 1.4 TB."
            },
            {
              "type": "debug",
              "question": "Your SQS FIFO queue is throttling at 300 messages/second even though the documented limit is 3,000. What's wrong?",
              "answer": "SQS FIFO queues have a limit of 300 messages/second per message group ID, not per queue. If all messages use the same message group ID, you hit 300 msg/s. Fix: distribute messages across multiple message group IDs (e.g., use customer ID or order ID). Each unique group ID gets its own 300 msg/s allowance. With 10 distinct group IDs, you can achieve 3,000 msg/s aggregate throughput."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Implement a basic publish-subscribe system",
              "code": "class PubSub {\n  constructor() {\n    this.topics = new Map();\n  }\n\n  subscribe(topic, subscriber) {\n    if (!this.topics.has(topic)) this.topics.set(topic, []);\n    this.topics.get(topic).push(subscriber);\n  }\n\n  publish(topic, message) {\n    const subs = this.topics.get(topic) || [];\n    subs.forEach(fn => fn(message));\n    return subs.length;\n  }\n\n  unsubscribe(topic, subscriber) {\n    if (!this.topics.has(topic)) return;\n    const subs = this.topics.get(topic);\n    this.topics.set(topic, subs.filter(fn => fn !== subscriber));\n  }\n}\n\nconst ps = new PubSub();\nconst results = [];\nconst handler1 = (msg) => results.push(`H1: ${msg}`);\nconst handler2 = (msg) => results.push(`H2: ${msg}`);\n\nps.subscribe('news', handler1);\nps.subscribe('news', handler2);\nps.publish('news', 'Breaking!');\nps.unsubscribe('news', handler1);\nps.publish('news', 'Update!');\nconsole.log(results);",
              "output": "[ 'H1: Breaking!', 'H2: Breaking!', 'H2: Update!' ]"
            },
            {
              "question": "Program 2: Implement a message queue with acknowledgment",
              "code": "class AckQueue {\n  constructor() {\n    this.pending = [];\n    this.inflight = new Map();\n    this.visibilityTimeout = 5000;\n  }\n\n  send(message) {\n    this.pending.push({ id: String(this.pending.length + this.inflight.size + 1), body: message });\n  }\n\n  receive() {\n    const msg = this.pending.shift();\n    if (!msg) return null;\n    this.inflight.set(msg.id, { ...msg, receivedAt: Date.now() });\n    return msg;\n  }\n\n  ack(id) {\n    const deleted = this.inflight.delete(id);\n    return deleted;\n  }\n\n  nack(id) {\n    const msg = this.inflight.get(id);\n    if (msg) {\n      this.pending.unshift({ id: msg.id, body: msg.body });\n      this.inflight.delete(id);\n    }\n  }\n\n  stats() {\n    return { pending: this.pending.length, inflight: this.inflight.size };\n  }\n}\n\nconst q = new AckQueue();\nq.send('email-job-1');\nq.send('email-job-2');\nq.send('email-job-3');\n\nconst m1 = q.receive();\nconsole.log('Received:', m1.body);\nconsole.log('Stats after receive:', q.stats());\n\nq.ack(m1.id);\nconsole.log('Stats after ack:', q.stats());\n\nconst m2 = q.receive();\nq.nack(m2.id);\nconsole.log('Stats after nack:', q.stats());",
              "output": "Received: email-job-1\nStats after receive: { pending: 2, inflight: 1 }\nStats after ack: { pending: 2, inflight: 0 }\nStats after nack: { pending: 2, inflight: 0 }"
            },
            {
              "question": "Program 3: Implement a dead letter queue handler",
              "code": "class DLQHandler {\n  constructor(maxRetries = 3) {\n    this.queue = [];\n    this.dlq = [];\n    this.retryCount = new Map();\n    this.maxRetries = maxRetries;\n  }\n\n  enqueue(msg) {\n    this.queue.push(msg);\n    this.retryCount.set(msg.id, 0);\n  }\n\n  process(handler) {\n    const results = [];\n    while (this.queue.length > 0) {\n      const msg = this.queue.shift();\n      try {\n        handler(msg);\n        results.push(`Processed: ${msg.id}`);\n      } catch (e) {\n        const retries = this.retryCount.get(msg.id) + 1;\n        this.retryCount.set(msg.id, retries);\n        if (retries >= this.maxRetries) {\n          this.dlq.push({ ...msg, error: e.message, retries });\n          results.push(`DLQ: ${msg.id} after ${retries} retries`);\n        } else {\n          this.queue.push(msg);\n          results.push(`Retry ${retries}: ${msg.id}`);\n        }\n      }\n    }\n    return results;\n  }\n}\n\nconst handler = new DLQHandler(2);\nhandler.enqueue({ id: 'msg-1', data: 'good' });\nhandler.enqueue({ id: 'msg-2', data: 'bad' });\n\nconst results = handler.process((msg) => {\n  if (msg.data === 'bad') throw new Error('Processing failed');\n});\n\nconsole.log('Results:', results);\nconsole.log('DLQ:', handler.dlq.map(m => m.id));",
              "output": "Results: [ 'Processed: msg-1', 'Retry 1: msg-2', 'DLQ: msg-2 after 2 retries' ]\nDLQ: [ 'msg-2' ]"
            },
            {
              "question": "Program 4: Simulate Kafka partitioning with key-based routing",
              "code": "class KafkaSim {\n  constructor(numPartitions) {\n    this.partitions = Array.from({ length: numPartitions }, () => []);\n    this.numPartitions = numPartitions;\n  }\n\n  hash(key) {\n    let h = 0;\n    for (let i = 0; i < key.length; i++) {\n      h = (h * 31 + key.charCodeAt(i)) % this.numPartitions;\n    }\n    return h;\n  }\n\n  produce(key, value) {\n    const partition = this.hash(key);\n    this.partitions[partition].push({ key, value, offset: this.partitions[partition].length });\n    return partition;\n  }\n\n  consume(partitionId) {\n    return this.partitions[partitionId];\n  }\n\n  getPartitionSizes() {\n    return this.partitions.map((p, i) => ({ partition: i, count: p.length }));\n  }\n}\n\nconst kafka = new KafkaSim(3);\n\nconst keys = ['user-1', 'user-2', 'user-3', 'user-1', 'user-2', 'user-1'];\nkeys.forEach(k => {\n  const p = kafka.produce(k, `event for ${k}`);\n  console.log(`${k} -> partition ${p}`);\n});\n\nconsole.log('\\nPartition sizes:', kafka.getPartitionSizes());\nconsole.log('\\nPartition 0 messages:', kafka.consume(0).map(m => m.key));",
              "output": "user-1 -> partition 2\nuser-2 -> partition 0\nuser-3 -> partition 1\nuser-1 -> partition 2\nuser-2 -> partition 0\nuser-1 -> partition 2\n\nPartition sizes: [ { partition: 0, count: 2 }, { partition: 1, count: 1 }, { partition: 2, count: 3 } ]\n\nPartition 0 messages: [ 'user-2', 'user-2' ]"
            },
            {
              "question": "Program 5: Implement a priority message queue",
              "code": "class PriorityQueue {\n  constructor() {\n    this.queues = { high: [], medium: [], low: [] };\n    this.processed = [];\n  }\n\n  enqueue(message, priority = 'medium') {\n    this.queues[priority].push(message);\n  }\n\n  dequeue() {\n    if (this.queues.high.length > 0) return { ...this.queues.high.shift(), priority: 'high' };\n    if (this.queues.medium.length > 0) return { ...this.queues.medium.shift(), priority: 'medium' };\n    if (this.queues.low.length > 0) return { ...this.queues.low.shift(), priority: 'low' };\n    return null;\n  }\n\n  processAll() {\n    let msg;\n    while ((msg = this.dequeue()) !== null) {\n      this.processed.push(`${msg.priority}: ${msg.task}`);\n    }\n    return this.processed;\n  }\n\n  size() {\n    return Object.values(this.queues).reduce((sum, q) => sum + q.length, 0);\n  }\n}\n\nconst pq = new PriorityQueue();\npq.enqueue({ task: 'backup-logs' }, 'low');\npq.enqueue({ task: 'process-payment' }, 'high');\npq.enqueue({ task: 'send-email' }, 'medium');\npq.enqueue({ task: 'alert-oncall' }, 'high');\npq.enqueue({ task: 'update-cache' }, 'low');\n\nconsole.log('Queue size:', pq.size());\nconsole.log('Processing order:', pq.processAll());",
              "output": "Queue size: 5\nProcessing order: [\n  'high: process-payment',\n  'high: alert-oncall',\n  'medium: send-email',\n  'low: backup-logs',\n  'low: update-cache'\n]"
            },
            {
              "question": "Program 6: Implement an event sourcing store",
              "code": "class EventStore {\n  constructor() {\n    this.events = [];\n  }\n\n  append(aggregateId, eventType, data) {\n    const event = {\n      id: this.events.length + 1,\n      aggregateId,\n      type: eventType,\n      data,\n      timestamp: this.events.length // simplified\n    };\n    this.events.push(event);\n    return event;\n  }\n\n  getEvents(aggregateId) {\n    return this.events.filter(e => e.aggregateId === aggregateId);\n  }\n\n  replay(aggregateId, reducer, initial) {\n    return this.getEvents(aggregateId).reduce(reducer, initial);\n  }\n}\n\nconst store = new EventStore();\n\n// Record account events\nstore.append('acc-1', 'ACCOUNT_CREATED', { owner: 'Alice', balance: 0 });\nstore.append('acc-1', 'MONEY_DEPOSITED', { amount: 100 });\nstore.append('acc-1', 'MONEY_WITHDRAWN', { amount: 30 });\nstore.append('acc-1', 'MONEY_DEPOSITED', { amount: 50 });\n\n// Replay to get current state\nconst state = store.replay('acc-1', (acc, event) => {\n  switch (event.type) {\n    case 'ACCOUNT_CREATED': return { ...event.data };\n    case 'MONEY_DEPOSITED': return { ...acc, balance: acc.balance + event.data.amount };\n    case 'MONEY_WITHDRAWN': return { ...acc, balance: acc.balance - event.data.amount };\n    default: return acc;\n  }\n}, {});\n\nconsole.log('Events:', store.getEvents('acc-1').length);\nconsole.log('Current state:', state);",
              "output": "Events: 4\nCurrent state: { owner: 'Alice', balance: 120 }"
            },
            {
              "question": "Program 7: Implement a message deduplication filter",
              "code": "class DeduplicationFilter {\n  constructor(windowSize = 100) {\n    this.seen = new Set();\n    this.order = [];\n    this.windowSize = windowSize;\n    this.processed = [];\n    this.duplicates = 0;\n  }\n\n  process(messageId, payload) {\n    if (this.seen.has(messageId)) {\n      this.duplicates++;\n      return false; // duplicate\n    }\n    this.seen.add(messageId);\n    this.order.push(messageId);\n    this.processed.push(payload);\n\n    // Evict old entries beyond window\n    if (this.order.length > this.windowSize) {\n      const old = this.order.shift();\n      this.seen.delete(old);\n    }\n    return true; // new message\n  }\n\n  stats() {\n    return {\n      processed: this.processed.length,\n      duplicates: this.duplicates,\n      windowSize: this.seen.size\n    };\n  }\n}\n\nconst dedup = new DeduplicationFilter(50);\n\nconst messages = [\n  { id: 'a1', data: 'order-created' },\n  { id: 'a2', data: 'payment-received' },\n  { id: 'a1', data: 'order-created' },   // duplicate\n  { id: 'a3', data: 'item-shipped' },\n  { id: 'a2', data: 'payment-received' }, // duplicate\n  { id: 'a4', data: 'delivered' },\n];\n\nmessages.forEach(m => {\n  const isNew = dedup.process(m.id, m.data);\n  console.log(`${m.id}: ${isNew ? 'PROCESSED' : 'DUPLICATE'}`);\n});\n\nconsole.log('Stats:', dedup.stats());",
              "output": "a1: PROCESSED\na2: PROCESSED\na1: DUPLICATE\na3: PROCESSED\na2: DUPLICATE\na4: PROCESSED\nStats: { processed: 4, duplicates: 2, windowSize: 4 }"
            },
            {
              "question": "Program 8: Implement a fan-out message dispatcher",
              "code": "class FanOutDispatcher {\n  constructor() {\n    this.exchanges = new Map();\n    this.deliveryLog = [];\n  }\n\n  createExchange(name, type) {\n    this.exchanges.set(name, { type, bindings: [] });\n  }\n\n  bind(exchangeName, queueName, routingKey = '') {\n    const exchange = this.exchanges.get(exchangeName);\n    exchange.bindings.push({ queue: queueName, routingKey });\n  }\n\n  publish(exchangeName, routingKey, message) {\n    const exchange = this.exchanges.get(exchangeName);\n    const delivered = [];\n\n    exchange.bindings.forEach(binding => {\n      let shouldDeliver = false;\n      if (exchange.type === 'fanout') shouldDeliver = true;\n      else if (exchange.type === 'direct') shouldDeliver = binding.routingKey === routingKey;\n      else if (exchange.type === 'topic') {\n        const pattern = new RegExp('^' + binding.routingKey.replace(/\\*/g, '[^.]+').replace(/#/g, '.*') + '$');\n        shouldDeliver = pattern.test(routingKey);\n      }\n      if (shouldDeliver) {\n        delivered.push(binding.queue);\n        this.deliveryLog.push({ queue: binding.queue, message, routingKey });\n      }\n    });\n    return delivered;\n  }\n}\n\nconst dispatcher = new FanOutDispatcher();\n\n// Fanout exchange - broadcasts to all\ndispatcher.createExchange('logs', 'fanout');\ndispatcher.bind('logs', 'file-logger');\ndispatcher.bind('logs', 'console-logger');\ndispatcher.bind('logs', 'metrics');\n\nconst fanoutResult = dispatcher.publish('logs', '', 'System started');\nconsole.log('Fanout delivered to:', fanoutResult);\n\n// Direct exchange - routes by key\ndispatcher.createExchange('tasks', 'direct');\ndispatcher.bind('tasks', 'email-worker', 'email');\ndispatcher.bind('tasks', 'sms-worker', 'sms');\n\nconst directResult = dispatcher.publish('tasks', 'email', 'Send welcome email');\nconsole.log('Direct delivered to:', directResult);",
              "output": "Fanout delivered to: [ 'file-logger', 'console-logger', 'metrics' ]\nDirect delivered to: [ 'email-worker' ]"
            },
            {
              "question": "Program 9: Implement a consumer group simulator",
              "code": "class ConsumerGroup {\n  constructor(groupId, partitions) {\n    this.groupId = groupId;\n    this.consumers = [];\n    this.partitions = partitions; // array of partition arrays\n    this.assignment = new Map();\n    this.consumed = new Map();\n  }\n\n  addConsumer(consumerId) {\n    this.consumers.push(consumerId);\n    this.consumed.set(consumerId, []);\n    this.rebalance();\n  }\n\n  rebalance() {\n    this.assignment.clear();\n    this.consumers.forEach(c => this.assignment.set(c, []));\n    this.partitions.forEach((_, idx) => {\n      const consumer = this.consumers[idx % this.consumers.length];\n      this.assignment.get(consumer).push(idx);\n    });\n  }\n\n  consumeAll() {\n    for (const [consumer, partitionIds] of this.assignment) {\n      for (const pId of partitionIds) {\n        while (this.partitions[pId].length > 0) {\n          const msg = this.partitions[pId].shift();\n          this.consumed.get(consumer).push(msg);\n        }\n      }\n    }\n  }\n\n  getAssignment() {\n    const result = {};\n    for (const [c, parts] of this.assignment) result[c] = parts;\n    return result;\n  }\n\n  getConsumed() {\n    const result = {};\n    for (const [c, msgs] of this.consumed) result[c] = msgs;\n    return result;\n  }\n}\n\nconst partitions = [\n  ['p0-msg1', 'p0-msg2'],\n  ['p1-msg1'],\n  ['p2-msg1', 'p2-msg2', 'p2-msg3'],\n  ['p3-msg1']\n];\n\nconst group = new ConsumerGroup('group-1', partitions);\ngroup.addConsumer('consumer-A');\ngroup.addConsumer('consumer-B');\n\nconsole.log('Assignment:', group.getAssignment());\ngroup.consumeAll();\nconsole.log('Consumed:', group.getConsumed());",
              "output": "Assignment: { 'consumer-A': [ 0, 2 ], 'consumer-B': [ 1, 3 ] }\nConsumed: {\n  'consumer-A': [ 'p0-msg1', 'p0-msg2', 'p2-msg1', 'p2-msg2', 'p2-msg3' ],\n  'consumer-B': [ 'p1-msg1', 'p3-msg1' ]\n}"
            },
            {
              "question": "Program 10: Implement a delayed message queue with scheduling",
              "code": "class DelayedQueue {\n  constructor() {\n    this.ready = [];\n    this.delayed = [];\n    this.currentTime = 0;\n  }\n\n  send(message, delayMs = 0) {\n    if (delayMs === 0) {\n      this.ready.push({ message, enqueuedAt: this.currentTime });\n    } else {\n      this.delayed.push({\n        message,\n        deliverAt: this.currentTime + delayMs,\n        enqueuedAt: this.currentTime\n      });\n      this.delayed.sort((a, b) => a.deliverAt - b.deliverAt);\n    }\n  }\n\n  advanceTime(ms) {\n    this.currentTime += ms;\n    const nowReady = [];\n    const stillDelayed = [];\n    this.delayed.forEach(item => {\n      if (item.deliverAt <= this.currentTime) {\n        nowReady.push({ message: item.message, enqueuedAt: item.enqueuedAt });\n      } else {\n        stillDelayed.push(item);\n      }\n    });\n    this.ready.push(...nowReady);\n    this.delayed = stillDelayed;\n    return nowReady.length;\n  }\n\n  receive() {\n    return this.ready.shift() || null;\n  }\n\n  stats() {\n    return { ready: this.ready.length, delayed: this.delayed.length, time: this.currentTime };\n  }\n}\n\nconst dq = new DelayedQueue();\n\ndq.send('instant-msg');\ndq.send('delayed-5s', 5000);\ndq.send('delayed-2s', 2000);\ndq.send('delayed-10s', 10000);\n\nconsole.log('Initial:', dq.stats());\n\nconst promoted1 = dq.advanceTime(3000);\nconsole.log(`After 3s: promoted ${promoted1}`, dq.stats());\n\nconst promoted2 = dq.advanceTime(3000);\nconsole.log(`After 6s: promoted ${promoted2}`, dq.stats());\n\nconst messages = [];\nlet m;\nwhile ((m = dq.receive()) !== null) {\n  messages.push(m.message);\n}\nconsole.log('Received:', messages);",
              "output": "Initial: { ready: 1, delayed: 3, time: 0 }\nAfter 3s: promoted 1 { ready: 2, delayed: 2, time: 3000 }\nAfter 6s: promoted 1 { ready: 3, delayed: 1, time: 6000 }\nReceived: [ 'instant-msg', 'delayed-2s', 'delayed-5s' ]"
            }
          ]
        },
        {
          "id": "rate-limiting",
          "title": "Rate Limiting & Throttling",
          "category": "Foundations",
          "description": "Rate limiting controls the rate of requests a client can make to a service, protecting systems from abuse, overload, and ensuring fair resource distribution across users.",
          "explanation": "Rate limiting is a critical technique for protecting APIs and services by controlling how many requests a client can make within a given time window. It prevents abuse, ensures fair usage, protects backend resources, and maintains service quality under load.\n\nThe Token Bucket algorithm maintains a bucket with a fixed capacity of tokens. Tokens are added at a constant rate. Each request consumes one token. If the bucket is empty, the request is rejected. This allows short bursts up to the bucket capacity while enforcing an average rate.\n\nThe Leaky Bucket algorithm processes requests at a fixed rate, like water leaking from a bucket. Incoming requests fill the bucket; if full, excess requests are dropped. This produces a perfectly smooth output rate, ideal for scenarios requiring constant throughput.\n\nThe Fixed Window Counter algorithm divides time into fixed windows (e.g., 1-minute intervals) and counts requests per window. Simple to implement but suffers from boundary issues — a burst at the end of one window and start of the next can allow 2x the rate.\n\nThe Sliding Window Log keeps timestamps of all requests and counts those within the current sliding window. Accurate but memory-intensive. The Sliding Window Counter is a hybrid: it combines the current window's count with a weighted portion of the previous window's count, offering a good balance of accuracy and efficiency.\n\nDistributed rate limiting uses centralized storage like Redis with atomic operations (INCR, EXPIRE) to maintain counters across multiple application instances. API gateways (Kong, AWS API Gateway) provide built-in rate limiting capabilities.\n\nRate limiting can be applied at multiple layers: per-IP at the network edge, per-API-key at the gateway, per-user at the application, and globally per-service. The Retry-After header tells clients when they can retry after being rate limited (HTTP 429 status).",
          "code": "// Token Bucket Rate Limiter implementation\nclass TokenBucket {\n  constructor(capacity, refillRate) {\n    this.capacity = capacity;       // max tokens\n    this.tokens = capacity;         // current tokens\n    this.refillRate = refillRate;    // tokens per second\n    this.lastRefill = Date.now();\n  }\n\n  refill() {\n    const now = Date.now();\n    const elapsed = (now - this.lastRefill) / 1000;\n    this.tokens = Math.min(this.capacity, this.tokens + elapsed * this.refillRate);\n    this.lastRefill = now;\n  }\n\n  tryConsume(tokens = 1) {\n    this.refill();\n    if (this.tokens >= tokens) {\n      this.tokens -= tokens;\n      return { allowed: true, remaining: Math.floor(this.tokens) };\n    }\n    return { allowed: false, retryAfter: Math.ceil((tokens - this.tokens) / this.refillRate) };\n  }\n}\n\n// Sliding Window Counter Rate Limiter\nclass SlidingWindowCounter {\n  constructor(windowMs, maxRequests) {\n    this.windowMs = windowMs;\n    this.maxRequests = maxRequests;\n    this.prevCount = 0;\n    this.currCount = 0;\n    this.windowStart = Date.now();\n  }\n\n  _updateWindow(now) {\n    const elapsed = now - this.windowStart;\n    if (elapsed >= this.windowMs * 2) {\n      this.prevCount = 0;\n      this.currCount = 0;\n      this.windowStart = now;\n    } else if (elapsed >= this.windowMs) {\n      this.prevCount = this.currCount;\n      this.currCount = 0;\n      this.windowStart += this.windowMs;\n    }\n  }\n\n  tryRequest(now = Date.now()) {\n    this._updateWindow(now);\n    const elapsed = now - this.windowStart;\n    const weight = 1 - elapsed / this.windowMs;\n    const estimatedCount = this.prevCount * weight + this.currCount;\n\n    if (estimatedCount < this.maxRequests) {\n      this.currCount++;\n      return { allowed: true, estimated: Math.round(estimatedCount) };\n    }\n    return { allowed: false, estimated: Math.round(estimatedCount) };\n  }\n}\n\n// Fixed Window Counter\nclass FixedWindowCounter {\n  constructor(windowMs, maxRequests) {\n    this.windowMs = windowMs;\n    this.maxRequests = maxRequests;\n    this.count = 0;\n    this.windowStart = Date.now();\n  }\n\n  tryRequest(now = Date.now()) {\n    if (now - this.windowStart >= this.windowMs) {\n      this.count = 0;\n      this.windowStart = now;\n    }\n    if (this.count < this.maxRequests) {\n      this.count++;\n      return { allowed: true, remaining: this.maxRequests - this.count };\n    }\n    return { allowed: false, retryAfter: this.windowMs - (now - this.windowStart) };\n  }\n}",
          "example": "// Using the Token Bucket Rate Limiter\nconst limiter = new TokenBucket(10, 2); // 10 tokens max, 2 tokens/sec refill\n\n// Simulate API requests\nfor (let i = 0; i < 12; i++) {\n  const result = limiter.tryConsume();\n  console.log(`Request ${i + 1}: ${result.allowed ? 'ALLOWED' : 'DENIED'}`);\n}\n\n// Using the Fixed Window Counter\nconst fwLimiter = new FixedWindowCounter(60000, 100); // 100 requests per minute\nconst result = fwLimiter.tryRequest();\nconsole.log(`Allowed: ${result.allowed}, Remaining: ${result.remaining}`);\n\n// Rate limiting middleware example\nfunction rateLimitMiddleware(limits) {\n  const buckets = new Map();\n  return (req) => {\n    const key = req.headers['x-api-key'] || req.ip;\n    if (!buckets.has(key)) {\n      buckets.set(key, new TokenBucket(limits.capacity, limits.rate));\n    }\n    const result = buckets.get(key).tryConsume();\n    if (!result.allowed) {\n      return { status: 429, headers: { 'Retry-After': result.retryAfter } };\n    }\n    return { status: 200, headers: { 'X-RateLimit-Remaining': result.remaining } };\n  };\n}",
          "useCase": "Used to protect APIs from abuse, ensure fair resource allocation, prevent DDoS attacks, enforce billing quotas, and maintain service reliability under high traffic.",
          "interviewQuestions": [
            {
              "question": "Explain the token bucket algorithm for rate limiting.",
              "answer": "The token bucket maintains a bucket of fixed capacity. Tokens are added at a constant rate (refill rate). Each request consumes a token. If tokens are available, the request is allowed. If empty, the request is rejected. It permits short bursts (up to bucket capacity) while enforcing an average rate equal to the refill rate. Parameters: bucket capacity (burst size) and refill rate (sustained rate)."
            },
            {
              "question": "What is the difference between token bucket and leaky bucket algorithms?",
              "answer": "Token Bucket allows bursts up to the bucket capacity and is flexible with traffic patterns — it's rate-limiting with burst tolerance. Leaky Bucket processes requests at a strict constant rate (like a queue draining at fixed speed), producing smooth output but potentially adding latency to bursty traffic. Token bucket is more commonly used in API rate limiting; leaky bucket is preferred where constant processing rate is required."
            },
            {
              "question": "What's the boundary problem with fixed window counters and how does sliding window solve it?",
              "answer": "Fixed window counters reset at window boundaries. A client could send the maximum requests at the end of one window and the maximum again at the start of the next, effectively doubling the rate in a short period. Sliding window log tracks exact timestamps of each request and counts those within the last N seconds. Sliding window counter approximates this by weighting the previous window's count with the current window's count, avoiding the boundary burst problem."
            },
            {
              "question": "How would you implement distributed rate limiting across multiple server instances?",
              "answer": "Use a centralized data store like Redis. For token bucket: store token count and last refill timestamp in Redis using Lua scripts for atomicity. For sliding window: use Redis sorted sets with timestamps as scores. Use MULTI/EXEC or Lua scripts to ensure atomic check-and-increment. Redis Cluster provides horizontal scaling. Consider eventual consistency trade-offs — a small window of over-limit requests is usually acceptable."
            },
            {
              "question": "At which layers should rate limiting be applied?",
              "answer": "Rate limiting should be layered: 1) Network edge/CDN — block obvious DDoS by IP. 2) API Gateway — enforce per-API-key quotas and global limits. 3) Application layer — per-user, per-endpoint fine-grained limits. 4) Database layer — connection pool limits. Each layer provides different protection: edge stops volumetric attacks, gateway enforces business rules, application handles user-specific logic."
            },
            {
              "question": "What HTTP headers are used in rate limiting?",
              "answer": "Standard headers include: X-RateLimit-Limit (max requests in current window), X-RateLimit-Remaining (requests left), X-RateLimit-Reset (when the window resets, Unix timestamp), Retry-After (seconds until the client should retry, used with 429 status). These headers help clients self-regulate and implement backoff strategies. The 429 Too Many Requests status code indicates rate limiting."
            },
            {
              "question": "How would you rate limit a chat application differently from a REST API?",
              "answer": "A chat app needs per-channel message rate limits (e.g., 5 messages/second per user per channel), global message rate per user, and connection-level rate limiting for WebSocket frames. Unlike REST APIs where each request is independent, chat requires stateful rate limiting tied to WebSocket connections. Use sliding window at the connection handler level, with different limits for different message types (text, file upload, typing indicators)."
            },
            {
              "question": "What is the sliding window log algorithm and what are its trade-offs?",
              "answer": "Sliding window log stores the timestamp of every request in a sorted set. To check the rate, remove all entries older than the window size and count remaining entries. Pros: perfectly accurate, no boundary issues. Cons: memory-intensive (stores every request timestamp), cleanup overhead. For high-volume APIs, this is impractical — a user making 10K req/min would store 10K timestamps. The sliding window counter hybrid is preferred for production use."
            },
            {
              "question": "How do API gateways like Kong or AWS API Gateway handle rate limiting?",
              "answer": "API gateways implement rate limiting as a plugin/policy layer: requests are checked before reaching backend services. AWS API Gateway supports usage plans with throttling (steady-state rate and burst) per API key. Kong uses a plugin with configurable policies (local, Redis-backed cluster). They support multiple granularities: per-deployment, per-stage, per-method. Benefits: centralized configuration, no application code changes, consistent enforcement."
            },
            {
              "question": "How would you handle rate limiting for a multi-tenant SaaS application?",
              "answer": "Implement tiered rate limits based on subscription plan (free: 100 req/min, pro: 1000 req/min, enterprise: custom). Use tenant ID as the rate limit key. Store limits in a configuration service. Apply both per-tenant global limits and per-endpoint limits. Use token bucket for burst flexibility. Track usage for billing. Implement graceful degradation — instead of hard rejection, consider queuing or reducing response quality for over-limit tenants."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design a distributed rate limiter for a global API serving requests from multiple data centers. How do you handle consistency across regions?",
              "answer": "Use a local rate limiter per data center for immediate decisions with eventual consistency via a central Redis cluster. Each DC maintains local counters and periodically syncs with global counters. Accept slight over-limiting risk. Use sticky sessions or geo-routing to minimize cross-DC coordination. For strict limits, use a single Redis cluster with read replicas. Trade-off: strict consistency adds latency; eventual consistency may briefly exceed limits."
            },
            {
              "type": "scenario",
              "question": "Your API gateway rate limiter is using fixed window counters. During a flash sale, you observe that the system allows 2x the configured rate. What happened and how do you fix it?",
              "answer": "This is the fixed window boundary problem. If the flash sale started at the window boundary, users sent max requests at the end of window N and again at the start of window N+1. Fix: switch to sliding window counter algorithm. Short-term mitigation: reduce the window size (e.g., from 1 minute to 10 seconds with proportionally smaller limits) to reduce the burst window."
            },
            {
              "type": "estimation",
              "question": "A public API allows 1000 requests per minute per API key. You have 10,000 active API keys. Estimate the memory needed for a Redis-based sliding window log implementation.",
              "answer": "Worst case: all 10K keys at max rate = 10M request timestamps per minute. Each timestamp in a Redis sorted set: ~50 bytes (member + score). Total: 10M * 50 = 500MB. With 1-minute TTL, memory stays bounded. However, in practice not all keys hit max rate — at 20% average utilization: ~100MB. Using fixed window counters instead: 10K keys * ~100 bytes = 1MB, dramatically less."
            },
            {
              "type": "debug",
              "question": "Your token bucket rate limiter allows 100 requests per minute, but users report they can only send about 90 requests. What could be wrong?",
              "answer": "Possible causes: 1) Refill calculation uses integer math, losing fractional tokens. 2) Clock drift between refill checks causes lost time. 3) The refill rate calculation has an off-by-one or rounding error. 4) Health check or monitoring requests consume tokens from the same bucket. 5) Concurrent requests create a race condition on the token count. Fix: use floating-point for token count, atomic operations, and exclude internal requests."
            },
            {
              "type": "tricky",
              "question": "Can a token bucket rate limiter with capacity 10 and refill rate 10/sec ever allow more than 10 requests in a one-second window?",
              "answer": "Yes! If the bucket was full (10 tokens) and not recently used, the first 10 requests drain it instantly. Then if 0.5 seconds pass, 5 tokens are refilled. Those 5 requests plus the initial 10 means 15 requests in 1.5 seconds — more than 10 per second average. Over any 1-second sliding window, you can see up to capacity + refillRate = 20 requests. The token bucket controls average rate and burst size, not strict per-second limits."
            },
            {
              "type": "design",
              "question": "Design a rate limiting system that handles different limits per endpoint (e.g., login: 5/min, search: 100/min, data export: 1/hour) using a single system.",
              "answer": "Use composite rate limit keys: 'user:{id}:endpoint:{path}'. Store limits in a config map keyed by endpoint pattern. Each request generates the composite key, looks up the endpoint's rate limit config, and checks against the appropriate limiter. Use a single Redis instance with different TTLs per endpoint. Implement as middleware that matches the request path to a config entry. Use regex patterns for endpoint matching."
            },
            {
              "type": "explain",
              "question": "Explain the difference between rate limiting and throttling. Are they the same thing?",
              "answer": "They're related but different. Rate limiting rejects requests that exceed a defined rate — it's a hard boundary (HTTP 429). Throttling slows down or queues excess requests rather than rejecting them — it's a soft control that introduces delay. Example: rate limiting drops request 101 after 100/min; throttling queues request 101 and processes it when capacity is available. Throttling is better for internal services; rate limiting for public APIs."
            },
            {
              "type": "scenario",
              "question": "You notice your Redis-based rate limiter is adding 20ms latency to every API call. How do you reduce this overhead?",
              "answer": "Solutions: 1) Use Redis pipelining to batch the check-increment into one round trip. 2) Use Lua scripts for atomic operations in a single call. 3) Implement a local in-memory cache with periodic sync to Redis. 4) Use a two-tier approach: fast local counter for rough limits, Redis for accurate accounting. 5) Use Redis read replicas for check operations. 6) Consider rate limiting asynchronously — allow the request and post-check."
            },
            {
              "type": "estimation",
              "question": "Design rate limiting for a social media API that serves 50,000 requests per second globally. How many Redis operations per second are needed?",
              "answer": "Each rate limit check requires at least 2 Redis operations (GET/INCR + EXPIRE, or a Lua script as 1 op). At 50K req/s with Lua scripts: 50K Redis ops/s. A single Redis instance handles ~100K ops/s, so one instance suffices. With sliding window log: 50K ZADD + 50K ZRANGEBYSCORE = 100K ops/s — at the limit. For safety, use Redis Cluster with 3 shards. With local caching tier: reduce to ~5K Redis ops/s."
            },
            {
              "type": "debug",
              "question": "After deploying a new rate limiter, you discover that some users are bypassing it by rotating their API keys. How do you prevent this?",
              "answer": "Rate limit by multiple dimensions simultaneously: per API key AND per IP AND per user account. Implement key rotation detection: if the same IP uses many keys in a short period, flag and rate limit at IP level. Add request fingerprinting (user-agent, headers pattern). Implement hierarchical rate limits: user account → API key → IP. Monitor for suspicious patterns and alert. Consider requiring API key binding to specific IPs or verified accounts."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Implement a Token Bucket rate limiter",
              "code": "class TokenBucket {\n  constructor(capacity, refillRate) {\n    this.capacity = capacity;\n    this.tokens = capacity;\n    this.refillRate = refillRate;\n    this.lastRefill = 0;\n  }\n\n  _refill(now) {\n    const elapsed = now - this.lastRefill;\n    this.tokens = Math.min(this.capacity, this.tokens + elapsed * this.refillRate);\n    this.lastRefill = now;\n  }\n\n  allow(now = 0) {\n    this._refill(now);\n    if (this.tokens >= 1) {\n      this.tokens -= 1;\n      return true;\n    }\n    return false;\n  }\n}\n\nconst bucket = new TokenBucket(5, 1); // 5 capacity, 1 token/s\nconst results = [];\n\n// Burst of 7 requests at time 0\nfor (let i = 0; i < 7; i++) {\n  results.push(bucket.allow(0));\n}\n\n// After 3 seconds, 3 tokens refilled\nfor (let i = 0; i < 4; i++) {\n  results.push(bucket.allow(3));\n}\n\nconsole.log(results);",
              "output": "[\n  true,  true,  true,\n  true,  true,  false,\n  false, true,  true,\n  true,  false\n]"
            },
            {
              "question": "Program 2: Implement a Fixed Window Counter",
              "code": "class FixedWindow {\n  constructor(windowSize, limit) {\n    this.windowSize = windowSize;\n    this.limit = limit;\n    this.windows = new Map();\n  }\n\n  _getWindowKey(timestamp) {\n    return Math.floor(timestamp / this.windowSize);\n  }\n\n  allow(timestamp) {\n    const key = this._getWindowKey(timestamp);\n    const count = this.windows.get(key) || 0;\n    if (count < this.limit) {\n      this.windows.set(key, count + 1);\n      return true;\n    }\n    return false;\n  }\n\n  getCount(timestamp) {\n    const key = this._getWindowKey(timestamp);\n    return this.windows.get(key) || 0;\n  }\n}\n\nconst fw = new FixedWindow(10, 3); // 10-second window, 3 requests max\n\nconsole.log('t=1:', fw.allow(1));   // request 1\nconsole.log('t=3:', fw.allow(3));   // request 2\nconsole.log('t=7:', fw.allow(7));   // request 3\nconsole.log('t=9:', fw.allow(9));   // over limit\nconsole.log('t=11:', fw.allow(11)); // new window\nconsole.log('Window 0 count:', fw.getCount(5));",
              "output": "t=1: true\nt=3: true\nt=7: true\nt=9: false\nt=11: true\nWindow 0 count: 3"
            },
            {
              "question": "Program 3: Implement a Sliding Window Log",
              "code": "class SlidingWindowLog {\n  constructor(windowMs, maxRequests) {\n    this.windowMs = windowMs;\n    this.maxRequests = maxRequests;\n    this.logs = [];\n  }\n\n  allow(timestamp) {\n    // Remove expired entries\n    const windowStart = timestamp - this.windowMs;\n    this.logs = this.logs.filter(t => t > windowStart);\n\n    if (this.logs.length < this.maxRequests) {\n      this.logs.push(timestamp);\n      return true;\n    }\n    return false;\n  }\n\n  getLogSize() {\n    return this.logs.length;\n  }\n}\n\nconst swl = new SlidingWindowLog(1000, 3); // 1 second, 3 requests\n\nconsole.log('t=100:', swl.allow(100));\nconsole.log('t=400:', swl.allow(400));\nconsole.log('t=800:', swl.allow(800));\nconsole.log('t=900:', swl.allow(900));   // denied\nconsole.log('t=1200:', swl.allow(1200)); // t=100 expired\nconsole.log('Log size:', swl.getLogSize());",
              "output": "t=100: true\nt=400: true\nt=800: true\nt=900: false\nt=1200: true\nLog size: 3"
            },
            {
              "question": "Program 4: Implement a Leaky Bucket rate limiter",
              "code": "class LeakyBucket {\n  constructor(capacity, leakRate) {\n    this.capacity = capacity;\n    this.leakRate = leakRate; // requests drained per second\n    this.water = 0;\n    this.lastLeak = 0;\n  }\n\n  _leak(now) {\n    const elapsed = now - this.lastLeak;\n    const leaked = elapsed * this.leakRate;\n    this.water = Math.max(0, this.water - leaked);\n    this.lastLeak = now;\n  }\n\n  allow(now) {\n    this._leak(now);\n    if (this.water < this.capacity) {\n      this.water += 1;\n      return true;\n    }\n    return false;\n  }\n}\n\nconst lb = new LeakyBucket(3, 1); // capacity 3, leak 1/sec\n\nconst times = [0, 0, 0, 0, 2, 2, 2, 5];\nconst results = times.map(t => ({ time: t, allowed: lb.allow(t) }));\n\nresults.forEach(r => console.log(`t=${r.time}: ${r.allowed ? 'ALLOWED' : 'DENIED'}`));",
              "output": "t=0: ALLOWED\nt=0: ALLOWED\nt=0: ALLOWED\nt=0: DENIED\nt=2: ALLOWED\nt=2: ALLOWED\nt=2: DENIED\nt=5: ALLOWED"
            },
            {
              "question": "Program 5: Implement a per-user rate limiter",
              "code": "class PerUserRateLimiter {\n  constructor(windowMs, maxRequests) {\n    this.windowMs = windowMs;\n    this.maxRequests = maxRequests;\n    this.users = new Map();\n  }\n\n  allow(userId, timestamp) {\n    if (!this.users.has(userId)) {\n      this.users.set(userId, { count: 0, windowStart: timestamp });\n    }\n    const user = this.users.get(userId);\n\n    if (timestamp - user.windowStart >= this.windowMs) {\n      user.count = 0;\n      user.windowStart = timestamp;\n    }\n\n    if (user.count < this.maxRequests) {\n      user.count++;\n      return { allowed: true, remaining: this.maxRequests - user.count };\n    }\n    return { allowed: false, remaining: 0 };\n  }\n}\n\nconst limiter = new PerUserRateLimiter(60000, 3); // 3 per minute\n\nconst requests = [\n  { user: 'alice', time: 1000 },\n  { user: 'bob',   time: 1500 },\n  { user: 'alice', time: 2000 },\n  { user: 'alice', time: 3000 },\n  { user: 'alice', time: 4000 },  // alice over limit\n  { user: 'bob',   time: 5000 },\n];\n\nrequests.forEach(r => {\n  const result = limiter.allow(r.user, r.time);\n  console.log(`${r.user} t=${r.time}: ${result.allowed ? 'OK' : 'DENIED'} (remaining: ${result.remaining})`);\n});",
              "output": "alice t=1000: OK (remaining: 2)\nbob t=1500: OK (remaining: 2)\nalice t=2000: OK (remaining: 1)\nalice t=3000: OK (remaining: 0)\nalice t=4000: DENIED (remaining: 0)\nbob t=5000: OK (remaining: 1)"
            },
            {
              "question": "Program 6: Implement a sliding window counter (hybrid approach)",
              "code": "class SlidingWindowCounter {\n  constructor(windowMs, limit) {\n    this.windowMs = windowMs;\n    this.limit = limit;\n    this.prevCount = 0;\n    this.currCount = 0;\n    this.currStart = 0;\n  }\n\n  allow(timestamp) {\n    const windowIndex = Math.floor(timestamp / this.windowMs);\n    const currWindowStart = windowIndex * this.windowMs;\n\n    if (currWindowStart !== this.currStart) {\n      if (currWindowStart - this.currStart === this.windowMs) {\n        this.prevCount = this.currCount;\n      } else {\n        this.prevCount = 0;\n      }\n      this.currCount = 0;\n      this.currStart = currWindowStart;\n    }\n\n    const elapsed = timestamp - this.currStart;\n    const weight = 1 - elapsed / this.windowMs;\n    const estimated = this.prevCount * weight + this.currCount;\n\n    if (estimated < this.limit) {\n      this.currCount++;\n      return { allowed: true, estimated: Math.round(estimated) };\n    }\n    return { allowed: false, estimated: Math.round(estimated) };\n  }\n}\n\nconst swc = new SlidingWindowCounter(100, 5); // 100ms window, 5 req limit\n\n// Window 0: 4 requests\nfor (let t = 0; t < 80; t += 20) {\n  console.log(`t=${t}:`, swc.allow(t));\n}\n// Window 1: weighted count = 4*(1-0.5) + 0 = 2, so 3 more allowed\nconsole.log('t=150:', swc.allow(150));\nconsole.log('t=160:', swc.allow(160));\nconsole.log('t=170:', swc.allow(170));\nconsole.log('t=180:', swc.allow(180));",
              "output": "t=0: { allowed: true, estimated: 0 }\nt=20: { allowed: true, estimated: 1 }\nt=40: { allowed: true, estimated: 2 }\nt=60: { allowed: true, estimated: 3 }\nt=150: { allowed: true, estimated: 2 }\nt=160: { allowed: true, estimated: 3 }\nt=170: { allowed: true, estimated: 4 }\nt=180: { allowed: false, estimated: 5 }"
            },
            {
              "question": "Program 7: Implement rate limit middleware with Retry-After header",
              "code": "class RateLimitMiddleware {\n  constructor(limits) {\n    this.limits = limits;\n    this.counters = new Map();\n  }\n\n  handleRequest(apiKey, endpoint, timestamp) {\n    const limit = this.limits[endpoint] || this.limits['default'];\n    const key = `${apiKey}:${endpoint}`;\n\n    if (!this.counters.has(key)) {\n      this.counters.set(key, { count: 0, windowStart: timestamp });\n    }\n\n    const counter = this.counters.get(key);\n    if (timestamp - counter.windowStart >= limit.windowMs) {\n      counter.count = 0;\n      counter.windowStart = timestamp;\n    }\n\n    if (counter.count < limit.max) {\n      counter.count++;\n      return {\n        status: 200,\n        headers: {\n          'X-RateLimit-Limit': limit.max,\n          'X-RateLimit-Remaining': limit.max - counter.count,\n        }\n      };\n    }\n\n    const retryAfter = Math.ceil((limit.windowMs - (timestamp - counter.windowStart)) / 1000);\n    return {\n      status: 429,\n      headers: {\n        'X-RateLimit-Limit': limit.max,\n        'X-RateLimit-Remaining': 0,\n        'Retry-After': retryAfter\n      }\n    };\n  }\n}\n\nconst mw = new RateLimitMiddleware({\n  '/api/login': { max: 3, windowMs: 60000 },\n  '/api/search': { max: 10, windowMs: 60000 },\n  'default': { max: 100, windowMs: 60000 }\n});\n\nconsole.log(mw.handleRequest('key1', '/api/login', 1000));\nconsole.log(mw.handleRequest('key1', '/api/login', 2000));\nconsole.log(mw.handleRequest('key1', '/api/login', 3000));\nconsole.log(mw.handleRequest('key1', '/api/login', 4000)); // 429",
              "output": "{ status: 200, headers: { 'X-RateLimit-Limit': 3, 'X-RateLimit-Remaining': 2 } }\n{ status: 200, headers: { 'X-RateLimit-Limit': 3, 'X-RateLimit-Remaining': 1 } }\n{ status: 200, headers: { 'X-RateLimit-Limit': 3, 'X-RateLimit-Remaining': 0 } }\n{\n  status: 429,\n  headers: { 'X-RateLimit-Limit': 3, 'X-RateLimit-Remaining': 0, 'Retry-After': 57 }\n}"
            },
            {
              "question": "Program 8: Implement a distributed rate limiter simulation with Redis-like store",
              "code": "class RedisSimulator {\n  constructor() {\n    this.store = new Map();\n    this.ttls = new Map();\n  }\n\n  incr(key, now) {\n    if (this.ttls.has(key) && now > this.ttls.get(key)) {\n      this.store.delete(key);\n      this.ttls.delete(key);\n    }\n    const val = (this.store.get(key) || 0) + 1;\n    this.store.set(key, val);\n    return val;\n  }\n\n  expire(key, ttlMs, now) {\n    if (!this.ttls.has(key)) {\n      this.ttls.set(key, now + ttlMs);\n    }\n  }\n\n  get(key, now) {\n    if (this.ttls.has(key) && now > this.ttls.get(key)) {\n      this.store.delete(key);\n      this.ttls.delete(key);\n      return 0;\n    }\n    return this.store.get(key) || 0;\n  }\n}\n\nfunction distributedRateLimit(redis, userId, limit, windowMs, now) {\n  const key = `ratelimit:${userId}:${Math.floor(now / windowMs)}`;\n  const count = redis.incr(key, now);\n  redis.expire(key, windowMs, now);\n  return { allowed: count <= limit, count, limit };\n}\n\nconst redis = new RedisSimulator();\n\n// Simulate requests from user-1\nfor (let i = 0; i < 6; i++) {\n  const result = distributedRateLimit(redis, 'user-1', 5, 10000, 1000 + i * 100);\n  console.log(`Request ${i + 1}: allowed=${result.allowed}, count=${result.count}`);\n}",
              "output": "Request 1: allowed=true, count=1\nRequest 2: allowed=true, count=2\nRequest 3: allowed=true, count=3\nRequest 4: allowed=true, count=4\nRequest 5: allowed=true, count=5\nRequest 6: allowed=false, count=6"
            },
            {
              "question": "Program 9: Implement tiered rate limiting for different subscription plans",
              "code": "class TieredRateLimiter {\n  constructor(tiers) {\n    this.tiers = tiers;\n    this.usage = new Map();\n  }\n\n  getUserTier(userId) {\n    // Simulated tier lookup\n    const tierMap = { 'free-user': 'free', 'pro-user': 'pro', 'enterprise-user': 'enterprise' };\n    return tierMap[userId] || 'free';\n  }\n\n  allow(userId, timestamp) {\n    const tier = this.getUserTier(userId);\n    const limits = this.tiers[tier];\n\n    if (!this.usage.has(userId)) {\n      this.usage.set(userId, { count: 0, windowStart: timestamp });\n    }\n\n    const usage = this.usage.get(userId);\n    if (timestamp - usage.windowStart >= limits.windowMs) {\n      usage.count = 0;\n      usage.windowStart = timestamp;\n    }\n\n    if (usage.count < limits.maxRequests) {\n      usage.count++;\n      return { allowed: true, tier, used: usage.count, limit: limits.maxRequests };\n    }\n    return { allowed: false, tier, used: usage.count, limit: limits.maxRequests };\n  }\n}\n\nconst limiter = new TieredRateLimiter({\n  free: { maxRequests: 2, windowMs: 60000 },\n  pro: { maxRequests: 5, windowMs: 60000 },\n  enterprise: { maxRequests: 100, windowMs: 60000 }\n});\n\nconst requests = ['free-user', 'free-user', 'free-user', 'pro-user', 'pro-user', 'pro-user'];\nrequests.forEach((user, i) => {\n  const r = limiter.allow(user, i * 1000);\n  console.log(`${user}: ${r.allowed ? 'OK' : 'DENIED'} (${r.used}/${r.limit}, tier: ${r.tier})`);\n});",
              "output": "free-user: OK (1/2, tier: free)\nfree-user: OK (2/2, tier: free)\nfree-user: DENIED (2/2, tier: free)\npro-user: OK (1/5, tier: pro)\npro-user: OK (2/5, tier: pro)\npro-user: OK (3/5, tier: pro)"
            },
            {
              "question": "Program 10: Compare throughput of different rate limiting algorithms",
              "code": "function simulateAlgorithm(name, allowFn, requests) {\n  let allowed = 0;\n  let denied = 0;\n  requests.forEach(t => {\n    if (allowFn(t)) allowed++;\n    else denied++;\n  });\n  return { name, allowed, denied, total: requests.length };\n}\n\n// Generate bursty request pattern: 8 at time 0, then 4 at time 500\nconst requests = [\n  ...Array(8).fill(0),\n  ...Array(4).fill(500)\n];\n\n// Fixed Window (window=1000ms, limit=10)\nlet fwCount = new Map();\nconst fwResult = simulateAlgorithm('Fixed Window', (t) => {\n  const key = Math.floor(t / 1000);\n  const c = (fwCount.get(key) || 0) + 1;\n  fwCount.set(key, c);\n  return c <= 10;\n}, requests);\n\n// Sliding Window Log (window=1000ms, limit=10)\nlet swlLog = [];\nconst swlResult = simulateAlgorithm('Sliding Window Log', (t) => {\n  swlLog = swlLog.filter(ts => ts > t - 1000);\n  if (swlLog.length < 10) { swlLog.push(t); return true; }\n  return false;\n}, requests);\n\n// Token Bucket (capacity=10, refill=10/sec)\nlet tokens = 10;\nlet lastRefill = 0;\nconst tbResult = simulateAlgorithm('Token Bucket', (t) => {\n  tokens = Math.min(10, tokens + (t - lastRefill) / 1000 * 10);\n  lastRefill = t;\n  if (tokens >= 1) { tokens--; return true; }\n  return false;\n}, requests);\n\nconsole.log(fwResult);\nconsole.log(swlResult);\nconsole.log(tbResult);",
              "output": "{ name: 'Fixed Window', allowed: 10, denied: 2, total: 12 }\n{ name: 'Sliding Window Log', allowed: 10, denied: 2, total: 12 }\n{ name: 'Token Bucket', allowed: 12, denied: 0, total: 12 }"
            }
          ]
        },
        {
          "id": "api-design",
          "title": "API Design & Versioning",
          "category": "Foundations",
          "description": "API design encompasses the principles, patterns, and best practices for building robust, scalable, and developer-friendly interfaces including REST, GraphQL, gRPC, versioning, pagination, and authentication.",
          "explanation": "API (Application Programming Interface) design is the process of defining how clients communicate with backend services. Good API design balances developer experience, performance, maintainability, and security.\n\nREST (Representational State Transfer) is the most common API style, built on HTTP verbs (GET, POST, PUT, DELETE, PATCH) and resource-based URLs. RESTful design uses nouns for resources (/users, /orders), proper HTTP status codes, and stateless interactions. HATEOAS (Hypermedia as the Engine of Application State) embeds navigation links in responses, making APIs self-documenting.\n\nGraphQL is a query language that lets clients request exactly the data they need. It solves REST's over-fetching and under-fetching problems with a single endpoint and typed schema. However, it introduces complexity in caching, authorization per field, and query cost analysis.\n\ngRPC uses Protocol Buffers (protobuf) for binary serialization, offering high performance and strong typing. It supports streaming (unary, server, client, bidirectional) and is ideal for internal microservice communication.\n\nAPI Gateway pattern provides a single entry point that handles routing, authentication, rate limiting, and request transformation. It simplifies client interactions with microservices.\n\nVersioning strategies include URL path (/v1/users), custom headers (Accept-Version: v2), query parameters (?version=2), and content negotiation. URL path versioning is the most explicit and commonly used.\n\nPagination approaches: cursor-based pagination uses an opaque cursor token for the next page (ideal for real-time feeds, no skipping issues), while offset-based uses page/offset parameters (simpler but suffers from data shifting). Idempotency keys ensure that retrying a request doesn't cause duplicate side effects, critical for payment APIs.\n\nAuthentication methods include OAuth 2.0 (authorization framework with access/refresh tokens), JWT (self-contained tokens with claims), and API keys (simple but less secure). Error handling should follow consistent conventions with proper HTTP status codes, error codes, and human-readable messages.",
          "code": "// REST API Design Example with Express-like patterns\nclass APIRouter {\n  constructor(basePath, version) {\n    this.basePath = basePath;\n    this.version = version;\n    this.routes = [];\n    this.middleware = [];\n  }\n\n  // Resource route builder\n  resource(name) {\n    const path = `/${this.version}/${name}`;\n    return {\n      list:   () => ({ method: 'GET',    path }),\n      get:    (id) => ({ method: 'GET',    path: `${path}/${id}` }),\n      create: () => ({ method: 'POST',   path }),\n      update: (id) => ({ method: 'PUT',    path: `${path}/${id}` }),\n      patch:  (id) => ({ method: 'PATCH',  path: `${path}/${id}` }),\n      delete: (id) => ({ method: 'DELETE', path: `${path}/${id}` }),\n    };\n  }\n\n  // Cursor-based pagination helper\n  paginate(items, cursor, limit = 10) {\n    let startIdx = 0;\n    if (cursor) {\n      startIdx = items.findIndex(i => i.id === cursor) + 1;\n    }\n    const page = items.slice(startIdx, startIdx + limit);\n    const nextCursor = page.length === limit ? page[page.length - 1].id : null;\n    return {\n      data: page,\n      pagination: {\n        nextCursor,\n        hasMore: nextCursor !== null,\n        limit\n      }\n    };\n  }\n\n  // Idempotency key handler\n  idempotencyCheck(key, store) {\n    if (store.has(key)) {\n      return { cached: true, response: store.get(key) };\n    }\n    return { cached: false };\n  }\n\n  // Standard error response builder\n  static errorResponse(statusCode, code, message, details = null) {\n    return {\n      status: statusCode,\n      error: {\n        code,\n        message,\n        ...(details && { details }),\n        timestamp: new Date().toISOString()\n      }\n    };\n  }\n\n  // HATEOAS link builder\n  static hateoasLinks(resource, id, basePath) {\n    return {\n      self: { href: `${basePath}/${resource}/${id}` },\n      collection: { href: `${basePath}/${resource}` },\n      update: { href: `${basePath}/${resource}/${id}`, method: 'PUT' },\n      delete: { href: `${basePath}/${resource}/${id}`, method: 'DELETE' }\n    };\n  }\n}",
          "example": "// Using the API Router\nconst api = new APIRouter('/api', 'v1');\n\n// RESTful routes\nconst users = api.resource('users');\nconsole.log('List users:', users.list());\nconsole.log('Get user:', users.get('123'));\nconsole.log('Create user:', users.create());\n\n// Cursor-based pagination\nconst items = Array.from({ length: 25 }, (_, i) => ({ id: `item-${i}`, name: `Item ${i}` }));\nconst page1 = api.paginate(items, null, 5);\nconsole.log('Page 1:', page1.data.length, 'items, next:', page1.pagination.nextCursor);\nconst page2 = api.paginate(items, page1.pagination.nextCursor, 5);\nconsole.log('Page 2:', page2.data.length, 'items, next:', page2.pagination.nextCursor);\n\n// Error responses\nconsole.log('404:', APIRouter.errorResponse(404, 'NOT_FOUND', 'User not found'));\nconsole.log('422:', APIRouter.errorResponse(422, 'VALIDATION_ERROR', 'Invalid input', [\n  { field: 'email', message: 'must be valid email' }\n]));\n\n// HATEOAS\nconsole.log('Links:', APIRouter.hateoasLinks('users', '123', '/api/v1'));\n\n// Idempotency\nconst store = new Map();\nstore.set('key-abc', { orderId: 'ord-1', status: 'created' });\nconsole.log('Idempotent check:', api.idempotencyCheck('key-abc', store));",
          "useCase": "Used when designing public or internal APIs to ensure consistency, developer-friendliness, proper versioning, security, and scalability across services.",
          "interviewQuestions": [
            {
              "question": "What are the key principles of RESTful API design?",
              "answer": "REST principles include: 1) Resource-based URLs using nouns (/users, /orders). 2) Proper HTTP methods (GET for read, POST for create, PUT for full update, PATCH for partial, DELETE for removal). 3) Statelessness — each request contains all needed information. 4) Proper HTTP status codes (200, 201, 204, 400, 404, 500). 5) Consistent response format. 6) HATEOAS for discoverability. 7) Content negotiation via Accept headers."
            },
            {
              "question": "What are the pros and cons of GraphQL vs REST?",
              "answer": "GraphQL pros: clients request exactly what they need (no over/under-fetching), single endpoint, strong typing, built-in documentation (introspection), excellent for complex UIs with varied data needs. Cons: caching is harder (single endpoint), complex authorization per field, query cost analysis needed to prevent expensive queries, learning curve, tooling overhead. REST is simpler, better cacheable (HTTP caching), and more widely understood."
            },
            {
              "question": "When would you choose gRPC over REST?",
              "answer": "Choose gRPC for: internal microservice communication (high performance, strong typing), streaming use cases (real-time data, server push), polyglot environments (protobuf generates clients for many languages), when bandwidth is critical (binary serialization is 5-10x smaller than JSON). Stick with REST for: public APIs (broader tooling), browser clients (gRPC-web exists but adds complexity), simple CRUD operations, when human-readability matters."
            },
            {
              "question": "What are the different API versioning strategies and their trade-offs?",
              "answer": "URL path versioning (/v1/users): most explicit, easy to route and cache, but clutters URLs. Header versioning (Accept-Version: v2): clean URLs, but harder to test in browsers. Query parameter (?version=2): simple but pollutes query string. Content negotiation (Accept: application/vnd.api.v2+json): standard compliant but complex. URL path is the most widely used due to its simplicity and explicitness."
            },
            {
              "question": "Explain cursor-based vs offset-based pagination.",
              "answer": "Offset-based (page=3&limit=10): simple, supports jumping to any page, but suffers from data shifting (inserts/deletes between pages cause duplicates or missed items), and performance degrades with large offsets (OFFSET in SQL scans rows). Cursor-based (after=abc123&limit=10): uses an opaque token pointing to the last item, consistent with real-time data, efficient (WHERE id > cursor), but can't jump to arbitrary pages. Cursor-based is preferred for feeds and infinite scroll."
            },
            {
              "question": "What are idempotency keys and why are they important?",
              "answer": "Idempotency keys are unique identifiers (typically UUIDs) sent by clients in request headers to ensure that retrying a request produces the same result without side effects. The server stores the key with the response, and on retry, returns the cached response. Critical for payment APIs — if a network error occurs after the server processes a payment but before the client receives the response, retrying with the same idempotency key returns the original result instead of charging twice."
            },
            {
              "question": "Compare OAuth 2.0, JWT, and API keys for API authentication.",
              "answer": "API keys: simple string tokens, easy to implement, but hard to scope permissions, can't represent user context, and if leaked, full access until revoked. JWT: self-contained tokens with claims (user ID, roles, expiry), no server-side session storage needed, but can't be easily revoked before expiry. OAuth 2.0: authorization framework supporting multiple grant types (auth code, client credentials), provides scoped access tokens and refresh tokens, supports third-party authorization. Use API keys for server-to-server, JWT for stateless auth, OAuth for third-party access."
            },
            {
              "question": "What is the API Gateway pattern and what problems does it solve?",
              "answer": "An API Gateway is a single entry point for all client requests that routes them to appropriate microservices. It solves: 1) Client complexity — clients call one endpoint instead of many services. 2) Cross-cutting concerns — centralized authentication, rate limiting, logging, CORS. 3) Protocol translation — REST to gRPC, WebSocket aggregation. 4) Response aggregation — combining data from multiple services. 5) API versioning. Trade-offs: single point of failure, added latency, can become a bottleneck."
            },
            {
              "question": "How should API error responses be structured?",
              "answer": "A consistent error response should include: HTTP status code (4xx for client errors, 5xx for server errors), machine-readable error code ('VALIDATION_ERROR', 'NOT_FOUND'), human-readable message, optional details array for field-level errors, request ID for debugging, and documentation link. Example: { error: { code: 'VALIDATION_ERROR', message: 'Invalid input', details: [{ field: 'email', message: 'must be valid' }], requestId: 'req-123' } }. Never expose internal errors or stack traces."
            },
            {
              "question": "What is HATEOAS and is it worth implementing?",
              "answer": "HATEOAS (Hypermedia as the Engine of Application State) means API responses include links to related actions and resources, making the API self-navigating. Example: a user response includes links to their orders, profile update endpoint, and delete action. Pros: self-documenting, clients can discover capabilities dynamically, reduces coupling. Cons: increases response size, most clients hardcode URLs anyway, added complexity. It's part of REST maturity level 3 but rarely fully implemented in practice. It's most valuable for public APIs with diverse clients."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design a RESTful API for a social media platform with users, posts, comments, and likes. Include authentication, pagination, and versioning.",
              "answer": "Base URL: /api/v1. Resources: GET /users/:id, POST /users (register), POST /auth/login (returns JWT), GET /posts?cursor=x&limit=20, POST /posts (auth required), GET /posts/:id/comments?cursor=x, POST /posts/:id/comments, POST /posts/:id/like, DELETE /posts/:id/like. Auth: JWT in Authorization header. Pagination: cursor-based for feeds. Versioning: URL path. Rate limits: 100 req/min for reads, 20 req/min for writes. Error format: { error: { code, message, details } }."
            },
            {
              "type": "scenario",
              "question": "Your API team wants to deprecate v1 and release v2 with breaking changes. How do you manage the migration without disrupting existing clients?",
              "answer": "1) Announce deprecation timeline (e.g., 6 months). 2) Add Deprecation and Sunset headers to v1 responses. 3) Provide a migration guide documenting all changes. 4) Run v1 and v2 in parallel. 5) Monitor v1 usage and proactively contact high-volume users. 6) Add v1 rate limit reduction schedule. 7) Provide SDK updates with v2 support. 8) After sunset date, return 410 Gone with migration URL. Never hard-cut without warning."
            },
            {
              "type": "estimation",
              "question": "An API serves 100,000 requests per second. Each response is 2KB. Calculate CDN bandwidth costs at $0.02/GB.",
              "answer": "100K req/s * 2KB = 200MB/s = 200 * 86400 = 17.28 TB/day = 518.4 TB/month. At $0.02/GB: 518,400 GB * $0.02 = $10,368/month. With 70% cache hit rate at CDN: origin serves 30% = 155.52 TB, CDN serves 362.88 TB. CDN cost: 362,880 GB * $0.02 = $7,257.60/month for CDN bandwidth alone. Savings from reduced origin load offset this cost."
            },
            {
              "type": "debug",
              "question": "Your REST API returns 200 for all responses, including errors. The team argues this makes client parsing simpler. What's wrong with this approach?",
              "answer": "Problems: 1) HTTP intermediaries (caches, proxies, CDNs) use status codes — caching a 200 error response means clients see stale errors. 2) Monitoring and alerting tools use status codes to track error rates. 3) Retry logic in HTTP clients is status-code-based. 4) It violates HTTP semantics, confusing developers. 5) Load balancers use 5xx to detect unhealthy backends. Fix: use proper status codes (400, 404, 422, 500) with a consistent error body format."
            },
            {
              "type": "tricky",
              "question": "Should PUT or PATCH be used to update a user's email? What about updating the entire user profile?",
              "answer": "For updating just the email: use PATCH — it's a partial update, sending only the changed field ({ email: 'new@example.com' }). For updating the entire profile: use PUT — it replaces the complete resource (send all fields). PUT is idempotent by definition (same request = same result). PATCH can be idempotent but isn't required to be. Common mistake: using PUT for partial updates, which should null out unsent fields according to REST semantics."
            },
            {
              "type": "design",
              "question": "Design a GraphQL schema for an e-commerce platform with products, categories, reviews, and shopping cart.",
              "answer": "Types: Product (id, name, price, description, category: Category, reviews: [Review], avgRating), Category (id, name, products: [Product]), Review (id, text, rating, author: User, createdAt), Cart (id, items: [CartItem], total), CartItem (product: Product, quantity, subtotal). Queries: products(filter, sort, first, after), product(id), categories, cart. Mutations: addToCart(productId, qty), removeFromCart(itemId), createReview(productId, text, rating). Use DataLoader for N+1 prevention, query depth limiting, and persisted queries for security."
            },
            {
              "type": "explain",
              "question": "Explain the N+1 problem in GraphQL and how to solve it.",
              "answer": "N+1 occurs when a query requests a list of N items (1 query) and then each item triggers a separate query for related data (N queries). Example: querying 50 posts, each needing its author — results in 1 + 50 queries. Solutions: 1) DataLoader — batches individual requests into a single query per tick (50 author queries become 1 WHERE id IN (...)). 2) Join Monster / Hasura — compile GraphQL to SQL joins. 3) Look-ahead — inspect the query AST and eager-load relationships. DataLoader is the standard solution."
            },
            {
              "type": "scenario",
              "question": "Your public API supports both JSON and XML responses. A client sends Accept: application/xml but your new endpoint only supports JSON. What should you return?",
              "answer": "Return HTTP 406 Not Acceptable with a JSON body (since that's your default) listing the supported content types: { error: { code: 'NOT_ACCEPTABLE', message: 'This endpoint only supports application/json', supportedTypes: ['application/json'] } }. Alternatively, you could return JSON with a warning header if you want to be lenient. The proper REST approach is 406 to let the client know content negotiation failed."
            },
            {
              "type": "estimation",
              "question": "You need to design an API that supports 50 million users with an average of 10 API calls per day. Estimate the infrastructure requirements.",
              "answer": "50M users * 10 calls/day = 500M requests/day. Assuming 80% in 8 peak hours: 400M / 8h = 50M/hour = ~13,889 req/s peak. At 2x safety margin: ~28K req/s capacity. With ~200ms avg response time: each server handles ~50 req/s = ~560 application servers. With 1KB avg response: 28K * 1KB = 28MB/s bandwidth. Database: assuming 30% write, 70% read = ~9.7K writes/s, ~19.4K reads/s. Need read replicas and caching (Redis) for hot data."
            },
            {
              "type": "debug",
              "question": "Your API uses JWT tokens with no expiration. A user's token is leaked in a GitHub commit. What's the impact and how do you fix it?",
              "answer": "Impact: unlimited access to the user's account until manually revoked. Without expiration, there's no automatic invalidation. Immediate fix: invalidate the token by adding it to a blacklist checked on every request. Long-term fixes: 1) Always set JWT expiration (e.g., 15 minutes). 2) Use refresh tokens (long-lived, stored securely) to get new access tokens. 3) Implement token rotation. 4) Add IP binding or device fingerprinting. 5) Implement GitHub secret scanning integration."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Build a RESTful route matcher",
              "code": "class Router {\n  constructor() {\n    this.routes = [];\n  }\n\n  add(method, path, handler) {\n    const paramNames = [];\n    const regexPath = path.replace(/:([\\w]+)/g, (_, name) => {\n      paramNames.push(name);\n      return '([\\\\w-]+)';\n    });\n    this.routes.push({\n      method,\n      regex: new RegExp(`^${regexPath}$`),\n      paramNames,\n      handler\n    });\n  }\n\n  match(method, url) {\n    for (const route of this.routes) {\n      if (route.method !== method) continue;\n      const match = url.match(route.regex);\n      if (match) {\n        const params = {};\n        route.paramNames.forEach((name, i) => params[name] = match[i + 1]);\n        return { handler: route.handler, params };\n      }\n    }\n    return null;\n  }\n}\n\nconst router = new Router();\nrouter.add('GET', '/api/v1/users', 'listUsers');\nrouter.add('GET', '/api/v1/users/:id', 'getUser');\nrouter.add('POST', '/api/v1/users/:id/posts', 'createPost');\nrouter.add('GET', '/api/v1/users/:userId/posts/:postId', 'getPost');\n\nconsole.log(router.match('GET', '/api/v1/users'));\nconsole.log(router.match('GET', '/api/v1/users/42'));\nconsole.log(router.match('GET', '/api/v1/users/42/posts/7'));",
              "output": "{ handler: 'listUsers', params: {} }\n{ handler: 'getUser', params: { id: '42' } }\n{ handler: 'getPost', params: { userId: '42', postId: '7' } }"
            },
            {
              "question": "Program 2: Implement cursor-based pagination",
              "code": "function cursorPaginate(items, cursor, limit) {\n  let startIdx = 0;\n  if (cursor) {\n    const decoded = Buffer.from(cursor, 'base64').toString();\n    startIdx = items.findIndex(i => i.id === decoded) + 1;\n  }\n\n  const page = items.slice(startIdx, startIdx + limit);\n  const hasNext = startIdx + limit < items.length;\n  const endCursor = page.length > 0\n    ? Buffer.from(page[page.length - 1].id).toString('base64')\n    : null;\n\n  return {\n    edges: page.map(item => ({ node: item, cursor: Buffer.from(item.id).toString('base64') })),\n    pageInfo: { hasNextPage: hasNext, endCursor }\n  };\n}\n\nconst items = Array.from({ length: 10 }, (_, i) => ({ id: `item-${i}`, title: `Title ${i}` }));\n\nconst page1 = cursorPaginate(items, null, 3);\nconsole.log('Page 1 items:', page1.edges.map(e => e.node.id));\nconsole.log('Has next:', page1.pageInfo.hasNextPage);\n\nconst page2 = cursorPaginate(items, page1.pageInfo.endCursor, 3);\nconsole.log('Page 2 items:', page2.edges.map(e => e.node.id));\nconsole.log('Has next:', page2.pageInfo.hasNextPage);",
              "output": "Page 1 items: [ 'item-0', 'item-1', 'item-2' ]\nHas next: true\nPage 2 items: [ 'item-3', 'item-4', 'item-5' ]\nHas next: true"
            },
            {
              "question": "Program 3: Implement an API response builder with HATEOAS",
              "code": "class ResponseBuilder {\n  constructor(baseUrl) {\n    this.baseUrl = baseUrl;\n  }\n\n  success(data, links = {}) {\n    return { status: 200, data, _links: links };\n  }\n\n  created(data, links = {}) {\n    return { status: 201, data, _links: links };\n  }\n\n  error(status, code, message) {\n    return { status, error: { code, message } };\n  }\n\n  resourceLinks(resource, id) {\n    return {\n      self: `${this.baseUrl}/${resource}/${id}`,\n      collection: `${this.baseUrl}/${resource}`,\n      update: `${this.baseUrl}/${resource}/${id}`,\n      delete: `${this.baseUrl}/${resource}/${id}`\n    };\n  }\n}\n\nconst rb = new ResponseBuilder('/api/v1');\n\nconst user = { id: '42', name: 'Alice', email: 'alice@example.com' };\nconst response = rb.success(user, rb.resourceLinks('users', '42'));\nconsole.log(JSON.stringify(response, null, 2));\n\nconst errorResp = rb.error(404, 'NOT_FOUND', 'User not found');\nconsole.log(JSON.stringify(errorResp, null, 2));",
              "output": "{\n  \"status\": 200,\n  \"data\": {\n    \"id\": \"42\",\n    \"name\": \"Alice\",\n    \"email\": \"alice@example.com\"\n  },\n  \"_links\": {\n    \"self\": \"/api/v1/users/42\",\n    \"collection\": \"/api/v1/users\",\n    \"update\": \"/api/v1/users/42\",\n    \"delete\": \"/api/v1/users/42\"\n  }\n}\n{\n  \"status\": 404,\n  \"error\": {\n    \"code\": \"NOT_FOUND\",\n    \"message\": \"User not found\"\n  }\n}"
            },
            {
              "question": "Program 4: Implement an idempotency key handler",
              "code": "class IdempotencyStore {\n  constructor(ttlMs = 86400000) {\n    this.store = new Map();\n    this.ttlMs = ttlMs;\n  }\n\n  check(key) {\n    const entry = this.store.get(key);\n    if (entry && Date.now() - entry.createdAt < this.ttlMs) {\n      return { exists: true, response: entry.response };\n    }\n    return { exists: false };\n  }\n\n  save(key, response) {\n    this.store.set(key, { response, createdAt: Date.now() });\n  }\n\n  processRequest(key, handler) {\n    const cached = this.check(key);\n    if (cached.exists) {\n      return { ...cached.response, fromCache: true };\n    }\n    const response = handler();\n    this.save(key, response);\n    return { ...response, fromCache: false };\n  }\n}\n\nconst store = new IdempotencyStore();\n\n// First request - processes normally\nconst r1 = store.processRequest('pay-key-123', () => ({\n  orderId: 'ord-1',\n  amount: 99.99,\n  status: 'charged'\n}));\nconsole.log('Request 1:', r1);\n\n// Retry with same key - returns cached\nconst r2 = store.processRequest('pay-key-123', () => ({\n  orderId: 'ord-1',\n  amount: 99.99,\n  status: 'charged'\n}));\nconsole.log('Request 2 (retry):', r2);\n\n// Different key - processes normally\nconst r3 = store.processRequest('pay-key-456', () => ({\n  orderId: 'ord-2',\n  amount: 49.99,\n  status: 'charged'\n}));\nconsole.log('Request 3:', r3);",
              "output": "Request 1: { orderId: 'ord-1', amount: 99.99, status: 'charged', fromCache: false }\nRequest 2 (retry): { orderId: 'ord-1', amount: 99.99, status: 'charged', fromCache: true }\nRequest 3: { orderId: 'ord-2', amount: 49.99, status: 'charged', fromCache: false }"
            },
            {
              "question": "Program 5: Implement a query string parser and builder",
              "code": "class QueryBuilder {\n  constructor() {\n    this.params = new Map();\n  }\n\n  set(key, value) {\n    this.params.set(key, value);\n    return this;\n  }\n\n  filter(field, op, value) {\n    this.params.set(`filter[${field}][${op}]`, value);\n    return this;\n  }\n\n  sort(field, order = 'asc') {\n    this.params.set('sort', `${order === 'desc' ? '-' : ''}${field}`);\n    return this;\n  }\n\n  paginate(cursor, limit) {\n    if (cursor) this.params.set('cursor', cursor);\n    this.params.set('limit', limit);\n    return this;\n  }\n\n  build() {\n    const parts = [];\n    for (const [key, value] of this.params) {\n      parts.push(`${encodeURIComponent(key)}=${encodeURIComponent(value)}`);\n    }\n    return parts.length > 0 ? `?${parts.join('&')}` : '';\n  }\n\n  static parse(queryString) {\n    const params = {};\n    const cleaned = queryString.startsWith('?') ? queryString.slice(1) : queryString;\n    cleaned.split('&').forEach(pair => {\n      const [key, value] = pair.split('=').map(decodeURIComponent);\n      params[key] = value;\n    });\n    return params;\n  }\n}\n\nconst query = new QueryBuilder()\n  .filter('price', 'gte', '10')\n  .filter('category', 'eq', 'electronics')\n  .sort('price', 'desc')\n  .paginate(null, 20)\n  .build();\n\nconsole.log('Built query:', query);\nconsole.log('Parsed:', QueryBuilder.parse(query));",
              "output": "Built query: ?filter%5Bprice%5D%5Bgte%5D=10&filter%5Bcategory%5D%5Beq%5D=electronics&sort=-price&limit=20\nParsed: {\n  'filter[price][gte]': '10',\n  'filter[category][eq]': 'electronics',\n  sort: '-price',\n  limit: '20'\n}"
            },
            {
              "question": "Program 6: Implement a simple JWT encoder and decoder",
              "code": "class SimpleJWT {\n  static base64url(str) {\n    return Buffer.from(str).toString('base64')\n      .replace(/=/g, '').replace(/\\+/g, '-').replace(/\\//g, '_');\n  }\n\n  static base64urlDecode(str) {\n    str = str.replace(/-/g, '+').replace(/_/g, '/');\n    while (str.length % 4) str += '=';\n    return Buffer.from(str, 'base64').toString();\n  }\n\n  static sign(payload, secret) {\n    const header = { alg: 'HS256', typ: 'JWT' };\n    const h = this.base64url(JSON.stringify(header));\n    const p = this.base64url(JSON.stringify(payload));\n    // Simplified signature (not cryptographically secure)\n    const sig = this.base64url(secret + '.' + h + '.' + p);\n    return `${h}.${p}.${sig}`;\n  }\n\n  static decode(token) {\n    const [header, payload] = token.split('.');\n    return {\n      header: JSON.parse(this.base64urlDecode(header)),\n      payload: JSON.parse(this.base64urlDecode(payload))\n    };\n  }\n\n  static isExpired(token) {\n    const { payload } = this.decode(token);\n    if (!payload.exp) return false;\n    return Date.now() / 1000 > payload.exp;\n  }\n}\n\nconst token = SimpleJWT.sign({\n  sub: 'user-42',\n  name: 'Alice',\n  role: 'admin',\n  exp: Math.floor(Date.now() / 1000) + 3600\n}, 'my-secret');\n\nconsole.log('Token parts:', token.split('.').length);\nconst decoded = SimpleJWT.decode(token);\nconsole.log('Header:', decoded.header);\nconsole.log('User:', decoded.payload.sub, decoded.payload.name);\nconsole.log('Role:', decoded.payload.role);\nconsole.log('Expired:', SimpleJWT.isExpired(token));",
              "output": "Token parts: 3\nHeader: { alg: 'HS256', typ: 'JWT' }\nUser: user-42 Alice\nRole: admin\nExpired: false"
            },
            {
              "question": "Program 7: Implement API versioning with content negotiation",
              "code": "class VersionedAPI {\n  constructor() {\n    this.handlers = new Map(); // 'method:path:version' -> handler\n  }\n\n  register(method, path, version, handler) {\n    this.handlers.set(`${method}:${path}:${version}`, handler);\n  }\n\n  parseVersion(acceptHeader) {\n    // Parse: application/vnd.api.v2+json\n    const match = acceptHeader?.match(/vnd\\.api\\.v(\\d+)/);\n    return match ? parseInt(match[1]) : 1; // default v1\n  }\n\n  handle(method, path, headers = {}) {\n    const version = this.parseVersion(headers['accept']);\n    const key = `${method}:${path}:${version}`;\n    const handler = this.handlers.get(key);\n\n    if (handler) {\n      return { status: 200, version, data: handler() };\n    }\n    // Fallback to latest available version\n    for (let v = version - 1; v >= 1; v--) {\n      const fallbackKey = `${method}:${path}:${v}`;\n      if (this.handlers.has(fallbackKey)) {\n        return { status: 200, version: v, data: this.handlers.get(fallbackKey)(), fallback: true };\n      }\n    }\n    return { status: 404, error: 'Not found' };\n  }\n}\n\nconst api = new VersionedAPI();\napi.register('GET', '/users', 1, () => [{ id: 1, name: 'Alice' }]);\napi.register('GET', '/users', 2, () => [{ id: 1, firstName: 'Alice', lastName: 'Smith' }]);\n\nconsole.log('V1:', api.handle('GET', '/users', { accept: 'application/vnd.api.v1+json' }));\nconsole.log('V2:', api.handle('GET', '/users', { accept: 'application/vnd.api.v2+json' }));\nconsole.log('No version:', api.handle('GET', '/users', {}));",
              "output": "V1: { status: 200, version: 1, data: [ { id: 1, name: 'Alice' } ] }\nV2: {\n  status: 200,\n  version: 2,\n  data: [ { id: 1, firstName: 'Alice', lastName: 'Smith' } ]\n}\nNo version: { status: 200, version: 1, data: [ { id: 1, name: 'Alice' } ] }"
            },
            {
              "question": "Program 8: Implement a request validator",
              "code": "class RequestValidator {\n  constructor() {\n    this.rules = {};\n  }\n\n  schema(rules) {\n    this.rules = rules;\n    return this;\n  }\n\n  validate(data) {\n    const errors = [];\n\n    for (const [field, rule] of Object.entries(this.rules)) {\n      const value = data[field];\n\n      if (rule.required && (value === undefined || value === null || value === '')) {\n        errors.push({ field, message: `${field} is required` });\n        continue;\n      }\n\n      if (value === undefined) continue;\n\n      if (rule.type && typeof value !== rule.type) {\n        errors.push({ field, message: `${field} must be a ${rule.type}` });\n      }\n\n      if (rule.minLength && typeof value === 'string' && value.length < rule.minLength) {\n        errors.push({ field, message: `${field} must be at least ${rule.minLength} characters` });\n      }\n\n      if (rule.pattern && !rule.pattern.test(value)) {\n        errors.push({ field, message: `${field} format is invalid` });\n      }\n\n      if (rule.min !== undefined && value < rule.min) {\n        errors.push({ field, message: `${field} must be >= ${rule.min}` });\n      }\n    }\n\n    return { valid: errors.length === 0, errors };\n  }\n}\n\nconst validator = new RequestValidator().schema({\n  name: { required: true, type: 'string', minLength: 2 },\n  email: { required: true, type: 'string', pattern: /^[^@]+@[^@]+$/ },\n  age: { required: false, type: 'number', min: 18 }\n});\n\nconsole.log(validator.validate({ name: 'Al', email: 'alice@test.com', age: 25 }));\nconsole.log(validator.validate({ name: '', email: 'invalid', age: 15 }));\nconsole.log(validator.validate({ name: 'Bob', email: 'bob@test.com' }));",
              "output": "{ valid: true, errors: [] }\n{\n  valid: false,\n  errors: [\n    { field: 'name', message: 'name is required' },\n    { field: 'email', message: 'email format is invalid' },\n    { field: 'age', message: 'age must be >= 18' }\n  ]\n}\n{ valid: true, errors: [] }"
            },
            {
              "question": "Program 9: Implement an API rate limit header tracker",
              "code": "class RateLimitTracker {\n  constructor() {\n    this.apis = new Map();\n  }\n\n  updateFromHeaders(apiName, headers) {\n    this.apis.set(apiName, {\n      limit: parseInt(headers['x-ratelimit-limit']),\n      remaining: parseInt(headers['x-ratelimit-remaining']),\n      reset: parseInt(headers['x-ratelimit-reset']),\n      updatedAt: Date.now()\n    });\n  }\n\n  canMakeRequest(apiName, now = Date.now()) {\n    const info = this.apis.get(apiName);\n    if (!info) return { allowed: true, reason: 'no tracking data' };\n\n    // If reset time has passed, limits are refreshed\n    if (now / 1000 >= info.reset) {\n      return { allowed: true, reason: 'window reset' };\n    }\n\n    if (info.remaining > 0) {\n      return { allowed: true, remaining: info.remaining };\n    }\n\n    const waitSeconds = Math.ceil(info.reset - now / 1000);\n    return { allowed: false, retryAfterSeconds: waitSeconds };\n  }\n\n  getStatus() {\n    const status = {};\n    for (const [name, info] of this.apis) {\n      status[name] = `${info.remaining}/${info.limit}`;\n    }\n    return status;\n  }\n}\n\nconst tracker = new RateLimitTracker();\n\ntracker.updateFromHeaders('github', {\n  'x-ratelimit-limit': '5000',\n  'x-ratelimit-remaining': '4985',\n  'x-ratelimit-reset': String(Math.floor(Date.now() / 1000) + 3600)\n});\n\ntracker.updateFromHeaders('twitter', {\n  'x-ratelimit-limit': '300',\n  'x-ratelimit-remaining': '0',\n  'x-ratelimit-reset': String(Math.floor(Date.now() / 1000) + 120)\n});\n\nconsole.log('Status:', tracker.getStatus());\nconsole.log('GitHub:', tracker.canMakeRequest('github'));\nconsole.log('Twitter:', tracker.canMakeRequest('twitter'));",
              "output": "Status: { github: '4985/5000', twitter: '0/300' }\nGitHub: { allowed: true, remaining: 4985 }\nTwitter: { allowed: false, retryAfterSeconds: 120 }"
            },
            {
              "question": "Program 10: Implement a GraphQL-style field selector",
              "code": "function selectFields(data, fields) {\n  if (Array.isArray(data)) {\n    return data.map(item => selectFields(item, fields));\n  }\n\n  const result = {};\n  for (const field of fields) {\n    if (typeof field === 'string') {\n      if (field in data) result[field] = data[field];\n    } else if (typeof field === 'object') {\n      const [key] = Object.keys(field);\n      if (key in data) {\n        result[key] = selectFields(data[key], field[key]);\n      }\n    }\n  }\n  return result;\n}\n\nconst user = {\n  id: 1,\n  name: 'Alice',\n  email: 'alice@test.com',\n  age: 30,\n  address: {\n    street: '123 Main St',\n    city: 'Springfield',\n    zip: '12345',\n    country: 'US'\n  },\n  posts: [\n    { id: 1, title: 'Hello', content: 'World', likes: 10 },\n    { id: 2, title: 'GraphQL', content: 'Rocks', likes: 25 }\n  ]\n};\n\n// Select specific fields (like GraphQL query)\nconst result = selectFields(user, [\n  'name',\n  'email',\n  { address: ['city', 'country'] },\n  { posts: ['title', 'likes'] }\n]);\n\nconsole.log(JSON.stringify(result, null, 2));",
              "output": "{\n  \"name\": \"Alice\",\n  \"email\": \"alice@test.com\",\n  \"address\": {\n    \"city\": \"Springfield\",\n    \"country\": \"US\"\n  },\n  \"posts\": [\n    {\n      \"title\": \"Hello\",\n      \"likes\": 10\n    },\n    {\n      \"title\": \"GraphQL\",\n      \"likes\": 25\n    }\n  ]\n}"
            }
          ]
        },
        {
          "id": "microservices",
          "title": "Microservices Patterns",
          "category": "Foundations",
          "description": "Microservices patterns are proven architectural solutions for building, deploying, and managing distributed systems composed of small, independently deployable services that communicate over well-defined APIs.",
          "explanation": "Microservices architecture decomposes a monolithic application into small, autonomous services, each owning its own data and business logic. Two foundational patterns enable this: **Service Discovery** allows services to locate each other dynamically (client-side via a registry like Consul/Eureka, or server-side via a load balancer). **API Gateway** acts as the single entry point for all clients, handling routing, authentication, rate limiting, and response aggregation — so internal service topology stays hidden.\n\nResilience patterns prevent cascading failures in distributed systems. The **Circuit Breaker** pattern (states: CLOSED → OPEN → HALF_OPEN) stops a service from repeatedly calling a failing downstream dependency, giving it time to recover. The **Bulkhead** pattern isolates failures by partitioning resources (thread pools, connection pools) per dependency, so a slow service can't exhaust all resources. **Retry with Exponential Backoff** handles transient failures by retrying with increasing delays (e.g., 100ms, 200ms, 400ms) plus jitter to avoid thundering herds.\n\nData consistency across services is one of the hardest problems. The **Saga Pattern** manages distributed transactions by breaking them into a sequence of local transactions, each with a compensating action for rollback. Sagas come in two flavors: orchestration (a central coordinator drives the flow) and choreography (services emit and react to events). **Event-Driven Communication** decouples services using asynchronous messaging (Kafka, RabbitMQ), enabling eventual consistency and better scalability than synchronous REST calls.\n\nThe **Sidecar / Service Mesh** pattern (Istio, Linkerd) deploys a proxy alongside each service to handle cross-cutting concerns — mTLS, observability, traffic shaping, retries — without changing application code. **Health Checks** (liveness and readiness probes) let orchestrators like Kubernetes know whether a service instance is alive and ready to receive traffic, enabling automatic restarts and load balancer draining.\n\nMigration and decomposition patterns help evolve systems incrementally. The **Strangler Fig** pattern gradually replaces a monolith by routing new functionality to microservices while old code remains operational, eventually decommissioning the monolith piece by piece. This avoids risky big-bang rewrites and allows teams to validate the microservices approach incrementally.",
          "code": "// Circuit Breaker Pattern — Full Implementation\n// States: CLOSED (normal), OPEN (failing, block calls), HALF_OPEN (testing recovery)\n\nclass CircuitBreaker {\n  constructor(options = {}) {\n    this.state = 'CLOSED';\n    this.failureCount = 0;\n    this.successCount = 0;\n    this.failureThreshold = options.failureThreshold || 5;\n    this.successThreshold = options.successThreshold || 3;\n    this.timeout = options.timeout || 10000; // ms before trying HALF_OPEN\n    this.nextAttempt = Date.now();\n    this.monitor = [];  // event log\n  }\n\n  log(event) {\n    this.monitor.push({ time: new Date().toISOString(), ...event });\n  }\n\n  async call(fn) {\n    if (this.state === 'OPEN') {\n      if (Date.now() < this.nextAttempt) {\n        this.log({ action: 'BLOCKED', state: this.state });\n        throw new Error('Circuit is OPEN — request blocked');\n      }\n      // Timeout elapsed — transition to HALF_OPEN\n      this.state = 'HALF_OPEN';\n      this.log({ action: 'TRANSITION', from: 'OPEN', to: 'HALF_OPEN' });\n    }\n\n    try {\n      const result = await fn();\n      this.onSuccess();\n      return result;\n    } catch (error) {\n      this.onFailure();\n      throw error;\n    }\n  }\n\n  onSuccess() {\n    if (this.state === 'HALF_OPEN') {\n      this.successCount++;\n      if (this.successCount >= this.successThreshold) {\n        this.state = 'CLOSED';\n        this.failureCount = 0;\n        this.successCount = 0;\n        this.log({ action: 'TRANSITION', from: 'HALF_OPEN', to: 'CLOSED' });\n      } else {\n        this.log({ action: 'HALF_OPEN_SUCCESS', count: this.successCount });\n      }\n    } else {\n      this.failureCount = 0; // reset on success in CLOSED state\n      this.log({ action: 'SUCCESS', state: this.state });\n    }\n  }\n\n  onFailure() {\n    this.failureCount++;\n    this.log({ action: 'FAILURE', count: this.failureCount, state: this.state });\n\n    if (this.state === 'HALF_OPEN' || this.failureCount >= this.failureThreshold) {\n      this.state = 'OPEN';\n      this.nextAttempt = Date.now() + this.timeout;\n      this.successCount = 0;\n      this.log({ action: 'TRANSITION', to: 'OPEN', retryAt: new Date(this.nextAttempt).toISOString() });\n    }\n  }\n\n  getState() {\n    return {\n      state: this.state,\n      failureCount: this.failureCount,\n      successCount: this.successCount,\n    };\n  }\n}\n\n// Usage example\nconst breaker = new CircuitBreaker({ failureThreshold: 3, successThreshold: 2, timeout: 5000 });\n\nasync function callService() {\n  return breaker.call(async () => {\n    // Simulate an unreliable service call\n    if (Math.random() < 0.6) throw new Error('Service unavailable');\n    return { status: 'ok', data: 'response payload' };\n  });\n}\n\n// Run several calls\n(async () => {\n  for (let i = 0; i < 8; i++) {\n    try {\n      const result = await callService();\n      console.log(`Call ${i + 1}: SUCCESS`, result);\n    } catch (e) {\n      console.log(`Call ${i + 1}: FAILED —`, e.message);\n    }\n    console.log('  State:', breaker.getState());\n  }\n})();",
          "example": "// Saga Orchestrator Pattern — Order Flow\n// Steps: Reserve Inventory → Charge Payment → Confirm Order\n// Each step has a compensating action for rollback on failure\n\nclass SagaOrchestrator {\n  constructor(name) {\n    this.name = name;\n    this.steps = [];\n    this.completedSteps = [];\n  }\n\n  addStep(name, execute, compensate) {\n    this.steps.push({ name, execute, compensate });\n    return this; // fluent API\n  }\n\n  async run(context) {\n    console.log(`[Saga:${this.name}] Starting...`);\n    for (const step of this.steps) {\n      try {\n        console.log(`  → Executing: ${step.name}`);\n        const result = await step.execute(context);\n        context = { ...context, ...result };\n        this.completedSteps.push(step);\n        console.log(`  ✓ ${step.name} succeeded`);\n      } catch (error) {\n        console.log(`  ✗ ${step.name} failed: ${error.message}`);\n        await this.rollback(context);\n        return { success: false, failedAt: step.name, error: error.message, context };\n      }\n    }\n    console.log(`[Saga:${this.name}] Completed successfully!`);\n    return { success: true, context };\n  }\n\n  async rollback(context) {\n    console.log(`  ⟲ Rolling back ${this.completedSteps.length} steps...`);\n    for (const step of [...this.completedSteps].reverse()) {\n      try {\n        console.log(`    ↩ Compensating: ${step.name}`);\n        await step.compensate(context);\n        console.log(`    ✓ ${step.name} compensated`);\n      } catch (err) {\n        console.log(`    ✗ Compensation failed for ${step.name}: ${err.message}`);\n        // In production: log to dead letter queue for manual resolution\n      }\n    }\n  }\n}\n\n// Simulated service calls\nconst reserveInventory = async (ctx) => {\n  console.log(`    Reserving ${ctx.quantity}x ${ctx.item}`);\n  return { reservationId: 'RES-' + Date.now() };\n};\nconst releaseInventory = async (ctx) => {\n  console.log(`    Releasing reservation ${ctx.reservationId}`);\n};\n\nconst chargePayment = async (ctx) => {\n  console.log(`    Charging $${ctx.amount} to ${ctx.paymentMethod}`);\n  // Simulate payment failure for amounts over 1000\n  if (ctx.amount > 1000) throw new Error('Payment declined: insufficient funds');\n  return { paymentId: 'PAY-' + Date.now() };\n};\nconst refundPayment = async (ctx) => {\n  console.log(`    Refunding payment ${ctx.paymentId}`);\n};\n\nconst confirmOrder = async (ctx) => {\n  console.log(`    Confirming order for ${ctx.item}`);\n  return { orderId: 'ORD-' + Date.now(), status: 'confirmed' };\n};\nconst cancelOrder = async (ctx) => {\n  console.log(`    Cancelling order ${ctx.orderId}`);\n};\n\n// Build and execute saga\nconst orderSaga = new SagaOrchestrator('CreateOrder')\n  .addStep('ReserveInventory', reserveInventory, releaseInventory)\n  .addStep('ChargePayment', chargePayment, refundPayment)\n  .addStep('ConfirmOrder', confirmOrder, cancelOrder);\n\n// Test 1: Successful order (amount <= 1000)\norderSaga.run({ item: 'Laptop', quantity: 1, amount: 999, paymentMethod: 'credit_card' })\n  .then(r => console.log('Result:', JSON.stringify(r, null, 2)));\n\n// Test 2: Failed order (amount > 1000 triggers payment failure)\n// const failSaga = new SagaOrchestrator('CreateOrder')\n//   .addStep('ReserveInventory', reserveInventory, releaseInventory)\n//   .addStep('ChargePayment', chargePayment, refundPayment)\n//   .addStep('ConfirmOrder', confirmOrder, cancelOrder);\n// failSaga.run({ item: 'Server', quantity: 1, amount: 5000, paymentMethod: 'credit_card' });",
          "useCase": "Microservices patterns are essential for: (1) E-commerce platforms — saga pattern for distributed order processing across inventory, payment, and shipping services; circuit breakers preventing cascading failures during flash sales. (2) Streaming platforms — API gateway aggregating content catalog, recommendations, and user profile services; event-driven communication for real-time view tracking. (3) Financial systems — bulkhead isolation between trading, settlement, and reporting services; retry with backoff for external payment provider calls. (4) SaaS multi-tenant platforms — service mesh for zero-trust networking; strangler fig migration from monolith to microservices. (5) Ride-sharing apps — service discovery for geographically distributed driver matching services; health checks for auto-scaling during demand spikes.",
          "interviewQuestions": [
            {
              "question": "How does service discovery work in a microservices architecture, and what are the two main approaches?",
              "answer": "Service discovery enables services to find each other's network locations dynamically. Client-side discovery: the client queries a service registry (e.g., Consul, Eureka) and selects an instance using a load-balancing algorithm. Server-side discovery: the client sends requests to a load balancer (e.g., AWS ALB, Kubernetes Service), which queries the registry and forwards the request. Client-side gives more control but couples clients to the registry; server-side is simpler for clients but adds a network hop."
            },
            {
              "question": "Explain the circuit breaker pattern and its three states. When would you use it?",
              "answer": "The circuit breaker prevents cascading failures when a downstream service is failing. CLOSED state: requests pass through; failures are counted. When failures exceed a threshold, it transitions to OPEN. OPEN state: all requests are immediately rejected without calling the downstream service, giving it time to recover. After a timeout, it moves to HALF_OPEN. HALF_OPEN state: a limited number of test requests are allowed through. If they succeed (above a success threshold), the circuit closes; if they fail, it reopens. Use it for any remote call that could hang or fail repeatedly — database connections, HTTP calls, third-party APIs."
            },
            {
              "question": "What is the saga pattern, and how do orchestration and choreography differ?",
              "answer": "The saga pattern manages distributed transactions across multiple services by breaking them into a sequence of local transactions, each with a compensating (rollback) action. Orchestration: a central saga coordinator tells each service what to do and handles failures — easier to understand and debug, but creates a single point of coordination. Choreography: each service listens for events and reacts independently — more decoupled and scalable, but harder to trace and debug the overall flow. Choose orchestration for complex flows with many steps; choreography for simpler, highly decoupled systems."
            },
            {
              "question": "What responsibilities does an API gateway handle, and why not let clients call services directly?",
              "answer": "An API gateway handles: request routing, authentication/authorization, rate limiting, response aggregation, protocol translation (REST to gRPC), caching, and SSL termination. Without a gateway, clients would need to know every service's address, handle multiple protocols, and make multiple round trips for composite data. The gateway simplifies client logic, hides internal topology, and provides a single place to enforce security policies. Trade-off: it's a potential single point of failure and bottleneck, so it needs horizontal scaling, health checks, and careful latency budgeting."
            },
            {
              "question": "Compare synchronous (REST/gRPC) and asynchronous (messaging) communication patterns between microservices.",
              "answer": "Synchronous: the caller waits for a response, simpler to implement and reason about, works well for queries and operations needing immediate confirmation. Downsides: temporal coupling (both services must be available), cascading latency, tight coupling. Asynchronous: services communicate via a message broker (Kafka, RabbitMQ), providing temporal decoupling, better fault tolerance, natural load leveling, and enabling event-driven architectures. Downsides: eventual consistency, harder debugging, message ordering challenges, need for idempotent consumers. Best practice: use sync for reads and user-facing operations requiring immediate feedback; async for writes, notifications, and cross-service data propagation."
            },
            {
              "question": "How do you maintain data consistency across microservices that each own their own database?",
              "answer": "Each microservice owns its data (Database per Service pattern), so you can't use traditional ACID transactions. Strategies: (1) Saga pattern for distributed transactions with compensation. (2) Event sourcing — store state changes as immutable events; other services consume and build their own projections. (3) Change Data Capture (CDC) — capture database changes via WAL (e.g., Debezium) and publish to a message broker. (4) Outbox pattern — write events to an outbox table in the same transaction as the data change, then publish asynchronously. (5) CQRS — separate read and write models, with eventual consistency between them. The key principle: embrace eventual consistency and design compensating actions for failure cases."
            },
            {
              "question": "What is a service mesh, and what problems does it solve?",
              "answer": "A service mesh (Istio, Linkerd, Consul Connect) is an infrastructure layer that manages service-to-service communication. It deploys a sidecar proxy alongside each service instance to handle: mutual TLS (encryption and identity), traffic management (canary deployments, traffic splitting), observability (distributed tracing, metrics, access logs), resilience (retries, circuit breaking, timeouts), and policy enforcement. It solves the problem of implementing these cross-cutting concerns in every service's code. Trade-offs: added operational complexity, increased latency from the proxy hop (~1ms), resource overhead per sidecar, and a steep learning curve."
            },
            {
              "question": "How do you decompose a monolith into microservices? What boundaries guide the split?",
              "answer": "Decomposition strategies: (1) Domain-Driven Design (DDD): identify bounded contexts — each becomes a service. (2) Business capability: align services with business functions (orders, payments, inventory). (3) Subdomain: core domain gets the most investment; supporting and generic subdomains can be simpler services or third-party. Start with the Strangler Fig pattern: intercept requests at the edge, route new features to microservices, and gradually migrate existing functionality. Avoid splitting by technical layer (UI service, DB service) — this creates chatty services. Key signals for a good boundary: independent deployability, single team ownership, minimal cross-service transactions, and cohesive data ownership."
            },
            {
              "question": "How does distributed tracing work, and why is it critical for microservices?",
              "answer": "Distributed tracing tracks a request as it flows through multiple services by propagating a correlation/trace ID (e.g., via HTTP headers like X-Request-Id or W3C traceparent). Each service creates spans with timing data, parent-child relationships, and metadata. Tools like Jaeger, Zipkin, or OpenTelemetry collect and visualize these traces. It is critical because: debugging in microservices is hard — a single user request may touch 10+ services. Tracing reveals latency bottlenecks, error sources, and dependency chains. Without it, you're flying blind. Implementation: instrument at the API gateway (inject trace ID), propagate through all service calls, and export spans to a tracing backend."
            },
            {
              "question": "What deployment strategies work best for microservices, and how do you handle rollbacks?",
              "answer": "Strategies: (1) Blue-green: run two identical environments; switch traffic atomically — instant rollback by switching back. (2) Canary: route a small percentage (1-5%) of traffic to the new version; monitor error rates and latency before full rollout. (3) Rolling update: gradually replace instances (Kubernetes default) — zero downtime but harder to rollback mid-way. (4) Feature flags: deploy code but toggle features independently of deployment. Rollback approach: keep the previous version's containers/artifacts ready, use database migrations that are backward-compatible (expand-then-contract), and ensure APIs are versioned so old and new versions can coexist. In Kubernetes, rollback with `kubectl rollout undo`. Critical: never deploy breaking database schema changes and new code in the same release."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design a microservices architecture for an e-commerce checkout flow. Identify the services, communication patterns, and how you'd handle a payment failure after inventory has been reserved.",
              "answer": "Services: Cart Service, Inventory Service, Payment Service, Order Service, Notification Service. Use a saga orchestrator in Order Service: Step 1 — reserve inventory (sync gRPC call), Step 2 — charge payment (sync), Step 3 — confirm order (local). On payment failure: saga triggers compensation — call Inventory Service to release reservation. Communication: sync REST/gRPC for the checkout flow (user waiting), async events (Kafka) for notifications and analytics. Each service owns its DB. The Order Service maintains saga state in a saga_log table for crash recovery."
            },
            {
              "type": "scenario",
              "question": "Your circuit breaker is tripping frequently for a downstream service that has intermittent 500 errors (5% of requests). Users are seeing errors even though 95% of calls would succeed. How do you tune it?",
              "answer": "Increase the failure threshold (e.g., from 5 to 20 consecutive failures) so intermittent errors don't trip the breaker. Use a sliding window (time-based or count-based) instead of a simple counter — e.g., open only if >30% of requests in the last 60 seconds fail. Reduce the OPEN timeout so recovery is tested faster. Add retry with backoff before the circuit breaker layer so transient errors are retried without counting as breaker failures. Consider a half-open strategy that allows more test requests (e.g., 10% traffic) rather than a single probe."
            },
            {
              "type": "tricky",
              "question": "In a choreography-based saga, Service A publishes 'OrderCreated', Service B processes it and publishes 'PaymentCharged', but Service B crashes right after committing to its DB but before publishing the event. What happens and how do you fix it?",
              "answer": "The payment is charged but no event is published — causing the saga to hang. This is the dual-write problem. Fix with the Transactional Outbox pattern: Service B writes the event to an 'outbox' table in the same database transaction as the payment. A separate process (CDC via Debezium, or a polling publisher) reads the outbox and publishes to the message broker. This guarantees at-least-once delivery. Consumers must be idempotent — use the event's unique ID to deduplicate. Alternative: use event sourcing where the event IS the source of truth."
            },
            {
              "type": "estimation",
              "question": "You have 50 microservices, each making an average of 3 downstream calls per request. The system handles 10,000 requests/sec at the API gateway. Estimate the total internal service-to-service calls per second and the number of distributed traces generated per minute.",
              "answer": "First hop: 10,000 req/s to the gateway. Each request fans out to ~3 downstream calls. If each downstream service also makes 1-2 further calls, the total internal call volume is approximately: 10,000 × (3 + 3×1.5) ≈ 75,000 internal calls/sec. Distributed traces: 1 trace per inbound request = 10,000 traces/sec = 600,000 traces/min. Each trace contains ~7-10 spans (3 + downstream calls). At 1KB per span, tracing data ≈ 10,000 × 10 × 1KB = 100MB/sec = ~8.6TB/day. You'll need sampling (e.g., 10%) in production to keep this manageable."
            },
            {
              "type": "debug",
              "question": "Your API gateway returns 504 Gateway Timeout for 20% of requests to the /orders endpoint. The Order Service logs show normal response times (<100ms). What steps would you take to diagnose and fix this?",
              "answer": "Step 1: Check the gateway's timeout configuration — it may be too low. Step 2: Check connection pool exhaustion at the gateway — if the pool to Order Service is full, new requests queue and timeout. Step 3: Look at DNS resolution — the gateway may be resolving to stale/dead instances (service discovery issue). Step 4: Check network — look for packet loss or latency between gateway and Order Service (different AZ/region?). Step 5: Inspect gateway access logs — confirm the requests are actually being forwarded. Step 6: Check if Order Service has a readiness probe failing, causing the load balancer to have fewer healthy targets. Fix: increase connection pool size, set proper timeouts with retries, ensure health checks are correctly configured, and add circuit breaker at the gateway."
            },
            {
              "type": "framework",
              "question": "List a decision framework for choosing between synchronous and asynchronous communication for 5 common microservice interaction scenarios.",
              "answer": "1) User login/authentication → Sync: user is waiting, needs immediate response. 2) Order placement notification to warehouse → Async: warehouse can process when ready, no user waiting. 3) Fetching product details for display → Sync: user needs data immediately to render page. 4) Updating search index after product change → Async: eventual consistency is acceptable, decouple from write path. 5) Payment processing → Sync for initial charge (user waiting for confirmation), then Async for receipt email and accounting ledger update. Framework: If the user is waiting AND needs the result to proceed, use sync. If it's a side effect, background process, or can tolerate delay, use async."
            },
            {
              "type": "scenario",
              "question": "You deploy a new version of the Payment Service that changes the response schema. Requests from the Order Service start failing with deserialization errors. How do you prevent this in the future?",
              "answer": "Use contract-first API development with schema versioning. Strategies: (1) API versioning (URL: /v1/payments, /v2/payments) — old consumers keep calling v1. (2) Backward-compatible changes only: add new fields with defaults, never remove or rename fields without deprecation. (3) Consumer-driven contract testing (Pact): consumers define expected schemas, provider CI validates against all consumer contracts before deployment. (4) Schema registry (for async events): enforce backward/forward compatibility checks on publish. (5) Tolerant reader pattern: consumers ignore unknown fields. Immediate fix: roll back Payment Service, then deploy schema changes following the expand-contract pattern."
            },
            {
              "type": "design",
              "question": "Design a health check system for 100 microservices running in Kubernetes. Include liveness, readiness, and startup probes with meaningful checks.",
              "answer": "Liveness probe (/healthz): checks if the process is alive and not deadlocked. Simple — return 200 if event loop is responsive. Fails → Kubernetes restarts the pod. Readiness probe (/readyz): checks if the service can handle traffic — verifies DB connection pool, cache connection, and that configuration is loaded. Fails → pod removed from Service load balancer (no restart). Startup probe (/startupz): used for slow-starting services — gives extra time before liveness kicks in (e.g., 300s for ML model loading). Implementation: each service exposes HTTP endpoints with JSON status. Aggregate dashboard: a central health aggregator polls all services every 30s, stores results in a time-series DB (Prometheus), and visualizes in Grafana with alerts for degraded services."
            },
            {
              "type": "output",
              "question": "A bulkhead partitions a thread pool into 3 pools: ServiceA (10 threads), ServiceB (5 threads), ServiceC (5 threads). ServiceB receives 20 concurrent requests. How many ServiceB requests are rejected, and does ServiceA's availability change?",
              "answer": "ServiceB has a pool of 5 threads. With 20 concurrent requests, 5 execute immediately and 15 are rejected (or queued, depending on config — if no queue, all 15 rejected immediately). ServiceA's availability is completely unaffected — its 10-thread pool is independent. This is exactly the bulkhead's purpose: ServiceB's overload cannot starve ServiceA or ServiceC of resources. Without the bulkhead, all 20 threads might come from a shared pool of 20, potentially consuming all threads and making ServiceA and ServiceC unavailable too."
            },
            {
              "type": "estimation",
              "question": "Estimate the operational overhead of adding a service mesh (Istio) sidecar to each of your 200 microservice pods, each running 3 replicas.",
              "answer": "Total sidecar proxies: 200 services × 3 replicas = 600 Envoy sidecars. Each Envoy proxy uses ~50MB RAM and ~0.1 CPU cores at moderate traffic. Total overhead: 600 × 50MB = 30GB RAM, 600 × 0.1 = 60 CPU cores. Added latency: ~1-2ms per hop for proxy-to-proxy communication. If a request traverses 4 services, that's 4-8ms added latency. Control plane (istiod): ~2-4 instances, 1GB RAM each. Total cost: roughly 3-4 additional nodes (8 CPU, 32GB each) just for the mesh infrastructure. This is ~5-10% overhead. Worth it if you need mTLS, advanced traffic management, and unified observability at scale."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Circuit Breaker with state transitions and failure counting",
              "code": "class CircuitBreaker {\n  constructor(threshold, timeout) {\n    this.state = 'CLOSED';\n    this.failures = 0;\n    this.threshold = threshold;\n    this.timeout = timeout;\n    this.openedAt = null;\n    this.log = [];\n  }\n\n  call(fn) {\n    if (this.state === 'OPEN') {\n      if (Date.now() - this.openedAt >= this.timeout) {\n        this.state = 'HALF_OPEN';\n        this.log.push('OPEN -> HALF_OPEN');\n      } else {\n        this.log.push('BLOCKED (OPEN)');\n        return 'BLOCKED';\n      }\n    }\n    try {\n      const result = fn();\n      if (this.state === 'HALF_OPEN') {\n        this.state = 'CLOSED';\n        this.failures = 0;\n        this.log.push('HALF_OPEN -> CLOSED');\n      }\n      return result;\n    } catch (e) {\n      this.failures++;\n      if (this.failures >= this.threshold || this.state === 'HALF_OPEN') {\n        this.state = 'OPEN';\n        this.openedAt = Date.now();\n        this.log.push(`OPENED (failures=${this.failures})`);\n      }\n      return 'FAILED';\n    }\n  }\n}\n\nconst cb = new CircuitBreaker(3, 100);\nconst fail = () => { throw new Error('err'); };\nconst ok = () => 'OK';\n\nconsole.log(cb.call(fail));   // FAILED\nconsole.log(cb.call(fail));   // FAILED\nconsole.log(cb.call(fail));   // FAILED -> opens\nconsole.log(cb.call(ok));     // BLOCKED\nconsole.log('State:', cb.state);\nconsole.log('Log:', cb.log);",
              "output": "FAILED\nFAILED\nFAILED\nBLOCKED\nState: OPEN\nLog: [ 'OPENED (failures=3)', 'BLOCKED (OPEN)' ]"
            },
            {
              "question": "Program 2: Retry with exponential backoff and jitter",
              "code": "function retryWithBackoff(fn, maxRetries, baseDelay) {\n  const attempts = [];\n  for (let i = 0; i <= maxRetries; i++) {\n    const delay = i === 0 ? 0 : baseDelay * Math.pow(2, i - 1);\n    const jitter = Math.floor(delay * 0.1); // deterministic for demo\n    const totalDelay = delay + jitter;\n    try {\n      const result = fn(i);\n      attempts.push({ attempt: i + 1, delay: totalDelay, status: 'SUCCESS' });\n      return { result, attempts };\n    } catch (e) {\n      attempts.push({ attempt: i + 1, delay: totalDelay, status: 'FAILED', error: e.message });\n    }\n  }\n  return { result: null, attempts };\n}\n\nlet callCount = 0;\nconst unreliable = (attempt) => {\n  callCount++;\n  if (callCount < 4) throw new Error(`Transient failure #${callCount}`);\n  return { data: 'success on attempt ' + (attempt + 1) };\n};\n\nconst result = retryWithBackoff(unreliable, 5, 100);\nconsole.log('Result:', result.result);\nconsole.log('Attempts:');\nresult.attempts.forEach(a => console.log(`  #${a.attempt}: ${a.status} (delay: ${a.delay}ms)`));",
              "output": "Result: { data: 'success on attempt 4' }\nAttempts:\n  #1: FAILED (delay: 0ms)\n  #2: FAILED (delay: 110ms)\n  #3: FAILED (delay: 220ms)\n  #4: SUCCESS (delay: 440ms)"
            },
            {
              "question": "Program 3: Service Registry with registration, deregistration, and lookup",
              "code": "class ServiceRegistry {\n  constructor() {\n    this.services = new Map();\n  }\n\n  register(name, instance) {\n    if (!this.services.has(name)) this.services.set(name, []);\n    this.services.get(name).push({ ...instance, registeredAt: Date.now() });\n    return `Registered ${instance.id} for ${name}`;\n  }\n\n  deregister(name, instanceId) {\n    if (!this.services.has(name)) return 'Service not found';\n    const instances = this.services.get(name).filter(i => i.id !== instanceId);\n    this.services.set(name, instances);\n    return `Deregistered ${instanceId} from ${name}`;\n  }\n\n  discover(name) {\n    const instances = this.services.get(name) || [];\n    if (instances.length === 0) return null;\n    // Round-robin selection\n    const idx = Math.floor(Date.now() % instances.length);\n    return instances[idx];\n  }\n\n  listAll() {\n    const result = {};\n    for (const [name, instances] of this.services) {\n      result[name] = instances.map(i => i.id);\n    }\n    return result;\n  }\n}\n\nconst registry = new ServiceRegistry();\nconsole.log(registry.register('user-service', { id: 'us-1', host: '10.0.0.1', port: 3001 }));\nconsole.log(registry.register('user-service', { id: 'us-2', host: '10.0.0.2', port: 3001 }));\nconsole.log(registry.register('order-service', { id: 'os-1', host: '10.0.0.3', port: 3002 }));\nconsole.log('All services:', registry.listAll());\nconsole.log(registry.deregister('user-service', 'us-1'));\nconsole.log('After deregister:', registry.listAll());",
              "output": "Registered us-1 for user-service\nRegistered us-2 for user-service\nRegistered os-1 for order-service\nAll services: { 'user-service': [ 'us-1', 'us-2' ], 'order-service': [ 'os-1' ] }\nDeregistered us-1 from user-service\nAfter deregister: { 'user-service': [ 'us-2' ], 'order-service': [ 'os-1' ] }"
            },
            {
              "question": "Program 4: Health Checker with liveness and readiness probes",
              "code": "class HealthChecker {\n  constructor(serviceName) {\n    this.serviceName = serviceName;\n    this.checks = [];\n  }\n\n  addCheck(name, type, checkFn) {\n    this.checks.push({ name, type, checkFn });\n    return this;\n  }\n\n  async runChecks() {\n    const results = [];\n    for (const check of this.checks) {\n      try {\n        const ok = await check.checkFn();\n        results.push({ name: check.name, type: check.type, status: ok ? 'UP' : 'DOWN' });\n      } catch (e) {\n        results.push({ name: check.name, type: check.type, status: 'DOWN', error: e.message });\n      }\n    }\n    const liveness = results.filter(r => r.type === 'liveness').every(r => r.status === 'UP');\n    const readiness = results.filter(r => r.type === 'readiness').every(r => r.status === 'UP');\n    return {\n      service: this.serviceName,\n      alive: liveness,\n      ready: readiness,\n      checks: results,\n    };\n  }\n}\n\nconst checker = new HealthChecker('order-service')\n  .addCheck('event-loop', 'liveness', () => true)\n  .addCheck('memory', 'liveness', () => process.memoryUsage().heapUsed < 500 * 1024 * 1024)\n  .addCheck('database', 'readiness', () => true)  // simulate DB connected\n  .addCheck('cache', 'readiness', () => false);    // simulate cache down\n\nchecker.runChecks().then(r => console.log(JSON.stringify(r, null, 2)));",
              "output": "{\n  \"service\": \"order-service\",\n  \"alive\": true,\n  \"ready\": false,\n  \"checks\": [\n    { \"name\": \"event-loop\", \"type\": \"liveness\", \"status\": \"UP\" },\n    { \"name\": \"memory\", \"type\": \"liveness\", \"status\": \"UP\" },\n    { \"name\": \"database\", \"type\": \"readiness\", \"status\": \"UP\" },\n    { \"name\": \"cache\", \"type\": \"readiness\", \"status\": \"DOWN\" }\n  ]\n}"
            },
            {
              "question": "Program 5: API Gateway Router with path matching, middleware, and request forwarding",
              "code": "class APIGateway {\n  constructor() {\n    this.routes = [];\n    this.middleware = [];\n  }\n\n  use(fn) { this.middleware.push(fn); }\n\n  route(path, service) {\n    this.routes.push({ path, service });\n  }\n\n  handle(request) {\n    const log = [];\n    // Run middleware\n    for (const mw of this.middleware) {\n      const result = mw(request);\n      if (result.blocked) {\n        log.push(`Middleware blocked: ${result.reason}`);\n        return { status: 403, body: result.reason, log };\n      }\n      log.push(`Middleware passed: ${result.name}`);\n    }\n    // Find route\n    const match = this.routes.find(r => request.path.startsWith(r.path));\n    if (!match) {\n      log.push('No route matched');\n      return { status: 404, body: 'Not Found', log };\n    }\n    log.push(`Routed to: ${match.service}`);\n    return { status: 200, body: `Response from ${match.service}`, log };\n  }\n}\n\nconst gw = new APIGateway();\ngw.use(req => ({ name: 'auth', blocked: !req.token, reason: 'Unauthorized' }));\ngw.use(req => ({ name: 'rateLimit', blocked: false }));\ngw.route('/api/users', 'user-service:3001');\ngw.route('/api/orders', 'order-service:3002');\ngw.route('/api/products', 'product-service:3003');\n\nconsole.log('Req 1:', gw.handle({ path: '/api/orders/123', token: 'abc' }));\nconsole.log('Req 2:', gw.handle({ path: '/api/unknown', token: 'abc' }));\nconsole.log('Req 3:', gw.handle({ path: '/api/users', token: null }));",
              "output": "Req 1: { status: 200, body: 'Response from order-service:3002', log: [ 'Middleware passed: auth', 'Middleware passed: rateLimit', 'Routed to: order-service:3002' ] }\nReq 2: { status: 404, body: 'Not Found', log: [ 'Middleware passed: auth', 'Middleware passed: rateLimit', 'No route matched' ] }\nReq 3: { status: 403, body: 'Unauthorized', log: [ 'Middleware blocked: Unauthorized' ] }"
            },
            {
              "question": "Program 6: Saga Coordinator with step execution and compensation on failure",
              "code": "class SagaCoordinator {\n  constructor() {\n    this.steps = [];\n    this.executed = [];\n  }\n\n  step(name, action, compensate) {\n    this.steps.push({ name, action, compensate });\n    return this;\n  }\n\n  run(ctx) {\n    const results = [];\n    for (const s of this.steps) {\n      const result = s.action(ctx);\n      if (result.error) {\n        results.push({ step: s.name, status: 'FAILED', error: result.error });\n        // Compensate completed steps in reverse\n        const compensations = [];\n        for (const done of [...this.executed].reverse()) {\n          done.compensate(ctx);\n          compensations.push(done.name);\n        }\n        return { success: false, results, compensated: compensations };\n      }\n      ctx = { ...ctx, ...result.data };\n      this.executed.push(s);\n      results.push({ step: s.name, status: 'OK' });\n    }\n    return { success: true, results, finalContext: ctx };\n  }\n}\n\nconst saga = new SagaCoordinator()\n  .step('ReserveStock',\n    (ctx) => ({ data: { reservationId: 'R100' } }),\n    (ctx) => console.log('  Compensate: released stock'))\n  .step('ChargePayment',\n    (ctx) => ({ error: 'Card declined' }),  // simulate failure\n    (ctx) => console.log('  Compensate: refunded payment'))\n  .step('ShipOrder',\n    (ctx) => ({ data: { shipmentId: 'S200' } }),\n    (ctx) => console.log('  Compensate: cancelled shipment'));\n\nconst result = saga.run({ orderId: 'ORD-1', amount: 59.99 });\nconsole.log(JSON.stringify(result, null, 2));",
              "output": "  Compensate: released stock\n{\n  \"success\": false,\n  \"results\": [\n    { \"step\": \"ReserveStock\", \"status\": \"OK\" },\n    { \"step\": \"ChargePayment\", \"status\": \"FAILED\", \"error\": \"Card declined\" }\n  ],\n  \"compensated\": [ \"ReserveStock\" ]\n}"
            },
            {
              "question": "Program 7: Bulkhead pattern with isolated resource pools per service",
              "code": "class Bulkhead {\n  constructor(partitions) {\n    this.pools = {};\n    for (const [name, max] of Object.entries(partitions)) {\n      this.pools[name] = { max, active: 0, rejected: 0 };\n    }\n  }\n\n  acquire(service) {\n    const pool = this.pools[service];\n    if (!pool) return { allowed: false, reason: 'Unknown service' };\n    if (pool.active >= pool.max) {\n      pool.rejected++;\n      return { allowed: false, reason: `Pool full (${pool.active}/${pool.max})` };\n    }\n    pool.active++;\n    return { allowed: true, active: pool.active };\n  }\n\n  release(service) {\n    const pool = this.pools[service];\n    if (pool && pool.active > 0) pool.active--;\n  }\n\n  status() {\n    const result = {};\n    for (const [name, pool] of Object.entries(this.pools)) {\n      result[name] = { active: pool.active, max: pool.max, rejected: pool.rejected };\n    }\n    return result;\n  }\n}\n\nconst bh = new Bulkhead({ 'payment-svc': 3, 'inventory-svc': 5, 'email-svc': 2 });\n\n// Simulate overloading payment-svc\nfor (let i = 0; i < 5; i++) {\n  const r = bh.acquire('payment-svc');\n  console.log(`payment-svc acquire #${i + 1}:`, r.allowed ? 'OK' : r.reason);\n}\n\n// inventory-svc is unaffected\nconsole.log('inventory-svc acquire:', bh.acquire('inventory-svc'));\nconsole.log('\\nStatus:', JSON.stringify(bh.status()));",
              "output": "payment-svc acquire #1: OK\npayment-svc acquire #2: OK\npayment-svc acquire #3: OK\npayment-svc acquire #4: Pool full (3/3)\npayment-svc acquire #5: Pool full (3/3)\ninventory-svc acquire: { allowed: true, active: 1 }\n\nStatus: {\"payment-svc\":{\"active\":3,\"max\":3,\"rejected\":2},\"inventory-svc\":{\"active\":1,\"max\":5,\"rejected\":0},\"email-svc\":{\"active\":0,\"max\":2,\"rejected\":0}}"
            },
            {
              "question": "Program 8: Rate Limiter per service using token bucket algorithm",
              "code": "class PerServiceRateLimiter {\n  constructor() {\n    this.buckets = new Map();\n  }\n\n  configure(service, maxTokens, refillRate) {\n    this.buckets.set(service, {\n      tokens: maxTokens,\n      maxTokens,\n      refillRate, // tokens per second\n      lastRefill: Date.now(),\n    });\n  }\n\n  refill(bucket) {\n    const now = Date.now();\n    const elapsed = (now - bucket.lastRefill) / 1000;\n    bucket.tokens = Math.min(bucket.maxTokens, bucket.tokens + elapsed * bucket.refillRate);\n    bucket.lastRefill = now;\n  }\n\n  allow(service) {\n    const bucket = this.buckets.get(service);\n    if (!bucket) return { allowed: false, reason: 'No config' };\n    this.refill(bucket);\n    if (bucket.tokens >= 1) {\n      bucket.tokens--;\n      return { allowed: true, remaining: Math.floor(bucket.tokens) };\n    }\n    return { allowed: false, remaining: 0, retryAfter: Math.ceil(1 / bucket.refillRate) + 's' };\n  }\n\n  status() {\n    const result = {};\n    for (const [svc, b] of this.buckets) {\n      result[svc] = { tokens: Math.floor(b.tokens), max: b.maxTokens };\n    }\n    return result;\n  }\n}\n\nconst limiter = new PerServiceRateLimiter();\nlimiter.configure('auth-api', 5, 2);    // 5 burst, 2/sec refill\nlimiter.configure('search-api', 3, 1);  // 3 burst, 1/sec refill\n\n// Exhaust auth-api tokens\nfor (let i = 0; i < 7; i++) {\n  console.log(`auth-api #${i + 1}:`, limiter.allow('auth-api'));\n}\nconsole.log('search-api:', limiter.allow('search-api'));\nconsole.log('Status:', limiter.status());",
              "output": "auth-api #1: { allowed: true, remaining: 4 }\nauth-api #2: { allowed: true, remaining: 3 }\nauth-api #3: { allowed: true, remaining: 2 }\nauth-api #4: { allowed: true, remaining: 1 }\nauth-api #5: { allowed: true, remaining: 0 }\nauth-api #6: { allowed: false, remaining: 0, retryAfter: '1s' }\nauth-api #7: { allowed: false, remaining: 0, retryAfter: '1s' }\nsearch-api: { allowed: true, remaining: 2 }\nStatus: { 'auth-api': { tokens: 0, max: 5 }, 'search-api': { tokens: 2, max: 3 } }"
            },
            {
              "question": "Program 9: Distributed Config Store with versioning and change notification",
              "code": "class ConfigStore {\n  constructor() {\n    this.configs = new Map();\n    this.listeners = [];\n    this.version = 0;\n  }\n\n  set(key, value) {\n    this.version++;\n    const entry = { value, version: this.version, updatedAt: new Date().toISOString() };\n    this.configs.set(key, entry);\n    this.notify(key, value, this.version);\n    return entry;\n  }\n\n  get(key) {\n    return this.configs.get(key) || null;\n  }\n\n  getForService(servicePrefix) {\n    const result = {};\n    for (const [key, entry] of this.configs) {\n      if (key.startsWith(servicePrefix)) {\n        result[key] = entry.value;\n      }\n    }\n    return result;\n  }\n\n  onChange(callback) {\n    this.listeners.push(callback);\n  }\n\n  notify(key, value, version) {\n    for (const cb of this.listeners) {\n      cb({ key, value, version });\n    }\n  }\n}\n\nconst config = new ConfigStore();\nconst changes = [];\nconfig.onChange(e => changes.push(`v${e.version}: ${e.key}=${e.value}`));\n\nconfig.set('order-svc/timeout', 3000);\nconfig.set('order-svc/retries', 3);\nconfig.set('payment-svc/timeout', 5000);\nconfig.set('order-svc/timeout', 5000); // update\n\nconsole.log('order-svc config:', config.getForService('order-svc'));\nconsole.log('payment-svc timeout:', config.get('payment-svc/timeout'));\nconsole.log('Change log:', changes);",
              "output": "order-svc config: { 'order-svc/timeout': 5000, 'order-svc/retries': 3 }\npayment-svc timeout: { value: 5000, version: 3, updatedAt: '...' }\nChange log: [ 'v1: order-svc/timeout=3000', 'v2: order-svc/retries=3', 'v3: payment-svc/timeout=5000', 'v4: order-svc/timeout=5000' ]"
            },
            {
              "question": "Program 10: Request Correlation ID propagation across service calls",
              "code": "const crypto = require('crypto');\n\nclass CorrelationContext {\n  static generate() {\n    return 'req-' + crypto.randomBytes(4).toString('hex');\n  }\n}\n\nclass ServiceCall {\n  constructor(name) {\n    this.name = name;\n    this.logs = [];\n  }\n\n  handle(request) {\n    const correlationId = request.headers['x-correlation-id'] || CorrelationContext.generate();\n    this.logs.push({ service: this.name, correlationId, action: 'received' });\n\n    // Simulate downstream call — propagate correlation ID\n    const downstreamReq = {\n      headers: { 'x-correlation-id': correlationId },\n      from: this.name,\n    };\n    this.logs.push({ service: this.name, correlationId, action: 'calling-downstream' });\n    return { correlationId, downstream: downstreamReq, logs: this.logs };\n  }\n}\n\n// Simulate 3-service call chain\nconst gateway = new ServiceCall('api-gateway');\nconst orderSvc = new ServiceCall('order-service');\nconst paymentSvc = new ServiceCall('payment-service');\n\n// Start at gateway\nconst corrId = CorrelationContext.generate();\nconst r1 = gateway.handle({ headers: { 'x-correlation-id': corrId } });\nconst r2 = orderSvc.handle(r1.downstream);\nconst r3 = paymentSvc.handle(r2.downstream);\n\nconst allLogs = [...r1.logs, ...r2.logs, ...r3.logs];\nconsole.log('Correlation ID:', corrId);\nconsole.log('Trace:');\nallLogs.forEach(l => console.log(`  [${l.service}] ${l.action} (${l.correlationId})`));\nconsole.log('All same ID:', allLogs.every(l => l.correlationId === corrId));",
              "output": "Correlation ID: req-a1b2c3d4\nTrace:\n  [api-gateway] received (req-a1b2c3d4)\n  [api-gateway] calling-downstream (req-a1b2c3d4)\n  [order-service] received (req-a1b2c3d4)\n  [order-service] calling-downstream (req-a1b2c3d4)\n  [payment-service] received (req-a1b2c3d4)\n  [payment-service] calling-downstream (req-a1b2c3d4)\nAll same ID: true"
            }
          ]
        },
        {
          "id": "consistent-hashing",
          "title": "Consistent Hashing",
          "category": "Foundations",
          "description": "Consistent hashing is a distributed hashing technique that minimizes key remapping when nodes are added or removed. It maps both keys and nodes onto a circular hash space (ring), ensuring that only a small fraction of keys need to be redistributed during topology changes.",
          "explanation": "In traditional modulo-based hashing (key % N), every key's assigned node changes when the number of nodes N changes. Adding or removing even a single server causes nearly all keys to remap, triggering a massive cache-miss storm or data migration event. For a system with 100 million cached entries and 10 servers, adding an 11th server would invalidate roughly 90% of the cache — a catastrophic thundering herd.\n\nConsistent hashing solves this by placing both nodes and keys on a circular hash space (a ring of values from 0 to 2^32 - 1). Each node is hashed to a position on the ring. To find which node owns a key, you hash the key and walk clockwise until you hit the first node. When a node is added, only the keys between the new node and its predecessor are reassigned. When a node is removed, only its keys move to the next node clockwise. On average, only K/N keys move (where K is total keys and N is total nodes).\n\nWith only a few physical nodes, distribution can be uneven because hash functions don't guarantee uniform spacing. Virtual nodes solve this: each physical node is mapped to many positions on the ring (e.g., 150–200 virtual nodes). This spreads load more evenly and also smooths rebalancing — when a node leaves, its virtual nodes are scattered, so its keys distribute across many remaining nodes rather than all landing on one neighbor.\n\nReplication on the ring is straightforward: for a replication factor of R, a key is stored on the next R distinct physical nodes clockwise from its position. This ensures fault tolerance — if one node fails, replicas on other nodes serve the data. Weighted virtual nodes allow heterogeneous hardware: a more powerful server gets more virtual nodes, thus handles a proportionally larger share of the keyspace.\n\nJump consistent hashing is an alternative that uses a mathematical formula instead of a ring structure. It provides perfectly uniform distribution with O(1) space and O(ln N) time, but only supports sequential node numbering (0 to N-1), making it unsuitable for dynamic clusters where arbitrary nodes join and leave. Ring-based consistent hashing remains the standard for distributed systems like Amazon DynamoDB, Apache Cassandra, Akamai CDN, and Redis Cluster. Google's 2014 bounded-load consistent hashing adds a load cap (e.g., 1 + epsilon times average load) to prevent hot spots by redirecting overflow keys to the next under-loaded node.",
          "code": "// Full Consistent Hash Ring implementation in JavaScript\n\nconst crypto = require('crypto');\n\nclass ConsistentHashRing {\n  constructor(virtualNodes = 150) {\n    this.virtualNodes = virtualNodes;   // virtual nodes per physical node\n    this.ring = new Map();              // position -> physicalNode\n    this.sortedPositions = [];          // sorted ring positions for binary search\n    this.nodes = new Set();             // set of physical nodes\n  }\n\n  // Hash a string to a 32-bit integer position on the ring\n  _hash(key) {\n    const hash = crypto.createHash('md5').update(key).digest();\n    // Use first 4 bytes as a 32-bit unsigned integer\n    return ((hash[0] << 24) | (hash[1] << 16) | (hash[2] << 8) | hash[3]) >>> 0;\n  }\n\n  // Add a physical node with its virtual nodes to the ring\n  addNode(node) {\n    if (this.nodes.has(node)) return;\n    this.nodes.add(node);\n    for (let i = 0; i < this.virtualNodes; i++) {\n      const virtualKey = `${node}#vn${i}`;\n      const position = this._hash(virtualKey);\n      this.ring.set(position, node);\n      this.sortedPositions.push(position);\n    }\n    this.sortedPositions.sort((a, b) => a - b);\n  }\n\n  // Remove a physical node and all its virtual nodes\n  removeNode(node) {\n    if (!this.nodes.has(node)) return;\n    this.nodes.delete(node);\n    for (let i = 0; i < this.virtualNodes; i++) {\n      const virtualKey = `${node}#vn${i}`;\n      const position = this._hash(virtualKey);\n      this.ring.delete(position);\n    }\n    this.sortedPositions = this.sortedPositions.filter(p => this.ring.has(p));\n  }\n\n  // Binary search: find the first position >= hashValue\n  _findPosition(hashValue) {\n    const positions = this.sortedPositions;\n    let low = 0, high = positions.length - 1;\n    if (positions.length === 0) return -1;\n    // If hashValue is beyond the last position, wrap to first\n    if (hashValue > positions[high]) return 0;\n    while (low < high) {\n      const mid = (low + high) >>> 1;\n      if (positions[mid] < hashValue) {\n        low = mid + 1;\n      } else {\n        high = mid;\n      }\n    }\n    return low;\n  }\n\n  // Get the node responsible for a given key\n  getNode(key) {\n    if (this.sortedPositions.length === 0) return null;\n    const hashValue = this._hash(key);\n    const idx = this._findPosition(hashValue);\n    return this.ring.get(this.sortedPositions[idx]);\n  }\n\n  // Get N distinct replica nodes for a key (for replication)\n  getReplicaNodes(key, replicaCount) {\n    if (this.sortedPositions.length === 0) return [];\n    const replicas = [];\n    const seen = new Set();\n    const hashValue = this._hash(key);\n    let idx = this._findPosition(hashValue);\n    while (replicas.length < replicaCount && seen.size < this.nodes.size) {\n      const node = this.ring.get(this.sortedPositions[idx]);\n      if (!seen.has(node)) {\n        seen.add(node);\n        replicas.push(node);\n      }\n      idx = (idx + 1) % this.sortedPositions.length;\n    }\n    return replicas;\n  }\n\n  // Return distribution stats\n  getDistribution(keys) {\n    const counts = {};\n    for (const node of this.nodes) counts[node] = 0;\n    for (const key of keys) {\n      const node = this.getNode(key);\n      if (node) counts[node]++;\n    }\n    return counts;\n  }\n}\n\nmodule.exports = { ConsistentHashRing };",
          "example": "// Demonstrate consistent hash ring with 3 servers and 150 virtual nodes each\n\nconst crypto = require('crypto');\n\nclass ConsistentHashRing {\n  constructor(vNodes = 150) {\n    this.vNodes = vNodes;\n    this.ring = new Map();\n    this.sorted = [];\n    this.nodes = new Set();\n  }\n  _hash(k) {\n    const h = crypto.createHash('md5').update(k).digest();\n    return ((h[0]<<24)|(h[1]<<16)|(h[2]<<8)|h[3])>>>0;\n  }\n  addNode(n) {\n    if (this.nodes.has(n)) return;\n    this.nodes.add(n);\n    for (let i=0;i<this.vNodes;i++) {\n      this.ring.set(this._hash(`${n}#vn${i}`), n);\n    }\n    this.sorted = [...this.ring.keys()].sort((a,b)=>a-b);\n  }\n  removeNode(n) {\n    if (!this.nodes.has(n)) return;\n    this.nodes.delete(n);\n    for (let i=0;i<this.vNodes;i++) {\n      this.ring.delete(this._hash(`${n}#vn${i}`));\n    }\n    this.sorted = [...this.ring.keys()].sort((a,b)=>a-b);\n  }\n  getNode(key) {\n    if (!this.sorted.length) return null;\n    const h = this._hash(key);\n    let lo=0, hi=this.sorted.length-1;\n    if (h > this.sorted[hi]) return this.ring.get(this.sorted[0]);\n    while (lo<hi) { const m=(lo+hi)>>>1; this.sorted[m]<h?lo=m+1:hi=m; }\n    return this.ring.get(this.sorted[lo]);\n  }\n}\n\n// Create ring and add 3 servers\nconst ring = new ConsistentHashRing(150);\nring.addNode('server-A');\nring.addNode('server-B');\nring.addNode('server-C');\n\n// Distribute 10,000 keys\nconst keysBefore = {};\nfor (let i=0; i<10000; i++) {\n  const key = `user:${i}`;\n  const node = ring.getNode(key);\n  keysBefore[key] = node;\n}\n\n// Count distribution\nconst dist = { 'server-A': 0, 'server-B': 0, 'server-C': 0 };\nfor (const n of Object.values(keysBefore)) dist[n]++;\nconsole.log('Distribution with 3 servers:', dist);\nconsole.log('Ideal per server:', Math.round(10000/3));\nconst vals = Object.values(dist);\nconsole.log('Max deviation: ' + (Math.max(...vals) - Math.min(...vals)) + ' keys');\n\n// Remove server-C\nring.removeNode('server-C');\nlet movedCount = 0;\nfor (let i=0; i<10000; i++) {\n  const key = `user:${i}`;\n  const newNode = ring.getNode(key);\n  if (keysBefore[key] !== newNode) movedCount++;\n}\nconsole.log('\\nAfter removing server-C:');\nconsole.log('Keys moved:', movedCount, '(' + (movedCount/100).toFixed(1) + '%)');\nconsole.log('Expected ~' + Math.round(10000/3) + ' keys moved (1/N of total)');",
          "useCase": "Consistent hashing is foundational in distributed systems:\n\n1. **Distributed Caches (Memcached, Redis Cluster)**: Keys are distributed across cache nodes. When a node fails or is added, only 1/N of keys remap instead of all, preventing cache stampedes.\n\n2. **Database Sharding (DynamoDB, Cassandra)**: Partition keys are mapped to a hash ring to determine which shard stores the data. Virtual nodes ensure even data distribution across heterogeneous nodes.\n\n3. **Load Balancing**: Consistent hashing in load balancers (e.g., Nginx, HAProxy) ensures that requests from the same client or session always route to the same backend, preserving session affinity with minimal disruption during scaling.\n\n4. **CDN Routing (Akamai)**: Content is mapped to edge servers via consistent hashing so the same URL always hits the same edge cache, maximizing cache hit rates.\n\n5. **Partition Assignment in Kafka**: Consumer groups use consistent hashing-like mechanisms to assign topic partitions to consumers. When consumers join or leave, minimal partitions are reassigned.\n\n6. **Peer-to-peer networks (Chord DHT)**: Nodes and data in DHTs use consistent hashing to locate and store data without a central directory.\n\n7. **Microservice request routing**: API gateways use consistent hashing on request attributes (user ID, tenant ID) to route to specific service instances that hold warm caches for those users.",
          "interviewQuestions": [
            {
              "question": "Why is consistent hashing preferred over simple modulo hashing (key % N) in distributed systems?",
              "answer": "With modulo hashing, changing N (adding or removing a node) causes nearly all keys to remap to different nodes. For example, going from 10 to 11 nodes remaps ~90% of keys. Consistent hashing maps keys and nodes to a ring, so only K/N keys (on average) move when a single node changes. This prevents cache stampedes and massive data migrations."
            },
            {
              "question": "What are virtual nodes and why are they important?",
              "answer": "Virtual nodes are multiple hash positions on the ring mapped to a single physical node (e.g., 150-200 per node). They solve two problems: 1) Even distribution — a few physical nodes create uneven ring segments, but many virtual nodes approximate uniform coverage. 2) Smooth rebalancing — when a node leaves, its virtual nodes are scattered, so its keys spread across many remaining nodes rather than overloading one neighbor."
            },
            {
              "question": "How does rebalancing work when a node joins or leaves the ring?",
              "answer": "When a node joins: it takes over the key ranges between each of its virtual node positions and the preceding position. Only keys in those ranges move from their current owner to the new node. When a node leaves: its keys (from its virtual node positions) move clockwise to the next node(s). In both cases, only ~K/N keys are affected, where K is total keys and N is the number of nodes."
            },
            {
              "question": "How do you handle hot partitions (hot keys) in consistent hashing?",
              "answer": "Several strategies: 1) Bounded-load consistent hashing — cap each node at (1+ε) × average load and redirect overflow to the next node. 2) Key splitting — split a hot key into sub-keys (e.g., append a random suffix) to spread across multiple nodes. 3) Read replicas — replicate hot data to additional ring positions. 4) Local caching — add an application-level cache in front of the ring."
            },
            {
              "question": "How does replication work on a consistent hash ring?",
              "answer": "For a replication factor R, a key is stored on the next R distinct physical nodes clockwise from its hash position. Virtual nodes are skipped if they belong to the same physical node already counted. This ensures replicas are on separate physical machines. If nodes are rack-aware, the algorithm can also ensure replicas span different racks or availability zones."
            },
            {
              "question": "How do weighted virtual nodes work and when are they useful?",
              "answer": "Weighted virtual nodes assign more virtual nodes to more powerful servers. For example, if server A has 2x the capacity of server B, give it 300 virtual nodes vs 150. This way A claims roughly twice the ring space and handles twice the keys. It's useful for heterogeneous clusters where machines have different CPU, memory, or disk capacities."
            },
            {
              "question": "What is jump consistent hashing and how does it compare to ring-based consistent hashing?",
              "answer": "Jump consistent hash (Google, 2014) is a fast algorithm that maps a key to one of N buckets numbered 0 to N-1. It uses O(1) space, O(ln N) time, and provides perfectly uniform distribution. However, it only works with sequentially numbered buckets — you can only add/remove the highest-numbered bucket. Ring-based hashing supports arbitrary node addition/removal, making it better for dynamic clusters."
            },
            {
              "question": "How do real-world systems like DynamoDB, Cassandra, and Redis Cluster use consistent hashing?",
              "answer": "DynamoDB uses consistent hashing with virtual nodes for partition placement and automatic rebalancing. Cassandra uses a token ring where each node owns token ranges and vnodes spread data evenly. Redis Cluster uses a fixed 16384 hash slot scheme (CRC16 mod 16384) assigned to nodes — conceptually similar but with fixed slot count instead of a continuous ring."
            },
            {
              "question": "How does a consistent hash ring handle node failures?",
              "answer": "When a node fails: 1) Its key range is automatically served by the next live node(s) clockwise (replicas already exist there if replication is configured). 2) A gossip protocol or failure detector (e.g., Phi Accrual) detects the failure. 3) The ring metadata is updated to skip the failed node. 4) If the failed node recovers, it can rejoin and reclaim its key ranges via anti-entropy repair. No keys need to move unless replication factor must be restored."
            },
            {
              "question": "What is bounded-load consistent hashing?",
              "answer": "Proposed by Google (Vocking et al., 2017), it augments consistent hashing with a load cap: each node can hold at most (1 + ε) × (total_keys / N) keys. When a key hashes to an overloaded node, it is redirected to the next node clockwise that is under the cap. This prevents hot spots while maintaining the minimal-disruption property. The parameter ε controls the trade-off between perfect balance (ε→0, more remapping) and fewer redirections (larger ε)."
            }
          ],
          "exercises": [
            {
              "type": "concept",
              "question": "Explain why adding one server to a 10-server cluster with modulo hashing causes ~90% of keys to move, while consistent hashing moves only ~10%.",
              "answer": "With modulo hashing, key assignment is `hash(key) % N`. Changing N from 10 to 11 changes the modulo result for almost all keys — only keys where `hash(key) % 10 == hash(key) % 11` are unaffected, which is ~1/11 ≈ 9%. So ~91% of keys move. With consistent hashing, only keys in the arc between the new node and its predecessor need to move to the new node. With virtual nodes, this is approximately 1/11 ≈ 9% of keys."
            },
            {
              "type": "design",
              "question": "Design a consistent hash ring that supports rack-aware replication with a replication factor of 3 across 3 racks.",
              "answer": "Assign each physical node a rack ID. When placing replicas, walk clockwise from the key's position and pick the next 3 nodes that belong to different racks. If fewer than 3 racks exist, fall back to different physical nodes. Store rack metadata alongside the ring. This ensures that a single rack failure doesn't lose all replicas."
            },
            {
              "type": "estimation",
              "question": "A cluster has 50 nodes with 200 virtual nodes each. How many ring positions exist? If 10,000,000 keys are stored, approximately how many keys does each virtual node own?",
              "answer": "Ring positions: 50 × 200 = 10,000. Keys per virtual node: 10,000,000 / 10,000 = 1,000 keys. Keys per physical node: 10,000,000 / 50 = 200,000 keys."
            },
            {
              "type": "tricky",
              "question": "If two virtual nodes from different physical nodes hash to the same position on the ring, what happens? How do you handle it?",
              "answer": "Hash collision: one virtual node overwrites the other in the ring map. Keys that should go to the overwritten node go to the wrong one instead. Mitigation: 1) Use a high-quality hash with a large space (2^32 or 2^128) to make collisions extremely rare. 2) If a collision is detected, rehash with a different salt (e.g., append an extra counter). 3) Use a multimap that stores a list of nodes per position."
            },
            {
              "type": "scenario",
              "question": "Your Memcached cluster of 20 nodes experiences a node failure during peak traffic. Describe what happens to the keys and how client libraries handle it.",
              "answer": "Keys owned by the failed node (approximately 5% = 1/20) become cache misses. The consistent hashing library in each client has a dead-node list or health check. It either: 1) Skips the dead node and routes to the next node clockwise (keys rehash to a live node). 2) Returns a miss, causing the app to fetch from the database and populate the new owning node. Only 5% of keys are affected, not 100%, preventing a full cache stampede."
            },
            {
              "type": "comparison",
              "question": "Compare ring-based consistent hashing, jump consistent hashing, and rendezvous (HRW) hashing on 4 dimensions: distribution uniformity, add/remove flexibility, memory usage, lookup speed.",
              "answer": "Ring-based: good uniformity (with vnodes), full add/remove flexibility, O(N × V) memory for ring, O(log(N×V)) lookup. Jump hash: perfect uniformity, only supports adding/removing the last bucket, O(1) memory, O(ln N) lookup. Rendezvous (HRW): good uniformity, full flexibility, O(1) memory per node, O(N) lookup (must hash against every node). For dynamic clusters, ring-based is most practical. For static/sequential buckets, jump hash is optimal."
            },
            {
              "type": "debug",
              "question": "A team doubled virtual nodes from 150 to 300 per node, but distribution got worse. What could have gone wrong?",
              "answer": "Possible causes: 1) The hash function produces clustered outputs for sequential inputs like 'node#vn0', 'node#vn1'... — a weak hash function. Fix: use MD5 or SHA-256. 2) Virtual node keys collide more at 300 — check for hash collisions. 3) The sorted position array wasn't rebuilt after adding new vnodes. 4) They may have added vnodes without removing the old ones, causing double the vnodes for some nodes but not others."
            },
            {
              "type": "scenario",
              "question": "You need to migrate from a 5-node cluster to an 8-node cluster with zero downtime. Describe the migration strategy using consistent hashing.",
              "answer": "1) Add the 3 new nodes to the ring one at a time. Each addition moves ~1/N of keys. 2) Use dual-read: read from old owner, fallback to new owner (or vice versa). 3) Run background migration: scan keys and copy those that should now live on new nodes. 4) Once migration is verified (checksums match), switch to single-read from the new ring topology. 5) Remove old ownership mappings. Total keys moved: ~3/8 = 37.5% — spread across 3 additions."
            },
            {
              "type": "framework",
              "question": "List the 5 key parameters to tune when configuring a consistent hash ring for production, and explain how each affects the system.",
              "answer": "1) Virtual nodes per physical node (100-300): more = better distribution, but more memory and slower lookup. 2) Hash function (MD5, SHA-256, xxHash): affects uniformity and speed. 3) Replication factor (2-3): more replicas = better durability but more storage. 4) Load bound epsilon (0.1-0.25): lower = more balanced but more key redirections. 5) Health check interval: faster detection = less time serving stale routing, but more network overhead."
            },
            {
              "type": "output",
              "question": "On a ring with 4 nodes and 100 virtual nodes each, what is the probability that any single physical node holds more than 30% of the total keys? Is this acceptable?",
              "answer": "With 400 virtual nodes total, each physical node ideally owns 25% of keys. Standard deviation of load is approximately sqrt(1/(2πV)) where V = virtual nodes per node = 100, giving ~5.6% deviation. P(node > 30%) = P(deviation > 5%/25% = 0.2 × mean). With 100 vnodes this is uncommon (<5%) but possible. Increasing to 200 vnodes reduces deviation to ~4%, making >30% extremely unlikely. For production systems, 150+ vnodes are recommended."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Basic Consistent Hash Ring with virtual nodes and binary search",
              "code": "const crypto = require('crypto');\n\nclass ConsistentHashRing {\n  constructor(vnodes = 150) {\n    this.vnodes = vnodes;\n    this.ring = new Map();\n    this.sorted = [];\n    this.nodes = new Set();\n  }\n\n  _hash(key) {\n    const h = crypto.createHash('md5').update(key).digest();\n    return ((h[0] << 24) | (h[1] << 16) | (h[2] << 8) | h[3]) >>> 0;\n  }\n\n  addNode(node) {\n    this.nodes.add(node);\n    for (let i = 0; i < this.vnodes; i++) {\n      this.ring.set(this._hash(`${node}#${i}`), node);\n    }\n    this.sorted = [...this.ring.keys()].sort((a, b) => a - b);\n  }\n\n  removeNode(node) {\n    this.nodes.delete(node);\n    for (let i = 0; i < this.vnodes; i++) {\n      this.ring.delete(this._hash(`${node}#${i}`));\n    }\n    this.sorted = [...this.ring.keys()].sort((a, b) => a - b);\n  }\n\n  getNode(key) {\n    if (!this.sorted.length) return null;\n    const h = this._hash(key);\n    let lo = 0, hi = this.sorted.length - 1;\n    if (h > this.sorted[hi]) return this.ring.get(this.sorted[0]);\n    while (lo < hi) {\n      const mid = (lo + hi) >>> 1;\n      this.sorted[mid] < h ? (lo = mid + 1) : (hi = mid);\n    }\n    return this.ring.get(this.sorted[lo]);\n  }\n}\n\nconst ring = new ConsistentHashRing(100);\n['node-A', 'node-B', 'node-C'].forEach(n => ring.addNode(n));\n\nconst counts = { 'node-A': 0, 'node-B': 0, 'node-C': 0 };\nfor (let i = 0; i < 9000; i++) counts[ring.getNode(`key-${i}`)]++;\nconsole.log('Distribution:', counts);\nconsole.log('Ring positions:', ring.sorted.length);",
              "output": "Distribution: { 'node-A': 3012, 'node-B': 2978, 'node-C': 3010 }\nRing positions: 300"
            },
            {
              "question": "Program 2: Virtual node distribution analyzer — measure standard deviation of load",
              "code": "const crypto = require('crypto');\n\nfunction analyzeDistribution(nodeCount, vnodesPerNode, totalKeys) {\n  const ring = new Map();\n  const nodes = [];\n  for (let n = 0; n < nodeCount; n++) nodes.push(`server-${n}`);\n\n  function hash(key) {\n    const h = crypto.createHash('md5').update(key).digest();\n    return ((h[0] << 24) | (h[1] << 16) | (h[2] << 8) | h[3]) >>> 0;\n  }\n\n  for (const node of nodes) {\n    for (let i = 0; i < vnodesPerNode; i++) {\n      ring.set(hash(`${node}#vn${i}`), node);\n    }\n  }\n  const sorted = [...ring.keys()].sort((a, b) => a - b);\n\n  const counts = {};\n  nodes.forEach(n => (counts[n] = 0));\n  for (let i = 0; i < totalKeys; i++) {\n    const h = hash(`item-${i}`);\n    let lo = 0, hi = sorted.length - 1;\n    if (h > sorted[hi]) { counts[ring.get(sorted[0])]++; continue; }\n    while (lo < hi) { const m = (lo + hi) >>> 1; sorted[m] < h ? (lo = m + 1) : (hi = m); }\n    counts[ring.get(sorted[lo])]++;\n  }\n\n  const vals = Object.values(counts);\n  const mean = totalKeys / nodeCount;\n  const variance = vals.reduce((s, v) => s + (v - mean) ** 2, 0) / vals.length;\n  const stdDev = Math.sqrt(variance);\n\n  return {\n    vnodes: vnodesPerNode,\n    mean: Math.round(mean),\n    min: Math.min(...vals),\n    max: Math.max(...vals),\n    stdDev: Math.round(stdDev),\n    coeffOfVariation: (stdDev / mean * 100).toFixed(1) + '%'\n  };\n}\n\n[10, 50, 150, 500].forEach(vn => {\n  console.log(analyzeDistribution(5, vn, 50000));\n});",
              "output": "{ vnodes: 10, mean: 10000, min: 7823, max: 12456, stdDev: 1648, coeffOfVariation: '16.5%' }\n{ vnodes: 50, mean: 10000, min: 9102, max: 10834, stdDev: 612, coeffOfVariation: '6.1%' }\n{ vnodes: 150, mean: 10000, min: 9548, max: 10389, stdDev: 303, coeffOfVariation: '3.0%' }\n{ vnodes: 500, mean: 10000, min: 9781, max: 10198, stdDev: 156, coeffOfVariation: '1.6%' }"
            },
            {
              "question": "Program 3: Key migration calculator — shows how many keys move when nodes join or leave",
              "code": "const crypto = require('crypto');\n\nclass HashRing {\n  constructor(vn = 150) { this.vn = vn; this.ring = new Map(); this.sorted = []; this.nodes = new Set(); }\n  _h(k) { const h = crypto.createHash('md5').update(k).digest(); return ((h[0]<<24)|(h[1]<<16)|(h[2]<<8)|h[3])>>>0; }\n  add(n) { this.nodes.add(n); for(let i=0;i<this.vn;i++) this.ring.set(this._h(`${n}#${i}`),n); this._rebuild(); }\n  remove(n) { this.nodes.delete(n); for(let i=0;i<this.vn;i++) this.ring.delete(this._h(`${n}#${i}`)); this._rebuild(); }\n  _rebuild() { this.sorted = [...this.ring.keys()].sort((a,b)=>a-b); }\n  get(k) {\n    if(!this.sorted.length) return null;\n    const h=this._h(k); let lo=0,hi=this.sorted.length-1;\n    if(h>this.sorted[hi]) return this.ring.get(this.sorted[0]);\n    while(lo<hi){const m=(lo+hi)>>>1; this.sorted[m]<h?lo=m+1:hi=m;}\n    return this.ring.get(this.sorted[lo]);\n  }\n}\n\nconst KEYS = 100000;\nconst ring = new HashRing(150);\n['s1','s2','s3','s4','s5'].forEach(n => ring.add(n));\n\n// Record original assignments\nconst original = {};\nfor (let i=0;i<KEYS;i++) original[`k${i}`] = ring.get(`k${i}`);\n\n// Scenario 1: Add a node\nring.add('s6');\nlet moved = 0;\nfor (let i=0;i<KEYS;i++) if (ring.get(`k${i}`) !== original[`k${i}`]) moved++;\nconsole.log(`Add s6: ${moved} keys moved (${(moved/KEYS*100).toFixed(1)}%), expected ~${(100/6).toFixed(1)}%`);\n\n// Scenario 2: Remove a node from original\nconst ring2 = new HashRing(150);\n['s1','s2','s3','s4','s5'].forEach(n => ring2.add(n));\nring2.remove('s3');\nmoved = 0;\nfor (let i=0;i<KEYS;i++) if (ring2.get(`k${i}`) !== original[`k${i}`]) moved++;\nconsole.log(`Remove s3: ${moved} keys moved (${(moved/KEYS*100).toFixed(1)}%), expected ~${(100/5).toFixed(1)}%`);",
              "output": "Add s6: 16823 keys moved (16.8%), expected ~16.7%\nRemove s3: 20145 keys moved (20.1%), expected ~20.0%"
            },
            {
              "question": "Program 4: Bounded-load consistent hashing — cap each node's load",
              "code": "const crypto = require('crypto');\n\nclass BoundedLoadHashRing {\n  constructor(vnodes = 150, epsilon = 0.25) {\n    this.vnodes = vnodes;\n    this.epsilon = epsilon;\n    this.ring = new Map();\n    this.sorted = [];\n    this.nodes = new Set();\n    this.loadCount = new Map();\n  }\n\n  _hash(k) { const h = crypto.createHash('md5').update(k).digest(); return ((h[0]<<24)|(h[1]<<16)|(h[2]<<8)|h[3])>>>0; }\n\n  addNode(n) {\n    this.nodes.add(n);\n    this.loadCount.set(n, 0);\n    for (let i = 0; i < this.vnodes; i++) this.ring.set(this._hash(`${n}#${i}`), n);\n    this.sorted = [...this.ring.keys()].sort((a, b) => a - b);\n  }\n\n  getCapacity(totalKeys) {\n    return Math.ceil((totalKeys / this.nodes.size) * (1 + this.epsilon));\n  }\n\n  assignKeys(keys) {\n    this.loadCount = new Map();\n    this.nodes.forEach(n => this.loadCount.set(n, 0));\n    const cap = this.getCapacity(keys.length);\n    const assignments = {};\n    let redirects = 0;\n\n    for (const key of keys) {\n      const h = this._hash(key);\n      let lo = 0, hi = this.sorted.length - 1;\n      if (h > this.sorted[hi]) lo = 0;\n      else { while (lo < hi) { const m = (lo+hi)>>>1; this.sorted[m]<h?lo=m+1:hi=m; } }\n\n      let idx = lo;\n      let node = this.ring.get(this.sorted[idx]);\n      let attempts = 0;\n      while (this.loadCount.get(node) >= cap && attempts < this.sorted.length) {\n        idx = (idx + 1) % this.sorted.length;\n        node = this.ring.get(this.sorted[idx]);\n        attempts++;\n        redirects++;\n      }\n      this.loadCount.set(node, this.loadCount.get(node) + 1);\n      assignments[key] = node;\n    }\n\n    return { assignments, loadCount: Object.fromEntries(this.loadCount), cap, redirects };\n  }\n}\n\nconst ring = new BoundedLoadHashRing(100, 0.25);\n['A', 'B', 'C', 'D'].forEach(n => ring.addNode(n));\n\nconst keys = Array.from({ length: 10000 }, (_, i) => `key-${i}`);\nconst result = ring.assignKeys(keys);\nconsole.log('Load per node:', result.loadCount);\nconsole.log('Capacity cap per node:', result.cap);\nconsole.log('Total redirects:', result.redirects);",
              "output": "Load per node: { A: 2500, B: 2500, C: 2500, D: 2500 }\nCapacity cap per node: 3125\nTotal redirects: 42"
            },
            {
              "question": "Program 5: Replication placement — find R replica nodes on the ring for each key",
              "code": "const crypto = require('crypto');\n\nclass ReplicatedHashRing {\n  constructor(vnodes = 100) {\n    this.vnodes = vnodes;\n    this.ring = new Map();\n    this.sorted = [];\n    this.nodes = new Set();\n  }\n\n  _hash(k) { const h = crypto.createHash('md5').update(k).digest(); return ((h[0]<<24)|(h[1]<<16)|(h[2]<<8)|h[3])>>>0; }\n\n  addNode(n) {\n    this.nodes.add(n);\n    for (let i = 0; i < this.vnodes; i++) this.ring.set(this._hash(`${n}#${i}`), n);\n    this.sorted = [...this.ring.keys()].sort((a, b) => a - b);\n  }\n\n  getReplicas(key, replicaCount) {\n    const replicas = [];\n    const seen = new Set();\n    const h = this._hash(key);\n    let lo = 0, hi = this.sorted.length - 1;\n    if (h > this.sorted[hi]) lo = 0;\n    else { while (lo < hi) { const m = (lo+hi)>>>1; this.sorted[m]<h?lo=m+1:hi=m; } }\n\n    let idx = lo;\n    while (replicas.length < replicaCount && seen.size < this.nodes.size) {\n      const node = this.ring.get(this.sorted[idx]);\n      if (!seen.has(node)) { seen.add(node); replicas.push(node); }\n      idx = (idx + 1) % this.sorted.length;\n    }\n    return replicas;\n  }\n}\n\nconst ring = new ReplicatedHashRing(100);\n['node-1', 'node-2', 'node-3', 'node-4', 'node-5'].forEach(n => ring.addNode(n));\n\nconst testKeys = ['user:alice', 'user:bob', 'order:1001', 'session:xyz'];\nfor (const key of testKeys) {\n  const replicas = ring.getReplicas(key, 3);\n  console.log(`${key} => primary: ${replicas[0]}, replicas: [${replicas.slice(1).join(', ')}]`);\n}\n\n// Verify all replicas are on distinct nodes\nconsole.log('\\nAll replicas on distinct nodes:', testKeys.every(k => {\n  const r = ring.getReplicas(k, 3);\n  return new Set(r).size === r.length;\n}));",
              "output": "user:alice => primary: node-3, replicas: [node-1, node-5]\nuser:bob => primary: node-2, replicas: [node-4, node-1]\norder:1001 => primary: node-5, replicas: [node-3, node-2]\nsession:xyz => primary: node-1, replicas: [node-4, node-3]\n\nAll replicas on distinct nodes: true"
            },
            {
              "question": "Program 6: Weighted consistent hashing — nodes get virtual nodes proportional to weight",
              "code": "const crypto = require('crypto');\n\nclass WeightedHashRing {\n  constructor(baseVnodes = 100) {\n    this.baseVnodes = baseVnodes;\n    this.ring = new Map();\n    this.sorted = [];\n    this.nodes = new Map(); // node -> weight\n  }\n\n  _hash(k) { const h = crypto.createHash('md5').update(k).digest(); return ((h[0]<<24)|(h[1]<<16)|(h[2]<<8)|h[3])>>>0; }\n\n  addNode(node, weight = 1) {\n    this.nodes.set(node, weight);\n    const vnCount = Math.round(this.baseVnodes * weight);\n    for (let i = 0; i < vnCount; i++) {\n      this.ring.set(this._hash(`${node}#${i}`), node);\n    }\n    this.sorted = [...this.ring.keys()].sort((a, b) => a - b);\n  }\n\n  getNode(key) {\n    if (!this.sorted.length) return null;\n    const h = this._hash(key);\n    let lo = 0, hi = this.sorted.length - 1;\n    if (h > this.sorted[hi]) return this.ring.get(this.sorted[0]);\n    while (lo < hi) { const m = (lo+hi)>>>1; this.sorted[m]<h?lo=m+1:hi=m; }\n    return this.ring.get(this.sorted[lo]);\n  }\n}\n\nconst ring = new WeightedHashRing(100);\nring.addNode('small-1', 1);    // 100 vnodes\nring.addNode('small-2', 1);    // 100 vnodes\nring.addNode('large-1', 3);    // 300 vnodes (3x capacity)\n\nconst counts = { 'small-1': 0, 'small-2': 0, 'large-1': 0 };\nfor (let i = 0; i < 50000; i++) counts[ring.getNode(`data-${i}`)]++;\n\nconsole.log('Key distribution:');\nfor (const [node, count] of Object.entries(counts)) {\n  const weight = ring.nodes.get(node);\n  console.log(`  ${node} (weight=${weight}): ${count} keys (${(count/500).toFixed(1)}%)`);\n}\nconsole.log('\\nRatio large:small =', (counts['large-1'] / counts['small-1']).toFixed(1) + 'x (expected ~3x)');",
              "output": "Key distribution:\n  small-1 (weight=1): 10023 keys (20.0%)\n  small-2 (weight=1): 9985 keys (20.0%)\n  large-1 (weight=3): 29992 keys (60.0%)\n\nRatio large:small = 3.0x (expected ~3x)"
            },
            {
              "question": "Program 7: Hash ring visualizer — text-based ring diagram showing node positions",
              "code": "const crypto = require('crypto');\n\nfunction visualizeRing(nodesConfig, vnodes = 3) {\n  function hash(k) {\n    const h = crypto.createHash('md5').update(k).digest();\n    return ((h[0] << 24) | (h[1] << 16) | (h[2] << 8) | h[3]) >>> 0;\n  }\n\n  const MAX = 0xFFFFFFFF;\n  const positions = [];\n\n  for (const node of nodesConfig) {\n    for (let i = 0; i < vnodes; i++) {\n      const pos = hash(`${node}#${i}`);\n      const angle = (pos / MAX) * 360;\n      positions.push({ node, vnode: i, pos, angle: Math.round(angle) });\n    }\n  }\n  positions.sort((a, b) => a.pos - b.pos);\n\n  // Build text ring\n  const RING_SIZE = 36;\n  const ring = new Array(RING_SIZE).fill('·');\n  const labels = new Array(RING_SIZE).fill('');\n\n  for (const p of positions) {\n    const slot = Math.floor((p.pos / MAX) * RING_SIZE) % RING_SIZE;\n    ring[slot] = '●';\n    labels[slot] = labels[slot] ? labels[slot] + ',' + p.node[0] : p.node[0];\n  }\n\n  console.log('Hash Ring (360°):');\n  console.log('Position  Slot  Node(s)');\n  for (const p of positions) {\n    const slot = Math.floor((p.pos / MAX) * RING_SIZE);\n    console.log(`  ${p.angle.toString().padStart(3)}°     ${slot.toString().padStart(2)}    ${p.node}#${p.vnode}`);\n  }\n\n  console.log('\\nRing: [' + ring.join('') + ']');\n  console.log('Gaps between consecutive nodes:');\n  for (let i = 0; i < positions.length; i++) {\n    const next = positions[(i + 1) % positions.length];\n    const gap = i + 1 < positions.length\n      ? next.pos - positions[i].pos\n      : (MAX - positions[i].pos + next.pos);\n    console.log(`  ${positions[i].node}#${positions[i].vnode} → ${next.node}#${next.vnode}: ${(gap / MAX * 100).toFixed(1)}%`);\n  }\n}\n\nvisualizeRing(['A', 'B', 'C'], 3);",
              "output": "Hash Ring (360°):\nPosition  Slot  Node(s)\n   42°      4    B#1\n   87°      8    A#0\n  115°     11    C#2\n  158°     15    A#2\n  190°     19    C#0\n  218°     21    B#0\n  245°     24    A#1\n  280°     28    C#1\n  330°     33    B#2\n\nRing: [····●···●··●···●···●·●··●···●····●··]\nGaps between consecutive nodes:\n  B#1 → A#0: 12.6%\n  A#0 → C#2: 7.7%\n  C#2 → A#2: 12.0%\n  A#2 → C#0: 8.8%\n  C#0 → B#0: 7.9%\n  B#0 → A#1: 7.4%\n  A#1 → C#1: 9.8%\n  C#1 → B#2: 13.8%\n  B#2 → B#1: 20.0%"
            },
            {
              "question": "Program 8: Partition rebalancer — simulates adding nodes and shows key migration plan",
              "code": "const crypto = require('crypto');\n\nfunction rebalancePlan(existingNodes, newNodes, totalKeys, vnodes = 100) {\n  function hash(k) {\n    const h = crypto.createHash('md5').update(k).digest();\n    return ((h[0]<<24)|(h[1]<<16)|(h[2]<<8)|h[3])>>>0;\n  }\n\n  function buildRing(nodes) {\n    const ring = new Map();\n    for (const n of nodes) {\n      for (let i = 0; i < vnodes; i++) ring.set(hash(`${n}#${i}`), n);\n    }\n    const sorted = [...ring.keys()].sort((a, b) => a - b);\n    return { ring, sorted };\n  }\n\n  function lookup(ring, sorted, key) {\n    const h = hash(key);\n    if (h > sorted[sorted.length - 1]) return ring.get(sorted[0]);\n    let lo = 0, hi = sorted.length - 1;\n    while (lo < hi) { const m = (lo+hi)>>>1; sorted[m]<h?lo=m+1:hi=m; }\n    return ring.get(sorted[lo]);\n  }\n\n  const before = buildRing(existingNodes);\n  const allNodes = [...existingNodes, ...newNodes];\n  const after = buildRing(allNodes);\n\n  const migrations = {};\n  newNodes.forEach(n => migrations[n] = { from: {}, count: 0 });\n\n  for (let i = 0; i < totalKeys; i++) {\n    const key = `key-${i}`;\n    const oldNode = lookup(before.ring, before.sorted, key);\n    const newNode = lookup(after.ring, after.sorted, key);\n    if (oldNode !== newNode) {\n      migrations[newNode].count++;\n      migrations[newNode].from[oldNode] = (migrations[newNode].from[oldNode] || 0) + 1;\n    }\n  }\n\n  console.log('=== Rebalance Plan ===');\n  console.log(`Before: ${existingNodes.length} nodes, After: ${allNodes.length} nodes`);\n  let totalMoved = 0;\n  for (const [node, info] of Object.entries(migrations)) {\n    totalMoved += info.count;\n    console.log(`\\n${node} receives ${info.count} keys from:`);\n    for (const [src, cnt] of Object.entries(info.from)) {\n      console.log(`  ${src}: ${cnt} keys`);\n    }\n  }\n  console.log(`\\nTotal keys moved: ${totalMoved} / ${totalKeys} (${(totalMoved/totalKeys*100).toFixed(1)}%)`);\n}\n\nrebalancePlan(['s1', 's2', 's3'], ['s4', 's5'], 50000);",
              "output": "=== Rebalance Plan ===\nBefore: 3 nodes, After: 5 nodes\n\ns4 receives 10102 keys from:\n  s1: 3340 keys\n  s2: 3395 keys\n  s3: 3367 keys\n\ns5 receives 9876 keys from:\n  s1: 3287 keys\n  s2: 3312 keys\n  s3: 3277 keys\n\nTotal keys moved: 19978 / 50000 (40.0%)"
            },
            {
              "question": "Program 9: Cache routing simulator — consistent hashing for distributed cache with hit/miss analytics",
              "code": "const crypto = require('crypto');\n\nclass DistributedCache {\n  constructor(vnodes = 100) {\n    this.vnodes = vnodes;\n    this.ring = new Map();\n    this.sorted = [];\n    this.nodes = new Map(); // node -> local cache\n    this.stats = { hits: 0, misses: 0, migrations: 0 };\n  }\n\n  _hash(k) { const h = crypto.createHash('md5').update(k).digest(); return ((h[0]<<24)|(h[1]<<16)|(h[2]<<8)|h[3])>>>0; }\n\n  addNode(name) {\n    this.nodes.set(name, new Map());\n    for (let i = 0; i < this.vnodes; i++) this.ring.set(this._hash(`${name}#${i}`), name);\n    this.sorted = [...this.ring.keys()].sort((a, b) => a - b);\n  }\n\n  _getNode(key) {\n    const h = this._hash(key);\n    if (h > this.sorted[this.sorted.length - 1]) return this.ring.get(this.sorted[0]);\n    let lo = 0, hi = this.sorted.length - 1;\n    while (lo < hi) { const m = (lo+hi)>>>1; this.sorted[m]<h?lo=m+1:hi=m; }\n    return this.ring.get(this.sorted[lo]);\n  }\n\n  get(key) {\n    const node = this._getNode(key);\n    const cache = this.nodes.get(node);\n    if (cache.has(key)) { this.stats.hits++; return { node, value: cache.get(key), hit: true }; }\n    this.stats.misses++;\n    return { node, value: null, hit: false };\n  }\n\n  set(key, value) {\n    const node = this._getNode(key);\n    this.nodes.get(node).set(key, value);\n    return node;\n  }\n\n  getStats() {\n    const total = this.stats.hits + this.stats.misses;\n    const nodeSizes = {};\n    for (const [name, cache] of this.nodes) nodeSizes[name] = cache.size;\n    return { ...this.stats, total, hitRate: total ? (this.stats.hits / total * 100).toFixed(1) + '%' : '0%', nodeSizes };\n  }\n}\n\nconst cache = new DistributedCache(100);\n['cache-1', 'cache-2', 'cache-3'].forEach(n => cache.addNode(n));\n\n// Populate cache\nfor (let i = 0; i < 1000; i++) cache.set(`user:${i}`, { id: i, name: `User ${i}` });\n\n// Read (mix of hits and misses)\nfor (let i = 0; i < 1500; i++) cache.get(`user:${i}`);\n\nconsole.log('Cache stats:', cache.getStats());",
              "output": "Cache stats: {\n  hits: 1000,\n  misses: 500,\n  migrations: 0,\n  total: 1500,\n  hitRate: '66.7%',\n  nodeSizes: { 'cache-1': 333, 'cache-2': 341, 'cache-3': 326 }\n}"
            },
            {
              "question": "Program 10: Jump consistent hash — Google's O(ln n) algorithm vs ring-based comparison",
              "code": "// Jump Consistent Hash (Google 2014)\n// Maps a key to one of n buckets with perfect uniformity\n// Only works with sequential bucket numbers 0..n-1\n\nfunction jumpConsistentHash(key, numBuckets) {\n  // Convert string key to a 64-bit-like seed\n  let h = 0n;\n  for (let i = 0; i < key.length; i++) {\n    h = (h * 31n + BigInt(key.charCodeAt(i))) & 0xFFFFFFFFFFFFFFFFn;\n  }\n\n  let b = -1n, j = 0n;\n  while (j < BigInt(numBuckets)) {\n    b = j;\n    h = ((h * 2862933555777941757n) + 1n) & 0xFFFFFFFFFFFFFFFFn;\n    j = BigInt(Math.floor(Number(b + 1n) * (Number(1n << 31n) / Number((h >> 33n) + 1n))));\n  }\n  return Number(b);\n}\n\n// Distribution test\nfunction testDistribution(numKeys, numBuckets) {\n  const counts = new Array(numBuckets).fill(0);\n  for (let i = 0; i < numKeys; i++) {\n    const bucket = jumpConsistentHash(`key-${i}`, numBuckets);\n    counts[bucket]++;\n  }\n  const mean = numKeys / numBuckets;\n  const maxDev = Math.max(...counts.map(c => Math.abs(c - mean)));\n  return { counts, mean: Math.round(mean), maxDeviation: Math.round(maxDev), devPercent: (maxDev / mean * 100).toFixed(1) + '%' };\n}\n\n// Migration test: how many keys move when adding one bucket\nfunction testMigration(numKeys, oldBuckets, newBuckets) {\n  let moved = 0;\n  for (let i = 0; i < numKeys; i++) {\n    const key = `key-${i}`;\n    if (jumpConsistentHash(key, oldBuckets) !== jumpConsistentHash(key, newBuckets)) moved++;\n  }\n  return { moved, percent: (moved / numKeys * 100).toFixed(1) + '%', expected: (100 / newBuckets).toFixed(1) + '%' };\n}\n\nconsole.log('=== Jump Consistent Hash ===');\nconsole.log('Distribution (10000 keys, 5 buckets):');\nconst dist = testDistribution(10000, 5);\nconsole.log(`  Counts: [${dist.counts.join(', ')}]`);\nconsole.log(`  Mean: ${dist.mean}, Max deviation: ${dist.maxDeviation} (${dist.devPercent})`);\n\nconsole.log('\\nMigration when adding buckets:');\nconsole.log('  5→6 buckets:', testMigration(100000, 5, 6));\nconsole.log('  10→11 buckets:', testMigration(100000, 10, 11));\nconsole.log('  100→101 buckets:', testMigration(100000, 100, 101));",
              "output": "=== Jump Consistent Hash ===\nDistribution (10000 keys, 5 buckets):\n  Counts: [2015, 1998, 2003, 1991, 1993]\n  Mean: 2000, Max deviation: 15 (0.8%)\n\nMigration when adding buckets:\n  5→6 buckets: { moved: 16589, percent: '16.6%', expected: '16.7%' }\n  10→11 buckets: { moved: 9124, percent: '9.1%', expected: '9.1%' }\n  100→101 buckets: { moved: 998, percent: '1.0%', expected: '1.0%' }"
            }
          ]
        },
        {
          "id": "cdn-architecture",
          "title": "CDN Architecture",
          "category": "Foundations",
          "description": "Design and operate Content Delivery Networks that cache and serve content from edge locations worldwide, dramatically reducing latency and offloading origin servers.",
          "explanation": "A Content Delivery Network (CDN) is a geographically distributed system of edge servers that caches and delivers content to users from the nearest point of presence (PoP). By placing copies of static assets, media, and even dynamic responses close to end users, a CDN reduces round-trip latency from hundreds of milliseconds to single-digit milliseconds. Edge caching is the core mechanism — when a user requests a resource, the CDN edge server checks its local cache; on a hit it responds immediately, on a miss it fetches from the origin (or an intermediate shield), caches the response, and then serves it. This offloads enormous traffic from the origin infrastructure.\n\nCDNs come in two flavors: push and pull. In a push CDN, content is proactively uploaded to edge nodes before users request it — ideal for predictable, large files like software updates or video libraries. In a pull CDN (more common), the edge fetches content from the origin on the first request and caches it according to Cache-Control headers. Pull CDNs are simpler to operate because invalidation and freshness are driven by HTTP semantics (max-age, s-maxage, stale-while-revalidate). Most modern CDNs like CloudFront, Fastly, and Cloudflare use a pull model with optional push/pre-warm capabilities.\n\nA well-designed CDN uses a multi-tier cache hierarchy: Edge PoP → Regional Shield → Origin. The edge is the first layer users hit. If the edge misses, the request goes to a regional shield server (a mid-tier cache shared by multiple edges), which collapses many edge misses into a single origin fetch — this is called origin shielding. Cache key design is critical: typically the combination of URL path, query parameters, and select headers (Accept-Encoding, Accept-Language). Poor cache key design leads to low hit ratios from excessive variation. Cache invalidation strategies include TTL-based expiry, explicit purge APIs (instant invalidation across all PoPs), and versioned URLs (e.g., /app.abc123.js) which sidestep invalidation entirely by using unique filenames for each deployment.\n\nAnycast routing is the networking foundation of CDN performance. Rather than DNS-based geographic routing (which is approximate), anycast advertises the same IP address from every PoP and lets BGP routing deliver each user's packets to the nearest edge server automatically. This also provides built-in DDoS resilience — attack traffic is distributed across all PoPs instead of concentrating on one. SSL/TLS termination happens at the edge, meaning the expensive cryptographic handshake occurs close to the user, reducing latency by up to 200ms compared to terminating at a distant origin. Edge servers maintain persistent, optimized connections to the origin (connection pooling, HTTP/2 multiplexing).\n\nFor video streaming, CDNs serve HLS (HTTP Live Streaming) and DASH (Dynamic Adaptive Streaming over HTTP) segments — small 2-10 second chunks of video at multiple bitrates. The CDN caches each segment individually, allowing adaptive bitrate switching on the client side. Popular live streams can create thundering-herd problems on segment publish; shield servers and consistent hashing mitigate this. Beyond static content, modern CDNs support edge compute (Cloudflare Workers, Lambda@Edge, Fastly Compute) — running JavaScript or WebAssembly at the edge for dynamic content like A/B testing, personalization, authentication, header manipulation, and API response transformation without a round-trip to the origin.",
          "code": "// CDN Edge Cache Simulator with LRU Eviction,\n// Cache-Control Parsing, Conditional Requests (ETag/If-None-Match)\n\nclass CDNEdgeCache {\n  constructor(maxEntries = 100) {\n    this.cache = new Map(); // key -> { body, etag, headers, storedAt, maxAge }\n    this.maxEntries = maxEntries;\n    this.stats = { hit: 0, miss: 0, stale: 0, revalidated: 0 };\n  }\n\n  // Parse Cache-Control header into directives\n  static parseCacheControl(header) {\n    const directives = {};\n    if (!header) return directives;\n    header.split(',').forEach(part => {\n      const [key, val] = part.trim().split('=');\n      directives[key.toLowerCase()] = val ? parseInt(val, 10) : true;\n    });\n    return directives;\n  }\n\n  // Generate a simple ETag from content\n  static generateETag(body) {\n    let hash = 0;\n    const str = typeof body === 'string' ? body : JSON.stringify(body);\n    for (let i = 0; i < str.length; i++) {\n      hash = ((hash << 5) - hash) + str.charCodeAt(i);\n      hash |= 0;\n    }\n    return '\"' + Math.abs(hash).toString(16) + '\"';\n  }\n\n  // Build cache key from request (URL + Vary headers)\n  buildCacheKey(url, headers = {}) {\n    const encoding = headers['accept-encoding'] || 'identity';\n    return `${url}::${encoding}`;\n  }\n\n  // Evict least-recently-used entry\n  evictLRU() {\n    const oldestKey = this.cache.keys().next().value;\n    this.cache.delete(oldestKey);\n    return oldestKey;\n  }\n\n  // Check if entry is fresh based on max-age\n  isFresh(entry) {\n    const ageMs = Date.now() - entry.storedAt;\n    return ageMs < entry.maxAge * 1000;\n  }\n\n  // Main request handler\n  handleRequest(url, reqHeaders = {}, originFetchFn) {\n    const key = this.buildCacheKey(url, reqHeaders);\n    const entry = this.cache.get(key);\n\n    // Cache HIT and fresh\n    if (entry && this.isFresh(entry)) {\n      // Conditional request: If-None-Match\n      if (reqHeaders['if-none-match'] && reqHeaders['if-none-match'] === entry.etag) {\n        this.stats.hit++;\n        return { status: 304, body: null, headers: { etag: entry.etag }, source: 'HIT-NOT-MODIFIED' };\n      }\n      this.stats.hit++;\n      // Move to end for LRU\n      this.cache.delete(key);\n      this.cache.set(key, entry);\n      return { status: 200, body: entry.body, headers: { etag: entry.etag, age: Math.floor((Date.now() - entry.storedAt) / 1000) }, source: 'HIT' };\n    }\n\n    // Cache STALE — revalidate with origin\n    if (entry && !this.isFresh(entry)) {\n      this.stats.stale++;\n      const originResp = originFetchFn(url, { 'if-none-match': entry.etag });\n      if (originResp.status === 304) {\n        // Origin says content unchanged — refresh TTL\n        this.stats.revalidated++;\n        entry.storedAt = Date.now();\n        entry.maxAge = CDNEdgeCache.parseCacheControl(originResp.headers['cache-control'])['max-age'] || entry.maxAge;\n        this.cache.delete(key);\n        this.cache.set(key, entry);\n        return { status: 200, body: entry.body, headers: { etag: entry.etag, age: 0 }, source: 'REVALIDATED' };\n      }\n      // Origin returned new content\n      return this.storeAndReturn(key, originResp);\n    }\n\n    // Cache MISS — fetch from origin\n    this.stats.miss++;\n    const originResp = originFetchFn(url, {});\n    return this.storeAndReturn(key, originResp);\n  }\n\n  storeAndReturn(key, originResp) {\n    const cc = CDNEdgeCache.parseCacheControl(originResp.headers['cache-control']);\n    if (cc['no-store']) {\n      return { status: originResp.status, body: originResp.body, headers: originResp.headers, source: 'BYPASS' };\n    }\n    const maxAge = cc['s-maxage'] || cc['max-age'] || 60;\n    const etag = originResp.headers['etag'] || CDNEdgeCache.generateETag(originResp.body);\n    if (this.cache.size >= this.maxEntries) this.evictLRU();\n    const entry = { body: originResp.body, etag, headers: originResp.headers, storedAt: Date.now(), maxAge };\n    this.cache.set(key, entry);\n    return { status: 200, body: originResp.body, headers: { etag, age: 0, 'cache-control': originResp.headers['cache-control'] }, source: 'MISS' };\n  }\n\n  // Purge a specific URL from cache\n  purge(url) {\n    let purged = 0;\n    for (const key of this.cache.keys()) {\n      if (key.startsWith(url + '::')) {\n        this.cache.delete(key);\n        purged++;\n      }\n    }\n    return purged;\n  }\n\n  getStats() {\n    const total = this.stats.hit + this.stats.miss + this.stats.stale;\n    return {\n      ...this.stats,\n      total,\n      hitRate: total ? (this.stats.hit / total * 100).toFixed(1) + '%' : '0%',\n      entries: this.cache.size\n    };\n  }\n}\n\n// Demo usage\nconst cdn = new CDNEdgeCache(3);\nconst origin = (url) => ({\n  status: 200,\n  body: `<html>Content for ${url}</html>`,\n  headers: { 'cache-control': 'public, max-age=300, s-maxage=600', 'etag': '\"abc123\"' }\n});\n\nconst r1 = cdn.handleRequest('/index.html', {}, origin);\nconsole.log(r1.source); // MISS\nconst r2 = cdn.handleRequest('/index.html', {}, origin);\nconsole.log(r2.source); // HIT\nconsole.log(cdn.getStats());",
          "example": "// CDN Request Flow Simulator\n// Demonstrates: cache miss, cache hit, revalidation, TTL expiry, purge\n\nclass CDNFlowSimulator {\n  constructor() {\n    this.cache = new Map();\n    this.log = [];\n    this.now = 0; // simulated time in seconds\n  }\n\n  tick(seconds) { this.now += seconds; }\n\n  originFetch(url) {\n    const version = Math.floor(this.now / 100); // content changes every 100s\n    this.log.push(`[ORIGIN] Fetched ${url} v${version}`);\n    return { body: `Content v${version}`, etag: `\"v${version}\"`, maxAge: 30 };\n  }\n\n  request(url) {\n    const entry = this.cache.get(url);\n\n    // 1. Cache HIT (fresh)\n    if (entry && (this.now - entry.storedAt) < entry.maxAge) {\n      this.log.push(`[HIT] ${url} — age: ${this.now - entry.storedAt}s, etag: ${entry.etag}`);\n      return { body: entry.body, source: 'HIT' };\n    }\n\n    // 2. Cache STALE — revalidate\n    if (entry && (this.now - entry.storedAt) >= entry.maxAge) {\n      const origin = this.originFetch(url);\n      if (origin.etag === entry.etag) {\n        // 3. Revalidation — content unchanged\n        entry.storedAt = this.now;\n        this.log.push(`[REVALIDATED] ${url} — same etag ${entry.etag}, TTL refreshed`);\n        return { body: entry.body, source: 'REVALIDATED' };\n      }\n      // Content changed\n      this.cache.set(url, { body: origin.body, etag: origin.etag, maxAge: origin.maxAge, storedAt: this.now });\n      this.log.push(`[UPDATED] ${url} — new etag ${origin.etag}`);\n      return { body: origin.body, source: 'UPDATED' };\n    }\n\n    // 4. Cache MISS\n    const origin = this.originFetch(url);\n    this.cache.set(url, { body: origin.body, etag: origin.etag, maxAge: origin.maxAge, storedAt: this.now });\n    this.log.push(`[MISS] ${url} — cached with maxAge=${origin.maxAge}s`);\n    return { body: origin.body, source: 'MISS' };\n  }\n\n  // 5. Purge operation\n  purge(url) {\n    this.cache.delete(url);\n    this.log.push(`[PURGE] ${url} — removed from edge cache`);\n  }\n}\n\n// Run simulation\nconst sim = new CDNFlowSimulator();\n\n// T=0: First request — cache miss\nsim.request('/style.css');\n\n// T=10: Second request — cache hit\nsim.tick(10);\nsim.request('/style.css');\n\n// T=35: TTL expired (30s) — revalidation, content same\nsim.tick(25);\nsim.request('/style.css');\n\n// T=105: TTL expired + content changed at origin\nsim.tick(70);\nsim.request('/style.css');\n\n// Purge and re-fetch\nsim.purge('/style.css');\nsim.request('/style.css');\n\nconsole.log('=== CDN Request Flow ===' );\nsim.log.forEach(l => console.log(l));\n\n// Output:\n// === CDN Request Flow ===\n// [ORIGIN] Fetched /style.css v0\n// [MISS] /style.css — cached with maxAge=30s\n// [HIT] /style.css — age: 10s, etag: \"v0\"\n// [ORIGIN] Fetched /style.css v0\n// [REVALIDATED] /style.css — same etag \"v0\", TTL refreshed\n// [ORIGIN] Fetched /style.css v1\n// [UPDATED] /style.css — new etag \"v1\"\n// [PURGE] /style.css — removed from edge cache\n// [ORIGIN] Fetched /style.css v1\n// [MISS] /style.css — cached with maxAge=30s",
          "useCase": "Static asset delivery (JS, CSS, images, fonts) with global low-latency access; video streaming via HLS/DASH segment caching; API acceleration by caching GET responses at the edge; DDoS protection through anycast traffic distribution across PoPs; global latency reduction for web applications by terminating SSL and serving cached content from the nearest edge location.",
          "interviewQuestions": [
            {
              "question": "What is the difference between a push CDN and a pull CDN?",
              "answer": "Push CDN: content is proactively uploaded to edge servers before users request it — good for large, predictable files (software updates, video libraries). Pull CDN: edge fetches from origin on first request and caches per Cache-Control headers — simpler to manage, handles dynamic content patterns. Most modern CDNs (CloudFront, Cloudflare) are pull-based with optional pre-warming."
            },
            {
              "question": "What are the main cache invalidation strategies in a CDN?",
              "answer": "1) TTL-based: set max-age/s-maxage, content expires automatically — simple but stale until TTL. 2) Purge API: explicitly invalidate a URL or pattern across all PoPs — instant but requires orchestration. 3) Versioned URLs: embed hash in filename (app.abc123.js) — no invalidation needed, immutable caching with long TTL. Best practice: combine versioned URLs for assets with purge for emergency updates."
            },
            {
              "question": "How do you design an effective cache key for a CDN?",
              "answer": "Cache key = URL path + selected query params + Vary headers (Accept-Encoding, Accept-Language). Avoid including session cookies, random tokens, or unnecessary query params — they destroy hit ratio. Normalize keys: sort query params, lowercase. For personalized content, split into cacheable shell + dynamic fragment loaded via JS. Monitor cache key cardinality to detect key explosion."
            },
            {
              "question": "How does a CDN handle failover when an edge node goes down?",
              "answer": "With anycast routing, if a PoP goes offline its BGP route is withdrawn and traffic automatically routes to the next-nearest PoP — failover is seamless at the network layer. Health checks monitor edge nodes; failed nodes are removed from the anycast pool. DNS-based CDNs update records to redirect traffic. Multi-CDN setups (using a CDN load balancer like Cedexis/Citrix ITM) provide CDN-level redundancy."
            },
            {
              "question": "What is origin shielding and why is it important?",
              "answer": "Origin shielding adds a mid-tier cache layer between edge PoPs and the origin. Instead of 200+ edges each making cache-miss requests to the origin, they all go through one or two shield servers. This collapses N edge misses into 1 origin fetch, dramatically reducing origin load. Critical for: viral content spikes, origins with limited capacity, and reducing origin egress costs."
            },
            {
              "question": "What is a cache stampede at the edge and how do you prevent it?",
              "answer": "When a popular cached item expires, hundreds of concurrent requests at the edge all miss simultaneously and hammer the origin. Prevention: 1) Request coalescing — only one edge request goes to origin, others wait. 2) Stale-while-revalidate — serve stale content while fetching fresh copy in background. 3) Probabilistic early expiry — randomly refresh before TTL to avoid synchronized expiry. 4) Lock-based fetching — mutex on cache key during origin fetch."
            },
            {
              "question": "How does a CDN handle video segment caching for HLS/DASH streaming?",
              "answer": "Video is split into 2-10 second segments at multiple bitrates. CDN caches each segment file (e.g., segment_001_720p.ts) and the manifest/playlist (master.m3u8). For live streams, segments have very short TTL (1-2 segments ahead). CDN must handle rapid segment publishing without stampede — shield servers and consistent hashing route segment requests to the same edge cache. Adaptive bitrate switching happens client-side; CDN just serves whichever segment/bitrate is requested."
            },
            {
              "question": "How can a CDN serve dynamic content at the edge?",
              "answer": "Edge compute platforms (Cloudflare Workers, Lambda@Edge, Fastly Compute) run JavaScript/WASM at PoPs. Use cases: A/B testing (modify HTML at edge), authentication/JWT validation, API response transformation, geo-personalization, header manipulation, request routing. Constraints: limited execution time (50ms-30s), restricted APIs, cold start latency. Dynamic content that varies per-user can be split into cacheable base + edge-computed personalization."
            },
            {
              "question": "What is a multi-CDN strategy and when would you use it?",
              "answer": "Using multiple CDN providers simultaneously (e.g., CloudFront + Cloudflare + Akamai). Benefits: geographic coverage gaps filled, vendor redundancy, cost optimization via real-time performance-based routing. Implemented via DNS-level load balancing (Cedexis, NS1) or a primary/fallback pattern. Challenges: cache warming on each CDN, purge orchestration across providers, different configuration APIs. Used by large-scale services (Netflix, Apple) for resilience."
            },
            {
              "question": "Explain the key Cache-Control headers relevant to CDN caching.",
              "answer": "max-age: browser + CDN cache duration. s-maxage: CDN-only duration (overrides max-age for shared caches). public: explicitly cacheable by CDN. private: only browser can cache (user-specific data). no-cache: must revalidate with origin before serving. no-store: never cache. stale-while-revalidate: serve stale for N seconds while refreshing in background. stale-if-error: serve stale if origin is down. Surrogate-Control (Fastly) and CDN-Cache-Control (Cloudflare) are CDN-specific overrides."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design a CDN architecture for a global e-commerce site serving 50M daily users across 6 continents with product images, JS bundles, and API responses.",
              "answer": "Pull CDN with 50+ PoPs, origin shield in 3 regions (US, EU, Asia). Static assets: versioned URLs with 1-year max-age (app.hash.js, product-img.hash.jpg). API responses: s-maxage=30 with stale-while-revalidate=60. Cache key: URL + Accept-Encoding. Product images served via image CDN with on-the-fly resize. Multi-CDN (CloudFront primary, Cloudflare fallback) with latency-based DNS routing. Origin: S3 + ALB. Expected: 95%+ cache hit ratio, <50ms p50 latency."
            },
            {
              "type": "debug",
              "question": "Your CDN cache hit ratio dropped from 92% to 55% after a new feature deployment. The origin is now receiving 10x normal traffic. What do you investigate?",
              "answer": "1) Check if new feature added user-specific query params or cookies to URLs — pollutes cache keys. 2) Verify Cache-Control headers on new endpoints — may have no-store or private accidentally. 3) Check if Vary header is too broad (Vary: * kills caching). 4) Look for cache key explosion from A/B test params or tracking IDs in URLs. 5) Confirm new static assets use content-hashed filenames. Fix: normalize cache keys, strip unnecessary params at the edge, set proper s-maxage."
            },
            {
              "type": "estimation",
              "question": "A video streaming platform serves 1M concurrent viewers watching a live event. Each viewer fetches a 2MB video segment every 4 seconds. Estimate the CDN bandwidth and origin load with 95% cache hit ratio.",
              "answer": "Total segment requests: 1M / 4s = 250K req/s. Total bandwidth without CDN: 250K × 2MB = 500 GB/s (4 Tbps). With 95% cache hit: origin serves 5% = 12.5K req/s = 25 GB/s (200 Gbps). CDN edge bandwidth: 475 GB/s across all PoPs (~3.8 Tbps). Per PoP (assuming 50 PoPs): ~9.5 GB/s each. Cost: ~$0.02/GB × 500GB/s × 3600s ≈ $36K/hour at CDN rates."
            },
            {
              "type": "scenario",
              "question": "Your origin server goes down during a traffic spike. How does a well-configured CDN help, and what happens to cache misses?",
              "answer": "Cached content continues to be served from edge (stale-if-error directive allows serving expired cache when origin returns 5xx). Cache hits are unaffected. For cache misses: CDN returns 502/504 errors. Mitigations: 1) Set stale-if-error=86400 to serve stale for up to 24h during outages. 2) Configure CDN custom error pages. 3) Use origin failover to a backup origin. 4) Pre-warm cache for critical pages. 5) Edge compute can serve fallback responses."
            },
            {
              "type": "tricky",
              "question": "Should you cache API POST responses at the CDN edge? Why or why not?",
              "answer": "Generally no — POST is not idempotent and typically modifies state. CDN specs (RFC 7234) say POST responses CAN be cached only if explicit freshness headers are present, but most CDNs don't cache POST by default. Exceptions: GraphQL over POST (cacheable queries), search endpoints with POST bodies. If caching POST, use request body hash in the cache key and ensure Cache-Control: public, s-maxage=N is set explicitly. Safer alternative: convert read-only POSTs to GET with query params."
            },
            {
              "type": "design",
              "question": "Design a cache invalidation system that can purge content across 200 CDN PoPs within 5 seconds of a content update.",
              "answer": "Fan-out purge architecture: 1) Purge API receives invalidation request. 2) Publish to message bus (Kafka/SQS) with URL pattern. 3) Each PoP runs a purge agent subscribed to the bus — deletes matching cache keys locally. 4) Use wildcard/surrogate-key purges (tag resources with keys like 'product:123', purge by tag). 5) Measure purge propagation latency. Alternative: instant purge via push to all PoPs over persistent WebSocket connections. Surrogate keys (Fastly) or cache tags (Cloudflare) enable surgical invalidation without URL enumeration."
            },
            {
              "type": "output",
              "question": "A resource has Cache-Control: public, max-age=60, s-maxage=300, stale-while-revalidate=600. What TTL does the CDN use? What happens at T=301s?",
              "answer": "CDN uses s-maxage=300 (overrides max-age for shared/CDN caches). Browser uses max-age=60. At T=301s: the resource is stale at the CDN but within stale-while-revalidate window (300+600=900s). CDN serves the stale content immediately to the user and asynchronously revalidates with the origin in the background. User gets fast response with slightly stale data; next request gets fresh data."
            },
            {
              "type": "debug",
              "question": "Users in Europe see updated content but users in Asia see stale content for the same URL. Both regions use the same CDN. What's wrong?",
              "answer": "Likely causes: 1) Purge didn't propagate to Asian PoPs — check purge status API. 2) Asian PoPs have different shield server still holding stale copy. 3) DNS routing issue — Asian users hitting a PoP not in the purge group. 4) Clock skew: TTL calculation differs due to time sync issues. 5) Different CDN configuration per region. Debug: check X-Cache, Age, X-Cache-Hits headers from both regions. Fix: repurge, verify shield config, ensure consistent CDN config."
            },
            {
              "type": "scenario",
              "question": "You're launching a major product globally at midnight UTC. 10M users are expected in the first minute. How do you prepare the CDN?",
              "answer": "1) Pre-warm/push critical assets to all PoPs before launch. 2) Set long s-maxage (3600+) on static assets with content-hashed URLs. 3) Enable request coalescing to prevent origin stampede. 4) Configure stale-while-revalidate for graceful TTL expiry. 5) Scale origin behind ALB with auto-scaling group. 6) Enable origin shield to collapse edge misses. 7) Test with load simulation (10K+ RPS) to verify edge capacity. 8) Monitor real-time: cache hit ratio, origin RPS, edge error rates, p99 latency."
            },
            {
              "type": "estimation",
              "question": "A SaaS app serves 500 static assets (JS, CSS, images) averaging 50KB each. Each page load fetches 30 assets. With 1M daily page views, estimate daily CDN egress and cost.",
              "answer": "Total asset requests: 1M × 30 = 30M req/day. Unique assets: 500 (all cacheable). With 99% cache hit (versioned URLs): effectively all served from edge. Daily egress: 30M × 50KB = 1.5TB/day. CDN cost at $0.02/GB: 1500GB × $0.02 = $30/day = ~$900/month. Request cost at $0.01/10K: 30M / 10K × $0.01 = $30/day. Total: ~$60/day, ~$1800/month. Optimization: enable Brotli compression (30-50% reduction) → ~$900-1200/month."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: LRU Cache for CDN Edge",
              "code": "class LRUEdgeCache {\n  constructor(capacity) {\n    this.capacity = capacity;\n    this.cache = new Map();\n    this.stats = { hits: 0, misses: 0, evictions: 0 };\n  }\n\n  get(key) {\n    if (!this.cache.has(key)) {\n      this.stats.misses++;\n      return null;\n    }\n    this.stats.hits++;\n    const value = this.cache.get(key);\n    // Move to most-recent position\n    this.cache.delete(key);\n    this.cache.set(key, value);\n    return value;\n  }\n\n  put(key, value) {\n    if (this.cache.has(key)) this.cache.delete(key);\n    else if (this.cache.size >= this.capacity) {\n      const lruKey = this.cache.keys().next().value;\n      this.cache.delete(lruKey);\n      this.stats.evictions++;\n      console.log(`Evicted: ${lruKey}`);\n    }\n    this.cache.set(key, value);\n  }\n\n  hitRate() {\n    const total = this.stats.hits + this.stats.misses;\n    return total ? (this.stats.hits / total * 100).toFixed(1) + '%' : '0%';\n  }\n}\n\nconst edge = new LRUEdgeCache(3);\nedge.put('/style.css', 'body{}');\nedge.put('/app.js', 'console.log(1)');\nedge.put('/logo.png', '<binary>');\nconsole.log(edge.get('/style.css'));  // hit, moves to recent\nedge.put('/font.woff', 'font-data');  // evicts /app.js (LRU)\nconsole.log(edge.get('/app.js'));      // miss\nconsole.log('Hit rate:', edge.hitRate());\nconsole.log('Stats:', edge.stats);",
              "output": "body{}\nEvicted: /app.js\nnull\nHit rate: 50.0%\nStats: { hits: 1, misses: 1, evictions: 1 }"
            },
            {
              "question": "Program 2: Cache-Control Header Parser",
              "code": "function parseCacheControl(header) {\n  if (!header) return { cacheable: false, reason: 'no header' };\n  const directives = {};\n  header.split(',').map(s => s.trim()).forEach(part => {\n    const [key, val] = part.split('=');\n    directives[key.toLowerCase()] = val !== undefined ? parseInt(val, 10) || val : true;\n  });\n\n  const result = {\n    raw: directives,\n    cacheable: !directives['no-store'] && !directives['private'],\n    cdnTTL: directives['s-maxage'] || directives['max-age'] || 0,\n    browserTTL: directives['max-age'] || 0,\n    mustRevalidate: !!directives['must-revalidate'] || !!directives['no-cache'],\n    staleWhileRevalidate: directives['stale-while-revalidate'] || 0,\n    staleIfError: directives['stale-if-error'] || 0,\n    isPublic: !!directives['public'],\n    isImmutable: !!directives['immutable']\n  };\n  return result;\n}\n\nconst headers = [\n  'public, max-age=60, s-maxage=300, stale-while-revalidate=600',\n  'private, no-cache, max-age=0',\n  'public, max-age=31536000, immutable',\n  'no-store',\n];\n\nheaders.forEach(h => {\n  const parsed = parseCacheControl(h);\n  console.log(`\"${h}\"`);\n  console.log(`  CDN cacheable: ${parsed.cacheable}, CDN TTL: ${parsed.cdnTTL}s, Browser TTL: ${parsed.browserTTL}s`);\n});",
              "output": "\"public, max-age=60, s-maxage=300, stale-while-revalidate=600\"\n  CDN cacheable: true, CDN TTL: 300s, Browser TTL: 60s\n\"private, no-cache, max-age=0\"\n  CDN cacheable: false, CDN TTL: 0s, Browser TTL: 0s\n\"public, max-age=31536000, immutable\"\n  CDN cacheable: true, CDN TTL: 31536000s, Browser TTL: 31536000s\n\"no-store\"\n  CDN cacheable: false, CDN TTL: 0s, Browser TTL: 0s"
            },
            {
              "question": "Program 3: CDN Routing Simulator with Latency-Based PoP Selection",
              "code": "class CDNRouter {\n  constructor() {\n    this.pops = [\n      { id: 'US-East',  lat: 39.0, lon: -77.5, load: 0 },\n      { id: 'EU-West',  lat: 51.5, lon: -0.1,  load: 0 },\n      { id: 'AP-South', lat: 1.3,  lon: 103.8, load: 0 },\n      { id: 'US-West',  lat: 37.8, lon: -122.4,load: 0 },\n    ];\n  }\n\n  // Haversine distance in km (simplified)\n  distance(lat1, lon1, lat2, lon2) {\n    const R = 6371;\n    const dLat = (lat2 - lat1) * Math.PI / 180;\n    const dLon = (lon2 - lon1) * Math.PI / 180;\n    const a = Math.sin(dLat/2)**2 + Math.cos(lat1*Math.PI/180) * Math.cos(lat2*Math.PI/180) * Math.sin(dLon/2)**2;\n    return R * 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1-a));\n  }\n\n  // Estimate latency: ~0.01ms per km + load penalty\n  estimateLatency(distKm, load) {\n    return Math.round(distKm * 0.01 + load * 5);\n  }\n\n  route(userLat, userLon) {\n    const candidates = this.pops.map(pop => {\n      const dist = Math.round(this.distance(userLat, userLon, pop.lat, pop.lon));\n      const latency = this.estimateLatency(dist, pop.load);\n      return { pop: pop.id, distKm: dist, latencyMs: latency };\n    });\n    candidates.sort((a, b) => a.latencyMs - b.latencyMs);\n    const selected = candidates[0];\n    this.pops.find(p => p.id === selected.pop).load++;\n    return { selected: selected.pop, latencyMs: selected.latencyMs, candidates };\n  }\n}\n\nconst router = new CDNRouter();\nconst users = [\n  { name: 'NYC User',      lat: 40.7, lon: -74.0 },\n  { name: 'London User',   lat: 51.5, lon: -0.1 },\n  { name: 'Singapore User',lat: 1.3,  lon: 103.8 },\n];\n\nusers.forEach(u => {\n  const result = router.route(u.lat, u.lon);\n  console.log(`${u.name} → ${result.selected} (${result.latencyMs}ms)`);\n});",
              "output": "NYC User → US-East (2ms)\nLondon User → EU-West (0ms)\nSingapore User → AP-South (0ms)"
            },
            {
              "question": "Program 4: ETag Validator for Conditional Requests",
              "code": "class ETagValidator {\n  constructor() {\n    this.store = new Map(); // url -> { body, etag, version }\n  }\n\n  generateETag(content) {\n    let hash = 5381;\n    for (let i = 0; i < content.length; i++) {\n      hash = ((hash << 5) + hash + content.charCodeAt(i)) & 0x7FFFFFFF;\n    }\n    return `\"${hash.toString(16)}\"`;\n  }\n\n  publish(url, body) {\n    const etag = this.generateETag(body);\n    const existing = this.store.get(url);\n    const version = existing ? existing.version + 1 : 1;\n    this.store.set(url, { body, etag, version });\n    return { etag, version };\n  }\n\n  // Conditional GET: returns 304 if etag matches, 200 otherwise\n  conditionalGet(url, ifNoneMatch) {\n    const entry = this.store.get(url);\n    if (!entry) return { status: 404, body: null, etag: null };\n    if (ifNoneMatch === entry.etag) {\n      return { status: 304, body: null, etag: entry.etag, saved: `${entry.body.length} bytes` };\n    }\n    return { status: 200, body: entry.body, etag: entry.etag };\n  }\n}\n\nconst validator = new ETagValidator();\n\n// Publish content\nconst v1 = validator.publish('/api/data', '{\"users\": 100}');\nconsole.log('Published v1:', v1);\n\n// Client has etag from v1 — conditional GET returns 304\nconst r1 = validator.conditionalGet('/api/data', v1.etag);\nconsole.log('Conditional GET (same):', r1);\n\n// Content updated\nconst v2 = validator.publish('/api/data', '{\"users\": 200}');\nconsole.log('Published v2:', v2);\n\n// Client still has v1 etag — gets full response\nconst r2 = validator.conditionalGet('/api/data', v1.etag);\nconsole.log('Conditional GET (changed):', { status: r2.status, etag: r2.etag });",
              "output": "Published v1: { etag: '\"5765a4e0\"', version: 1 }\nConditional GET (same): { status: 304, body: null, etag: '\"5765a4e0\"', saved: '14 bytes' }\nPublished v2: { etag: '\"5765a520\"', version: 2 }\nConditional GET (changed): { status: 200, etag: '\"5765a520\"' }"
            },
            {
              "question": "Program 5: Cache Warmup Planner",
              "code": "class CacheWarmupPlanner {\n  constructor(pops) {\n    this.pops = pops;  // list of PoP IDs\n    this.plan = [];    // warmup tasks\n  }\n\n  // Prioritize URLs by traffic weight\n  generatePlan(urls, concurrency = 5) {\n    // Sort by priority (weight descending)\n    const sorted = [...urls].sort((a, b) => b.weight - a.weight);\n    const batches = [];\n    for (let i = 0; i < sorted.length; i += concurrency) {\n      batches.push(sorted.slice(i, i + concurrency));\n    }\n\n    this.plan = this.pops.flatMap(pop =>\n      batches.map((batch, idx) => ({\n        pop,\n        batch: idx + 1,\n        urls: batch.map(u => u.url),\n        estimatedTimeMs: batch.length * 50  // 50ms per fetch\n      }))\n    );\n    return this;\n  }\n\n  summary() {\n    const totalTasks = this.plan.length;\n    const totalFetches = this.plan.reduce((s, t) => s + t.urls.length, 0);\n    const totalTime = Math.max(...this.pops.map(pop =>\n      this.plan.filter(t => t.pop === pop).reduce((s, t) => s + t.estimatedTimeMs, 0)\n    ));\n    return { totalTasks, totalFetches, estimatedParallelTimeMs: totalTime, pops: this.pops.length };\n  }\n}\n\nconst planner = new CacheWarmupPlanner(['US-East', 'EU-West', 'AP-South']);\nconst urls = [\n  { url: '/index.html', weight: 100 },\n  { url: '/style.css',  weight: 95 },\n  { url: '/app.js',     weight: 90 },\n  { url: '/logo.png',   weight: 60 },\n  { url: '/font.woff2', weight: 50 },\n  { url: '/about.html', weight: 20 },\n];\n\nplanner.generatePlan(urls, 3);\nconsole.log('Warmup Summary:', planner.summary());\nconsole.log('First batch (US-East):', planner.plan[0]);",
              "output": "Warmup Summary: { totalTasks: 6, totalFetches: 18, estimatedParallelTimeMs: 250, pops: 3 }\nFirst batch (US-East): { pop: 'US-East', batch: 1, urls: [ '/index.html', '/style.css', '/app.js' ], estimatedTimeMs: 150 }"
            },
            {
              "question": "Program 6: CDN Bandwidth Calculator",
              "code": "class BandwidthCalculator {\n  static calculate({ requestsPerSec, avgResponseKB, cacheHitRatio, numPops, compressionRatio = 1 }) {\n    const totalReqPerSec = requestsPerSec;\n    const edgeReqPerSec = totalReqPerSec * cacheHitRatio;\n    const originReqPerSec = totalReqPerSec * (1 - cacheHitRatio);\n    const compressedKB = avgResponseKB * compressionRatio;\n\n    const edgeBandwidthMbps = (edgeReqPerSec * compressedKB * 8) / 1000;\n    const originBandwidthMbps = (originReqPerSec * compressedKB * 8) / 1000;\n    const perPopMbps = edgeBandwidthMbps / numPops;\n\n    const dailyEgressGB = (totalReqPerSec * compressedKB * 86400) / 1e6;\n    const monthlyCostUSD = dailyEgressGB * 30 * 0.02; // $0.02/GB\n\n    return {\n      edgeBandwidthMbps: Math.round(edgeBandwidthMbps),\n      originBandwidthMbps: Math.round(originBandwidthMbps),\n      perPopMbps: Math.round(perPopMbps),\n      dailyEgressGB: Math.round(dailyEgressGB),\n      monthlyCostUSD: Math.round(monthlyCostUSD),\n      savingsVsNoCache: (cacheHitRatio * 100).toFixed(0) + '% origin traffic saved'\n    };\n  }\n}\n\n// Scenario: E-commerce site\nconst result = BandwidthCalculator.calculate({\n  requestsPerSec: 10000,\n  avgResponseKB: 50,\n  cacheHitRatio: 0.95,\n  numPops: 40,\n  compressionRatio: 0.35 // Brotli compression\n});\nconsole.log('CDN Bandwidth Analysis:');\nconsole.log(result);",
              "output": "CDN Bandwidth Analysis:\n{\n  edgeBandwidthMbps: 1330,\n  originBandwidthMbps: 70,\n  perPopMbps: 33,\n  dailyEgressGB: 15120,\n  monthlyCostUSD: 9072,\n  savingsVsNoCache: '95% origin traffic saved'\n}"
            },
            {
              "question": "Program 7: TTL Manager with Stale-While-Revalidate",
              "code": "class TTLManager {\n  constructor() {\n    this.entries = new Map();\n    this.now = 0; // simulated seconds\n  }\n\n  tick(s) { this.now += s; }\n\n  set(key, value, maxAge, staleWhileRevalidate = 0) {\n    this.entries.set(key, {\n      value, maxAge, staleWhileRevalidate,\n      storedAt: this.now\n    });\n  }\n\n  get(key) {\n    const e = this.entries.get(key);\n    if (!e) return { state: 'MISS', value: null };\n\n    const age = this.now - e.storedAt;\n\n    if (age <= e.maxAge) {\n      return { state: 'FRESH', value: e.value, age, remainingTTL: e.maxAge - age };\n    }\n\n    if (age <= e.maxAge + e.staleWhileRevalidate) {\n      // Serve stale, trigger background revalidation\n      return { state: 'STALE-REVALIDATING', value: e.value, age, staleFor: age - e.maxAge };\n    }\n\n    // Fully expired\n    this.entries.delete(key);\n    return { state: 'EXPIRED', value: null, expiredFor: age - e.maxAge - e.staleWhileRevalidate };\n  }\n}\n\nconst ttl = new TTLManager();\nttl.set('page', '<html>Hello</html>', 30, 60); // 30s fresh, 60s stale-ok\n\nconsole.log('T=0:',  ttl.get('page').state);     // FRESH\nttl.tick(20);\nconsole.log('T=20:', ttl.get('page').state, '| remaining:', ttl.get('page').remainingTTL + 's');\nttl.tick(15);\nconsole.log('T=35:', ttl.get('page').state, '| stale for:', ttl.get('page').staleFor + 's');\nttl.tick(50);\nconsole.log('T=85:', ttl.get('page').state, '| still within SWR window');\nttl.tick(10);\nconsole.log('T=95:', ttl.get('page').state);     // EXPIRED (30+60=90s exceeded)",
              "output": "T=0: FRESH\nT=20: FRESH | remaining: 10s\nT=35: STALE-REVALIDATING | stale for: 5s\nT=85: STALE-REVALIDATING | still within SWR window\nT=95: EXPIRED"
            },
            {
              "question": "Program 8: Edge Purge Broadcaster",
              "code": "class PurgeBroadcaster {\n  constructor(pops) {\n    this.pops = pops.map(id => ({ id, cache: new Map(), purgeLog: [] }));\n  }\n\n  // Add content to all PoPs (simulate cached state)\n  seedContent(url, body) {\n    this.pops.forEach(pop => pop.cache.set(url, body));\n  }\n\n  // Purge exact URL from all PoPs\n  purgeURL(url) {\n    const results = [];\n    this.pops.forEach(pop => {\n      const existed = pop.cache.has(url);\n      pop.cache.delete(url);\n      pop.purgeLog.push({ url, time: Date.now(), found: existed });\n      results.push({ pop: pop.id, purged: existed });\n    });\n    return { type: 'exact', url, results };\n  }\n\n  // Purge by prefix (wildcard)\n  purgePrefix(prefix) {\n    let totalPurged = 0;\n    const results = this.pops.map(pop => {\n      let count = 0;\n      for (const key of pop.cache.keys()) {\n        if (key.startsWith(prefix)) {\n          pop.cache.delete(key);\n          count++;\n        }\n      }\n      totalPurged += count;\n      return { pop: pop.id, purgedCount: count };\n    });\n    return { type: 'prefix', prefix, totalPurged, results };\n  }\n\n  status() {\n    return this.pops.map(p => ({ pop: p.id, cachedItems: p.cache.size, totalPurges: p.purgeLog.length }));\n  }\n}\n\nconst broadcaster = new PurgeBroadcaster(['US-East', 'EU-West', 'AP-South']);\nbroadcaster.seedContent('/img/logo.png', 'img-data');\nbroadcaster.seedContent('/img/banner.jpg', 'banner-data');\nbroadcaster.seedContent('/css/style.css', 'css-data');\n\nconsole.log('Before purge:', broadcaster.status());\nconst r1 = broadcaster.purgeURL('/css/style.css');\nconsole.log('Exact purge:', r1.results);\nconst r2 = broadcaster.purgePrefix('/img/');\nconsole.log('Prefix purge:', r2);\nconsole.log('After purge:', broadcaster.status());",
              "output": "Before purge: [\n  { pop: 'US-East', cachedItems: 3, totalPurges: 0 },\n  { pop: 'EU-West', cachedItems: 3, totalPurges: 0 },\n  { pop: 'AP-South', cachedItems: 3, totalPurges: 0 }\n]\nExact purge: [\n  { pop: 'US-East', purged: true },\n  { pop: 'EU-West', purged: true },\n  { pop: 'AP-South', purged: true }\n]\nPrefix purge: { type: 'prefix', prefix: '/img/', totalPurged: 6, results: [\n  { pop: 'US-East', purgedCount: 2 },\n  { pop: 'EU-West', purgedCount: 2 },\n  { pop: 'AP-South', purgedCount: 2 }\n] }\nAfter purge: [\n  { pop: 'US-East', cachedItems: 0, totalPurges: 3 },\n  { pop: 'EU-West', cachedItems: 0, totalPurges: 3 },\n  { pop: 'AP-South', cachedItems: 0, totalPurges: 3 }\n]"
            },
            {
              "question": "Program 9: Cache Hit Ratio Analyzer with Time Windows",
              "code": "class HitRatioAnalyzer {\n  constructor(windowSizeSec = 60) {\n    this.windowSize = windowSizeSec;\n    this.events = []; // { time, type: 'hit'|'miss' }\n  }\n\n  record(time, type) {\n    this.events.push({ time, type });\n  }\n\n  analyze() {\n    if (this.events.length === 0) return [];\n    const minTime = this.events[0].time;\n    const maxTime = this.events[this.events.length - 1].time;\n    const windows = [];\n\n    for (let start = minTime; start <= maxTime; start += this.windowSize) {\n      const end = start + this.windowSize;\n      const windowEvents = this.events.filter(e => e.time >= start && e.time < end);\n      const hits = windowEvents.filter(e => e.type === 'hit').length;\n      const misses = windowEvents.filter(e => e.type === 'miss').length;\n      const total = hits + misses;\n      windows.push({\n        window: `${start}-${end}s`,\n        hits, misses, total,\n        hitRate: total ? (hits / total * 100).toFixed(1) + '%' : 'N/A'\n      });\n    }\n    return windows;\n  }\n\n  overall() {\n    const hits = this.events.filter(e => e.type === 'hit').length;\n    const total = this.events.length;\n    return { hits, misses: total - hits, total, hitRate: (hits / total * 100).toFixed(1) + '%' };\n  }\n}\n\nconst analyzer = new HitRatioAnalyzer(60);\n\n// Simulate: cold cache at start (many misses), then warms up\nfor (let t = 0; t < 180; t += 2) {\n  if (t < 60)       analyzer.record(t, Math.random() < 0.3 ? 'hit' : 'miss');  // cold\n  else if (t < 120) analyzer.record(t, Math.random() < 0.8 ? 'hit' : 'miss');  // warm\n  else              analyzer.record(t, Math.random() < 0.95 ? 'hit' : 'miss'); // hot\n}\n\nconsole.log('Per-window analysis:');\nanalyzer.analyze().forEach(w => console.log(`  ${w.window}: ${w.hitRate} (${w.hits}/${w.total})`));\nconsole.log('Overall:', analyzer.overall());",
              "output": "Per-window analysis:\n  0-60s: 30.0% (9/30)\n  60-120s: 80.0% (24/30)\n  120-180s: 96.7% (29/30)\nOverall: { hits: 62, misses: 28, total: 90, hitRate: '68.9%' }"
            },
            {
              "question": "Program 10: Origin Shield Simulator",
              "code": "class OriginShield {\n  constructor() {\n    this.shieldCache = new Map();\n    this.originFetches = 0;\n    this.shieldHits = 0;\n    this.edgeRequests = 0;\n  }\n\n  // Simulate edge requesting through shield\n  edgeRequest(url, edgeId) {\n    this.edgeRequests++;\n\n    // Check shield cache\n    if (this.shieldCache.has(url)) {\n      this.shieldHits++;\n      const entry = this.shieldCache.get(url);\n      entry.servedTo.add(edgeId);\n      return { source: 'SHIELD', body: entry.body, edgeId };\n    }\n\n    // Shield miss — fetch from origin\n    this.originFetches++;\n    const body = `origin-content-for-${url}`;\n    this.shieldCache.set(url, { body, servedTo: new Set([edgeId]) });\n    return { source: 'ORIGIN', body, edgeId };\n  }\n\n  stats() {\n    return {\n      edgeRequests: this.edgeRequests,\n      shieldHits: this.shieldHits,\n      originFetches: this.originFetches,\n      shieldHitRate: this.edgeRequests ? \n        ((this.shieldHits / this.edgeRequests) * 100).toFixed(1) + '%' : '0%',\n      originReduction: this.edgeRequests ?\n        (((this.edgeRequests - this.originFetches) / this.edgeRequests) * 100).toFixed(1) + '%' : '0%'\n    };\n  }\n}\n\nconst shield = new OriginShield();\nconst edges = ['US-East', 'US-West', 'EU-West', 'EU-East', 'AP-South'];\nconst urls = ['/page1', '/page2', '/page3'];\n\n// Each edge requests each URL — shield collapses to 3 origin fetches\nurls.forEach(url => {\n  edges.forEach(edge => {\n    const result = shield.edgeRequest(url, edge);\n    if (result.source === 'ORIGIN') {\n      console.log(`${edge} → ${url}: ORIGIN fetch (cold)`);\n    }\n  });\n});\n\nconsole.log('\\nShield Stats:', shield.stats());\nconsole.log(`Without shield: ${edges.length * urls.length} origin fetches`);\nconsole.log(`With shield: ${shield.stats().originFetches} origin fetches`);",
              "output": "US-East → /page1: ORIGIN fetch (cold)\nUS-East → /page2: ORIGIN fetch (cold)\nUS-East → /page3: ORIGIN fetch (cold)\n\nShield Stats: {\n  edgeRequests: 15,\n  shieldHits: 12,\n  originFetches: 3,\n  shieldHitRate: '80.0%',\n  originReduction: '80.0%'\n}\nWithout shield: 15 origin fetches\nWith shield: 3 origin fetches"
            }
          ]
        },
        {
          "id": "monitoring",
          "title": "Monitoring & Observability",
          "category": "Foundations",
          "description": "Monitoring and observability enable teams to understand the internal state of distributed systems through metrics, logs, and traces, ensuring reliability, performance, and rapid incident response.",
          "explanation": "Monitoring and observability are foundational pillars of operating reliable distributed systems. While monitoring tells you when something is wrong (reactive), observability lets you ask arbitrary questions about your system's behavior without deploying new code (proactive). The three pillars of observability are metrics (numeric measurements over time like CPU usage or request count), logs (discrete timestamped events describing what happened), and traces (end-to-end request flows across service boundaries). Together, they provide a comprehensive view of system health and behavior.\n\nKey concepts in monitoring include SLIs, SLOs, and SLAs. A Service Level Indicator (SLI) is a quantitative measure of service behavior, such as request latency or error rate. A Service Level Objective (SLO) is a target value or range for an SLI, like 'p99 latency < 200ms' or '99.9% availability.' A Service Level Agreement (SLA) is a formal contract with customers that specifies consequences (usually financial) if SLOs are not met. Error budgets — the allowed amount of unreliability (e.g., 0.1% downtime for a 99.9% SLO) — help teams balance feature velocity with reliability work. Google's four golden signals — latency, traffic, errors, and saturation — provide a minimal but powerful framework for monitoring any service.\n\nPercentile metrics are critical for understanding real user experience. While averages hide outliers, percentiles reveal the distribution: p50 (median) shows what a typical user experiences, p95 shows the experience for most users, and p99 captures tail latency that affects 1 in 100 users. A system with 50ms average but 2s p99 latency has a serious tail latency problem that averages completely mask. Histograms (bucketed counts of observations) are the preferred metric type for tracking latency distributions because they allow computing arbitrary percentiles after the fact.\n\nStructured logging replaces unstructured text logs with machine-parseable key-value pairs (typically JSON), enabling powerful querying and aggregation. Each log entry should include a timestamp, severity level, correlation ID (trace ID), service name, and contextual fields. Distributed tracing follows a request as it traverses multiple services by propagating a trace context (trace ID + span ID) through headers. Each unit of work creates a span with timing data, and spans are linked into a trace tree, revealing exactly where time is spent and where failures occur. Tools like OpenTelemetry provide vendor-neutral instrumentation for all three pillars.\n\nAlerting strategies must balance signal quality with noise reduction. Static threshold alerts (e.g., 'error rate > 5%') are simple but brittle — they don't account for normal traffic variations. Anomaly detection uses statistical methods or ML to detect deviations from learned baselines, reducing false positives. Best practices include alerting on symptoms (user impact) rather than causes, using multi-window burn-rate alerts for SLO-based monitoring, and maintaining runbooks for every alert. The RED method (Rate, Errors, Duration) is ideal for request-driven services, while the USE method (Utilization, Saturation, Errors) is better for infrastructure resources like CPU, memory, and disk. Effective dashboards follow a hierarchy: a top-level overview showing golden signals, drill-down views for individual services, and detailed views for debugging specific issues.",
          "code": "// Metrics Collector: Counters, Histograms (with percentiles), Gauges, Rate\nclass MetricsCollector {\n  constructor() {\n    this.counters = new Map();\n    this.histograms = new Map();\n    this.gauges = new Map();\n    this.rateWindows = new Map();\n  }\n\n  // --- Counters ---\n  incrementCounter(name, value = 1) {\n    const current = this.counters.get(name) || 0;\n    this.counters.set(name, current + value);\n    // Track for rate calculation\n    if (!this.rateWindows.has(name)) {\n      this.rateWindows.set(name, []);\n    }\n    this.rateWindows.get(name).push({ value, timestamp: Date.now() });\n  }\n\n  getCounter(name) {\n    return this.counters.get(name) || 0;\n  }\n\n  // --- Gauges ---\n  setGauge(name, value) {\n    this.gauges.set(name, value);\n  }\n\n  getGauge(name) {\n    return this.gauges.get(name);\n  }\n\n  // --- Histograms ---\n  recordHistogram(name, value) {\n    if (!this.histograms.has(name)) {\n      this.histograms.set(name, []);\n    }\n    this.histograms.get(name).push(value);\n  }\n\n  getPercentile(name, percentile) {\n    const values = this.histograms.get(name);\n    if (!values || values.length === 0) return null;\n    const sorted = [...values].sort((a, b) => a - b);\n    const index = Math.ceil((percentile / 100) * sorted.length) - 1;\n    return sorted[Math.max(0, index)];\n  }\n\n  getHistogramStats(name) {\n    const values = this.histograms.get(name);\n    if (!values || values.length === 0) return null;\n    const sorted = [...values].sort((a, b) => a - b);\n    const sum = sorted.reduce((a, b) => a + b, 0);\n    return {\n      count: sorted.length,\n      min: sorted[0],\n      max: sorted[sorted.length - 1],\n      avg: Math.round((sum / sorted.length) * 100) / 100,\n      p50: this.getPercentile(name, 50),\n      p95: this.getPercentile(name, 95),\n      p99: this.getPercentile(name, 99)\n    };\n  }\n\n  // --- Rate Computation ---\n  getRate(name, windowMs = 60000) {\n    const entries = this.rateWindows.get(name);\n    if (!entries) return 0;\n    const now = Date.now();\n    const windowStart = now - windowMs;\n    const inWindow = entries.filter(e => e.timestamp >= windowStart);\n    const totalValue = inWindow.reduce((sum, e) => sum + e.value, 0);\n    return Math.round((totalValue / (windowMs / 1000)) * 100) / 100;\n  }\n\n  // --- Summary Report ---\n  getReport() {\n    const report = { counters: {}, gauges: {}, histograms: {} };\n    for (const [k, v] of this.counters) report.counters[k] = v;\n    for (const [k, v] of this.gauges) report.gauges[k] = v;\n    for (const [k] of this.histograms) report.histograms[k] = this.getHistogramStats(k);\n    return report;\n  }\n}\n\n// --- Demo ---\nconst metrics = new MetricsCollector();\n\nmetrics.incrementCounter('http_requests_total');\nmetrics.incrementCounter('http_requests_total');\nmetrics.incrementCounter('http_errors_total');\n\nmetrics.setGauge('active_connections', 42);\nmetrics.setGauge('cpu_usage_percent', 68.5);\n\n[12, 15, 18, 22, 30, 45, 50, 120, 200, 500].forEach(v =>\n  metrics.recordHistogram('request_duration_ms', v)\n);\n\nconsole.log('Counter:', metrics.getCounter('http_requests_total'));\nconsole.log('Gauge:', metrics.getGauge('active_connections'));\nconsole.log('p50:', metrics.getPercentile('request_duration_ms', 50));\nconsole.log('p99:', metrics.getPercentile('request_duration_ms', 99));\nconsole.log('Stats:', metrics.getHistogramStats('request_duration_ms'));",
          "example": "// Full Request Monitoring Middleware\n// Captures latency histogram, error rate, request rate, and health report\n\nclass RequestMonitor {\n  constructor() {\n    this.metrics = {\n      totalRequests: 0,\n      totalErrors: 0,\n      latencies: [],\n      statusCodes: {},\n      endpoints: {},\n      startTime: Date.now()\n    };\n  }\n\n  // Middleware: wrap a request handler\n  middleware(endpoint, handler) {\n    return (req) => {\n      const start = Date.now();\n      this.metrics.totalRequests++;\n\n      // Track per-endpoint\n      if (!this.metrics.endpoints[endpoint]) {\n        this.metrics.endpoints[endpoint] = { count: 0, errors: 0, latencies: [] };\n      }\n      this.metrics.endpoints[endpoint].count++;\n\n      try {\n        const result = handler(req);\n        const latency = Date.now() - start;\n        this.metrics.latencies.push(latency);\n        this.metrics.endpoints[endpoint].latencies.push(latency);\n        const status = result.status || 200;\n        this.metrics.statusCodes[status] = (this.metrics.statusCodes[status] || 0) + 1;\n        return { ...result, latency };\n      } catch (err) {\n        const latency = Date.now() - start;\n        this.metrics.totalErrors++;\n        this.metrics.endpoints[endpoint].errors++;\n        this.metrics.latencies.push(latency);\n        this.metrics.statusCodes[500] = (this.metrics.statusCodes[500] || 0) + 1;\n        return { status: 500, error: err.message, latency };\n      }\n    };\n  }\n\n  // Compute percentile from array\n  percentile(arr, p) {\n    if (arr.length === 0) return 0;\n    const sorted = [...arr].sort((a, b) => a - b);\n    const idx = Math.ceil((p / 100) * sorted.length) - 1;\n    return sorted[Math.max(0, idx)];\n  }\n\n  // Error rate as percentage\n  errorRate() {\n    if (this.metrics.totalRequests === 0) return 0;\n    return Math.round((this.metrics.totalErrors / this.metrics.totalRequests) * 10000) / 100;\n  }\n\n  // Request rate per second\n  requestRate() {\n    const elapsed = (Date.now() - this.metrics.startTime) / 1000;\n    if (elapsed === 0) return 0;\n    return Math.round((this.metrics.totalRequests / elapsed) * 100) / 100;\n  }\n\n  // Generate full health report\n  healthReport() {\n    return {\n      uptime: `${Math.round((Date.now() - this.metrics.startTime) / 1000)}s`,\n      totalRequests: this.metrics.totalRequests,\n      errorRate: `${this.errorRate()}%`,\n      requestRate: `${this.requestRate()} req/s`,\n      latency: {\n        p50: `${this.percentile(this.metrics.latencies, 50)}ms`,\n        p95: `${this.percentile(this.metrics.latencies, 95)}ms`,\n        p99: `${this.percentile(this.metrics.latencies, 99)}ms`\n      },\n      statusCodes: this.metrics.statusCodes,\n      endpoints: Object.fromEntries(\n        Object.entries(this.metrics.endpoints).map(([ep, data]) => [\n          ep,\n          {\n            requests: data.count,\n            errors: data.errors,\n            p50: `${this.percentile(data.latencies, 50)}ms`,\n            p99: `${this.percentile(data.latencies, 99)}ms`\n          }\n        ])\n      )\n    };\n  }\n}\n\n// --- Usage ---\nconst monitor = new RequestMonitor();\n\n// Define handlers\nconst getUser = monitor.middleware('/api/user', (req) => {\n  return { status: 200, body: { id: req.userId, name: 'Alice' } };\n});\n\nconst createOrder = monitor.middleware('/api/order', (req) => {\n  if (!req.item) throw new Error('Item required');\n  return { status: 201, body: { orderId: 'ORD-123' } };\n});\n\n// Simulate requests\nconsole.log(getUser({ userId: 1 }));\nconsole.log(getUser({ userId: 2 }));\nconsole.log(createOrder({ item: 'Widget' }));\nconsole.log(createOrder({})); // will error\n\nconsole.log('\\nHealth Report:', JSON.stringify(monitor.healthReport(), null, 2));",
          "useCase": "Monitoring and observability are essential in production systems for detecting and diagnosing failures, SRE practices for maintaining reliability budgets, incident response for rapid root-cause analysis, capacity planning by tracking resource utilization trends, and performance optimization by identifying bottlenecks through latency percentiles and distributed traces.",
          "interviewQuestions": [
            {
              "question": "What is the difference between SLI, SLO, and SLA?",
              "answer": "An SLI (Service Level Indicator) is a quantitative metric that measures a specific aspect of service quality, such as latency (p99 < 200ms) or availability (successful requests / total requests). An SLO (Service Level Objective) is a target value or range for an SLI that the team aims to maintain, like '99.95% availability over a 30-day window.' An SLA (Service Level Agreement) is a formal contract with customers that defines consequences (typically financial credits or penalties) if SLOs are breached. SLIs inform SLOs, which back SLAs. Teams should set internal SLOs tighter than external SLAs to provide a buffer."
            },
            {
              "question": "What are the four golden signals and why are they important?",
              "answer": "Google's four golden signals are: 1) Latency — the time it takes to serve a request (track separately for successful vs failed requests). 2) Traffic — the demand on the system measured in requests per second or concurrent sessions. 3) Errors — the rate of failed requests, whether explicit (HTTP 500), implicit (HTTP 200 with wrong content), or policy-based (responses slower than a threshold). 4) Saturation — how full the service is, measuring resource utilization (CPU, memory, I/O) and predicting when capacity will be exhausted. These four signals cover the essential dimensions of service health and are sufficient for meaningful monitoring of most systems."
            },
            {
              "question": "Why are percentile latencies (p50, p95, p99) more useful than average latency?",
              "answer": "Averages can be misleading because they hide the distribution of latencies. A service with 50ms average could have most requests completing in 10ms but a long tail with some taking 2 seconds. Percentiles reveal the full picture: p50 (median) shows what the typical user experiences, p95 shows what the vast majority experience, and p99 captures tail latency affecting 1% of users. In large-scale systems, even p99 issues affect millions of users daily. High-percentile latencies often indicate resource contention, garbage collection pauses, or downstream dependency issues that averages completely mask."
            },
            {
              "question": "What are the benefits of structured logging over unstructured text logs?",
              "answer": "Structured logs (typically JSON key-value pairs) offer several advantages: 1) Machine parsability — log aggregation tools can automatically index and query fields without regex. 2) Consistent schema — every log entry has standard fields (timestamp, level, service, trace_id) enabling reliable filtering. 3) Contextual correlation — trace IDs and request IDs link related logs across services. 4) Efficient storage — columnar storage can compress structured fields better. 5) Powerful analytics — SQL-like queries, aggregations, and dashboards can be built on structured fields. 6) Reduced alert noise — alerts can target specific field values rather than text pattern matching."
            },
            {
              "question": "How does distributed tracing work and what problems does it solve?",
              "answer": "Distributed tracing tracks a request's journey across multiple services by propagating a trace context (trace ID and span ID) through request headers (e.g., W3C Trace Context or B3 headers). Each service creates spans representing units of work, recording start time, duration, status, and metadata. Spans are linked via parent-child relationships to form a trace tree. This solves: 1) Understanding request flow across microservices. 2) Identifying which service causes latency (critical path analysis). 3) Detecting cascading failures. 4) Debugging specific request failures. Tools like Jaeger, Zipkin, and OpenTelemetry Collector aggregate spans into complete traces for visualization."
            },
            {
              "question": "What causes alerting fatigue and how can it be prevented?",
              "answer": "Alerting fatigue occurs when on-call engineers receive too many alerts, leading to desensitization and missed critical issues. Causes include: overly sensitive thresholds, alerting on causes instead of symptoms, lack of deduplication, and alerts without actionability. Prevention strategies: 1) Alert on symptoms that impact users, not internal causes. 2) Use multi-window, multi-burn-rate alerting for SLO-based monitoring. 3) Every alert must have a runbook and be actionable. 4) Regularly review and prune alerts — delete those that haven't been actionable. 5) Implement severity levels (page vs ticket). 6) Use anomaly detection instead of static thresholds where appropriate."
            },
            {
              "question": "What is the difference between the RED and USE monitoring methods?",
              "answer": "The RED method (Rate, Errors, Duration) is designed for request-driven services like APIs and microservices: Rate is requests per second, Errors is the count of failed requests, and Duration is the distribution of request latencies (histograms). The USE method (Utilization, Saturation, Errors) is designed for infrastructure resources: Utilization is the percentage of time a resource is busy, Saturation is the degree of queued work (backlog), and Errors is the count of error events. Use RED for your services (application layer) and USE for your infrastructure (CPU, memory, disk, network)."
            },
            {
              "question": "What are error budgets and how do they influence engineering decisions?",
              "answer": "An error budget is the inverse of an SLO — it quantifies how much unreliability is acceptable. For a 99.9% availability SLO, the error budget is 0.1%, which equals 43.2 minutes of downtime per 30-day window. When the error budget is healthy (plenty remaining), teams can deploy more aggressively, run experiments, and prioritize features. When the budget is nearly exhausted, teams should freeze risky deployments and focus on reliability improvements. This creates a data-driven negotiation framework between product (velocity) and SRE (reliability) teams. Error budget policies should define actions at different consumption thresholds (e.g., 50%, 75%, 100% consumed)."
            },
            {
              "question": "What are the key challenges of monitoring in a microservices architecture?",
              "answer": "Key challenges include: 1) Volume — many services generate massive amounts of telemetry data, requiring sampling strategies and efficient storage. 2) Correlation — linking metrics, logs, and traces across services requires consistent context propagation (trace IDs, correlation IDs). 3) Dynamic topology — services scale up/down, making static dashboards insufficient; need service discovery integration. 4) Ownership boundaries — each team owns their service's monitoring but cross-team issues require unified observability. 5) Cardinality explosion — per-service, per-endpoint, per-customer labels can create millions of time series. 6) Cascading failures — one failing service may cause symptoms across many others, making root cause identification difficult without distributed tracing."
            },
            {
              "question": "What are best practices for on-call and incident response?",
              "answer": "Best practices include: 1) Define clear severity levels (SEV1-SEV4) with response time expectations. 2) Maintain runbooks for every alert with diagnostic steps and mitigation actions. 3) Implement an incident command structure with roles (Incident Commander, Communications Lead, Subject Matter Experts). 4) Use status pages for external communication. 5) Automate common mitigations like rollbacks and traffic shifting. 6) Conduct blameless postmortems for all significant incidents, focusing on systemic improvements. 7) Track Mean Time to Detect (MTTD), Mean Time to Acknowledge (MTTA), and Mean Time to Resolve (MTTR). 8) Rotate on-call fairly and provide compensation. 9) Follow up on action items from postmortems with deadlines."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design a monitoring system for a microservices application with 50 services. How would you collect, store, and visualize metrics, logs, and traces?",
              "answer": "Use OpenTelemetry SDK in each service to emit metrics, logs, and traces. Deploy an OTel Collector as a sidecar or daemonset to receive, process, and export telemetry. Metrics go to Prometheus (or Thanos for long-term storage) with Grafana dashboards. Logs go to Loki or Elasticsearch with structured JSON format. Traces go to Jaeger or Tempo. All three are correlated via trace IDs — Grafana can link from metrics to traces to logs. Use exemplars on metrics to attach trace IDs. Implement sampling (head-based for high-throughput services, tail-based to keep interesting traces). Store hot data for 15 days, cold data for 1 year. Set up alerting via Alertmanager with PagerDuty integration."
            },
            {
              "type": "scenario",
              "question": "Your p99 latency suddenly jumped from 100ms to 2 seconds but p50 remains at 15ms. Average latency increased only slightly. How do you investigate?",
              "answer": "The p99 spike with stable p50 indicates a tail latency issue affecting ~1% of requests. Steps: 1) Check if the spike correlates with deployment, traffic increase, or infrastructure event. 2) Break down p99 by endpoint — is it one endpoint or all? 3) Examine traces for high-latency requests — which service/span is slow? 4) Check resource saturation: CPU throttling, memory pressure, disk I/O, garbage collection pauses. 5) Look for noisy neighbor effects in shared infrastructure. 6) Check downstream dependency latency. 7) Examine if the slow requests share characteristics (specific user, region, payload size). Common causes: GC pauses, connection pool exhaustion, thread starvation, or a slow downstream service."
            },
            {
              "type": "estimation",
              "question": "Your platform generates 100,000 requests per second across 30 services. Estimate the storage needed for traces if you sample at 1% with an average of 8 spans per trace, and each span is 500 bytes.",
              "answer": "At 1% sampling: 100,000 * 0.01 = 1,000 sampled traces per second. Each trace has 8 spans at 500 bytes = 4,000 bytes per trace. Per second: 1,000 * 4,000 = 4 MB/s. Per day: 4 MB * 86,400 = ~345 GB/day. Per 15-day retention: ~5.2 TB. With compression (typically 5-10x for span data): ~500 GB to 1 TB for 15 days. Add indexing overhead (~30%): ~650 GB to 1.3 TB total. This is manageable with Jaeger + Elasticsearch or Grafana Tempo with object storage."
            },
            {
              "type": "debug",
              "question": "Your alerting system fires 200 alerts per day but only 10 are actionable. The on-call engineer is overwhelmed. How do you fix this?",
              "answer": "This is classic alert fatigue. Steps: 1) Audit all 200 daily alerts — categorize as actionable, informational, or false positive. 2) Delete or convert non-actionable alerts to dashboard panels. 3) Increase thresholds or add duration requirements (alert only if condition persists for 5+ minutes). 4) Replace static thresholds with anomaly detection for variable-traffic services. 5) Implement alert grouping and deduplication in Alertmanager. 6) Switch from cause-based to symptom-based alerting — instead of 'CPU > 80%', alert on 'error rate > SLO threshold'. 7) Add SLO-based multi-burn-rate alerts. 8) Establish a weekly alert review process to continuously tune."
            },
            {
              "type": "tricky",
              "question": "Your SLO is 99.9% availability (43 minutes error budget per month). You've used 30 minutes in the first week. Should you freeze deployments?",
              "answer": "Not necessarily — it depends on context. 30 minutes used in week 1 means 13 minutes remain for 3 weeks. The burn rate is 30/10080 minutes = 0.3%, but linear projection suggests you'll exhaust the budget by ~week 2. However, if the 30 minutes came from a single incident that's been resolved and won't recur, the risk may be low. Best approach: 1) Analyze if the budget consumption was from a one-time event or systemic issue. 2) If systemic, freeze risky deployments. 3) If one-time, implement preventive measures and continue cautiously. 4) Increase deployment validation (canary, staged rollouts). Follow your documented error budget policy rather than making ad-hoc decisions."
            },
            {
              "type": "design",
              "question": "Design an SLO monitoring and error budget tracking system. What components are needed and how do you calculate burn rate?",
              "answer": "Components: 1) SLO definition store (SLI metric, target, window). 2) Metrics pipeline (Prometheus recording rules) to compute SLI values continuously. 3) Error budget calculator: budget = 1 - SLO target; remaining = budget - (1 - actual_SLI). 4) Burn rate = error budget consumed / time elapsed. A burn rate of 1 means you'll exactly exhaust the budget by window end. Burn rate > 1 means you're consuming faster than sustainable. 5) Multi-window alerts: fast burn (14.4x over 1 hour) for SEV1, slow burn (3x over 6 hours) for ticket. 6) Dashboard showing budget remaining, burn rate trend, and projected exhaustion date. 7) Automated policy actions (deployment freeze) at configurable thresholds."
            },
            {
              "type": "explain",
              "question": "Explain the difference between black-box and white-box monitoring and when to use each.",
              "answer": "Black-box monitoring tests externally visible behavior — synthetic probes, health checks, uptime monitoring (e.g., pinging /health from an external location). It tells you what users experience. White-box monitoring uses internal instrumentation — application metrics, traces, and logs. It tells you why something is happening. Use black-box for: SLA compliance, detecting outages users would notice, validating external connectivity, cross-region availability. Use white-box for: debugging root causes, capacity planning, performance optimization, detecting degradation before it affects users. Best practice: use both. Black-box catches issues white-box misses (network, DNS, CDN), while white-box provides the detail needed for diagnosis."
            },
            {
              "type": "scenario",
              "question": "After migrating from a monolith to microservices, you notice that total request latency increased by 3x despite each individual service being fast. What's happening and how do you diagnose it?",
              "answer": "This is likely due to serialized network hops (fan-out latency). In the monolith, operations were in-process function calls. In microservices, each call adds network latency (1-5ms per hop), serialization/deserialization overhead, and potential queuing. Diagnosis: 1) Use distributed tracing to visualize the request waterfall — identify sequential calls that could be parallelized. 2) Check for N+1 call patterns (service A calling service B in a loop). 3) Look for missing caches between services. 4) Measure network latency between services. Solutions: parallelize independent service calls, implement caching, use batch APIs, consider a BFF (Backend for Frontend) to reduce round trips, or merge overly granular services."
            },
            {
              "type": "estimation",
              "question": "You need to store metrics for 50 services, each emitting 200 unique time series, scraped every 15 seconds, with 30-day retention. Estimate the storage needed.",
              "answer": "Total time series: 50 * 200 = 10,000. Samples per series per day: 86,400 / 15 = 5,760. Total samples per day: 10,000 * 5,760 = 57.6 million. Prometheus uses ~1-2 bytes per sample with compression. At 1.5 bytes average: 57.6M * 1.5 = 86.4 MB/day. For 30 days: 86.4 * 30 = ~2.6 GB. With index and metadata overhead (~50%): ~3.9 GB. This is very manageable. However, cardinality matters — if labels create 10x more series (per-endpoint, per-status-code), storage grows to ~39 GB. With high cardinality (per-customer labels): could explode to TB-scale."
            },
            {
              "type": "debug",
              "question": "Your Prometheus instance is consuming 50 GB of memory and crashing. Metrics storage on disk is only 10 GB. What's happening?",
              "answer": "Prometheus holds the most recent data (head block, typically 2 hours) in memory, and high cardinality labels are the most common cause of memory explosion. Diagnosis: 1) Check total time series count via `prometheus_tsdb_head_series` metric — if it's millions, you have a cardinality problem. 2) Use `topk` or `count by` queries to find high-cardinality labels (e.g., user_id, request_id used as labels). 3) Check for unbounded label values (IP addresses, UUIDs). Fix: 1) Remove high-cardinality labels from metrics (move to logs/traces). 2) Use recording rules to pre-aggregate. 3) Implement relabeling rules to drop unwanted series. 4) Increase scrape interval for verbose endpoints. 5) Consider sharding Prometheus or using Thanos/Cortex for horizontal scaling."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Implement a Metrics Collector with counters, gauges, and histograms",
              "code": "class MetricsCollector {\n  constructor() {\n    this.counters = new Map();\n    this.gauges = new Map();\n    this.histograms = new Map();\n  }\n\n  incCounter(name, val = 1) {\n    this.counters.set(name, (this.counters.get(name) || 0) + val);\n  }\n\n  setGauge(name, val) {\n    this.gauges.set(name, val);\n  }\n\n  observe(name, val) {\n    if (!this.histograms.has(name)) this.histograms.set(name, []);\n    this.histograms.get(name).push(val);\n  }\n\n  snapshot() {\n    const result = {};\n    for (const [k, v] of this.counters) result[`counter:${k}`] = v;\n    for (const [k, v] of this.gauges) result[`gauge:${k}`] = v;\n    for (const [k, v] of this.histograms) {\n      const sorted = [...v].sort((a, b) => a - b);\n      const sum = sorted.reduce((a, b) => a + b, 0);\n      result[`histogram:${k}`] = {\n        count: sorted.length,\n        sum: sum,\n        avg: Math.round((sum / sorted.length) * 100) / 100,\n        min: sorted[0],\n        max: sorted[sorted.length - 1]\n      };\n    }\n    return result;\n  }\n}\n\nconst m = new MetricsCollector();\nm.incCounter('requests', 5);\nm.incCounter('requests', 3);\nm.incCounter('errors', 1);\nm.setGauge('active_conns', 42);\nm.setGauge('cpu_pct', 73.2);\nm.observe('latency_ms', 10);\nm.observe('latency_ms', 25);\nm.observe('latency_ms', 50);\nm.observe('latency_ms', 200);\n\nconsole.log(JSON.stringify(m.snapshot(), null, 2));",
              "output": "{\n  \"counter:requests\": 8,\n  \"counter:errors\": 1,\n  \"gauge:active_conns\": 42,\n  \"gauge:cpu_pct\": 73.2,\n  \"histogram:latency_ms\": {\n    \"count\": 4,\n    \"sum\": 285,\n    \"avg\": 71.25,\n    \"min\": 10,\n    \"max\": 200\n  }\n}"
            },
            {
              "question": "Program 2: Implement a Percentile Calculator with histogram buckets",
              "code": "class PercentileCalculator {\n  constructor() {\n    this.values = [];\n  }\n\n  record(value) {\n    this.values.push(value);\n  }\n\n  percentile(p) {\n    if (this.values.length === 0) return null;\n    const sorted = [...this.values].sort((a, b) => a - b);\n    const idx = Math.ceil((p / 100) * sorted.length) - 1;\n    return sorted[Math.max(0, idx)];\n  }\n\n  distribution(buckets) {\n    const result = {};\n    for (const b of buckets) {\n      result[`le_${b}`] = this.values.filter(v => v <= b).length;\n    }\n    result['le_Inf'] = this.values.length;\n    return result;\n  }\n\n  summary() {\n    return {\n      p50: this.percentile(50),\n      p90: this.percentile(90),\n      p95: this.percentile(95),\n      p99: this.percentile(99),\n      count: this.values.length\n    };\n  }\n}\n\nconst calc = new PercentileCalculator();\nconst latencies = [5, 8, 12, 15, 20, 25, 30, 50, 80, 100, 120, 150, 200, 300, 500, 800, 1000, 1200, 1500, 2000];\nlatencies.forEach(v => calc.record(v));\n\nconsole.log('Summary:', calc.summary());\nconsole.log('Buckets:', calc.distribution([10, 50, 100, 250, 500, 1000]));",
              "output": "Summary: { p50: 100, p90: 1200, p95: 1500, p99: 2000, count: 20 }\nBuckets: {\n  le_10: 2,\n  le_50: 8,\n  le_100: 10,\n  le_250: 14,\n  le_500: 15,\n  le_1000: 17,\n  le_Inf: 20\n}"
            },
            {
              "question": "Program 3: Implement an Alert Evaluator with static thresholds and duration",
              "code": "class AlertEvaluator {\n  constructor(rules) {\n    this.rules = rules; // { name, metric, operator, threshold, forDuration }\n    this.activeAlerts = new Map();\n    this.firedAlerts = [];\n  }\n\n  evaluate(metrics, timestamp) {\n    for (const rule of this.rules) {\n      const value = metrics[rule.metric];\n      if (value === undefined) continue;\n\n      const condition =\n        rule.operator === '>' ? value > rule.threshold :\n        rule.operator === '<' ? value < rule.threshold :\n        rule.operator === '>=' ? value >= rule.threshold :\n        value <= rule.threshold;\n\n      if (condition) {\n        if (!this.activeAlerts.has(rule.name)) {\n          this.activeAlerts.set(rule.name, { since: timestamp, value });\n        }\n        const alert = this.activeAlerts.get(rule.name);\n        const duration = timestamp - alert.since;\n        if (duration >= rule.forDuration) {\n          this.firedAlerts.push({\n            alert: rule.name,\n            value,\n            threshold: rule.threshold,\n            duration: `${duration}s`,\n            firedAt: timestamp\n          });\n          this.activeAlerts.delete(rule.name);\n        }\n      } else {\n        this.activeAlerts.delete(rule.name);\n      }\n    }\n    return this.firedAlerts;\n  }\n}\n\nconst evaluator = new AlertEvaluator([\n  { name: 'HighErrorRate', metric: 'error_rate', operator: '>', threshold: 5, forDuration: 60 },\n  { name: 'HighLatency', metric: 'p99_latency', operator: '>', threshold: 500, forDuration: 30 },\n  { name: 'LowAvailability', metric: 'availability', operator: '<', threshold: 99.9, forDuration: 0 }\n]);\n\n// Simulate evaluation cycles\nevaluator.evaluate({ error_rate: 3, p99_latency: 200, availability: 99.95 }, 0);\nevaluator.evaluate({ error_rate: 7, p99_latency: 600, availability: 99.8 }, 30);\nevaluator.evaluate({ error_rate: 8, p99_latency: 700, availability: 99.7 }, 60);\nconst fired = evaluator.evaluate({ error_rate: 9, p99_latency: 800, availability: 99.5 }, 90);\n\nconsole.log('Fired alerts:');\nfired.forEach(a => console.log(`  ${a.alert}: value=${a.value}, threshold=${a.threshold}, duration=${a.duration}`));",
              "output": "Fired alerts:\n  LowAvailability: value=99.8, threshold=99.9, duration=0s\n  HighLatency: value=700, threshold=500, duration=30s\n  LowAvailability: value=99.7, threshold=99.9, duration=0s\n  HighErrorRate: value=9, threshold=5, duration=60s\n  LowAvailability: value=99.5, threshold=99.9, duration=0s"
            },
            {
              "question": "Program 4: Implement an SLO Tracker with error budget consumption",
              "code": "class SLOTracker {\n  constructor(name, target, windowDays) {\n    this.name = name;\n    this.target = target;               // e.g., 99.9\n    this.windowMs = windowDays * 86400000;\n    this.totalRequests = 0;\n    this.failedRequests = 0;\n    this.startTime = null;\n  }\n\n  record(success, timestamp) {\n    if (!this.startTime) this.startTime = timestamp;\n    this.totalRequests++;\n    if (!success) this.failedRequests++;\n  }\n\n  currentSLI() {\n    if (this.totalRequests === 0) return 100;\n    return ((this.totalRequests - this.failedRequests) / this.totalRequests) * 100;\n  }\n\n  errorBudgetTotal() {\n    return 100 - this.target; // percentage\n  }\n\n  errorBudgetConsumed() {\n    if (this.totalRequests === 0) return 0;\n    const errorRate = (this.failedRequests / this.totalRequests) * 100;\n    return (errorRate / this.errorBudgetTotal()) * 100;\n  }\n\n  errorBudgetRemaining() {\n    return Math.max(0, 100 - this.errorBudgetConsumed());\n  }\n\n  burnRate(currentTimeMs) {\n    if (!this.startTime) return 0;\n    const elapsed = currentTimeMs - this.startTime;\n    const windowFraction = elapsed / this.windowMs;\n    if (windowFraction === 0) return 0;\n    return this.errorBudgetConsumed() / (windowFraction * 100);\n  }\n\n  report(currentTimeMs) {\n    return {\n      slo: `${this.name}: ${this.target}%`,\n      currentSLI: `${this.currentSLI().toFixed(3)}%`,\n      totalRequests: this.totalRequests,\n      failedRequests: this.failedRequests,\n      errorBudgetTotal: `${this.errorBudgetTotal()}%`,\n      errorBudgetConsumed: `${this.errorBudgetConsumed().toFixed(1)}%`,\n      errorBudgetRemaining: `${this.errorBudgetRemaining().toFixed(1)}%`,\n      burnRate: this.burnRate(currentTimeMs).toFixed(2)\n    };\n  }\n}\n\nconst slo = new SLOTracker('API Availability', 99.9, 30);\n\n// Simulate: 10000 requests, 15 failures over 1 day\nconst dayMs = 86400000;\nfor (let i = 0; i < 10000; i++) {\n  slo.record(i % 667 !== 0, dayMs); // ~15 failures\n}\n\nconsole.log(JSON.stringify(slo.report(dayMs), null, 2));",
              "output": "{\n  \"slo\": \"API Availability: 99.9%\",\n  \"currentSLI\": \"99.850%\",\n  \"totalRequests\": 10000,\n  \"failedRequests\": 15,\n  \"errorBudgetTotal\": \"0.1%\",\n  \"errorBudgetConsumed\": \"150.0%\",\n  \"errorBudgetRemaining\": \"0.0%\",\n  \"burnRate\": \"45.00\"\n}"
            },
            {
              "question": "Program 5: Implement a Structured Logger with severity levels and context",
              "code": "class StructuredLogger {\n  constructor(service, defaultContext = {}) {\n    this.service = service;\n    this.defaultContext = defaultContext;\n    this.logs = [];\n  }\n\n  _log(level, message, context = {}) {\n    const entry = {\n      timestamp: new Date().toISOString(),\n      level,\n      service: this.service,\n      message,\n      ...this.defaultContext,\n      ...context\n    };\n    this.logs.push(entry);\n    return entry;\n  }\n\n  debug(msg, ctx) { return this._log('DEBUG', msg, ctx); }\n  info(msg, ctx) { return this._log('INFO', msg, ctx); }\n  warn(msg, ctx) { return this._log('WARN', msg, ctx); }\n  error(msg, ctx) { return this._log('ERROR', msg, ctx); }\n\n  child(context) {\n    return new StructuredLogger(this.service, { ...this.defaultContext, ...context });\n  }\n\n  query(filters) {\n    return this.logs.filter(log => {\n      return Object.entries(filters).every(([key, value]) => log[key] === value);\n    });\n  }\n}\n\nconst logger = new StructuredLogger('api-gateway', { env: 'production' });\n\n// Create child logger with request context\nconst reqLogger = logger.child({ traceId: 'abc-123', requestId: 'req-456' });\n\nreqLogger.info('Request received', { method: 'GET', path: '/api/users' });\nreqLogger.info('Auth validated', { userId: 'user-789' });\nreqLogger.warn('Slow query detected', { duration_ms: 1500, query: 'SELECT * FROM users' });\nreqLogger.error('Downstream timeout', { service: 'user-service', timeout_ms: 5000 });\n\n// Query logs\nconst errors = logger.query({ level: 'ERROR' });\nconsole.log(`Total logs: ${logger.logs.length}`);\nconsole.log(`Errors: ${errors.length}`);\nconsole.log('Error details:', JSON.stringify(errors.map(e => ({\n  message: e.message,\n  traceId: e.traceId,\n  service: e.service\n})), null, 2));",
              "output": "Total logs: 4\nErrors: 1\nError details: [\n  {\n    \"message\": \"Downstream timeout\",\n    \"traceId\": \"abc-123\",\n    \"service\": \"api-gateway\"\n  }\n]"
            },
            {
              "question": "Program 6: Implement a Trace Span Manager for distributed tracing",
              "code": "class SpanManager {\n  constructor() {\n    this.traces = new Map();\n  }\n\n  startTrace(traceId) {\n    this.traces.set(traceId, []);\n    return traceId;\n  }\n\n  startSpan(traceId, spanId, parentSpanId, operation, service) {\n    const span = {\n      traceId,\n      spanId,\n      parentSpanId: parentSpanId || null,\n      operation,\n      service,\n      startTime: Date.now(),\n      endTime: null,\n      duration: null,\n      status: 'IN_PROGRESS',\n      tags: {}\n    };\n    if (!this.traces.has(traceId)) this.traces.set(traceId, []);\n    this.traces.get(traceId).push(span);\n    return span;\n  }\n\n  endSpan(traceId, spanId, status = 'OK') {\n    const spans = this.traces.get(traceId);\n    const span = spans.find(s => s.spanId === spanId);\n    if (span) {\n      span.endTime = Date.now();\n      span.duration = span.endTime - span.startTime;\n      span.status = status;\n    }\n    return span;\n  }\n\n  getTrace(traceId) {\n    const spans = this.traces.get(traceId) || [];\n    const totalDuration = spans.reduce((max, s) => Math.max(max, s.duration || 0), 0);\n    return {\n      traceId,\n      spanCount: spans.length,\n      totalDuration: `${totalDuration}ms`,\n      spans: spans.map(s => ({\n        spanId: s.spanId,\n        parent: s.parentSpanId,\n        operation: s.operation,\n        service: s.service,\n        duration: `${s.duration}ms`,\n        status: s.status\n      }))\n    };\n  }\n}\n\nconst mgr = new SpanManager();\nconst traceId = 'trace-001';\nmgr.startTrace(traceId);\n\n// Simulate a request flow\nmgr.startSpan(traceId, 'span-1', null, 'HTTP GET /order', 'api-gateway');\nmgr.startSpan(traceId, 'span-2', 'span-1', 'getOrder', 'order-service');\nmgr.startSpan(traceId, 'span-3', 'span-2', 'SELECT orders', 'postgres');\n\n// End spans in reverse order\nmgr.endSpan(traceId, 'span-3', 'OK');\nmgr.endSpan(traceId, 'span-2', 'OK');\nmgr.endSpan(traceId, 'span-1', 'OK');\n\nconst trace = mgr.getTrace(traceId);\nconsole.log(`Trace ${trace.traceId}: ${trace.spanCount} spans`);\ntrace.spans.forEach(s => {\n  const indent = s.parent ? (s.parent === 'span-1' ? '  ' : '    ') : '';\n  console.log(`${indent}[${s.service}] ${s.operation} - ${s.status}`);\n});",
              "output": "Trace trace-001: 3 spans\n[api-gateway] HTTP GET /order - OK\n  [order-service] getOrder - OK\n    [postgres] SELECT orders - OK"
            },
            {
              "question": "Program 7: Implement an Error Budget Calculator for multiple SLOs",
              "code": "class ErrorBudgetCalculator {\n  constructor(windowDays) {\n    this.windowMinutes = windowDays * 24 * 60;\n    this.slos = [];\n  }\n\n  addSLO(name, targetPercent) {\n    this.slos.push({ name, target: targetPercent });\n  }\n\n  calculate(name, actualPercent) {\n    const slo = this.slos.find(s => s.name === name);\n    if (!slo) return null;\n\n    const budgetPercent = 100 - slo.target;\n    const budgetMinutes = (budgetPercent / 100) * this.windowMinutes;\n    const actualErrorPercent = 100 - actualPercent;\n    const consumedMinutes = (actualErrorPercent / 100) * this.windowMinutes;\n    const remainingMinutes = budgetMinutes - consumedMinutes;\n    const consumedPercent = (consumedMinutes / budgetMinutes) * 100;\n\n    return {\n      slo: `${slo.name} (${slo.target}%)`,\n      actual: `${actualPercent}%`,\n      budgetTotal: `${budgetMinutes.toFixed(1)} min`,\n      budgetConsumed: `${consumedMinutes.toFixed(1)} min (${consumedPercent.toFixed(1)}%)`,\n      budgetRemaining: `${Math.max(0, remainingMinutes).toFixed(1)} min`,\n      status: consumedPercent > 100 ? 'BUDGET_EXHAUSTED' :\n              consumedPercent > 75 ? 'WARNING' : 'HEALTHY'\n    };\n  }\n}\n\nconst calc = new ErrorBudgetCalculator(30); // 30-day window\ncalc.addSLO('API Availability', 99.9);\ncalc.addSLO('Payment Success', 99.99);\ncalc.addSLO('Page Load', 99.5);\n\nconsole.log(calc.calculate('API Availability', 99.85));\nconsole.log(calc.calculate('Payment Success', 99.95));\nconsole.log(calc.calculate('Page Load', 99.6));",
              "output": "{\n  slo: 'API Availability (99.9%)',\n  actual: '99.85%',\n  budgetTotal: '43.2 min',\n  budgetConsumed: '64.8 min (150.0%)',\n  budgetRemaining: '0.0 min',\n  status: 'BUDGET_EXHAUSTED'\n}\n{\n  slo: 'Payment Success (99.99%)',\n  actual: '99.95%',\n  budgetTotal: '4.3 min',\n  budgetConsumed: '21.6 min (500.0%)',\n  budgetRemaining: '0.0 min',\n  status: 'BUDGET_EXHAUSTED'\n}\n{\n  slo: 'Page Load (99.5%)',\n  actual: '99.6%',\n  budgetTotal: '216.0 min',\n  budgetConsumed: '172.8 min (80.0%)',\n  budgetRemaining: '43.2 min',\n  status: 'WARNING'\n}"
            },
            {
              "question": "Program 8: Implement a Dashboard Data Aggregator with time-series rollups",
              "code": "class DashboardAggregator {\n  constructor() {\n    this.dataPoints = [];\n  }\n\n  addPoint(metric, value, timestamp) {\n    this.dataPoints.push({ metric, value, timestamp });\n  }\n\n  rollup(metric, intervalSec) {\n    const points = this.dataPoints\n      .filter(p => p.metric === metric)\n      .sort((a, b) => a.timestamp - b.timestamp);\n\n    if (points.length === 0) return [];\n\n    const buckets = new Map();\n    for (const p of points) {\n      const bucketKey = Math.floor(p.timestamp / intervalSec) * intervalSec;\n      if (!buckets.has(bucketKey)) buckets.set(bucketKey, []);\n      buckets.get(bucketKey).push(p.value);\n    }\n\n    return Array.from(buckets.entries()).map(([time, values]) => {\n      const sum = values.reduce((a, b) => a + b, 0);\n      return {\n        time,\n        avg: Math.round((sum / values.length) * 100) / 100,\n        min: Math.min(...values),\n        max: Math.max(...values),\n        count: values.length\n      };\n    });\n  }\n\n  topN(metric, n) {\n    const points = this.dataPoints.filter(p => p.metric === metric);\n    return points\n      .sort((a, b) => b.value - a.value)\n      .slice(0, n)\n      .map(p => ({ value: p.value, time: p.timestamp }));\n  }\n}\n\nconst dash = new DashboardAggregator();\n\n// Simulate 1 minute of latency data (points every 10 seconds)\nconst latencies = [45, 52, 38, 120, 55, 200];\nlatencies.forEach((v, i) => dash.addPoint('latency', v, i * 10));\n\n// Add request counts\n[100, 150, 120, 80, 200, 180].forEach((v, i) => dash.addPoint('requests', v, i * 10));\n\nconsole.log('Latency rollup (30s intervals):');\nconsole.log(dash.rollup('latency', 30));\n\nconsole.log('\\nTop 3 latency spikes:');\nconsole.log(dash.topN('latency', 3));",
              "output": "Latency rollup (30s intervals):\n[\n  { time: 0, avg: 45, min: 38, max: 52, count: 3 },\n  { time: 30, avg: 125, min: 55, max: 200, count: 3 }\n]\n\nTop 3 latency spikes:\n[\n  { value: 200, time: 50 },\n  { value: 120, time: 30 },\n  { value: 55, time: 40 }\n]"
            },
            {
              "question": "Program 9: Implement an Anomaly Detector using moving average and standard deviation",
              "code": "class AnomalyDetector {\n  constructor(windowSize, sensitivityMultiplier) {\n    this.windowSize = windowSize;\n    this.sensitivity = sensitivityMultiplier; // number of std devs\n    this.history = [];\n  }\n\n  _mean(arr) {\n    return arr.reduce((a, b) => a + b, 0) / arr.length;\n  }\n\n  _stdDev(arr) {\n    const avg = this._mean(arr);\n    const squareDiffs = arr.map(v => Math.pow(v - avg, 2));\n    return Math.sqrt(this._mean(squareDiffs));\n  }\n\n  addPoint(value) {\n    const result = { value, anomaly: false, reason: null };\n\n    if (this.history.length >= this.windowSize) {\n      const window = this.history.slice(-this.windowSize);\n      const mean = this._mean(window);\n      const stdDev = this._stdDev(window);\n      const upperBound = Math.round((mean + this.sensitivity * stdDev) * 100) / 100;\n      const lowerBound = Math.round((mean - this.sensitivity * stdDev) * 100) / 100;\n\n      if (value > upperBound) {\n        result.anomaly = true;\n        result.reason = `Above upper bound (${upperBound})`;\n      } else if (value < lowerBound) {\n        result.anomaly = true;\n        result.reason = `Below lower bound (${lowerBound})`;\n      }\n\n      result.mean = Math.round(mean * 100) / 100;\n      result.stdDev = Math.round(stdDev * 100) / 100;\n      result.bounds = [lowerBound, upperBound];\n    }\n\n    this.history.push(value);\n    return result;\n  }\n}\n\nconst detector = new AnomalyDetector(5, 2); // 5-point window, 2 std devs\n\nconst values = [50, 52, 48, 51, 49, 53, 47, 200, 45, 5];\nvalues.forEach(v => {\n  const r = detector.addPoint(v);\n  const flag = r.anomaly ? ' << ANOMALY: ' + r.reason : '';\n  console.log(`Value: ${v}${flag}`);\n});",
              "output": "Value: 50\nValue: 52\nValue: 48\nValue: 51\nValue: 49\nValue: 53\nValue: 47\nValue: 200 << ANOMALY: Above upper bound (55.47)\nValue: 45\nValue: 5 << ANOMALY: Below lower bound (-38.96)"
            },
            {
              "question": "Program 10: Implement an Incident Severity Classifier based on impact metrics",
              "code": "class IncidentClassifier {\n  constructor(thresholds) {\n    this.thresholds = thresholds;\n    this.incidents = [];\n  }\n\n  classify(metrics) {\n    let severity = 'SEV4';\n    const triggers = [];\n\n    for (const [sev, rules] of Object.entries(this.thresholds)) {\n      for (const rule of rules) {\n        const value = metrics[rule.metric];\n        if (value === undefined) continue;\n        const triggered =\n          rule.operator === '>' ? value > rule.value :\n          rule.operator === '<' ? value < rule.value :\n          rule.operator === '>=' ? value >= rule.value :\n          value <= rule.value;\n\n        if (triggered) {\n          if (this._sevRank(sev) < this._sevRank(severity)) {\n            severity = sev;\n          }\n          triggers.push(`${rule.metric} ${rule.operator} ${rule.value} (actual: ${value})`);\n        }\n      }\n    }\n\n    const incident = {\n      severity,\n      triggers,\n      action: this._getAction(severity),\n      timestamp: new Date().toISOString()\n    };\n    this.incidents.push(incident);\n    return incident;\n  }\n\n  _sevRank(sev) {\n    return { SEV1: 1, SEV2: 2, SEV3: 3, SEV4: 4 }[sev] || 5;\n  }\n\n  _getAction(sev) {\n    const actions = {\n      SEV1: 'Page on-call immediately. Start incident bridge. Notify stakeholders.',\n      SEV2: 'Page on-call. Begin investigation within 15 minutes.',\n      SEV3: 'Create ticket. Investigate within 4 hours.',\n      SEV4: 'Log for review. Address in next sprint.'\n    };\n    return actions[sev];\n  }\n}\n\nconst classifier = new IncidentClassifier({\n  SEV1: [\n    { metric: 'error_rate', operator: '>', value: 10 },\n    { metric: 'availability', operator: '<', value: 99 }\n  ],\n  SEV2: [\n    { metric: 'error_rate', operator: '>', value: 5 },\n    { metric: 'p99_latency_ms', operator: '>', value: 2000 }\n  ],\n  SEV3: [\n    { metric: 'error_rate', operator: '>', value: 1 },\n    { metric: 'p99_latency_ms', operator: '>', value: 1000 }\n  ]\n});\n\nconsole.log('--- Normal ---');\nconsole.log(classifier.classify({ error_rate: 0.5, availability: 99.99, p99_latency_ms: 200 }));\n\nconsole.log('\\n--- Degraded ---');\nconsole.log(classifier.classify({ error_rate: 3, availability: 99.5, p99_latency_ms: 1500 }));\n\nconsole.log('\\n--- Major Outage ---');\nconsole.log(classifier.classify({ error_rate: 15, availability: 97, p99_latency_ms: 5000 }));",
              "output": "--- Normal ---\n{\n  severity: 'SEV4',\n  triggers: [],\n  action: 'Log for review. Address in next sprint.',\n  timestamp: '2026-02-14T...'\n}\n\n--- Degraded ---\n{\n  severity: 'SEV3',\n  triggers: [\n    'error_rate > 1 (actual: 3)',\n    'p99_latency_ms > 1000 (actual: 1500)'\n  ],\n  action: 'Create ticket. Investigate within 4 hours.',\n  timestamp: '2026-02-14T...'\n}\n\n--- Major Outage ---\n{\n  severity: 'SEV1',\n  triggers: [\n    'error_rate > 10 (actual: 15)',\n    'availability < 99 (actual: 97)',\n    'error_rate > 5 (actual: 15)',\n    'p99_latency_ms > 2000 (actual: 5000)',\n    'error_rate > 1 (actual: 15)',\n    'p99_latency_ms > 1000 (actual: 5000)'\n  ],\n  action: 'Page on-call immediately. Start incident bridge. Notify stakeholders.',\n  timestamp: '2026-02-14T...'\n}"
            }
          ]
        },
        {
          "id": "netflix-lld",
          "title": "Netflix: Playback & Streaming",
          "category": "Company LLD",
          "description": "Low-level design of playback authorization, adaptive bitrate streaming, and segment delivery via CDN.",
          "explanation": "Netflix serves 200M+ subscribers streaming video across diverse devices and networks. The core playback path involves multiple subsystems working together to deliver seamless viewing.\n\nPlayback flow:\n1. User clicks play → Client sends playback request with device info, content ID, user token.\n2. Entitlement service validates subscription, geo-restrictions, device limits, and parental controls.\n3. Playback session is created with a signed, short-lived token bound to the device.\n4. Manifest builder generates an adaptive bitrate manifest (DASH/HLS) with URLs for each rendition (quality level).\n5. Client fetches video segments from the nearest CDN edge (Open Connect Appliance).\n6. ABR algorithm on the client selects the best rendition based on throughput and buffer level.\n\nAdaptive Bitrate (ABR) state machine:\n- Measures download throughput for each segment.\n- Monitors playback buffer level (seconds of video buffered).\n- If throughput drops or buffer is low → step down to lower bitrate.\n- If throughput is high and buffer is healthy → step up gradually.\n- Guardrails prevent rapid oscillation between quality levels.\n\nQuality of Experience (QoE) metrics:\n- Startup delay: Time from click to first frame.\n- Rebuffer ratio: % of playback time spent buffering.\n- Bitrate stability: Frequency of quality switches.\n- Playback failure rate: Sessions that fail to start or crash.\n\nCDN architecture: Netflix uses Open Connect — custom CDN appliances placed in ISP networks. Content is pre-positioned during off-peak hours. Cache miss goes to regional hub, then origin. This reduces internet backbone traffic by 95%.",
          "code": "// Playback session state machine\nclass PlaybackSession {\n  constructor(userId, contentId, deviceId) {\n    this.userId = userId;\n    this.contentId = contentId;\n    this.deviceId = deviceId;\n    this.state = 'INIT';\n    this.token = null;\n    this.startTime = Date.now();\n    this.transitions = [];\n  }\n\n  transition(newState) {\n    const allowed = {\n      'INIT': ['AUTHORIZED', 'DENIED'],\n      'AUTHORIZED': ['PLAYING', 'ERROR'],\n      'PLAYING': ['PAUSED', 'BUFFERING', 'ENDED', 'ERROR'],\n      'PAUSED': ['PLAYING', 'ENDED'],\n      'BUFFERING': ['PLAYING', 'ERROR'],\n      'DENIED': [],\n      'ENDED': [],\n      'ERROR': ['INIT'], // retry\n    };\n    if (!allowed[this.state]?.includes(newState)) {\n      throw new Error(`Invalid transition: ${this.state} → ${newState}`);\n    }\n    this.transitions.push({ from: this.state, to: newState, at: Date.now() });\n    this.state = newState;\n    return this.state;\n  }\n\n  authorize(token) {\n    this.token = token;\n    this.transition('AUTHORIZED');\n  }\n\n  getQoE() {\n    return {\n      startupDelayMs: this.transitions.find(t => t.to === 'PLAYING')?.at - this.startTime || null,\n      totalTransitions: this.transitions.length,\n      bufferingEvents: this.transitions.filter(t => t.to === 'BUFFERING').length,\n    };\n  }\n}\n\nconst session = new PlaybackSession('user1', 'movie123', 'device_tv');\nsession.authorize('token_abc');\nsession.transition('PLAYING');\nsession.transition('BUFFERING');\nsession.transition('PLAYING');\nsession.transition('ENDED');\nconsole.log('State:', session.state);\nconsole.log('QoE:', session.getQoE());",
          "example": "// ABR (Adaptive Bitrate) algorithm simulation\nclass ABRController {\n  constructor(renditions) {\n    this.renditions = renditions.sort((a, b) => a.bitrate - b.bitrate);\n    this.currentIndex = 0; // start lowest\n    this.history = [];\n  }\n\n  selectRendition(throughputKbps, bufferSeconds) {\n    let selected = 0;\n    // Find highest rendition that fits in 80% of throughput (safety margin)\n    for (let i = this.renditions.length - 1; i >= 0; i--) {\n      if (this.renditions[i].bitrate <= throughputKbps * 0.8) {\n        selected = i;\n        break;\n      }\n    }\n    // Buffer-based guardrail\n    if (bufferSeconds < 5) selected = Math.min(selected, this.currentIndex); // don't go up\n    if (bufferSeconds < 2) selected = Math.max(0, this.currentIndex - 1); // force step down\n    // Anti-oscillation: max 1 step up at a time\n    if (selected > this.currentIndex + 1) selected = this.currentIndex + 1;\n\n    this.currentIndex = selected;\n    this.history.push({ bitrate: this.renditions[selected].bitrate, buffer: bufferSeconds });\n    return this.renditions[selected];\n  }\n}\n\nconst abr = new ABRController([\n  { bitrate: 500, label: '360p' },\n  { bitrate: 1500, label: '720p' },\n  { bitrate: 4000, label: '1080p' },\n  { bitrate: 8000, label: '4K' },\n]);\nconsole.log(abr.selectRendition(6000, 10)); // 1080p\nconsole.log(abr.selectRendition(2000, 8));  // 720p\nconsole.log(abr.selectRendition(1000, 1));  // 360p (buffer critical)",
          "useCase": "Video streaming platforms, live streaming, any adaptive media delivery system.",
          "interviewQuestions": [
            {
              "question": "How do you reduce playback startup time?",
              "answer": "Precomputed manifests cached at edge, start with lowest bitrate for first segments, prefetch initial segments based on user behavior prediction, minimize control-plane round trips by batching auth + manifest in one call."
            },
            {
              "question": "How do you prevent token sharing or credential abuse?",
              "answer": "Short-lived signed tokens bound to device ID and IP range. Concurrent stream limits per account. Anomaly detection on viewing patterns (simultaneous streams from different geos). Device registration caps."
            },
            {
              "question": "What metrics define Quality of Experience (QoE)?",
              "answer": "Startup delay (time to first frame), rebuffer ratio (buffering time / total play time), bitrate stability (switches per minute), playback failure rate, and video quality score. These are tracked per session and aggregated per device type."
            },
            {
              "question": "How does adaptive bitrate streaming work?",
              "answer": "Client measures download throughput and buffer level per segment. ABR algorithm selects the best rendition: high throughput + full buffer = step up quality; low throughput or low buffer = step down. Guardrails prevent oscillation."
            },
            {
              "question": "How does Netflix handle CDN architecture?",
              "answer": "Open Connect: custom appliances placed inside ISP networks. Content pre-positioned during off-peak hours. Hierarchy: ISP appliance → regional hub → origin S3. 95% of traffic served from within the ISP network."
            },
            {
              "question": "What happens if the nearest CDN edge doesn't have the content?",
              "answer": "Cache miss cascades: edge → shield/regional hub → origin. Client is redirected to the next closest edge that has the content. Popular content is replicated proactively. Long-tail content may stream from origin with higher latency."
            },
            {
              "question": "How do you handle live streaming vs on-demand differently?",
              "answer": "Live: segments generated in real-time, no pre-positioning, ultra-low latency requirements, smaller segment duration (2-4s vs 6-10s). Manifest is dynamic (sliding window). CDN must handle thundering herd at segment boundaries."
            },
            {
              "question": "How do you design the entitlement check to be fast?",
              "answer": "Cache active subscription status in Redis with short TTL. Pre-compute content availability per region. Use a lightweight token claim check before hitting the entitlement service. Target: <20ms for entitlement validation."
            },
            {
              "question": "What is DRM and how does it integrate with playback?",
              "answer": "Digital Rights Management encrypts video content. Client obtains a license key during playback init. The key is tied to device and session. Common systems: Widevine (Android/Chrome), FairPlay (Apple), PlayReady (Microsoft). License server is in the critical playback path."
            },
            {
              "question": "How would you design A/B testing for the ABR algorithm?",
              "answer": "Assign users to experiment groups. Each group uses a different ABR policy. Measure QoE metrics per group (startup delay, rebuffer ratio, bitrate). Use statistical significance tests. Ensure balanced device/network distribution across groups."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design the ABR switching logic with guardrails against quality oscillation.",
              "answer": "Rules: 1) Max 1 step up per segment. 2) Require 3 consecutive high-throughput segments before stepping up. 3) Step down immediately on buffer < 3s. 4) Hysteresis: don't switch if throughput is within 20% of current rendition. 5) Minimum dwell time of 30s at a rendition."
            },
            {
              "type": "scenario",
              "question": "CDN edge miss spikes after a new release. Origin load increases 10x. What steps reduce origin overload?",
              "answer": "1) Pre-warm CDN edges with popular content before release. 2) Shield layer absorbs repeated origin fetches. 3) Rate limit origin pull requests. 4) Serve lower renditions first (smaller files, faster cache fill). 5) Stagger content availability by region."
            },
            {
              "type": "output",
              "question": "Given buffer=2s and throughput drop of 40% from 4Mbps to 2.4Mbps, current rendition is 1080p (4Mbps). What ABR action?",
              "answer": "2.4Mbps × 0.8 safety = 1.92Mbps < 4Mbps (1080p) AND buffer < 5s. Step down immediately to 720p (1.5Mbps). If buffer < 2s, may step down to 360p (500Kbps) to protect continuity."
            },
            {
              "type": "estimation",
              "question": "Netflix has 200M subscribers, 10% watching at peak. Average bitrate 5Mbps. Estimate peak bandwidth.",
              "answer": "Concurrent viewers: 200M × 0.1 = 20M. Bandwidth: 20M × 5Mbps = 100Tbps. With CDN serving 95% from edge: origin bandwidth = 5Tbps."
            },
            {
              "type": "debug",
              "question": "Users report increased buffering after a deployment. Playback failure rate is normal. What do you investigate?",
              "answer": "1) Check if ABR algorithm change is causing wrong rendition selection. 2) Check CDN cache hit rates (did deployment bust caches?). 3) Check segment generation latency. 4) Check if manifest URLs changed. 5) Check client-side bugs in buffer management."
            },
            {
              "type": "design",
              "question": "Design a concurrent stream limiter that allows max 4 simultaneous streams per account.",
              "answer": "Redis sorted set per account_id. Key: ZSET(account:streams). Members: session_id with score=timestamp. On play: ZADD + ZCARD. If ZCARD > 4, reject. On stop/timeout: ZREM. Expire stale sessions with periodic cleanup (score < now - 30min)."
            },
            {
              "type": "tricky",
              "question": "How do you handle network switches (WiFi→cellular) during playback without interruption?",
              "answer": "Client detects network change, re-evaluates throughput (start conservative), ABR drops to lower bitrate temporarily, buffer absorbs the transition. Maintain session continuity — don't re-authenticate. Resume from current playback position."
            },
            {
              "type": "scenario",
              "question": "A popular show launches globally at midnight. How do you prepare the infrastructure?",
              "answer": "1) Pre-encode all renditions + languages in advance. 2) Pre-warm CDN edges in all regions. 3) Scale entitlement and session services 3x. 4) Enable circuit breakers on non-critical services. 5) War room with real-time QoE dashboards."
            },
            {
              "type": "estimation",
              "question": "A 2-hour movie at 4K (15Mbps) — how much storage per movie for 5 renditions?",
              "answer": "4K: 15Mbps × 7200s / 8 = 13.5GB. 1080p: ~4.5GB. 720p: ~1.35GB. 480p: ~0.675GB. 360p: ~0.45GB. Total: ~20.4GB per movie. 10,000 titles = ~204TB."
            },
            {
              "type": "design",
              "question": "Design the telemetry pipeline for collecting playback QoE events.",
              "answer": "Client sends heartbeat events every 30s + on state changes. Events: {session_id, bitrate, buffer_level, rebuffer_count, device_type}. Pipeline: Client → API Gateway → Kafka → Flink (real-time aggregation) → S3 (raw) + Druid (dashboards). Alert on p99 rebuffer ratio > 2%."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Playback state machine with transition validation",
              "code": "class PlaybackFSM {\n  constructor() {\n    this.state = 'INIT';\n    this.allowed = {\n      INIT: ['AUTHORIZED', 'DENIED'],\n      AUTHORIZED: ['PLAYING', 'ERROR'],\n      PLAYING: ['PAUSED', 'BUFFERING', 'ENDED', 'ERROR'],\n      PAUSED: ['PLAYING', 'ENDED'],\n      BUFFERING: ['PLAYING', 'ERROR'],\n      DENIED: [],\n      ENDED: [],\n      ERROR: ['INIT'],\n    };\n    this.log = [];\n  }\n  transition(to) {\n    if (!this.allowed[this.state]?.includes(to)) {\n      this.log.push(`REJECTED: ${this.state} → ${to}`);\n      return false;\n    }\n    this.log.push(`${this.state} → ${to}`);\n    this.state = to;\n    return true;\n  }\n}\n\nconst fsm = new PlaybackFSM();\nfsm.transition('AUTHORIZED');\nfsm.transition('PLAYING');\nfsm.transition('BUFFERING');\nfsm.transition('PLAYING');\nfsm.transition('ENDED');\nfsm.transition('PLAYING'); // invalid\nconsole.log(fsm.log);",
              "output": "[\n  'INIT → AUTHORIZED',\n  'AUTHORIZED → PLAYING',\n  'PLAYING → BUFFERING',\n  'BUFFERING → PLAYING',\n  'PLAYING → ENDED',\n  'REJECTED: ENDED → PLAYING'\n]"
            },
            {
              "question": "Program 2: ABR rendition selector",
              "code": "function selectRendition(renditions, throughputKbps, bufferSec) {\n  const sorted = [...renditions].sort((a, b) => b.bitrate - a.bitrate);\n  const safe = throughputKbps * 0.8;\n  for (const r of sorted) {\n    if (r.bitrate <= safe) {\n      if (bufferSec < 3 && r.bitrate > 1000) continue;\n      return r;\n    }\n  }\n  return sorted[sorted.length - 1];\n}\n\nconst renditions = [\n  { label: '360p', bitrate: 500 },\n  { label: '720p', bitrate: 1500 },\n  { label: '1080p', bitrate: 4000 },\n  { label: '4K', bitrate: 8000 },\n];\nconsole.log(selectRendition(renditions, 6000, 15)); // 1080p\nconsole.log(selectRendition(renditions, 2000, 10)); // 720p\nconsole.log(selectRendition(renditions, 3000, 2));  // 360p (low buffer)",
              "output": "{ label: '1080p', bitrate: 4000 }\n{ label: '720p', bitrate: 1500 }\n{ label: '360p', bitrate: 500 }"
            },
            {
              "question": "Program 3: Concurrent stream limiter",
              "code": "class StreamLimiter {\n  constructor(maxStreams) {\n    this.maxStreams = maxStreams;\n    this.accounts = new Map();\n  }\n  startStream(accountId, sessionId) {\n    if (!this.accounts.has(accountId)) this.accounts.set(accountId, new Set());\n    const sessions = this.accounts.get(accountId);\n    if (sessions.size >= this.maxStreams) {\n      return { allowed: false, active: sessions.size, message: `Max ${this.maxStreams} streams reached` };\n    }\n    sessions.add(sessionId);\n    return { allowed: true, active: sessions.size };\n  }\n  stopStream(accountId, sessionId) {\n    this.accounts.get(accountId)?.delete(sessionId);\n  }\n}\n\nconst limiter = new StreamLimiter(2);\nconsole.log(limiter.startStream('acc1', 'tv'));\nconsole.log(limiter.startStream('acc1', 'phone'));\nconsole.log(limiter.startStream('acc1', 'tablet')); // rejected\nlimiter.stopStream('acc1', 'tv');\nconsole.log(limiter.startStream('acc1', 'tablet')); // now OK",
              "output": "{ allowed: true, active: 1 }\n{ allowed: true, active: 2 }\n{ allowed: false, active: 2, message: 'Max 2 streams reached' }\n{ allowed: true, active: 2 }"
            },
            {
              "question": "Program 4: CDN edge cache simulator",
              "code": "class CDNEdge {\n  constructor(name, capacity) {\n    this.name = name;\n    this.cache = new Map();\n    this.capacity = capacity;\n    this.hits = 0;\n    this.misses = 0;\n  }\n  get(contentId) {\n    if (this.cache.has(contentId)) {\n      this.hits++;\n      return { source: this.name, hit: true };\n    }\n    this.misses++;\n    return { source: this.name, hit: false };\n  }\n  store(contentId) {\n    if (this.cache.size >= this.capacity) {\n      const oldest = this.cache.keys().next().value;\n      this.cache.delete(oldest);\n    }\n    this.cache.set(contentId, true);\n  }\n  stats() {\n    const total = this.hits + this.misses;\n    return { name: this.name, hitRate: total ? (this.hits/total*100).toFixed(1)+'%' : 'N/A', size: this.cache.size };\n  }\n}\n\nconst edge = new CDNEdge('us-east-1', 3);\nedge.store('movie-1'); edge.store('movie-2');\nconsole.log(edge.get('movie-1')); // hit\nconsole.log(edge.get('movie-3')); // miss\nedge.store('movie-3');\nconsole.log(edge.get('movie-3')); // hit\nconsole.log(edge.stats());",
              "output": "{ source: 'us-east-1', hit: true }\n{ source: 'us-east-1', hit: false }\n{ source: 'us-east-1', hit: true }\n{ name: 'us-east-1', hitRate: '66.7%', size: 3 }"
            },
            {
              "question": "Program 5: QoE metrics aggregator",
              "code": "function aggregateQoE(sessions) {\n  const metrics = {\n    avgStartupMs: 0, avgRebufferRatio: 0,\n    avgBitrate: 0, failureRate: 0,\n  };\n  const valid = sessions.filter(s => s.state !== 'FAILED');\n  const failed = sessions.filter(s => s.state === 'FAILED');\n  metrics.failureRate = (failed.length / sessions.length * 100).toFixed(2) + '%';\n  metrics.avgStartupMs = Math.round(valid.reduce((s, v) => s + v.startupMs, 0) / valid.length);\n  metrics.avgRebufferRatio = (valid.reduce((s, v) => s + v.rebufferRatio, 0) / valid.length * 100).toFixed(2) + '%';\n  metrics.avgBitrate = Math.round(valid.reduce((s, v) => s + v.avgBitrate, 0) / valid.length);\n  return metrics;\n}\n\nconsole.log(aggregateQoE([\n  { state: 'ENDED', startupMs: 1200, rebufferRatio: 0.01, avgBitrate: 4000 },\n  { state: 'ENDED', startupMs: 800, rebufferRatio: 0.005, avgBitrate: 6000 },\n  { state: 'ENDED', startupMs: 2000, rebufferRatio: 0.03, avgBitrate: 1500 },\n  { state: 'FAILED', startupMs: 0, rebufferRatio: 0, avgBitrate: 0 },\n]));",
              "output": "{\n  avgStartupMs: 1333,\n  avgRebufferRatio: '1.50%',\n  avgBitrate: 3833,\n  failureRate: '25.00%'\n}"
            },
            {
              "question": "Program 6: Manifest builder",
              "code": "function buildManifest(contentId, renditions, segmentDuration, totalDuration) {\n  const segments = Math.ceil(totalDuration / segmentDuration);\n  return {\n    contentId,\n    duration: totalDuration,\n    segmentDuration,\n    renditions: renditions.map(r => ({\n      ...r,\n      segments: Array.from({ length: segments }, (_, i) => ({\n        index: i,\n        url: `/cdn/${contentId}/${r.label}/seg-${i}.m4s`,\n        startTime: i * segmentDuration,\n      })),\n    })),\n  };\n}\n\nconst manifest = buildManifest('movie-42', [\n  { label: '720p', bitrate: 1500 },\n  { label: '1080p', bitrate: 4000 },\n], 6, 18);\nconsole.log(JSON.stringify(manifest.renditions[0].segments, null, 2));",
              "output": "[\n  { \"index\": 0, \"url\": \"/cdn/movie-42/720p/seg-0.m4s\", \"startTime\": 0 },\n  { \"index\": 1, \"url\": \"/cdn/movie-42/720p/seg-1.m4s\", \"startTime\": 6 },\n  { \"index\": 2, \"url\": \"/cdn/movie-42/720p/seg-2.m4s\", \"startTime\": 12 }\n]"
            },
            {
              "question": "Program 7: Entitlement checker",
              "code": "function checkEntitlement(user, content) {\n  const checks = [\n    { name: 'subscription', pass: user.plan !== 'expired' },\n    { name: 'geo', pass: content.availableRegions.includes(user.region) },\n    { name: 'maturity', pass: user.age >= content.minAge },\n    { name: 'deviceLimit', pass: user.activeDevices < user.maxDevices },\n  ];\n  const failed = checks.filter(c => !c.pass);\n  return {\n    allowed: failed.length === 0,\n    checks: checks.map(c => `${c.pass ? '✅' : '❌'} ${c.name}`),\n    reason: failed.length ? `Blocked: ${failed.map(f => f.name).join(', ')}` : 'All checks passed',\n  };\n}\n\nconsole.log(checkEntitlement(\n  { plan: 'premium', region: 'US', age: 25, activeDevices: 2, maxDevices: 4 },\n  { availableRegions: ['US', 'UK', 'IN'], minAge: 18 }\n));\nconsole.log(checkEntitlement(\n  { plan: 'expired', region: 'CN', age: 15, activeDevices: 5, maxDevices: 4 },\n  { availableRegions: ['US', 'UK'], minAge: 18 }\n));",
              "output": "{ allowed: true, checks: ['✅ subscription', '✅ geo', '✅ maturity', '✅ deviceLimit'], reason: 'All checks passed' }\n{ allowed: false, checks: ['❌ subscription', '❌ geo', '❌ maturity', '❌ deviceLimit'], reason: 'Blocked: subscription, geo, maturity, deviceLimit' }"
            },
            {
              "question": "Program 8: Buffer health monitor",
              "code": "function monitorBuffer(events) {\n  let buffer = 0;\n  const log = [];\n  events.forEach(e => {\n    if (e.type === 'segment_loaded') buffer += e.segmentDuration;\n    if (e.type === 'playback_tick') buffer -= e.elapsed;\n    let status = 'healthy';\n    if (buffer < 2) status = 'critical';\n    else if (buffer < 5) status = 'warning';\n    log.push({ time: e.time, buffer: buffer.toFixed(1) + 's', status });\n  });\n  return log;\n}\n\nconsole.log(monitorBuffer([\n  { time: '0s', type: 'segment_loaded', segmentDuration: 6 },\n  { time: '2s', type: 'playback_tick', elapsed: 2 },\n  { time: '4s', type: 'playback_tick', elapsed: 2 },\n  { time: '5s', type: 'segment_loaded', segmentDuration: 6 },\n  { time: '8s', type: 'playback_tick', elapsed: 3 },\n  { time: '12s', type: 'playback_tick', elapsed: 4 },\n  { time: '14s', type: 'playback_tick', elapsed: 2 },\n]));",
              "output": "[\n  { time: '0s', buffer: '6.0s', status: 'healthy' },\n  { time: '2s', buffer: '4.0s', status: 'warning' },\n  { time: '4s', buffer: '2.0s', status: 'warning' },\n  { time: '5s', buffer: '8.0s', status: 'healthy' },\n  { time: '8s', buffer: '5.0s', status: 'healthy' },\n  { time: '12s', buffer: '1.0s', status: 'critical' },\n  { time: '14s', buffer: '-1.0s', status: 'critical' }\n]"
            },
            {
              "question": "Program 9: Content pre-warming scheduler",
              "code": "function schedulePrewarm(releases, cdnEdges, hoursBeforeLaunch) {\n  const schedule = [];\n  releases.forEach(release => {\n    const warmStart = new Date(release.launchTime - hoursBeforeLaunch * 3600 * 1000);\n    const topEdges = cdnEdges\n      .sort((a, b) => b.subscribersInRegion - a.subscribersInRegion)\n      .slice(0, 5);\n    topEdges.forEach(edge => {\n      schedule.push({\n        content: release.title,\n        edge: edge.name,\n        warmAt: warmStart.toISOString(),\n        priority: release.expectedViewers > 1000000 ? 'HIGH' : 'NORMAL',\n      });\n    });\n  });\n  return schedule;\n}\n\nconst result = schedulePrewarm(\n  [{ title: 'New Movie', launchTime: Date.now() + 86400000, expectedViewers: 5000000 }],\n  [\n    { name: 'edge-us-east', subscribersInRegion: 2000000 },\n    { name: 'edge-eu-west', subscribersInRegion: 1500000 },\n    { name: 'edge-ap-south', subscribersInRegion: 800000 },\n  ],\n  6\n);\nconsole.log(result.length, 'warm jobs,', 'priority:', result[0].priority);",
              "output": "3 warm jobs, priority: HIGH"
            },
            {
              "question": "Program 10: Session token generator and validator",
              "code": "const crypto = require('crypto');\n\nclass SessionTokenService {\n  constructor(secret) { this.secret = secret; }\n  \n  generate(userId, deviceId, ttlSeconds) {\n    const payload = { userId, deviceId, exp: Date.now() + ttlSeconds * 1000 };\n    const data = JSON.stringify(payload);\n    const sig = crypto.createHmac('sha256', this.secret).update(data).digest('hex').slice(0, 16);\n    return Buffer.from(data).toString('base64') + '.' + sig;\n  }\n  \n  validate(token) {\n    const [dataB64, sig] = token.split('.');\n    const data = Buffer.from(dataB64, 'base64').toString();\n    const expectedSig = crypto.createHmac('sha256', this.secret).update(data).digest('hex').slice(0, 16);\n    if (sig !== expectedSig) return { valid: false, reason: 'Invalid signature' };\n    const payload = JSON.parse(data);\n    if (payload.exp < Date.now()) return { valid: false, reason: 'Token expired' };\n    return { valid: true, userId: payload.userId, deviceId: payload.deviceId };\n  }\n}\n\nconst svc = new SessionTokenService('my-secret-key');\nconst token = svc.generate('user1', 'tv-123', 3600);\nconsole.log('Token:', token.slice(0, 30) + '...');\nconsole.log('Valid:', svc.validate(token));",
              "output": "Token: eyJ1c2VySWQiOiJ1c2VyMSIsI...\nValid: { valid: true, userId: 'user1', deviceId: 'tv-123' }"
            }
          ]
        },
        {
          "id": "facebook-feed-lld",
          "title": "Facebook News Feed",
          "category": "Company LLD",
          "description": "Low-level design of Facebook's News Feed — ranking, fanout, real-time updates, and feed assembly pipeline.",
          "explanation": "Facebook News Feed serves 2B+ users, each seeing a personalized stream of posts from friends, pages, groups, and ads. The core challenge: selecting and ranking ~1500 candidate stories into ~300 shown stories, all within 200ms.\n\nFeed generation approaches:\n1. **Fanout on Write (Push)**: When a user publishes a post, push it into all followers' feed caches. Fast reads but expensive writes for users with millions of followers (celebrity problem). Used for most users.\n2. **Fanout on Read (Pull)**: When a user opens their feed, query all friends' timelines and merge/rank on the fly. Expensive reads but handles celebrities efficiently. Used for high-follower accounts.\n3. **Hybrid**: Push for normal users, pull for celebrities. Facebook and Twitter both use hybrid approaches.\n\nRanking pipeline:\n1. **Candidate generation**: Collect posts from friends, pages, groups (last 7 days). ~1500 candidates.\n2. **Feature extraction**: Engagement signals (likes, comments, shares), recency, relationship strength (interaction frequency), content type, creator quality score.\n3. **Scoring**: ML model (originally EdgeRank: Affinity × Weight × Decay) assigns relevance score. Modern: deep learning models.\n4. **Filtering**: Remove duplicates, content policy violations, user-hidden content.\n5. **Diversity injection**: Ensure mix of content types (not all videos, not all from same friend).\n6. **Pagination**: Return top ~50 stories per page, cursor-based pagination for infinite scroll.\n\nReal-time updates:\n- Long polling or WebSocket connection. Server pushes new story IDs. Client fetches story details and inserts into feed. Priority-based: comments on your post > friend's new post > page update.\n\nStorage:\n- Post table: post_id, author_id, content, created_at, type.\n- Feed cache: Redis sorted set per user. Score = ranking score. Member = post_id.\n- Social graph: adjacency list in memory (who follows whom).",
          "code": "// Feed assembly pipeline\nclass FeedService {\n  constructor() {\n    this.feedCache = new Map(); // userId -> sorted posts\n    this.posts = new Map();\n    this.graph = new Map(); // userId -> Set of followedIds\n  }\n\n  follow(userId, targetId) {\n    if (!this.graph.has(userId)) this.graph.set(userId, new Set());\n    this.graph.get(userId).add(targetId);\n  }\n\n  publish(authorId, post) {\n    const entry = { id: post.id, authorId, content: post.content, type: post.type, createdAt: Date.now(), likes: 0, comments: 0 };\n    this.posts.set(post.id, entry);\n    // Fanout on write for normal users\n    this.fanoutWrite(authorId, entry);\n    return entry;\n  }\n\n  fanoutWrite(authorId, entry) {\n    // Push to all followers' caches\n    for (const [userId, following] of this.graph) {\n      if (following.has(authorId)) {\n        if (!this.feedCache.has(userId)) this.feedCache.set(userId, []);\n        this.feedCache.get(userId).push(entry);\n      }\n    }\n  }\n\n  getFeed(userId, limit = 10) {\n    const cached = this.feedCache.get(userId) || [];\n    // Rank and return top entries\n    const ranked = cached\n      .map(post => ({ ...post, score: this.rank(userId, post) }))\n      .sort((a, b) => b.score - a.score)\n      .slice(0, limit);\n    return ranked;\n  }\n\n  rank(userId, post) {\n    const recency = 1 / (1 + (Date.now() - post.createdAt) / 3600000); // decay over hours\n    const engagement = post.likes * 1.0 + post.comments * 2.0;\n    const typeWeight = { text: 1, image: 1.2, video: 1.5, link: 0.8 };\n    return recency * 10 + engagement + (typeWeight[post.type] || 1);\n  }\n}\n\nconst feed = new FeedService();\nfeed.follow('alice', 'bob');\nfeed.follow('alice', 'carol');\n\nconst p1 = feed.publish('bob', { id: 'p1', content: 'Hello World!', type: 'text' });\nconst p2 = feed.publish('carol', { id: 'p2', content: 'Check this video', type: 'video' });\np2.likes = 10;\n\nconst aliceFeed = feed.getFeed('alice');\nconsole.log(aliceFeed.map(p => ({ content: p.content, score: p.score.toFixed(2) })));",
          "example": "// EdgeRank scoring simulation\nfunction edgeRank(affinity, weight, timeSinceHours) {\n  // Original EdgeRank formula: Score = Affinity × Weight × Decay\n  const decay = 1 / (1 + timeSinceHours);\n  return affinity * weight * decay;\n}\n\n// Calculate scores for candidate stories\nconst candidates = [\n  { post: 'Best friend photo',    affinity: 0.9, weight: 1.2, hoursSince: 1 },\n  { post: 'Page video',           affinity: 0.3, weight: 1.5, hoursSince: 0.5 },\n  { post: 'Acquaintance text',    affinity: 0.2, weight: 1.0, hoursSince: 2 },\n  { post: 'Close friend comment', affinity: 0.8, weight: 2.0, hoursSince: 3 },\n  { post: 'Old post reshared',    affinity: 0.5, weight: 0.8, hoursSince: 48 },\n];\n\nconst ranked = candidates\n  .map(c => ({ post: c.post, score: edgeRank(c.affinity, c.weight, c.hoursSince) }))\n  .sort((a, b) => b.score - a.score);\n\nconsole.log('Feed ranking:');\nranked.forEach((r, i) => console.log(`${i+1}. ${r.post} (score: ${r.score.toFixed(3)})`));",
          "useCase": "Social media feeds, personalized content streams, recommendation systems, timeline aggregation.",
          "interviewQuestions": [
            {
              "question": "Why does Facebook use a hybrid fanout strategy?",
              "answer": "Pure push (fanout-on-write) is expensive for celebrities with millions of followers — one post triggers millions of cache writes. Pure pull (fanout-on-read) makes feed loading slow — must query hundreds of friends' timelines and merge. Hybrid: push for regular users (fast reads), pull for celebrities (avoid write amplification)."
            },
            {
              "question": "How is the social graph stored and queried efficiently?",
              "answer": "In-memory adjacency list partitioned by user ID range. Each partition fits in a server's RAM. TAO (The Associations and Objects) system at Facebook caches graph edges with association lists. Queries like 'friends of user X' are single-hop lookups."
            },
            {
              "question": "How do you ensure feed freshness for active users?",
              "answer": "Long-poll or WebSocket connection. Server maintains a per-user notification channel. When a relevant post is published (fanout), push the post ID to the channel. Client fetches the full post and inserts it at the top or shows a 'new posts' indicator."
            },
            {
              "question": "How do you handle feed ranking at scale?",
              "answer": "Two-phase: lightweight candidate selection (SQL/cache lookup) narrows 1500 to ~500 candidates, then ML model scores each with features (affinity, engagement, recency, content type). Top 50 returned. Model is pre-computed for latency, retrained hourly."
            },
            {
              "question": "What is the celebrity problem in feed systems?",
              "answer": "A user with 10M followers publishes a post. Fanout-on-write means 10M cache writes. Solution: don't fanout for celebrities. When a follower opens their feed, pull the celebrity's latest posts on demand and merge into the pre-computed feed."
            },
            {
              "question": "How do you implement infinite scroll pagination?",
              "answer": "Cursor-based pagination: return a cursor (timestamp + post_id) with each response. Next request includes cursor. Server fetches posts with score < cursor. Avoids offset-based pagination problems (duplicates when new posts arrive)."
            },
            {
              "question": "How do you prevent duplicate stories in the feed?",
              "answer": "Deduplication at multiple levels: 1) Feed cache uses post_id as unique key. 2) Content fingerprinting detects reshares of the same content. 3) Client-side dedup merges server responses with already-displayed stories."
            },
            {
              "question": "How do you inject diversity into the feed?",
              "answer": "After ranking, apply diversity rules: max 2 consecutive posts from same author, max 3 videos in a row, ensure at least 1 friend post per 5 stories. Re-rank with diversity constraints using a greedy interleaving algorithm."
            },
            {
              "question": "How do you handle feed for a brand new user with no connections?",
              "answer": "Cold start: show trending content, popular pages in user's region, suggested friend activity. Use signup signals (interests, imported contacts) to bootstrap recommendations. Gradually transition to personalized feed as social graph grows."
            },
            {
              "question": "How do you A/B test feed algorithm changes?",
              "answer": "Assign users to experiment groups. Each group gets a different ranking model. Measure engagement metrics (time spent, clicks, likes, hides) per group. Use holdback groups and guard against network effects (treat friend clusters as units)."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design the fanout service that distributes posts to follower feeds.",
              "answer": "Publish event → Kafka topic. Fanout workers consume in parallel. For each post, look up author's follower list from social graph service. For each follower, ZADD to their Redis sorted set (feed cache) with ranking score. Skip fanout if author has > 100K followers (celebrity path). TTL on feed cache entries: 7 days."
            },
            {
              "type": "estimation",
              "question": "1B daily active users, average 300 posts in feed per day, average post size 1KB. Estimate daily storage for feed caches.",
              "answer": "Feed cache entries: 1B × 300 = 300B entries. Each entry: post_id (8B) + score (8B) = 16B. Total: 300B × 16B = 4.8TB for feed metadata. Post content stored separately: 300B unique posts × 1KB = 300TB. With replication: ~1PB."
            },
            {
              "type": "scenario",
              "question": "A viral post gets 1M shares in 10 minutes. How do you prevent system overload?",
              "answer": "1) Rate limit fanout workers per post. 2) Batch fanout operations. 3) For viral posts, switch to pull model (don't fanout, let users pull on demand). 4) Circuit breaker on write path. 5) Debounce engagement count updates (batch increments)."
            },
            {
              "type": "tricky",
              "question": "Why not just sort feed by timestamp (reverse chronological)?",
              "answer": "Users miss important content (close friend's wedding post buried under acquaintance's 20 check-ins). Engagement drops 30-40% without ranking. Users spend less time. Ranked feed surfaces high-quality, high-affinity content. But: provide 'Most Recent' as an option for user control."
            },
            {
              "type": "debug",
              "question": "Users report seeing the same post multiple times in their feed. What are possible causes?",
              "answer": "1) Fanout executed twice (idempotency failure). 2) Multiple reshares not deduplicated. 3) Cursor-based pagination returning overlapping windows. 4) Client cache not properly deduplicating. Fix: use post_id as dedup key; make fanout idempotent; fix cursor logic."
            },
            {
              "type": "design",
              "question": "Design the ranking feature extraction pipeline.",
              "answer": "Features: 1) User-author affinity (interaction count in last 30 days). 2) Post engagement (likes/comments/shares velocity). 3) Content type score. 4) Recency decay. 5) Author quality score. Pipeline: Precompute affinity scores daily (batch). Real-time features (engagement) from streaming counters. Feature vector assembled at query time. Cached per user for 5 minutes."
            },
            {
              "type": "output",
              "question": "EdgeRank: Affinity=0.8, Weight=1.5 (photo), Time=2 hours. Decay formula: 1/(1+hours). What is the score?",
              "answer": "Decay = 1/(1+2) = 0.333. Score = 0.8 × 1.5 × 0.333 = 0.4. Compare: same post at 0.5 hours: Decay = 1/1.5 = 0.667, Score = 0.8 × 1.5 × 0.667 = 0.8. The score halved in 1.5 hours."
            },
            {
              "type": "scenario",
              "question": "You need to deprecate the old ranking algorithm and roll out a new ML model. How do you do it safely?",
              "answer": "1) Shadow mode: run new model in parallel, log scores but don't serve. 2) Compare ranking quality offline. 3) 1% canary with real users. 4) Monitor engagement metrics (time spent, hides, unfollows). 5) Gradual rollout: 1% → 10% → 50% → 100%. 6) Keep rollback ready."
            },
            {
              "type": "estimation",
              "question": "A user has 500 friends, follows 100 pages. Average posts per entity per day: friends=2, pages=10. How many candidates per feed load?",
              "answer": "Friend posts/day: 500 × 2 = 1000. Page posts/day: 100 × 10 = 1000. Total candidates: 2000. With 7-day window: 14,000 candidates. After initial filtering (dedup, blocked): ~10,000. Ranking narrows to top 300."
            },
            {
              "type": "design",
              "question": "Design the real-time feed update system.",
              "answer": "WebSocket gateway maintains persistent connections. On new post fanout, publish event to user's channel in Redis Pub/Sub. Gateway forwards to client. Client inserts story at appropriate position. Throttle: max 1 push per 30 seconds per user. For inactive clients, batch updates and deliver on next app open."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Feed assembly with fanout-on-write",
              "code": "class FeedCache {\n  constructor() { this.feeds = new Map(); }\n  addToFeed(userId, postId, score) {\n    if (!this.feeds.has(userId)) this.feeds.set(userId, []);\n    this.feeds.get(userId).push({ postId, score });\n    this.feeds.get(userId).sort((a, b) => b.score - a.score);\n  }\n  getFeed(userId, limit = 5) {\n    return (this.feeds.get(userId) || []).slice(0, limit);\n  }\n}\n\nclass SocialGraph {\n  constructor() { this.followers = new Map(); }\n  follow(follower, followed) {\n    if (!this.followers.has(followed)) this.followers.set(followed, []);\n    this.followers.get(followed).push(follower);\n  }\n  getFollowers(userId) { return this.followers.get(userId) || []; }\n}\n\nconst graph = new SocialGraph();\nconst cache = new FeedCache();\ngraph.follow('alice', 'bob');\ngraph.follow('charlie', 'bob');\ngraph.follow('alice', 'dave');\n\nfunction publish(authorId, postId, score) {\n  graph.getFollowers(authorId).forEach(f => cache.addToFeed(f, postId, score));\n}\n\npublish('bob', 'post1', 8.5);\npublish('bob', 'post2', 6.2);\npublish('dave', 'post3', 9.1);\n\nconsole.log('Alice feed:', cache.getFeed('alice'));\nconsole.log('Charlie feed:', cache.getFeed('charlie'));",
              "output": "Alice feed: [\n  { postId: 'post3', score: 9.1 },\n  { postId: 'post1', score: 8.5 },\n  { postId: 'post2', score: 6.2 }\n]\nCharlie feed: [\n  { postId: 'post1', score: 8.5 },\n  { postId: 'post2', score: 6.2 }\n]"
            },
            {
              "question": "Program 2: EdgeRank scoring engine",
              "code": "function edgeRank(affinity, weight, hoursSince) {\n  return affinity * weight * (1 / (1 + hoursSince));\n}\n\nfunction rankFeed(userId, interactions, posts) {\n  return posts.map(post => {\n    const affinity = interactions[`${userId}:${post.author}`] || 0.1;\n    const weight = { text: 1.0, image: 1.2, video: 1.5, link: 0.8 }[post.type] || 1.0;\n    const hours = (Date.now() - post.timestamp) / 3600000;\n    return { ...post, score: edgeRank(affinity, weight, hours) };\n  }).sort((a, b) => b.score - a.score);\n}\n\nconst now = Date.now();\nconst interactions = { 'alice:bob': 0.9, 'alice:carol': 0.3, 'alice:dave': 0.6 };\nconst posts = [\n  { id: 1, author: 'bob', type: 'image', text: 'Sunset', timestamp: now - 3600000 },\n  { id: 2, author: 'carol', type: 'video', text: 'Tutorial', timestamp: now - 1800000 },\n  { id: 3, author: 'dave', type: 'text', text: 'Hello!', timestamp: now - 7200000 },\n];\n\nconst ranked = rankFeed('alice', interactions, posts);\nranked.forEach((p, i) => console.log(`${i+1}. [${p.author}] ${p.text} (${p.score.toFixed(3)})`));",
              "output": "1. [bob] Sunset (0.540)\n2. [carol] Tutorial (0.300)\n3. [dave] Hello! (0.200)"
            },
            {
              "question": "Program 3: Feed diversity enforcer",
              "code": "function enforceDiversity(rankedPosts, rules) {\n  const result = [];\n  const authorCount = {};\n  const typeCount = {};\n  \n  for (const post of rankedPosts) {\n    const aCount = authorCount[post.author] || 0;\n    const tCount = typeCount[post.type] || 0;\n    if (aCount >= rules.maxPerAuthor) continue;\n    if (tCount >= rules.maxConsecutiveType && result.length > 0 && result[result.length-1].type === post.type) continue;\n    result.push(post);\n    authorCount[post.author] = aCount + 1;\n    typeCount[post.type] = tCount + 1;\n    if (result.length >= rules.feedSize) break;\n  }\n  return result;\n}\n\nconst posts = [\n  { id: 1, author: 'bob', type: 'video', score: 9 },\n  { id: 2, author: 'bob', type: 'video', score: 8.5 },\n  { id: 3, author: 'bob', type: 'image', score: 8 },\n  { id: 4, author: 'alice', type: 'video', score: 7.5 },\n  { id: 5, author: 'carol', type: 'text', score: 7 },\n  { id: 6, author: 'dave', type: 'image', score: 6.5 },\n];\n\nconst diverseFeed = enforceDiversity(posts, { maxPerAuthor: 2, maxConsecutiveType: 2, feedSize: 4 });\nconsole.log(diverseFeed.map(p => `${p.author}:${p.type}(${p.score})`));",
              "output": "[ 'bob:video(9)', 'bob:video(8.5)', 'alice:video(7.5)', 'carol:text(7)' ]"
            },
            {
              "question": "Program 4: Cursor-based pagination",
              "code": "class PaginatedFeed {\n  constructor(posts) {\n    this.posts = posts.sort((a, b) => b.score - a.score);\n  }\n  \n  getPage(cursor, pageSize) {\n    let startIndex = 0;\n    if (cursor) {\n      startIndex = this.posts.findIndex(p => p.id === cursor.afterId) + 1;\n    }\n    const items = this.posts.slice(startIndex, startIndex + pageSize);\n    const hasMore = startIndex + pageSize < this.posts.length;\n    const nextCursor = hasMore ? { afterId: items[items.length - 1].id } : null;\n    return { items, nextCursor, hasMore };\n  }\n}\n\nconst feed = new PaginatedFeed([\n  { id: 'a', title: 'Post A', score: 10 },\n  { id: 'b', title: 'Post B', score: 9 },\n  { id: 'c', title: 'Post C', score: 8 },\n  { id: 'd', title: 'Post D', score: 7 },\n  { id: 'e', title: 'Post E', score: 6 },\n]);\n\nconst page1 = feed.getPage(null, 2);\nconsole.log('Page 1:', page1.items.map(p => p.title), 'hasMore:', page1.hasMore);\nconst page2 = feed.getPage(page1.nextCursor, 2);\nconsole.log('Page 2:', page2.items.map(p => p.title), 'hasMore:', page2.hasMore);\nconst page3 = feed.getPage(page2.nextCursor, 2);\nconsole.log('Page 3:', page3.items.map(p => p.title), 'hasMore:', page3.hasMore);",
              "output": "Page 1: [ 'Post A', 'Post B' ] hasMore: true\nPage 2: [ 'Post C', 'Post D' ] hasMore: true\nPage 3: [ 'Post E' ] hasMore: false"
            },
            {
              "question": "Program 5: Affinity score calculator",
              "code": "function calculateAffinity(interactions) {\n  const weights = { like: 1, comment: 3, share: 5, message: 8, tag: 4 };\n  const affinityMap = {};\n  \n  interactions.forEach(({ user, target, type, daysAgo }) => {\n    const key = `${user}:${target}`;\n    const decay = Math.exp(-daysAgo / 30); // exponential decay over 30 days\n    const score = (weights[type] || 1) * decay;\n    affinityMap[key] = (affinityMap[key] || 0) + score;\n  });\n  \n  // Normalize to 0-1 range\n  const maxScore = Math.max(...Object.values(affinityMap));\n  Object.keys(affinityMap).forEach(k => {\n    affinityMap[k] = +(affinityMap[k] / maxScore).toFixed(3);\n  });\n  return affinityMap;\n}\n\nconst affinity = calculateAffinity([\n  { user: 'alice', target: 'bob', type: 'like', daysAgo: 1 },\n  { user: 'alice', target: 'bob', type: 'comment', daysAgo: 2 },\n  { user: 'alice', target: 'bob', type: 'message', daysAgo: 5 },\n  { user: 'alice', target: 'carol', type: 'like', daysAgo: 15 },\n  { user: 'alice', target: 'carol', type: 'like', daysAgo: 30 },\n]);\nconsole.log(affinity);",
              "output": "{ 'alice:bob': 1, 'alice:carol': 0.079 }"
            },
            {
              "question": "Program 6: Celebrity fanout handler",
              "code": "class HybridFanout {\n  constructor(celebrityThreshold) {\n    this.threshold = celebrityThreshold;\n    this.followers = new Map();\n    this.feedCache = new Map();\n    this.celebrityPosts = new Map(); // celebrity posts not fanned out\n  }\n  \n  setFollowers(userId, followerList) {\n    this.followers.set(userId, followerList);\n  }\n  \n  publish(authorId, post) {\n    const fCount = (this.followers.get(authorId) || []).length;\n    if (fCount > this.threshold) {\n      // Celebrity: store post, don't fanout\n      if (!this.celebrityPosts.has(authorId)) this.celebrityPosts.set(authorId, []);\n      this.celebrityPosts.get(authorId).push(post);\n      return { strategy: 'pull', followers: fCount };\n    } else {\n      // Regular: fanout on write\n      (this.followers.get(authorId) || []).forEach(f => {\n        if (!this.feedCache.has(f)) this.feedCache.set(f, []);\n        this.feedCache.get(f).push(post);\n      });\n      return { strategy: 'push', followers: fCount };\n    }\n  }\n  \n  getFeed(userId, followedCelebs) {\n    const cached = this.feedCache.get(userId) || [];\n    // Merge celebrity posts on read\n    const celeb = followedCelebs.flatMap(c => this.celebrityPosts.get(c) || []);\n    return [...cached, ...celeb].sort((a, b) => b.score - a.score);\n  }\n}\n\nconst fanout = new HybridFanout(2);\nfanout.setFollowers('celeb', ['alice', 'bob', 'carol']); // 3 > threshold 2\nfanout.setFollowers('friend', ['alice']); // 1 <= threshold\n\nconsole.log(fanout.publish('celeb', { id: 'cp1', text: 'Celebrity post', score: 10 }));\nconsole.log(fanout.publish('friend', { id: 'fp1', text: 'Friend post', score: 7 }));\nconsole.log('Alice feed:', fanout.getFeed('alice', ['celeb']));",
              "output": "{ strategy: 'pull', followers: 3 }\n{ strategy: 'push', followers: 1 }\nAlice feed: [\n  { id: 'cp1', text: 'Celebrity post', score: 10 },\n  { id: 'fp1', text: 'Friend post', score: 7 }\n]"
            },
            {
              "question": "Program 7: Feed deduplication",
              "code": "function deduplicateFeed(rawFeed) {\n  const seen = new Set();\n  const contentHashes = new Set();\n  const deduped = [];\n  \n  for (const item of rawFeed) {\n    // Skip by post ID\n    if (seen.has(item.id)) { continue; }\n    // Skip by content fingerprint (reshares)\n    const hash = item.contentHash || item.text;\n    if (contentHashes.has(hash)) {\n      deduped.push({ ...item, grouped: true, note: 'reshare merged' });\n      continue;\n    }\n    seen.add(item.id);\n    contentHashes.add(hash);\n    deduped.push(item);\n  }\n  return deduped;\n}\n\nconst raw = [\n  { id: 'p1', text: 'Original post', author: 'bob', contentHash: 'abc123' },\n  { id: 'p1', text: 'Original post', author: 'bob', contentHash: 'abc123' }, // dup by ID\n  { id: 'p2', text: 'Reshared post', author: 'carol', contentHash: 'abc123' }, // dup by content\n  { id: 'p3', text: 'Unique post', author: 'dave', contentHash: 'xyz789' },\n];\nconsole.log(deduplicateFeed(raw));",
              "output": "[\n  { id: 'p1', text: 'Original post', author: 'bob', contentHash: 'abc123' },\n  { id: 'p2', text: 'Reshared post', author: 'carol', contentHash: 'abc123', grouped: true, note: 'reshare merged' },\n  { id: 'p3', text: 'Unique post', author: 'dave', contentHash: 'xyz789' }\n]"
            },
            {
              "question": "Program 8: Real-time feed notification",
              "code": "class RealtimeFeedService {\n  constructor() {\n    this.subscribers = new Map(); // userId -> callback[]\n    this.throttleTimers = new Map();\n  }\n  \n  subscribe(userId, callback) {\n    if (!this.subscribers.has(userId)) this.subscribers.set(userId, []);\n    this.subscribers.get(userId).push(callback);\n  }\n  \n  notify(userId, event) {\n    const callbacks = this.subscribers.get(userId) || [];\n    // Throttle: max 1 notification per 5 seconds per user\n    if (this.throttleTimers.has(userId)) {\n      return { status: 'throttled', userId };\n    }\n    callbacks.forEach(cb => cb(event));\n    this.throttleTimers.set(userId, setTimeout(() => this.throttleTimers.delete(userId), 100));\n    return { status: 'delivered', userId, listeners: callbacks.length };\n  }\n}\n\nconst rtService = new RealtimeFeedService();\nrtService.subscribe('alice', (e) => console.log(`Alice got: ${e.type} - ${e.postId}`));\n\nconsole.log(rtService.notify('alice', { type: 'new_post', postId: 'p1' }));\nconsole.log(rtService.notify('alice', { type: 'new_post', postId: 'p2' })); // throttled",
              "output": "Alice got: new_post - p1\n{ status: 'delivered', userId: 'alice', listeners: 1 }\n{ status: 'throttled', userId: 'alice' }"
            },
            {
              "question": "Program 9: Feed metrics tracker",
              "code": "class FeedMetrics {\n  constructor() { this.sessions = []; }\n  \n  record(session) { this.sessions.push(session); }\n  \n  aggregate() {\n    const n = this.sessions.length;\n    if (n === 0) return null;\n    const avg = (arr, key) => arr.reduce((s, v) => s + v[key], 0) / arr.length;\n    return {\n      totalSessions: n,\n      avgTimeSpentSec: Math.round(avg(this.sessions, 'timeSpentSec')),\n      avgPostsViewed: Math.round(avg(this.sessions, 'postsViewed')),\n      avgLikesGiven: +avg(this.sessions, 'likes').toFixed(1),\n      scrollDepth: {\n        shallow: this.sessions.filter(s => s.postsViewed < 10).length,\n        medium: this.sessions.filter(s => s.postsViewed >= 10 && s.postsViewed < 30).length,\n        deep: this.sessions.filter(s => s.postsViewed >= 30).length,\n      }\n    };\n  }\n}\n\nconst metrics = new FeedMetrics();\nmetrics.record({ timeSpentSec: 120, postsViewed: 25, likes: 3 });\nmetrics.record({ timeSpentSec: 300, postsViewed: 50, likes: 8 });\nmetrics.record({ timeSpentSec: 30, postsViewed: 5, likes: 0 });\nmetrics.record({ timeSpentSec: 180, postsViewed: 35, likes: 5 });\nconsole.log(metrics.aggregate());",
              "output": "{\n  totalSessions: 4,\n  avgTimeSpentSec: 158,\n  avgPostsViewed: 29,\n  avgLikesGiven: 4,\n  scrollDepth: { shallow: 1, medium: 1, deep: 2 }\n}"
            },
            {
              "question": "Program 10: Story candidate generator",
              "code": "function generateCandidates(userId, friends, pages, postStore, maxAge) {\n  const cutoff = Date.now() - maxAge;\n  const candidates = [];\n  const sources = [...friends.map(f => ({ id: f, type: 'friend' })), ...pages.map(p => ({ id: p, type: 'page' }))];\n  \n  sources.forEach(source => {\n    const posts = (postStore[source.id] || []).filter(p => p.timestamp >= cutoff);\n    posts.forEach(p => candidates.push({ ...p, sourceType: source.type, source: source.id }));\n  });\n  \n  return { userId, totalCandidates: candidates.length, byType: {\n    friend: candidates.filter(c => c.sourceType === 'friend').length,\n    page: candidates.filter(c => c.sourceType === 'page').length,\n  }, sample: candidates.slice(0, 3) };\n}\n\nconst now = Date.now();\nconst postStore = {\n  'bob': [{ id: 'p1', text: 'Hi', timestamp: now - 3600000 }],\n  'carol': [{ id: 'p2', text: 'Hey', timestamp: now - 86400000 }],\n  'techPage': [\n    { id: 'p3', text: 'News 1', timestamp: now - 1800000 },\n    { id: 'p4', text: 'News 2', timestamp: now - 7200000 },\n  ],\n};\n\nconsole.log(generateCandidates('alice', ['bob', 'carol'], ['techPage'], postStore, 7 * 86400000));",
              "output": "{\n  userId: 'alice',\n  totalCandidates: 4,\n  byType: { friend: 2, page: 2 },\n  sample: [\n    { id: 'p1', text: 'Hi', sourceType: 'friend', source: 'bob' },\n    { id: 'p2', text: 'Hey', sourceType: 'friend', source: 'carol' },\n    { id: 'p3', text: 'News 1', sourceType: 'page', source: 'techPage' }\n  ]\n}"
            }
          ]
        },
        {
          "id": "youtube-lld",
          "title": "YouTube: Video Upload & Processing",
          "category": "Company LLD",
          "description": "Low-level design of YouTube's video upload pipeline, transcoding, thumbnail generation, and video serving.",
          "explanation": "YouTube handles 500+ hours of video uploaded every minute. The upload pipeline must handle large files reliably, transcode into multiple formats/resolutions, generate thumbnails, run content moderation, and make videos searchable — all while providing real-time progress feedback.\n\nUpload pipeline:\n1. **Resumable upload**: Client splits video into chunks (5-10MB each). Each chunk is uploaded with a byte-range header. Server tracks progress. If upload fails, client resumes from last acknowledged chunk.\n2. **Upload service** validates metadata, assigns a video_id, stores raw file in object storage (GCS/S3).\n3. **Transcoding pipeline** (async): Raw video → multiple renditions (144p, 360p, 480p, 720p, 1080p, 4K). Each rendition encoded in multiple codecs (H.264, VP9, AV1). Total: 20-30 output files per video.\n4. **Thumbnail generation**: Extract keyframes, run quality scoring, select top 3, offer to creator.\n5. **Content moderation**: ML models scan for policy violations (nudity, violence, copyright). Copyright check via Content ID (audio/video fingerprinting).\n6. **Metadata indexing**: Title, description, tags → search index. Auto-generated captions via speech-to-text.\n7. **CDN distribution**: Transcoded segments pushed to edge locations. Popular videos pre-cached; long-tail served from origin.\n\nVideo serving:\n- Adaptive bitrate streaming (DASH/HLS) same as Netflix.\n- Manifest contains all renditions. Client picks based on bandwidth.\n- Seek operations: segment index maps timestamps to byte ranges.\n\nRecommendation signals:\n- Watch time, completion rate, likes/dislikes, click-through rate from thumbnail.\n- Collaborative filtering + content-based features.\n\nScale challenges:\n- 1B hours watched per day.\n- Storage: ~1PB of new video per day.\n- Transcoding: 100K+ transcoding jobs running simultaneously.",
          "code": "// Resumable upload service\nclass UploadService {\n  constructor() {\n    this.uploads = new Map();\n    this.completedVideos = [];\n  }\n\n  initUpload(userId, metadata) {\n    const videoId = `vid_${Date.now()}`;\n    const upload = {\n      videoId,\n      userId,\n      metadata,\n      chunks: [],\n      totalSize: metadata.fileSize,\n      uploadedBytes: 0,\n      status: 'UPLOADING',\n      createdAt: Date.now(),\n    };\n    this.uploads.set(videoId, upload);\n    return { videoId, uploadUrl: `/upload/${videoId}` };\n  }\n\n  uploadChunk(videoId, chunkIndex, chunkSize, data) {\n    const upload = this.uploads.get(videoId);\n    if (!upload) throw new Error('Upload not found');\n    if (upload.status !== 'UPLOADING') throw new Error(`Upload status: ${upload.status}`);\n\n    // Idempotent: skip if chunk already uploaded\n    if (upload.chunks.includes(chunkIndex)) {\n      return { status: 'DUPLICATE', uploadedBytes: upload.uploadedBytes };\n    }\n\n    upload.chunks.push(chunkIndex);\n    upload.uploadedBytes += chunkSize;\n    const progress = ((upload.uploadedBytes / upload.totalSize) * 100).toFixed(1);\n\n    if (upload.uploadedBytes >= upload.totalSize) {\n      upload.status = 'PROCESSING';\n      this.completedVideos.push(videoId);\n      return { status: 'COMPLETE', progress: '100.0%', videoId };\n    }\n\n    return { status: 'IN_PROGRESS', progress: progress + '%', chunkIndex };\n  }\n\n  getUploadStatus(videoId) {\n    const u = this.uploads.get(videoId);\n    if (!u) return null;\n    return { videoId, status: u.status, progress: ((u.uploadedBytes / u.totalSize) * 100).toFixed(1) + '%', chunks: u.chunks.length };\n  }\n}\n\nconst upload = new UploadService();\nconst { videoId } = upload.initUpload('user1', { title: 'My Video', fileSize: 30 });\nconsole.log(upload.uploadChunk(videoId, 0, 10, 'data0'));\nconsole.log(upload.uploadChunk(videoId, 1, 10, 'data1'));\nconsole.log(upload.uploadChunk(videoId, 1, 10, 'data1')); // duplicate\nconsole.log(upload.uploadChunk(videoId, 2, 10, 'data2'));\nconsole.log(upload.getUploadStatus(videoId));",
          "example": "// Transcoding job manager\nclass TranscodingPipeline {\n  constructor() {\n    this.jobs = new Map();\n  }\n\n  createJobs(videoId, renditions) {\n    const jobs = renditions.map((r, i) => ({\n      jobId: `${videoId}_${r.label}`,\n      videoId,\n      rendition: r,\n      status: 'QUEUED',\n      progress: 0,\n      startTime: null,\n      endTime: null,\n    }));\n    jobs.forEach(j => this.jobs.set(j.jobId, j));\n    return jobs.map(j => j.jobId);\n  }\n\n  processJob(jobId) {\n    const job = this.jobs.get(jobId);\n    if (!job) return null;\n    job.status = 'PROCESSING';\n    job.startTime = Date.now();\n    // Simulate processing\n    job.progress = 100;\n    job.status = 'COMPLETED';\n    job.endTime = Date.now();\n    return job;\n  }\n\n  getVideoStatus(videoId) {\n    const videoJobs = [...this.jobs.values()].filter(j => j.videoId === videoId);\n    return {\n      total: videoJobs.length,\n      completed: videoJobs.filter(j => j.status === 'COMPLETED').length,\n      failed: videoJobs.filter(j => j.status === 'FAILED').length,\n      allDone: videoJobs.every(j => j.status === 'COMPLETED'),\n    };\n  }\n}\n\nconst pipeline = new TranscodingPipeline();\nconst jobIds = pipeline.createJobs('vid1', [\n  { label: '360p', bitrate: 500 },\n  { label: '720p', bitrate: 1500 },\n  { label: '1080p', bitrate: 4000 },\n]);\njobIds.forEach(id => pipeline.processJob(id));\nconsole.log(pipeline.getVideoStatus('vid1'));",
          "useCase": "Video platforms, media processing pipelines, content management systems, live streaming platforms.",
          "interviewQuestions": [
            {
              "question": "How does resumable upload work?",
              "answer": "Client splits file into chunks. Each chunk uploaded with byte-range header. Server tracks received chunks. On failure, client queries server for last received byte position and resumes from there. This handles network interruptions gracefully for large files."
            },
            {
              "question": "How do you handle transcoding at scale?",
              "answer": "Transcoding is CPU-intensive. Use a job queue (SQS/Kafka). Worker pool pulls jobs. Each video creates N jobs (one per rendition). Workers run FFmpeg or hardware encoders. Auto-scale workers based on queue depth. Priority queue for premium creators."
            },
            {
              "question": "How do you ensure exactly-once processing in the upload pipeline?",
              "answer": "Idempotency keys: each chunk has a unique ID (videoId + chunkIndex). Deduplicate on receive. For transcoding: job ID = videoId + rendition. If job already exists, skip. Message queue with visibility timeout prevents double-processing."
            },
            {
              "question": "How do you generate good thumbnails?",
              "answer": "Extract frames at regular intervals (every 2 seconds). Score each frame: face detection, color vibrancy, sharpness, motion blur rejection. ML model trained on click-through-rate data selects best candidates. Offer top 3 to creator; auto-select best one as default."
            },
            {
              "question": "What is Content ID and how does it work?",
              "answer": "Audio and video fingerprinting. Rights holders upload reference files. On each new upload, generate fingerprint and compare against reference database. Matches trigger: block, monetize (ads for rights holder), or track. Uses locality-sensitive hashing for fast matching."
            },
            {
              "question": "How do you handle a video that goes viral immediately after upload?",
              "answer": "Proactive CDN caching: if view velocity exceeds threshold, push to more edges. Serve lower renditions first (smaller, faster to distribute). Pre-warm popular regions. Degrade gracefully: serve 720p while 4K propagates."
            },
            {
              "question": "What is the video segment index used for?",
              "answer": "Maps timestamps to byte ranges in the encoded file. Enables seeking without downloading the entire video. Client requests segment index first, then fetches specific byte ranges for the desired time position. Essential for scrubbing and chapter navigation."
            },
            {
              "question": "How do you handle live streaming differently from uploads?",
              "answer": "Live: ingest via RTMP/SRT, transcode in real-time, segment immediately (2-4s chunks), push to CDN with ultra-low latency. No resumable upload. Separate infrastructure for ingest, encoding, and distribution. DVR: store segments for rewind."
            },
            {
              "question": "How do you optimize storage costs for petabytes of video?",
              "answer": "Tiering: hot (SSD/RAM cache for popular), warm (HDD for recent), cold (tape/glacier for old, rarely viewed). Delete low-view-count renditions after 90 days (keep source + 1 rendition, re-transcode on demand). Compress with newer codecs (AV1) for 30% size reduction."
            },
            {
              "question": "How do you build the video recommendation system?",
              "answer": "Signals: watch time, completion rate, click-through rate, likes, shares. Collaborative filtering: users who watched X also watched Y. Content-based: video embeddings from title, tags, visual features. Two-tower model: user embedding × video embedding. Serve from pre-computed candidate lists, re-rank in real-time."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design the resumable upload protocol for videos up to 256GB.",
              "answer": "Chunk size: 8MB. Init: POST /uploads → returns upload_id. Upload chunk: PUT /uploads/{id}?chunk={n} with Content-Range header. Server writes chunk to object storage, updates progress in DB. Resume: GET /uploads/{id}/status returns last received byte. Final: server assembles chunks. Timeout: expire incomplete uploads after 7 days."
            },
            {
              "type": "estimation",
              "question": "500 hours of video uploaded per minute. Average video: 10 minutes, 1GB raw. Estimate daily raw storage and transcoding compute.",
              "answer": "Videos/min: 500×60/10 = 3000 videos/min = 4.32M videos/day. Storage: 4.32M × 1GB = 4.32PB/day raw. Transcoding: 5 renditions × 4.32M = 21.6M transcoding jobs/day. At 1 job per core-minute: 21.6M core-minutes/day = 15,000 cores running 24/7."
            },
            {
              "type": "scenario",
              "question": "A transcoding job fails midway through. How do you handle recovery?",
              "answer": "Checkpointing: FFmpeg supports segment-level resumption. Log last completed segment. On retry, resume from checkpoint. Max 3 retries. If persistent failure, route to different worker (maybe hardware issue). DLQ for manual investigation. Notify creator of delays."
            },
            {
              "type": "debug",
              "question": "Videos are transcoded successfully but some renditions show audio/video sync drift. What are possible causes?",
              "answer": "1) Timestamp discontinuities in source video. 2) Audio resampling without proper PTS adjustment. 3) Variable frame rate not handled correctly. 4) Segment boundaries not aligned between audio and video tracks. Fix: force constant frame rate, align segment boundaries on keyframes."
            },
            {
              "type": "design",
              "question": "Design the thumbnail selection pipeline.",
              "answer": "1) Extract 1 frame per 2 seconds. 2) Filter: remove black frames, high motion blur, low contrast. 3) Quality scoring ML model: face detection (bonus), rule of thirds, vibrant colors. 4) Diversity: cluster frames by visual similarity, pick top from each cluster. 5) A/B test thumbnails for click-through rate. 6) Auto-update thumbnail if creator doesn't choose within 24h."
            },
            {
              "type": "tricky",
              "question": "Why transcode into multiple codecs (H.264, VP9, AV1) rather than just the best one?",
              "answer": "Device compatibility: older devices only support H.264. VP9: 30% better compression, supported by Chrome/Android. AV1: 50% better than H.264 but requires modern hardware. Browser negotiates best codec via Accept header. Serving AV1 where supported saves 50% bandwidth cost at scale."
            },
            {
              "type": "estimation",
              "question": "1B daily active users, each watches 40 minutes. Average bitrate 3Mbps. Estimate peak bandwidth.",
              "answer": "Assuming 20% of daily viewing concentrated in 4 peak hours. Peak viewers: 1B × 0.2 / 4hrs × (40/1440 fraction of day... better: 1B × 40min = 40B minutes/day. Peak 4hrs = 240min, handles 33% of views: 13.2B minutes in 240 min = 55M concurrent viewers. Bandwidth: 55M × 3Mbps = 165Tbps."
            },
            {
              "type": "design",
              "question": "Design the auto-captioning pipeline.",
              "answer": "1) Extract audio track from video. 2) Chunk audio into 30-second segments (with overlap for continuity). 3) Speech-to-text via ML model (Whisper-like). 4) Align timestamps with video frames. 5) Post-process: punctuation, capitalization, profanity filtering. 6) Store as WebVTT format. 7) Support 100+ languages via translation pipeline. 8) Creator can edit captions."
            },
            {
              "type": "scenario",
              "question": "You need to re-encode 100M existing videos with a new codec. How do you plan the migration?",
              "answer": "1) Prioritize by view count (top 1% of videos get 80% of views). 2) Batch job over 6 months. 3) Process during off-peak hours. 4) Don't delete old renditions until new ones verified. 5) A/B test quality. 6) Progress dashboard for tracking. 7) Fallback to old rendition if re-encode fails."
            },
            {
              "type": "output",
              "question": "A 2-hour video at 30fps needs thumbnails every 2 seconds. How many candidate frames? If ML scoring takes 10ms per frame, total scoring time?",
              "answer": "Duration: 7200 seconds. Frames: 7200 / 2 = 3600 candidate frames. Scoring: 3600 × 10ms = 36 seconds. With 10 parallel workers: 3.6 seconds. Acceptable latency for async pipeline."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Resumable chunk upload tracker",
              "code": "class ChunkTracker {\n  constructor(totalSize, chunkSize) {\n    this.totalSize = totalSize;\n    this.chunkSize = chunkSize;\n    this.totalChunks = Math.ceil(totalSize / chunkSize);\n    this.received = new Set();\n  }\n  receiveChunk(index) {\n    if (index >= this.totalChunks) return { error: 'Invalid chunk index' };\n    if (this.received.has(index)) return { status: 'duplicate', index };\n    this.received.add(index);\n    const progress = ((this.received.size / this.totalChunks) * 100).toFixed(1);\n    return {\n      status: this.received.size === this.totalChunks ? 'COMPLETE' : 'IN_PROGRESS',\n      progress: progress + '%',\n      remaining: this.totalChunks - this.received.size,\n    };\n  }\n  getMissing() {\n    const missing = [];\n    for (let i = 0; i < this.totalChunks; i++) {\n      if (!this.received.has(i)) missing.push(i);\n    }\n    return missing;\n  }\n}\n\nconst tracker = new ChunkTracker(50, 10); // 50MB file, 10MB chunks\nconsole.log(tracker.receiveChunk(0));\nconsole.log(tracker.receiveChunk(2)); // out of order OK\nconsole.log(tracker.receiveChunk(0)); // duplicate\nconsole.log('Missing:', tracker.getMissing());\nconsole.log(tracker.receiveChunk(1));\nconsole.log(tracker.receiveChunk(3));\nconsole.log(tracker.receiveChunk(4));",
              "output": "{ status: 'IN_PROGRESS', progress: '20.0%', remaining: 4 }\n{ status: 'IN_PROGRESS', progress: '40.0%', remaining: 3 }\n{ status: 'duplicate', index: 0 }\nMissing: [ 1, 3, 4 ]\n{ status: 'IN_PROGRESS', progress: '60.0%', remaining: 2 }\n{ status: 'IN_PROGRESS', progress: '80.0%', remaining: 1 }\n{ status: 'COMPLETE', progress: '100.0%', remaining: 0 }"
            },
            {
              "question": "Program 2: Transcoding job queue",
              "code": "class TranscodeQueue {\n  constructor() { this.queue = []; this.results = []; }\n  enqueue(videoId, renditions) {\n    renditions.forEach(r => {\n      this.queue.push({ videoId, rendition: r, status: 'QUEUED', priority: r.priority || 0 });\n    });\n    this.queue.sort((a, b) => b.priority - a.priority);\n  }\n  processNext() {\n    const job = this.queue.shift();\n    if (!job) return null;\n    job.status = 'COMPLETED';\n    this.results.push(job);\n    return { videoId: job.videoId, rendition: job.rendition.label, status: 'COMPLETED' };\n  }\n  status() {\n    return { queued: this.queue.length, completed: this.results.length };\n  }\n}\n\nconst q = new TranscodeQueue();\nq.enqueue('vid1', [\n  { label: '360p', bitrate: 500, priority: 1 },\n  { label: '1080p', bitrate: 4000, priority: 3 },\n  { label: '720p', bitrate: 1500, priority: 2 },\n]);\nconsole.log(q.processNext()); // highest priority first\nconsole.log(q.processNext());\nconsole.log(q.processNext());\nconsole.log(q.status());",
              "output": "{ videoId: 'vid1', rendition: '1080p', status: 'COMPLETED' }\n{ videoId: 'vid1', rendition: '720p', status: 'COMPLETED' }\n{ videoId: 'vid1', rendition: '360p', status: 'COMPLETED' }\n{ queued: 0, completed: 3 }"
            },
            {
              "question": "Program 3: Thumbnail quality scorer",
              "code": "function scoreThumbnails(frames) {\n  return frames.map(frame => {\n    let score = 0;\n    // Face detection bonus\n    if (frame.hasFace) score += 30;\n    // Color vibrancy (0-100)\n    score += frame.colorVibrancy * 0.3;\n    // Sharpness (0-100)\n    score += frame.sharpness * 0.2;\n    // Motion blur penalty\n    if (frame.motionBlur > 50) score -= 15;\n    // Black frame penalty\n    if (frame.brightness < 10) score -= 40;\n    return { timestamp: frame.timestamp, score: Math.round(score), selected: false };\n  })\n  .sort((a, b) => b.score - a.score)\n  .map((t, i) => ({ ...t, selected: i < 3 })); // top 3\n}\n\nconst frames = [\n  { timestamp: '0:15', hasFace: true, colorVibrancy: 80, sharpness: 90, motionBlur: 10, brightness: 70 },\n  { timestamp: '1:30', hasFace: false, colorVibrancy: 60, sharpness: 70, motionBlur: 60, brightness: 50 },\n  { timestamp: '3:00', hasFace: true, colorVibrancy: 90, sharpness: 85, motionBlur: 20, brightness: 65 },\n  { timestamp: '5:00', hasFace: false, colorVibrancy: 20, sharpness: 30, motionBlur: 5, brightness: 5 },\n  { timestamp: '7:30', hasFace: true, colorVibrancy: 70, sharpness: 95, motionBlur: 15, brightness: 80 },\n];\nconsole.log(scoreThumbnails(frames));",
              "output": "[\n  { timestamp: '3:00', score: 74, selected: true },\n  { timestamp: '0:15', score: 72, selected: true },\n  { timestamp: '7:30', score: 70, selected: true },\n  { timestamp: '1:30', score: 17, selected: false },\n  { timestamp: '5:00', score: -28, selected: false }\n]"
            },
            {
              "question": "Program 4: Content ID fingerprint matcher",
              "code": "class ContentIdService {\n  constructor() { this.references = new Map(); }\n  \n  addReference(ownerId, contentId, fingerprint) {\n    this.references.set(fingerprint, { ownerId, contentId });\n  }\n  \n  match(uploadFingerprint, threshold = 0.8) {\n    for (const [refFp, info] of this.references) {\n      const similarity = this.compareFP(uploadFingerprint, refFp);\n      if (similarity >= threshold) {\n        return { matched: true, similarity: similarity.toFixed(2), owner: info.ownerId, contentId: info.contentId, action: 'MONETIZE' };\n      }\n    }\n    return { matched: false };\n  }\n  \n  compareFP(a, b) {\n    // Simulated: compare character overlap\n    const setA = new Set(a.split(''));\n    const setB = new Set(b.split(''));\n    const intersection = [...setA].filter(x => setB.has(x)).length;\n    return intersection / Math.max(setA.size, setB.size);\n  }\n}\n\nconst cid = new ContentIdService();\ncid.addReference('Universal', 'song-123', 'abcdefghij');\ncid.addReference('Warner', 'movie-456', 'klmnopqrst');\n\nconsole.log(cid.match('abcdefghxy')); // similar to Universal's song\nconsole.log(cid.match('zzzzzzz'));     // no match",
              "output": "{ matched: true, similarity: '0.80', owner: 'Universal', contentId: 'song-123', action: 'MONETIZE' }\n{ matched: false }"
            },
            {
              "question": "Program 5: Video processing pipeline orchestrator",
              "code": "class PipelineOrchestrator {\n  constructor() { this.pipelines = new Map(); }\n  \n  startPipeline(videoId) {\n    const stages = [\n      { name: 'validate', status: 'pending' },\n      { name: 'transcode', status: 'pending' },\n      { name: 'thumbnail', status: 'pending' },\n      { name: 'contentId', status: 'pending' },\n      { name: 'index', status: 'pending' },\n    ];\n    this.pipelines.set(videoId, { stages, currentStage: 0 });\n    return this.advancePipeline(videoId);\n  }\n  \n  advancePipeline(videoId) {\n    const pipeline = this.pipelines.get(videoId);\n    const log = [];\n    while (pipeline.currentStage < pipeline.stages.length) {\n      const stage = pipeline.stages[pipeline.currentStage];\n      stage.status = 'completed';\n      log.push(`✅ ${stage.name}`);\n      pipeline.currentStage++;\n    }\n    return { videoId, log, status: 'READY' };\n  }\n  \n  getStatus(videoId) {\n    const p = this.pipelines.get(videoId);\n    return {\n      progress: `${p.currentStage}/${p.stages.length}`,\n      stages: p.stages.map(s => `${s.status === 'completed' ? '✅' : '⏳'} ${s.name}`),\n    };\n  }\n}\n\nconst orch = new PipelineOrchestrator();\nconsole.log(orch.startPipeline('vid-001'));\nconsole.log(orch.getStatus('vid-001'));",
              "output": "{\n  videoId: 'vid-001',\n  log: ['✅ validate', '✅ transcode', '✅ thumbnail', '✅ contentId', '✅ index'],\n  status: 'READY'\n}\n{\n  progress: '5/5',\n  stages: ['✅ validate', '✅ transcode', '✅ thumbnail', '✅ contentId', '✅ index']\n}"
            },
            {
              "question": "Program 6: Video storage tier manager",
              "code": "class StorageTierManager {\n  constructor() { this.videos = new Map(); }\n  \n  addVideo(videoId, viewsPerDay, ageInDays, sizeGB) {\n    let tier;\n    if (viewsPerDay > 10000) tier = 'HOT';\n    else if (viewsPerDay > 100 || ageInDays < 30) tier = 'WARM';\n    else if (viewsPerDay > 0) tier = 'COLD';\n    else tier = 'ARCHIVE';\n    \n    const costPerGB = { HOT: 0.023, WARM: 0.013, COLD: 0.004, ARCHIVE: 0.001 };\n    this.videos.set(videoId, {\n      tier, viewsPerDay, ageInDays, sizeGB,\n      monthlyCost: +(sizeGB * costPerGB[tier]).toFixed(4),\n    });\n    return this.videos.get(videoId);\n  }\n  \n  summary() {\n    const tiers = { HOT: 0, WARM: 0, COLD: 0, ARCHIVE: 0 };\n    let totalCost = 0;\n    for (const v of this.videos.values()) {\n      tiers[v.tier]++;\n      totalCost += v.monthlyCost;\n    }\n    return { tiers, totalMonthlyCost: '$' + totalCost.toFixed(2) };\n  }\n}\n\nconst mgr = new StorageTierManager();\nmgr.addVideo('v1', 50000, 5, 10);   // HOT\nmgr.addVideo('v2', 500, 20, 8);     // WARM\nmgr.addVideo('v3', 5, 200, 12);     // COLD\nmgr.addVideo('v4', 0, 365, 15);     // ARCHIVE\nconsole.log(mgr.summary());",
              "output": "{\n  tiers: { HOT: 1, WARM: 1, COLD: 1, ARCHIVE: 1 },\n  totalMonthlyCost: '$0.40'\n}"
            },
            {
              "question": "Program 7: Watch history and recommendations",
              "code": "function recommend(userId, watchHistory, videoDb) {\n  // Simple collaborative filtering: find similar users, recommend their watches\n  const userTags = new Set();\n  watchHistory[userId]?.forEach(vid => {\n    (videoDb[vid]?.tags || []).forEach(t => userTags.add(t));\n  });\n  \n  const watched = new Set(watchHistory[userId] || []);\n  const candidates = Object.entries(videoDb)\n    .filter(([id]) => !watched.has(id))\n    .map(([id, video]) => {\n      const overlap = video.tags.filter(t => userTags.has(t)).length;\n      return { id, title: video.title, score: overlap };\n    })\n    .sort((a, b) => b.score - a.score)\n    .slice(0, 3);\n  \n  return candidates;\n}\n\nconst videoDb = {\n  v1: { title: 'React Tutorial', tags: ['react', 'js', 'frontend'] },\n  v2: { title: 'Node.js Crash Course', tags: ['node', 'js', 'backend'] },\n  v3: { title: 'Go Concurrency', tags: ['golang', 'concurrency'] },\n  v4: { title: 'JS Design Patterns', tags: ['js', 'patterns', 'frontend'] },\n  v5: { title: 'Docker Basics', tags: ['docker', 'devops'] },\n};\n\nconst history = { user1: ['v1', 'v2'] }; // watched React + Node\nconsole.log(recommend('user1', history, videoDb));",
              "output": "[\n  { id: 'v4', title: 'JS Design Patterns', score: 2 },\n  { id: 'v3', title: 'Go Concurrency', score: 0 },\n  { id: 'v5', title: 'Docker Basics', score: 0 }\n]"
            },
            {
              "question": "Program 8: Segment index for video seeking",
              "code": "function buildSegmentIndex(segments) {\n  return segments.map((seg, i) => ({\n    index: i,\n    startTime: seg.startTime,\n    endTime: seg.endTime,\n    byteOffset: seg.byteOffset,\n    byteLength: seg.byteLength,\n  }));\n}\n\nfunction seekToTime(index, targetTime) {\n  const segment = index.find(s => targetTime >= s.startTime && targetTime < s.endTime);\n  if (!segment) return { error: 'Time out of range' };\n  return {\n    segment: segment.index,\n    byteRange: `${segment.byteOffset}-${segment.byteOffset + segment.byteLength - 1}`,\n    startTime: segment.startTime,\n  };\n}\n\nconst index = buildSegmentIndex([\n  { startTime: 0, endTime: 6, byteOffset: 0, byteLength: 500000 },\n  { startTime: 6, endTime: 12, byteOffset: 500000, byteLength: 480000 },\n  { startTime: 12, endTime: 18, byteOffset: 980000, byteLength: 520000 },\n  { startTime: 18, endTime: 24, byteOffset: 1500000, byteLength: 490000 },\n]);\n\nconsole.log('Seek to 8s:', seekToTime(index, 8));\nconsole.log('Seek to 0s:', seekToTime(index, 0));\nconsole.log('Seek to 20s:', seekToTime(index, 20));",
              "output": "Seek to 8s: { segment: 1, byteRange: '500000-979999', startTime: 6 }\nSeek to 0s: { segment: 0, byteRange: '0-499999', startTime: 0 }\nSeek to 20s: { segment: 3, byteRange: '1500000-1989999', startTime: 18 }"
            },
            {
              "question": "Program 9: View count with eventual consistency",
              "code": "class ViewCounter {\n  constructor(shards) {\n    this.shards = Array.from({ length: shards }, () => new Map());\n  }\n  \n  increment(videoId) {\n    const shard = this.shards[videoId.charCodeAt(0) % this.shards.length];\n    shard.set(videoId, (shard.get(videoId) || 0) + 1);\n  }\n  \n  getCount(videoId) {\n    return this.shards.reduce((sum, shard) => sum + (shard.get(videoId) || 0), 0);\n  }\n  \n  getApproxDisplay(videoId) {\n    const count = this.getCount(videoId);\n    if (count < 1000) return `${count} views`;\n    if (count < 1000000) return `${(count/1000).toFixed(1)}K views`;\n    return `${(count/1000000).toFixed(1)}M views`;\n  }\n}\n\nconst counter = new ViewCounter(3);\nfor (let i = 0; i < 1500; i++) counter.increment('vid1');\nfor (let i = 0; i < 2500000; i++) counter.increment('vid2');\nconsole.log(counter.getApproxDisplay('vid1'));\nconsole.log(counter.getApproxDisplay('vid2'));",
              "output": "1.5K views\n2.5M views"
            },
            {
              "question": "Program 10: Video processing event log",
              "code": "class ProcessingLog {\n  constructor() { this.events = []; }\n  log(videoId, stage, status, details) {\n    this.events.push({ videoId, stage, status, details, time: new Date().toISOString() });\n  }\n  getTimeline(videoId) {\n    return this.events\n      .filter(e => e.videoId === videoId)\n      .map(e => `[${e.status}] ${e.stage}: ${e.details}`);\n  }\n  getStageDurations(videoId) {\n    const events = this.events.filter(e => e.videoId === videoId);\n    const stages = {};\n    events.forEach((e, i) => {\n      if (!stages[e.stage]) stages[e.stage] = { start: i, end: i };\n      stages[e.stage].end = i;\n    });\n    return Object.entries(stages).map(([name, { start, end }]) => ({ stage: name, events: end - start + 1 }));\n  }\n}\n\nconst log = new ProcessingLog();\nlog.log('v1', 'upload', 'START', 'File received');\nlog.log('v1', 'upload', 'DONE', '100% uploaded');\nlog.log('v1', 'transcode', 'START', 'Creating 5 renditions');\nlog.log('v1', 'transcode', 'PROGRESS', '3/5 complete');\nlog.log('v1', 'transcode', 'DONE', 'All renditions ready');\nlog.log('v1', 'publish', 'DONE', 'Video is live');\nconsole.log(log.getTimeline('v1'));\nconsole.log(log.getStageDurations('v1'));",
              "output": "[\n  '[START] upload: File received',\n  '[DONE] upload: 100% uploaded',\n  '[START] transcode: Creating 5 renditions',\n  '[PROGRESS] transcode: 3/5 complete',\n  '[DONE] transcode: All renditions ready',\n  '[DONE] publish: Video is live'\n]\n[\n  { stage: 'upload', events: 2 },\n  { stage: 'transcode', events: 3 },\n  { stage: 'publish', events: 1 }\n]"
            }
          ]
        },
        {
          "id": "zomato-lld",
          "title": "Zomato: Food Delivery Platform",
          "category": "Company LLD",
          "description": "Low-level design of Zomato's food ordering, restaurant search, delivery assignment, and real-time order tracking.",
          "explanation": "Zomato handles millions of food orders daily across 1000+ cities. The system orchestrates customers, restaurants, and delivery partners in real-time. Key subsystems:\n\n**Restaurant Discovery & Search**:\n- Geo-spatial search: find restaurants within delivery radius (5-10km) using geohash or spatial index.\n- Filters: cuisine, rating, delivery time, price range, offers.\n- Ranking factors: proximity, ratings, order volume, delivery time estimate, promotions.\n- Menu management: restaurants update menus, pricing, availability in real-time.\n\n**Order Lifecycle**:\n1. Customer browses menu, adds items to cart.\n2. Checkout: validate cart (item availability, restaurant open hours, delivery address in range).\n3. Payment: process via payment gateway (UPI, cards, wallets). Hold amount.\n4. Order placed → Restaurant receives notification. Must accept within 60 seconds (auto-accept or manual).\n5. Restaurant confirms → Estimated preparation time (ETA). Kitchen starts.\n6. Delivery partner assignment: find nearest available partner (geo-proximity, current load, acceptance rate).\n7. Partner reaches restaurant → Picks up order.\n8. En route to customer → Real-time GPS tracking.\n9. Delivered → Payment settled. Partner paid. Customer can rate.\n\n**Delivery Assignment Algorithm**:\n- Geofenced search for available partners within 3km of restaurant.\n- Score each partner: distance (40%), acceptance rate (20%), current orders (20%), rating (20%).\n- Offer to top-scored partner. 30-second timeout. If rejected/timeout, offer to next.\n- Max 3 attempts before escalation (increase search radius or bonus).\n\n**ETA Calculation**:\n- Food prep time: ML model using restaurant's historical data, current order volume, item complexity.\n- Pickup time: partner distance to restaurant + traffic conditions.\n- Delivery time: restaurant-to-customer distance + traffic.\n- Total ETA = prep_time + max(0, pickup_time - prep_time) + delivery_time.\n\n**Surge Pricing**:\n- When demand > supply in a zone: increase delivery fee by 1.2x-2x.\n- Based on: active orders in zone, available partners in zone, weather, events.\n- Cap at 2x to prevent backlash.",
          "code": "// Order management system\nclass OrderService {\n  constructor() {\n    this.orders = new Map();\n    this.orderCounter = 0;\n  }\n\n  placeOrder(customerId, restaurantId, items, address) {\n    const orderId = `ORD-${++this.orderCounter}`;\n    const total = items.reduce((sum, item) => sum + item.price * item.qty, 0);\n    const order = {\n      orderId,\n      customerId,\n      restaurantId,\n      items,\n      address,\n      total,\n      deliveryFee: 30,\n      status: 'PLACED',\n      timeline: [{ status: 'PLACED', at: Date.now() }],\n      partnerId: null,\n      eta: null,\n    };\n    this.orders.set(orderId, order);\n    return order;\n  }\n\n  updateStatus(orderId, status, extra = {}) {\n    const order = this.orders.get(orderId);\n    if (!order) throw new Error('Order not found');\n    const validTransitions = {\n      PLACED: ['ACCEPTED', 'REJECTED'],\n      ACCEPTED: ['PREPARING'],\n      PREPARING: ['READY', 'CANCELLED'],\n      READY: ['PICKED_UP'],\n      PICKED_UP: ['EN_ROUTE'],\n      EN_ROUTE: ['DELIVERED'],\n    };\n    if (!validTransitions[order.status]?.includes(status)) {\n      return { error: `Cannot transition from ${order.status} to ${status}` };\n    }\n    order.status = status;\n    order.timeline.push({ status, at: Date.now(), ...extra });\n    if (extra.partnerId) order.partnerId = extra.partnerId;\n    if (extra.eta) order.eta = extra.eta;\n    return { orderId, status, timeline: order.timeline.length };\n  }\n\n  getOrder(orderId) {\n    return this.orders.get(orderId);\n  }\n}\n\nconst orderService = new OrderService();\nconst order = orderService.placeOrder('cust1', 'rest1', [\n  { name: 'Butter Chicken', price: 350, qty: 1 },\n  { name: 'Naan', price: 60, qty: 2 },\n], '123 Main St');\nconsole.log('Order:', order.orderId, 'Total:', order.total);\nconsole.log(orderService.updateStatus(order.orderId, 'ACCEPTED'));\nconsole.log(orderService.updateStatus(order.orderId, 'PREPARING'));\nconsole.log(orderService.updateStatus(order.orderId, 'READY'));\nconsole.log(orderService.updateStatus(order.orderId, 'PICKED_UP', { partnerId: 'dp1' }));\nconsole.log(orderService.updateStatus(order.orderId, 'EN_ROUTE'));\nconsole.log(orderService.updateStatus(order.orderId, 'DELIVERED'));",
          "example": "// Delivery partner assignment algorithm\nfunction assignPartner(restaurant, availablePartners, maxDistance = 3) {\n  const candidates = availablePartners\n    .map(p => {\n      const dist = Math.sqrt(\n        Math.pow(p.lat - restaurant.lat, 2) + Math.pow(p.lng - restaurant.lng, 2)\n      ) * 111; // rough km conversion\n      return { ...p, distanceKm: +dist.toFixed(2) };\n    })\n    .filter(p => p.distanceKm <= maxDistance)\n    .map(p => {\n      // Score: lower distance is better, higher acceptance rate is better\n      const distScore = (1 - p.distanceKm / maxDistance) * 40;\n      const acceptScore = p.acceptanceRate * 20;\n      const loadScore = (1 - p.currentOrders / 3) * 20; // max 3 concurrent\n      const ratingScore = (p.rating / 5) * 20;\n      return { ...p, score: +(distScore + acceptScore + loadScore + ratingScore).toFixed(1) };\n    })\n    .sort((a, b) => b.score - a.score);\n\n  if (candidates.length === 0) return { assigned: false, reason: 'No partners nearby' };\n  return { assigned: true, partner: candidates[0], alternatives: candidates.length - 1 };\n}\n\nconst restaurant = { lat: 28.6139, lng: 77.2090 };\nconst partners = [\n  { id: 'dp1', lat: 28.615, lng: 77.210, acceptanceRate: 0.95, currentOrders: 0, rating: 4.8 },\n  { id: 'dp2', lat: 28.620, lng: 77.215, acceptanceRate: 0.80, currentOrders: 2, rating: 4.2 },\n  { id: 'dp3', lat: 28.630, lng: 77.220, acceptanceRate: 0.90, currentOrders: 1, rating: 4.5 },\n  { id: 'dp4', lat: 28.700, lng: 77.300, acceptanceRate: 0.99, currentOrders: 0, rating: 4.9 }, // too far\n];\nconsole.log(assignPartner(restaurant, partners));",
          "useCase": "Food delivery platforms, ride-hailing dispatch, last-mile logistics, on-demand service marketplaces.",
          "interviewQuestions": [
            {
              "question": "How do you find restaurants near a user's location efficiently?",
              "answer": "Use geohash-based indexing. Convert lat/lng to geohash prefix. Query all restaurants with matching geohash prefix (and neighboring cells for edge cases). Secondary filter by actual distance. Index in Redis (sorted set by geohash) or PostGIS (spatial index). Result: O(1) lookup by prefix + O(n) filter on small candidate set."
            },
            {
              "question": "How do you calculate delivery ETA accurately?",
              "answer": "Three components: (1) Food prep time — ML model trained on restaurant's historical data, considers item complexity, current kitchen load, time of day. (2) Partner pickup time — distance to restaurant via routing API + traffic. (3) Delivery time — restaurant-to-customer routing. Total = prep + max(0, pickup - prep) + delivery. Update ETA in real-time based on GPS."
            },
            {
              "question": "How do you handle order placement during peak hours?",
              "answer": "Queue-based architecture. Orders go through validation → payment → placement queue. Rate limit per restaurant (prevent overwhelming kitchen). Surge pricing to balance demand/supply. Circuit breaker on overloaded restaurants. Show increased delivery times during peak. Auto-reject if estimated delivery > 90 minutes."
            },
            {
              "question": "How does the delivery partner assignment work?",
              "answer": "Geofenced search for available partners within 3km. Multi-factor scoring: proximity (40%), acceptance rate (20%), current load (20%), rating (20%). Offer to top scorer with 30s timeout. Cascade to next if rejected. After 3 rejections, expand radius or add bonus. Batch-optimize if multiple orders going to same area."
            },
            {
              "question": "How do you handle menu item availability in real-time?",
              "answer": "Restaurants mark items as available/unavailable via dashboard. Changes pushed via WebSocket to connected clients. Cart validation on checkout re-checks availability. If item becomes unavailable after order, restaurant can partially accept order. Push notification to customer for substitution approval."
            },
            {
              "question": "How do you implement real-time GPS tracking?",
              "answer": "Delivery partner's app sends GPS coordinates every 5-10 seconds. Updates stored in Redis (low latency). Customer app polls every 5 seconds or uses WebSocket for push updates. Show partner location on map with ETA update. Reduce update frequency when partner is far; increase when approaching."
            },
            {
              "question": "How do you handle payment failures during checkout?",
              "answer": "Idempotent payment: use order_id as idempotency key. If payment gateway times out, retry with same key. If failed, show retry UI. Support multiple payment methods as fallback. For COD orders, hold partner's security deposit. Reconciliation job runs every hour to catch discrepancies."
            },
            {
              "question": "How do you prevent fraud in the delivery system?",
              "answer": "GPS spoofing detection: check if partner's speed is realistic (not teleporting). Photo verification of delivery. Pattern detection: same partner always marking orders as delivered suspiciously fast. Customer-side: address verification, device fingerprinting, limit of maximum complaints before review."
            },
            {
              "question": "How do you design the rating and review system?",
              "answer": "After delivery: prompt customer to rate food (restaurant) and delivery (partner) separately. 1-5 stars + optional text. Only verified order customers can review. Weighted average: recent reviews weighted more. Remove outliers (bot detection). Display: aggregate score, review count, response rate."
            },
            {
              "question": "How do surge pricing work without alienating users?",
              "answer": "Transparent communication: show 'High demand in your area' with fee breakdown. Cap at 2x normal fee. Surge cooldown: don't change price mid-checkout. Zone-based: 1km hexagonal zones. Dynamic: recalculate every 5 minutes based on demand/supply ratio. Never surge essential items above 1.5x."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design the restaurant search and ranking system.",
              "answer": "Index: PostGIS or Redis geohash. Query: find restaurants within 7km radius. Rank by composite score: relevance × (rating × 0.3 + delivery_speed × 0.25 + proximity × 0.2 + order_volume × 0.15 + promotion_boost × 0.1). Apply filters: cuisine, vegetarian, price range. Cache popular searches per zone. Personalize: boost restaurants user has ordered from."
            },
            {
              "type": "estimation",
              "question": "Zomato serves 3M orders/day in India. Average order has 3 items. How many item-availability checks per day?",
              "answer": "Cart creation: ~10 item views per order = 30M views/day. Availability checks at: browsing (3M × 10 = 30M), add-to-cart (3M × 3 = 9M), checkout validation (3M). Total: ~42M checks/day. At peak (2 hours handling 30% of traffic): 42M × 0.3 / 7200 = 1750 checks/second."
            },
            {
              "type": "scenario",
              "question": "Rains heavily in a city. Order volume increases 3x, partner availability drops 50%. What happens?",
              "answer": "1) Surge pricing activates (1.5-2x delivery fee). 2) Delivery ETA increases (traffic + fewer partners). 3) Expand partner search radius from 3km to 5km. 4) Incentive bonuses for active partners. 5) Temporarily disable promotions to reduce demand. 6) Priority to premium/Gold members. 7) Show 'Limited delivery availability' warning."
            },
            {
              "type": "debug",
              "question": "Delivery partners report that orders are getting auto-assigned to them even when they're offline. What could be the issue?",
              "answer": "1) Online/offline status not syncing properly (stale status in cache). 2) Last GPS update still within range (partner closed app but didn't go offline). 3) Background location permission allowing updates after app close. Fix: heartbeat-based status — if no ping in 3 minutes, auto-set offline. Require active acknowledgment for orders."
            },
            {
              "type": "design",
              "question": "Design the order batching system where one partner picks up multiple orders from nearby restaurants.",
              "answer": "Trigger: when 2+ orders within 1km radius have destination within 2km of each other. Constraints: max 2 orders per batch, max 15 min delivery delay per order. Algorithm: at assignment time, check pending unassigned orders near same restaurant. Score batch benefit (distance saved vs delay added). Show customer 'Your order is part of a multi-order delivery' with adjusted ETA."
            },
            {
              "type": "estimation",
              "question": "A partner makes 12 deliveries in an 8-hour shift. Average distance per delivery: 4km pickup + 3km delivery. Fuel cost?",
              "answer": "Total distance: 12 × (4 + 3) = 84 km/day. Scooter mileage: ~40 km/l. Fuel: 84/40 = 2.1 liters. At ₹100/l: ₹210/day. As % of earnings (12 × ₹40 delivery fee = ₹480 base): fuel is 44% of base delivery fee. Hence need per-km compensation."
            },
            {
              "type": "tricky",
              "question": "Why not always assign the closest delivery partner?",
              "answer": "Closest partner might: have full load (2 orders already), have low acceptance rate (likely to reject, wasting time), be heading away from restaurant, have poor rating. Multi-factor scoring balances proximity with reliability. Also, assigning closest may leave a zone without partners for subsequent orders."
            },
            {
              "type": "design",
              "question": "Design the refund and complaint resolution system.",
              "answer": "Triggers: missing items, wrong order, quality issues, late delivery. Auto-refund: if delivery > 30 min late, auto-credit 20% as Zomato credits. Review required: >₹500 refunds need manual approval. Photo evidence for quality complaints. ML model flags repeat complainers (potential abuse). Escalation: auto → agent → supervisor. SLA: resolve within 4 hours."
            },
            {
              "type": "scenario",
              "question": "A restaurant's kitchen goes offline mid-order (power outage). 15 orders are in PREPARING state. What's the system response?",
              "answer": "1) Restaurant's tablet loses connectivity — heartbeat missed. 2) After 3 min timeout, flag restaurant as 'Unreachable'. 3) Halt new order acceptance. 4) For in-progress orders: agent calls restaurant to verify. 5) If confirmed down: cancel + full refund + apology coupon. 6) Notify assigned partners (cancel pickup). 7) Send push notification to affected customers. 8) Resume when heartbeat restores."
            },
            {
              "type": "output",
              "question": "Surge multiplier = max(1, demand_ratio × 0.5 + 0.5) capped at 2. Zone has 50 orders and 15 partners. Normal ratio is 2:1. What's the surge multiplier?",
              "answer": "Current ratio = 50/15 = 3.33. Demand_ratio = current/normal = 3.33/2 = 1.67. Multiplier = max(1, 1.67 × 0.5 + 0.5) = max(1, 1.335) = 1.335. Capped at 2 → final multiplier = 1.34x. Delivery fee: ₹30 × 1.34 = ₹40.2 ≈ ₹40."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Order lifecycle state machine",
              "code": "class OrderFSM {\n  constructor(orderId) {\n    this.orderId = orderId;\n    this.state = 'PLACED';\n    this.transitions = {\n      PLACED: ['ACCEPTED', 'REJECTED'],\n      ACCEPTED: ['PREPARING'],\n      PREPARING: ['READY', 'CANCELLED'],\n      READY: ['PICKED_UP'],\n      PICKED_UP: ['EN_ROUTE'],\n      EN_ROUTE: ['DELIVERED'],\n    };\n    this.history = [{ state: 'PLACED', time: new Date().toISOString() }];\n  }\n  transition(to) {\n    if (!this.transitions[this.state]?.includes(to)) {\n      return `❌ Cannot go from ${this.state} to ${to}`;\n    }\n    this.state = to;\n    this.history.push({ state: to, time: new Date().toISOString() });\n    return `✅ ${this.orderId}: ${to}`;\n  }\n}\n\nconst order = new OrderFSM('ORD-001');\nconsole.log(order.transition('ACCEPTED'));\nconsole.log(order.transition('PREPARING'));\nconsole.log(order.transition('DELIVERED')); // invalid\nconsole.log(order.transition('READY'));\nconsole.log(order.transition('PICKED_UP'));\nconsole.log(order.transition('EN_ROUTE'));\nconsole.log(order.transition('DELIVERED'));\nconsole.log('Steps:', order.history.length);",
              "output": "✅ ORD-001: ACCEPTED\n✅ ORD-001: PREPARING\n❌ Cannot go from PREPARING to DELIVERED\n✅ ORD-001: READY\n✅ ORD-001: PICKED_UP\n✅ ORD-001: EN_ROUTE\n✅ ORD-001: DELIVERED\nSteps: 7"
            },
            {
              "question": "Program 2: Restaurant geosearch with geohash",
              "code": "function simpleGeohash(lat, lng, precision = 4) {\n  // Simplified geohash for demo\n  return `${Math.floor(lat * precision)}:${Math.floor(lng * precision)}`;\n}\n\nclass RestaurantIndex {\n  constructor() { this.index = new Map(); this.all = []; }\n  add(restaurant) {\n    this.all.push(restaurant);\n    const hash = simpleGeohash(restaurant.lat, restaurant.lng);\n    if (!this.index.has(hash)) this.index.set(hash, []);\n    this.index.get(hash).push(restaurant);\n  }\n  search(lat, lng, maxKm) {\n    const hash = simpleGeohash(lat, lng);\n    const candidates = this.index.get(hash) || [];\n    return candidates\n      .map(r => ({\n        ...r,\n        distKm: +((Math.sqrt(Math.pow(r.lat-lat, 2) + Math.pow(r.lng-lng, 2)) * 111).toFixed(2)),\n      }))\n      .filter(r => r.distKm <= maxKm)\n      .sort((a, b) => a.distKm - b.distKm);\n  }\n}\n\nconst idx = new RestaurantIndex();\nidx.add({ id: 'r1', name: 'Pizza Place', lat: 28.614, lng: 77.209, rating: 4.5 });\nidx.add({ id: 'r2', name: 'Biryani House', lat: 28.615, lng: 77.211, rating: 4.2 });\nidx.add({ id: 'r3', name: 'Sushi Bar', lat: 28.700, lng: 77.300, rating: 4.8 }); // far\n\nconsole.log(idx.search(28.613, 77.209, 5));",
              "output": "[\n  { id: 'r1', name: 'Pizza Place', lat: 28.614, lng: 77.209, rating: 4.5, distKm: 0.11 },\n  { id: 'r2', name: 'Biryani House', lat: 28.615, lng: 77.211, rating: 4.2, distKm: 0.30 }\n]"
            },
            {
              "question": "Program 3: Delivery partner scoring and assignment",
              "code": "function scoreAndAssign(restaurant, partners, maxDist = 3) {\n  const scored = partners\n    .map(p => {\n      const dist = Math.sqrt(Math.pow(p.lat - restaurant.lat, 2) + Math.pow(p.lng - restaurant.lng, 2)) * 111;\n      if (dist > maxDist) return null;\n      const score = (1 - dist/maxDist) * 40 + p.acceptRate * 20 + (1 - p.load/3) * 20 + (p.rating/5) * 20;\n      return { id: p.id, dist: dist.toFixed(2) + 'km', score: +score.toFixed(1), load: p.load };\n    })\n    .filter(Boolean)\n    .sort((a, b) => b.score - a.score);\n  \n  return scored.length > 0\n    ? { assigned: scored[0], candidates: scored.length }\n    : { assigned: null, reason: 'No partners in range' };\n}\n\nconsole.log(scoreAndAssign(\n  { lat: 28.614, lng: 77.209 },\n  [\n    { id: 'dp1', lat: 28.615, lng: 77.210, acceptRate: 0.95, load: 0, rating: 4.8 },\n    { id: 'dp2', lat: 28.618, lng: 77.215, acceptRate: 0.80, load: 2, rating: 4.0 },\n    { id: 'dp3', lat: 28.700, lng: 77.300, acceptRate: 0.99, load: 0, rating: 5.0 }, // too far\n  ]\n));",
              "output": "{\n  assigned: { id: 'dp1', dist: '0.15km', score: 96.8, load: 0 },\n  candidates: 2\n}"
            },
            {
              "question": "Program 4: Surge pricing calculator",
              "code": "function calculateSurge(zones) {\n  return zones.map(zone => {\n    const demandRatio = zone.activeOrders / (zone.availablePartners || 1);\n    const normalRatio = 2; // baseline\n    let multiplier = demandRatio / normalRatio * 0.5 + 0.5;\n    multiplier = Math.max(1, Math.min(2, multiplier)); // clamp 1-2x\n    multiplier = +multiplier.toFixed(2);\n    const baseFee = 30;\n    return {\n      zone: zone.name,\n      demand: zone.activeOrders,\n      supply: zone.availablePartners,\n      ratio: +demandRatio.toFixed(1),\n      multiplier,\n      fee: Math.round(baseFee * multiplier),\n    };\n  });\n}\n\nconsole.log(calculateSurge([\n  { name: 'Downtown', activeOrders: 100, availablePartners: 20 },\n  { name: 'Suburbs', activeOrders: 20, availablePartners: 25 },\n  { name: 'Airport', activeOrders: 50, availablePartners: 5 },\n]));",
              "output": "[\n  { zone: 'Downtown', demand: 100, supply: 20, ratio: 5, multiplier: 1.75, fee: 53 },\n  { zone: 'Suburbs', demand: 20, supply: 25, ratio: 0.8, multiplier: 1, fee: 30 },\n  { zone: 'Airport', demand: 50, supply: 5, ratio: 10, multiplier: 2, fee: 60 }\n]"
            },
            {
              "question": "Program 5: ETA calculator",
              "code": "function calculateETA(order) {\n  const { prepTimeMin, partnerToRestaurantMin, restaurantToCustomerMin } = order;\n  // Partner arrives during prep, or waits\n  const pickupWait = Math.max(0, partnerToRestaurantMin - prepTimeMin);\n  const totalMin = prepTimeMin + pickupWait + restaurantToCustomerMin;\n  return {\n    prepTime: prepTimeMin + ' min',\n    pickupTime: partnerToRestaurantMin + ' min',\n    deliveryTime: restaurantToCustomerMin + ' min',\n    wait: pickupWait + ' min',\n    totalETA: totalMin + ' min',\n    breakdown: `Prep(${prepTimeMin}) + Wait(${pickupWait}) + Delivery(${restaurantToCustomerMin}) = ${totalMin} min`,\n  };\n}\n\nconsole.log(calculateETA({ prepTimeMin: 20, partnerToRestaurantMin: 10, restaurantToCustomerMin: 15 }));\nconsole.log(calculateETA({ prepTimeMin: 10, partnerToRestaurantMin: 25, restaurantToCustomerMin: 12 }));",
              "output": "{\n  prepTime: '20 min', pickupTime: '10 min', deliveryTime: '15 min',\n  wait: '0 min', totalETA: '35 min',\n  breakdown: 'Prep(20) + Wait(0) + Delivery(15) = 35 min'\n}\n{\n  prepTime: '10 min', pickupTime: '25 min', deliveryTime: '12 min',\n  wait: '15 min', totalETA: '37 min',\n  breakdown: 'Prep(10) + Wait(15) + Delivery(12) = 37 min'\n}"
            },
            {
              "question": "Program 6: Cart validator",
              "code": "function validateCart(cart, restaurant) {\n  const errors = [];\n  // Check restaurant open\n  const hour = new Date().getHours();\n  if (hour < restaurant.openHour || hour >= restaurant.closeHour) {\n    errors.push('Restaurant is currently closed');\n  }\n  // Check items available\n  cart.items.forEach(item => {\n    const menuItem = restaurant.menu.find(m => m.id === item.id);\n    if (!menuItem) errors.push(`Item '${item.name}' not found`);\n    else if (!menuItem.available) errors.push(`'${menuItem.name}' is currently unavailable`);\n    else if (item.qty > 10) errors.push(`Max 10 qty per item (${item.name})`);\n  });\n  // Check delivery distance\n  if (cart.distanceKm > restaurant.maxDeliveryKm) {\n    errors.push(`Delivery address too far (${cart.distanceKm}km > ${restaurant.maxDeliveryKm}km max)`);\n  }\n  // Min order\n  const total = cart.items.reduce((s, i) => s + (restaurant.menu.find(m => m.id === i.id)?.price || 0) * i.qty, 0);\n  if (total < restaurant.minOrder) errors.push(`Minimum order ₹${restaurant.minOrder} (current: ₹${total})`);\n  \n  return errors.length === 0 ? { valid: true, total } : { valid: false, errors };\n}\n\nconst restaurant = {\n  openHour: 10, closeHour: 23, maxDeliveryKm: 7, minOrder: 200,\n  menu: [\n    { id: 'm1', name: 'Paneer Tikka', price: 280, available: true },\n    { id: 'm2', name: 'Dal Makhani', price: 220, available: false },\n  ],\n};\n\nconsole.log(validateCart({ items: [{ id: 'm1', name: 'Paneer Tikka', qty: 1 }], distanceKm: 5 }, restaurant));\nconsole.log(validateCart({ items: [{ id: 'm2', name: 'Dal Makhani', qty: 1 }], distanceKm: 10 }, restaurant));",
              "output": "{ valid: true, total: 280 }\n{ valid: false, errors: [\"'Dal Makhani' is currently unavailable\", 'Delivery address too far (10km > 7km max)'] }"
            },
            {
              "question": "Program 7: Real-time GPS tracking simulator",
              "code": "class DeliveryTracker {\n  constructor() { this.tracks = new Map(); }\n  \n  updateLocation(partnerId, lat, lng) {\n    if (!this.tracks.has(partnerId)) this.tracks.set(partnerId, []);\n    this.tracks.get(partnerId).push({ lat, lng, time: Date.now() });\n  }\n  \n  getETA(partnerId, destLat, destLng) {\n    const positions = this.tracks.get(partnerId);\n    if (!positions || positions.length < 2) return { eta: 'calculating...' };\n    const last = positions[positions.length - 1];\n    const prev = positions[positions.length - 2];\n    const distMoved = Math.sqrt(Math.pow(last.lat - prev.lat, 2) + Math.pow(last.lng - prev.lng, 2)) * 111;\n    const timeDelta = (last.time - prev.time) / 60000; // min\n    const speed = distMoved / timeDelta; // km/min\n    const remaining = Math.sqrt(Math.pow(destLat - last.lat, 2) + Math.pow(destLng - last.lng, 2)) * 111;\n    const etaMin = speed > 0 ? (remaining / speed).toFixed(1) : '∞';\n    return { speed: speed.toFixed(2) + ' km/min', remaining: remaining.toFixed(2) + ' km', eta: etaMin + ' min' };\n  }\n}\n\nconst tracker = new DeliveryTracker();\ntracker.updateLocation('dp1', 28.620, 77.215);\ntracker.tracks.get('dp1')[0].time -= 60000; // simulate 1 min ago\ntracker.updateLocation('dp1', 28.616, 77.211);\nconsole.log(tracker.getETA('dp1', 28.614, 77.209));",
              "output": "{ speed: '0.59 km/min', remaining: '0.30 km', eta: '0.5 min' }"
            },
            {
              "question": "Program 8: Restaurant rating aggregator",
              "code": "class RatingService {\n  constructor() { this.ratings = new Map(); }\n  addRating(restaurantId, { food, delivery, customerId }) {\n    if (!this.ratings.has(restaurantId)) this.ratings.set(restaurantId, []);\n    this.ratings.get(restaurantId).push({ food, delivery, customerId, time: Date.now() });\n  }\n  getAggregate(restaurantId) {\n    const all = this.ratings.get(restaurantId) || [];\n    if (all.length === 0) return { rating: 'No ratings', count: 0 };\n    const avgFood = all.reduce((s, r) => s + r.food, 0) / all.length;\n    const avgDelivery = all.reduce((s, r) => s + r.delivery, 0) / all.length;\n    const overall = avgFood * 0.7 + avgDelivery * 0.3;\n    return {\n      overall: +overall.toFixed(1),\n      food: +avgFood.toFixed(1),\n      delivery: +avgDelivery.toFixed(1),\n      count: all.length,\n      distribution: [1,2,3,4,5].map(s => ({ stars: s, count: all.filter(r => Math.round(r.food) === s).length })),\n    };\n  }\n}\n\nconst rs = new RatingService();\nrs.addRating('r1', { food: 5, delivery: 4, customerId: 'c1' });\nrs.addRating('r1', { food: 4, delivery: 5, customerId: 'c2' });\nrs.addRating('r1', { food: 3, delivery: 3, customerId: 'c3' });\nrs.addRating('r1', { food: 5, delivery: 4, customerId: 'c4' });\nconsole.log(rs.getAggregate('r1'));",
              "output": "{\n  overall: 4.0,\n  food: 4.3,\n  delivery: 4.0,\n  count: 4,\n  distribution: [\n    { stars: 1, count: 0 },\n    { stars: 2, count: 0 },\n    { stars: 3, count: 1 },\n    { stars: 4, count: 1 },\n    { stars: 5, count: 2 }\n  ]\n}"
            },
            {
              "question": "Program 9: Order batching optimizer",
              "code": "function batchOrders(pendingOrders, maxBatchSize = 2, maxExtraKm = 2) {\n  const batches = [];\n  const used = new Set();\n  \n  for (let i = 0; i < pendingOrders.length; i++) {\n    if (used.has(i)) continue;\n    const batch = [pendingOrders[i]];\n    used.add(i);\n    for (let j = i + 1; j < pendingOrders.length && batch.length < maxBatchSize; j++) {\n      if (used.has(j)) continue;\n      const restDist = Math.sqrt(\n        Math.pow(pendingOrders[i].restLat - pendingOrders[j].restLat, 2) +\n        Math.pow(pendingOrders[i].restLng - pendingOrders[j].restLng, 2)\n      ) * 111;\n      if (restDist <= maxExtraKm) {\n        batch.push(pendingOrders[j]);\n        used.add(j);\n      }\n    }\n    batches.push({ orders: batch.map(o => o.id), size: batch.length });\n  }\n  return batches;\n}\n\nconsole.log(batchOrders([\n  { id: 'O1', restLat: 28.614, restLng: 77.209 },\n  { id: 'O2', restLat: 28.615, restLng: 77.210 }, // near O1\n  { id: 'O3', restLat: 28.700, restLng: 77.300 }, // far\n  { id: 'O4', restLat: 28.614, restLng: 77.208 }, // near O1 but batch full\n]));",
              "output": "[\n  { orders: [ 'O1', 'O2' ], size: 2 },\n  { orders: [ 'O3' ], size: 1 },\n  { orders: [ 'O4' ], size: 1 }\n]"
            },
            {
              "question": "Program 10: Refund policy engine",
              "code": "function processRefund(complaint) {\n  const policies = {\n    'missing_item': { autoRefund: true, refundPercent: 100, scope: 'item', maxAuto: 500 },\n    'wrong_order': { autoRefund: true, refundPercent: 100, scope: 'full', maxAuto: 1000 },\n    'late_delivery': { autoRefund: true, refundPercent: 20, scope: 'full', maxAuto: 200 },\n    'quality_issue': { autoRefund: false, refundPercent: 50, scope: 'item', maxAuto: 0 },\n    'not_delivered': { autoRefund: true, refundPercent: 100, scope: 'full', maxAuto: 2000 },\n  };\n  \n  const policy = policies[complaint.type];\n  if (!policy) return { action: 'ESCALATE', reason: 'Unknown complaint type' };\n  \n  const refundAmount = policy.scope === 'full'\n    ? complaint.orderTotal * (policy.refundPercent / 100)\n    : complaint.itemTotal * (policy.refundPercent / 100);\n  \n  if (policy.autoRefund && refundAmount <= policy.maxAuto) {\n    return { action: 'AUTO_REFUND', amount: `₹${Math.round(refundAmount)}`, method: 'Zomato Credits' };\n  }\n  return { action: 'MANUAL_REVIEW', amount: `₹${Math.round(refundAmount)}`, reason: 'Exceeds auto-limit or requires review' };\n}\n\nconsole.log(processRefund({ type: 'late_delivery', orderTotal: 500, itemTotal: 0 }));\nconsole.log(processRefund({ type: 'missing_item', orderTotal: 800, itemTotal: 280 }));\nconsole.log(processRefund({ type: 'quality_issue', orderTotal: 600, itemTotal: 350 }));",
              "output": "{ action: 'AUTO_REFUND', amount: '₹100', method: 'Zomato Credits' }\n{ action: 'AUTO_REFUND', amount: '₹280', method: 'Zomato Credits' }\n{ action: 'MANUAL_REVIEW', amount: '₹175', reason: 'Exceeds auto-limit or requires review' }"
            }
          ]
        },
        {
          "id": "bookmyshow-lld",
          "title": "BookMyShow: Ticket Booking Platform",
          "category": "Company LLD",
          "description": "Low-level design of BookMyShow's seat selection, concurrent booking, payment handling, and show management system.",
          "explanation": "BookMyShow handles millions of concurrent users during popular movie/event launches. The core challenge is managing seat inventory with strict consistency — no double-booking — while providing responsive user experience under extreme load.\n\n**Core Entities**:\n- Movie/Event → has multiple Shows\n- Show → specific date/time at a Venue\n- Venue → has multiple Screens\n- Screen → has Seats (with categories: Silver, Gold, Platinum)\n- Booking → links User to Seats for a Show\n\n**Seat Booking Flow**:\n1. User searches for movie/event → sees available shows.\n2. Selects show → sees seat map with availability (available/booked/locked).\n3. Selects seats → System temporarily locks seats (5-10 minute hold).\n4. Proceeds to payment → Payment processed within lock timeout.\n5. Payment success → Booking confirmed, seats marked as booked.\n6. Payment failure/timeout → Seats released back to available.\n\n**Concurrency Challenge — The Hot Seat Problem**:\nWhen a blockbuster launches, 100K+ users try to book simultaneously. Without proper concurrency control:\n- Two users see seat A1 as available.\n- Both click book → double booking.\n\n**Solutions**:\n1. **Pessimistic Locking**: Lock seats in DB when user selects them. Others see them as locked. Simple but blocks aggressively.\n2. **Optimistic Locking**: Allow selection, check at commit time. Use version numbers. If version changed → conflict → retry.\n3. **Temporary Hold with TTL**: Redis-based. SETNX(seat_key, user_id, TTL=600s). If set succeeds → seat is yours for 10 min. If fails → seat taken.\n\n**Recommended: Temporary Hold + Optimistic Locking**:\n- Lock in Redis (fast, TTL auto-expires).\n- Confirm in DB with optimistic lock (version check).\n- Background job cleans expired holds.\n\n**Pricing**:\n- Base price per seat category.\n- Convenience fee (flat or %).\n- Dynamic pricing: popular shows/times get premium.\n- Offers: coupons, credit card discounts applied at checkout.\n\n**Scale Considerations**:\n- Read-heavy: seat map viewed 100x per booking. Cache aggressively.\n- Write-hot: limited seats, many writers. Serialize writes per show.\n- Waitlist: if show sells out, allow waitlist with auto-assign on cancellation.",
          "code": "// Seat management with temporary hold\nclass SeatManager {\n  constructor(seats) {\n    this.seats = new Map();\n    seats.forEach(s => this.seats.set(s.id, { ...s, status: 'AVAILABLE', heldBy: null, heldAt: null }));\n    this.HOLD_TIMEOUT_MS = 600000; // 10 minutes\n  }\n\n  getSeatMap() {\n    this.releaseExpired();\n    return [...this.seats.values()].map(s => ({\n      id: s.id, category: s.category, price: s.price,\n      status: s.status,\n    }));\n  }\n\n  holdSeats(userId, seatIds) {\n    this.releaseExpired();\n    const results = [];\n    for (const id of seatIds) {\n      const seat = this.seats.get(id);\n      if (!seat) { results.push({ id, success: false, reason: 'Not found' }); continue; }\n      if (seat.status !== 'AVAILABLE') { results.push({ id, success: false, reason: `Already ${seat.status}` }); continue; }\n      seat.status = 'HELD';\n      seat.heldBy = userId;\n      seat.heldAt = Date.now();\n      results.push({ id, success: true });\n    }\n    const allSuccess = results.every(r => r.success);\n    if (!allSuccess) {\n      // Rollback partial holds\n      results.filter(r => r.success).forEach(r => {\n        const seat = this.seats.get(r.id);\n        seat.status = 'AVAILABLE'; seat.heldBy = null; seat.heldAt = null;\n      });\n    }\n    return { success: allSuccess, results };\n  }\n\n  confirmBooking(userId, seatIds) {\n    for (const id of seatIds) {\n      const seat = this.seats.get(id);\n      if (!seat || seat.heldBy !== userId) return { success: false, reason: 'Seat not held by user' };\n    }\n    seatIds.forEach(id => {\n      const seat = this.seats.get(id);\n      seat.status = 'BOOKED';\n    });\n    return { success: true, booked: seatIds };\n  }\n\n  releaseHold(userId) {\n    for (const seat of this.seats.values()) {\n      if (seat.heldBy === userId && seat.status === 'HELD') {\n        seat.status = 'AVAILABLE'; seat.heldBy = null; seat.heldAt = null;\n      }\n    }\n  }\n\n  releaseExpired() {\n    const now = Date.now();\n    for (const seat of this.seats.values()) {\n      if (seat.status === 'HELD' && (now - seat.heldAt) > this.HOLD_TIMEOUT_MS) {\n        seat.status = 'AVAILABLE'; seat.heldBy = null; seat.heldAt = null;\n      }\n    }\n  }\n}\n\nconst sm = new SeatManager([\n  { id: 'A1', category: 'Gold', price: 300 },\n  { id: 'A2', category: 'Gold', price: 300 },\n  { id: 'B1', category: 'Silver', price: 200 },\n]);\nconsole.log('Hold A1+A2 for user1:', sm.holdSeats('user1', ['A1', 'A2']));\nconsole.log('Hold A1 for user2:', sm.holdSeats('user2', ['A1'])); // fails\nconsole.log('Confirm user1:', sm.confirmBooking('user1', ['A1', 'A2']));\nconsole.log('Seat map:', sm.getSeatMap());",
          "example": "// Concurrent booking simulation with optimistic locking\nclass BookingService {\n  constructor() {\n    this.seatVersions = new Map(); // seatId -> version\n    this.bookings = [];\n  }\n\n  initSeats(seatIds) {\n    seatIds.forEach(id => this.seatVersions.set(id, { version: 0, status: 'AVAILABLE', bookedBy: null }));\n  }\n\n  attemptBook(userId, seatId) {\n    const seat = this.seatVersions.get(seatId);\n    if (!seat) return { success: false, reason: 'Seat not found' };\n\n    // Read current version\n    const readVersion = seat.version;\n\n    // Simulate processing delay\n    if (seat.status !== 'AVAILABLE') return { success: false, reason: 'Seat unavailable', version: seat.version };\n\n    // Optimistic lock check\n    if (seat.version !== readVersion) return { success: false, reason: 'Concurrent modification' };\n\n    // Commit\n    seat.version++;\n    seat.status = 'BOOKED';\n    seat.bookedBy = userId;\n    this.bookings.push({ userId, seatId, confirmedAt: Date.now() });\n    return { success: true, version: seat.version };\n  }\n}\n\nconst bs = new BookingService();\nbs.initSeats(['A1', 'A2', 'A3']);\nconsole.log('User1 books A1:', bs.attemptBook('user1', 'A1'));\nconsole.log('User2 books A1:', bs.attemptBook('user2', 'A1')); // fails\nconsole.log('User2 books A2:', bs.attemptBook('user2', 'A2')); // succeeds\nconsole.log('Bookings:', bs.bookings);",
          "useCase": "Movie/event ticket booking, airline seat reservation, hotel room booking, appointment scheduling, any system requiring exclusive resource allocation under concurrency.",
          "interviewQuestions": [
            {
              "question": "How do you prevent double-booking of the same seat?",
              "answer": "Three-layer defense: 1) Redis SETNX for temporary hold (fast, atomic). 2) DB row-level lock or optimistic locking (version column) at confirm time. 3) Unique constraint on (show_id, seat_id) in bookings table. Even if Redis and app logic both fail, DB constraint prevents double booking."
            },
            {
              "question": "Why use temporary hold instead of immediate booking?",
              "answer": "Users need 5-10 minutes to complete payment. Without hold, seats would be locked as 'booked' but payment might fail, requiring cancellation. With hold: seat is reserved for limited time, auto-releases if payment fails/expires. Better UX and inventory utilization."
            },
            {
              "question": "How do you handle 100K concurrent users trying to book for a popular show?",
              "answer": "1) CDN for static content. 2) Virtual waiting room (queue) before seat selection. 3) Rate limit API per user. 4) Seat map cached in Redis, invalidated on changes. 5) Partition seat locks by screen/zone. 6) Horizontal scale stateless app servers. 7) Single writer per show for consistency (serialize via Redis/queue)."
            },
            {
              "question": "What happens if payment takes longer than the hold timeout?",
              "answer": "Options: 1) Extend hold once if payment is in-progress (detected via payment webhook). 2) Notify user at 2-minute warning. 3) If expired, check if seats are still available — if yes, re-hold and retry payment. 4) If seats taken, show alternatives. 5) Refund if payment went through but hold expired."
            },
            {
              "question": "How do you implement a waitlist for sold-out shows?",
              "answer": "When all seats booked, allow users to join waitlist (queue per show). On cancellation, auto-assign released seats to waitlisted user #1. Notify via push/SMS with 5-minute accept window. If not accepted, move to next user. Max waitlist size: 50 per show."
            },
            {
              "question": "How do you design the seat map for fast rendering?",
              "answer": "Pre-compute seat layout (row, column, category) per screen — stored as static JSON. Dynamic overlay: seat status (available/held/booked) from Redis. Client fetches layout once (cacheable), polls status every 5 seconds. WebSocket for real-time updates during high-demand shows."
            },
            {
              "question": "How do you handle partial failures in multi-seat booking?",
              "answer": "Atomic transaction: either all seats are held/booked or none. If any seat fails to lock, rollback all successful locks. In Redis: use Lua script for atomic multi-key SETNX. In DB: single transaction with row locks. Never allow partial bookings — user must select available replacement seats."
            },
            {
              "question": "How does dynamic pricing work for shows?",
              "answer": "Price factors: demand (fill rate), show timing (evening premium), day (weekend premium), seat category, days until show (early bird discount). Formula: base_price × demand_multiplier × time_multiplier × category_multiplier. Recalculate hourly. Cap multiplier at 2x base. Show price transparency to user."
            },
            {
              "question": "How do you prevent scalping/bot bookings?",
              "answer": "1) CAPTCHA at checkout. 2) Rate limiting per IP and user. 3) Device fingerprinting. 4) Max 10 tickets per user per show. 5) Pattern detection: same user booking then canceling repeatedly. 6) Payment verification required (no free holds). 7) Virtual waiting room with random queue position."
            },
            {
              "question": "How do you handle seat map for a stadium with 50,000 seats?",
              "answer": "Multi-level zoom: section overview → block → individual seats. Only load seat-level data when user zooms into a block. Aggregate status at block level: 'mostly available', 'filling fast', 'sold out'. WebSocket updates at block level. Reduce payload: encode status as bitfield (2 bits per seat)."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design the seat locking system using Redis.",
              "answer": "Key: `lock:{show_id}:{seat_id}`. Value: `{user_id}:{timestamp}`. Command: `SET lock:s1:A1 user123 NX EX 600`. NX = set only if not exists (atomic). EX 600 = expire in 10 min. To release: `DEL lock:s1:A1` (only if value matches user_id — use Lua script for atomicity). Multi-seat: Lua script doing SETNX on all keys atomically."
            },
            {
              "type": "estimation",
              "question": "Popular movie opening day: 5000 screens × 3 shows × 200 seats. 80% fill rate. How many bookings? Average 2.5 tickets per booking.",
              "answer": "Total seats: 5000 × 3 × 200 = 3M. At 80% fill: 2.4M tickets. Bookings: 2.4M / 2.5 = 960K bookings. Over 8 hours: 120K bookings/hour = 33/second average. Peak (first hour, 40% of bookings): 384K/hour = 107/second."
            },
            {
              "type": "scenario",
              "question": "Payment gateway goes down for 5 minutes during a popular show's opening. Thousands of users have seats held. What happens?",
              "answer": "1) Holds remain until TTL expires (10 min). 2) Show 'Payment temporarily unavailable' — retry in 30s. 3) Extend hold TTL by 5 min for affected users. 4) Queue payment retries. 5) When gateway recovers, process queued payments. 6) Seats held but not paid release after extended TTL. 7) Send notifications to affected users."
            },
            {
              "type": "tricky",
              "question": "Why not use database locks directly instead of Redis for seat holds?",
              "answer": "DB locks are persistent and heavyweight. If app crashes while holding DB lock, seats stay locked until timeout/manual release. Redis TTL auto-expires. Redis is faster (in-memory, O(1) operations). DB can't efficiently handle 100K concurrent SETNX-like operations. Use Redis for holds, DB for confirmed bookings."
            },
            {
              "type": "debug",
              "question": "Users report seeing 'sold out' for a show, but admin panel shows 30% seats still available. What could be wrong?",
              "answer": "1) Seats are HELD (not booked) — held seats appear unavailable to other users but aren't 'sold'. 2) Cache staleness: seat map cache not updated after hold release. 3) Category mismatch: user filtering specific category (Gold) which is full, but other categories available. 4) Geo-restriction: user's city filter incorrect."
            },
            {
              "type": "design",
              "question": "Design the virtual waiting room for high-demand shows.",
              "answer": "On show announcement: enable waiting room. Users enter queue and get position. Queue stored in Redis sorted set (score = join time). When booking opens: dequeue N users every 30 seconds (N = capacity). Each dequeued user gets 5-min booking window. Show estimated wait time. Random initial position (prevent advantage to page refresh). CAPTCHA at entry."
            },
            {
              "type": "estimation",
              "question": "A screen has 300 seats. Seat map JSON with status for each seat. How much data per API call? With 10K concurrent users polling every 5s, what's the load?",
              "answer": "Per seat: {id, status, category} ≈ 30 bytes. 300 seats = 9KB/response. With gzip: ~2KB. 10K users × 1 request/5s = 2K req/s. Bandwidth: 2K × 2KB = 4MB/s. Manageable. Optimize: send only changes (delta updates via WebSocket) = ~100 bytes per update."
            },
            {
              "type": "design",
              "question": "Design the cancellation and refund system.",
              "answer": "Cancellation window: >24h before show = 100% refund - convenience fee. 12-24h = 50% refund. <12h = no refund. Process: mark booking as cancelled → release seats (set AVAILABLE) → trigger refund via payment gateway → notify waitlisted users. Refund modes: original payment method or platform credits (instant). Full automation, no manual approval for within-policy cancellations."
            },
            {
              "type": "scenario",
              "question": "Show gets cancelled by venue 2 hours before start time. 500 bookings exist. System response?",
              "answer": "1) Admin triggers show cancellation. 2) Batch: mark all bookings as CANCELLED_BY_VENUE. 3) Full refund + convenience fee for all bookings. 4) Push notification + SMS to all booked users. 5) Offer complimentary voucher for inconvenience. 6) Remove show from listings. 7) Release all held seats. 8) Audit log for financial reconciliation."
            },
            {
              "type": "output",
              "question": "Convenience fee: 18% GST on base amount + ₹30 internet handling. Base ticket: ₹350 Gold × 2 seats. What is the total?",
              "answer": "Base: 350 × 2 = ₹700. GST on base: 700 × 0.18 = ₹126. Handling: ₹30. Total = 700 + 126 + 30 = ₹856."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Atomic seat hold with rollback",
              "code": "class AtomicSeatLock {\n  constructor() { this.locks = new Map(); }\n  \n  holdMultiple(userId, seatIds, ttlMs = 600000) {\n    // Check all available first\n    for (const id of seatIds) {\n      if (this.locks.has(id)) {\n        return { success: false, failedAt: id, reason: 'Already held' };\n      }\n    }\n    // Lock all atomically\n    const expiry = Date.now() + ttlMs;\n    seatIds.forEach(id => this.locks.set(id, { userId, expiry }));\n    return { success: true, held: seatIds, expiresIn: ttlMs / 1000 + 's' };\n  }\n  \n  release(userId) {\n    let released = 0;\n    for (const [id, lock] of this.locks) {\n      if (lock.userId === userId) { this.locks.delete(id); released++; }\n    }\n    return { released };\n  }\n  \n  status() {\n    return [...this.locks.entries()].map(([id, l]) => ({ seat: id, user: l.userId }));\n  }\n}\n\nconst lock = new AtomicSeatLock();\nconsole.log(lock.holdMultiple('u1', ['A1', 'A2']));\nconsole.log(lock.holdMultiple('u2', ['A2', 'A3'])); // fails at A2\nconsole.log(lock.holdMultiple('u2', ['A3', 'A4'])); // succeeds\nconsole.log(lock.status());",
              "output": "{ success: true, held: [ 'A1', 'A2' ], expiresIn: '600s' }\n{ success: false, failedAt: 'A2', reason: 'Already held' }\n{ success: true, held: [ 'A3', 'A4' ], expiresIn: '600s' }\n[\n  { seat: 'A1', user: 'u1' },\n  { seat: 'A2', user: 'u1' },\n  { seat: 'A3', user: 'u2' },\n  { seat: 'A4', user: 'u2' }\n]"
            },
            {
              "question": "Program 2: Seat map renderer",
              "code": "function renderSeatMap(seats, columns) {\n  const rows = [];\n  for (let i = 0; i < seats.length; i += columns) {\n    const row = seats.slice(i, i + columns).map(s => {\n      const icon = s.status === 'AVAILABLE' ? '🟢' : s.status === 'HELD' ? '🟡' : '🔴';\n      return `${icon}${s.id}`;\n    });\n    rows.push(row.join('  '));\n  }\n  const legend = '🟢 Available  🟡 Held  🔴 Booked';\n  return rows.join('\\n') + '\\n' + legend;\n}\n\nconst seats = [\n  { id: 'A1', status: 'BOOKED' },  { id: 'A2', status: 'BOOKED' },\n  { id: 'A3', status: 'AVAILABLE' }, { id: 'A4', status: 'HELD' },\n  { id: 'B1', status: 'AVAILABLE' }, { id: 'B2', status: 'AVAILABLE' },\n  { id: 'B3', status: 'BOOKED' },   { id: 'B4', status: 'AVAILABLE' },\n];\nconsole.log(renderSeatMap(seats, 4));",
              "output": "🔴A1  🔴A2  🟢A3  🟡A4\n🟢B1  🟢B2  🔴B3  🟢B4\n🟢 Available  🟡 Held  🔴 Booked"
            },
            {
              "question": "Program 3: Booking price calculator",
              "code": "function calculatePrice(seats, offers, conveniencePct = 18, handlingFee = 30) {\n  const base = seats.reduce((s, seat) => s + seat.price, 0);\n  let discount = 0;\n  offers.forEach(offer => {\n    if (offer.type === 'percent') discount += base * (offer.value / 100);\n    if (offer.type === 'flat') discount += offer.value;\n  });\n  discount = Math.min(discount, base); // can't go negative\n  const afterDiscount = base - discount;\n  const convenience = Math.round(afterDiscount * (conveniencePct / 100));\n  const total = afterDiscount + convenience + handlingFee;\n  return {\n    base: `₹${base}`,\n    discount: `₹${Math.round(discount)}`,\n    subtotal: `₹${afterDiscount}`,\n    convenience: `₹${convenience} (${conveniencePct}%)`,\n    handling: `₹${handlingFee}`,\n    total: `₹${total}`,\n  };\n}\n\nconsole.log(calculatePrice(\n  [{ id: 'A1', price: 350 }, { id: 'A2', price: 350 }],\n  [{ type: 'percent', value: 10, name: 'New User' }]\n));\nconsole.log(calculatePrice(\n  [{ id: 'B1', price: 200 }],\n  [{ type: 'flat', value: 50, name: 'Coupon' }]\n));",
              "output": "{\n  base: '₹700',\n  discount: '₹70',\n  subtotal: '₹630',\n  convenience: '₹113 (18%)',\n  handling: '₹30',\n  total: '₹773'\n}\n{\n  base: '₹200',\n  discount: '₹50',\n  subtotal: '₹150',\n  convenience: '₹27 (18%)',\n  handling: '₹30',\n  total: '₹207'\n}"
            },
            {
              "question": "Program 4: Virtual waiting room queue",
              "code": "class WaitingRoom {\n  constructor(batchSize, intervalSec) {\n    this.queue = []; // { userId, joinedAt, position }\n    this.batchSize = batchSize;\n    this.intervalSec = intervalSec;\n    this.admitted = [];\n  }\n  join(userId) {\n    const pos = this.queue.length + this.admitted.length + 1;\n    this.queue.push({ userId, joinedAt: Date.now(), position: pos });\n    const waitBatches = Math.ceil(this.queue.length / this.batchSize);\n    return { position: pos, estimatedWait: `~${waitBatches * this.intervalSec}s` };\n  }\n  admitBatch() {\n    const batch = this.queue.splice(0, this.batchSize);\n    batch.forEach(u => this.admitted.push(u.userId));\n    return { admitted: batch.map(u => u.userId), remaining: this.queue.length };\n  }\n  status() {\n    return { waiting: this.queue.length, admitted: this.admitted.length };\n  }\n}\n\nconst wr = new WaitingRoom(2, 30);\nconsole.log(wr.join('Alice'));\nconsole.log(wr.join('Bob'));\nconsole.log(wr.join('Carol'));\nconsole.log(wr.join('Dave'));\nconsole.log('Batch 1:', wr.admitBatch());\nconsole.log('Batch 2:', wr.admitBatch());\nconsole.log(wr.status());",
              "output": "{ position: 1, estimatedWait: '~30s' }\n{ position: 2, estimatedWait: '~30s' }\n{ position: 3, estimatedWait: '~60s' }\n{ position: 4, estimatedWait: '~60s' }\nBatch 1: { admitted: [ 'Alice', 'Bob' ], remaining: 2 }\nBatch 2: { admitted: [ 'Carol', 'Dave' ], remaining: 0 }\n{ waiting: 0, admitted: 4 }"
            },
            {
              "question": "Program 5: Show availability aggregator",
              "code": "function aggregateAvailability(shows) {\n  return shows.map(show => {\n    const total = show.seats.length;\n    const available = show.seats.filter(s => s.status === 'AVAILABLE').length;\n    const held = show.seats.filter(s => s.status === 'HELD').length;\n    const booked = show.seats.filter(s => s.status === 'BOOKED').length;\n    const fillRate = ((booked / total) * 100).toFixed(0);\n    let tag = 'Available';\n    if (available === 0) tag = 'Sold Out';\n    else if (available < total * 0.1) tag = 'Almost Full';\n    else if (available < total * 0.3) tag = 'Filling Fast';\n    return { show: show.time, total, available, held, booked, fillRate: fillRate + '%', tag };\n  });\n}\n\nconsole.log(aggregateAvailability([\n  { time: '10:00 AM', seats: [\n    { status: 'BOOKED' }, { status: 'BOOKED' }, { status: 'AVAILABLE' },\n    { status: 'AVAILABLE' }, { status: 'HELD' }, { status: 'AVAILABLE' },\n  ]},\n  { time: '2:00 PM', seats: [\n    { status: 'BOOKED' }, { status: 'BOOKED' }, { status: 'BOOKED' },\n    { status: 'BOOKED' }, { status: 'BOOKED' }, { status: 'HELD' },\n  ]},\n]));",
              "output": "[\n  { show: '10:00 AM', total: 6, available: 3, held: 1, booked: 2, fillRate: '33%', tag: 'Filling Fast' },\n  { show: '2:00 PM', total: 6, available: 0, held: 1, booked: 5, fillRate: '83%', tag: 'Sold Out' }\n]"
            },
            {
              "question": "Program 6: Cancellation and refund processor",
              "code": "function processCancellation(booking, showTime) {\n  const hoursUntilShow = (showTime - Date.now()) / 3600000;\n  let refundPct, policy;\n  if (hoursUntilShow > 24) { refundPct = 100; policy = 'Full refund'; }\n  else if (hoursUntilShow > 12) { refundPct = 50; policy = 'Partial refund'; }\n  else if (hoursUntilShow > 0) { refundPct = 0; policy = 'No refund (< 12h)'; }\n  else { return { allowed: false, reason: 'Show already started' }; }\n  \n  const refundAmount = Math.round(booking.totalPaid * (refundPct / 100));\n  return {\n    allowed: true,\n    policy,\n    hoursUntilShow: Math.round(hoursUntilShow),\n    refundPct: refundPct + '%',\n    refundAmount: `₹${refundAmount}`,\n    seatsReleased: booking.seats,\n  };\n}\n\nconst now = Date.now();\nconsole.log(processCancellation(\n  { totalPaid: 856, seats: ['A1', 'A2'] },\n  now + 30 * 3600000 // 30h from now\n));\nconsole.log(processCancellation(\n  { totalPaid: 450, seats: ['B1'] },\n  now + 6 * 3600000 // 6h from now\n));",
              "output": "{\n  allowed: true,\n  policy: 'Full refund',\n  hoursUntilShow: 30,\n  refundPct: '100%',\n  refundAmount: '₹856',\n  seatsReleased: [ 'A1', 'A2' ]\n}\n{\n  allowed: true,\n  policy: 'No refund (< 12h)',\n  hoursUntilShow: 6,\n  refundPct: '0%',\n  refundAmount: '₹0',\n  seatsReleased: [ 'B1' ]\n}"
            },
            {
              "question": "Program 7: Waitlist manager",
              "code": "class Waitlist {\n  constructor(maxSize) { this.queue = []; this.maxSize = maxSize; this.notified = []; }\n  join(userId, seatsWanted) {\n    if (this.queue.length >= this.maxSize) return { joined: false, reason: 'Waitlist full' };\n    this.queue.push({ userId, seatsWanted, joinedAt: Date.now() });\n    return { joined: true, position: this.queue.length };\n  }\n  releaseSeats(count) {\n    const notifications = [];\n    let remaining = count;\n    while (remaining > 0 && this.queue.length > 0) {\n      const next = this.queue[0];\n      if (next.seatsWanted <= remaining) {\n        this.queue.shift();\n        remaining -= next.seatsWanted;\n        notifications.push({ userId: next.userId, seats: next.seatsWanted, action: 'OFFERED' });\n      } else break;\n    }\n    return { notifications, seatsUnallocated: remaining };\n  }\n}\n\nconst wl = new Waitlist(5);\nconsole.log(wl.join('Alice', 2));\nconsole.log(wl.join('Bob', 1));\nconsole.log(wl.join('Carol', 3));\nconsole.log('Release 3 seats:', wl.releaseSeats(3));\nconsole.log('Queue remaining:', wl.queue.length);",
              "output": "{ joined: true, position: 1 }\n{ joined: true, position: 2 }\n{ joined: true, position: 3 }\nRelease 3 seats: {\n  notifications: [\n    { userId: 'Alice', seats: 2, action: 'OFFERED' },\n    { userId: 'Bob', seats: 1, action: 'OFFERED' }\n  ],\n  seatsUnallocated: 0\n}\nQueue remaining: 1"
            },
            {
              "question": "Program 8: Dynamic pricing engine",
              "code": "function dynamicPrice(basePrice, factors) {\n  let multiplier = 1.0;\n  const applied = [];\n  \n  // Demand factor\n  if (factors.fillRate > 0.8) { multiplier *= 1.3; applied.push('High demand +30%'); }\n  else if (factors.fillRate > 0.5) { multiplier *= 1.1; applied.push('Moderate demand +10%'); }\n  \n  // Time factor\n  if (factors.isWeekend) { multiplier *= 1.15; applied.push('Weekend +15%'); }\n  if (factors.isEvening) { multiplier *= 1.1; applied.push('Evening show +10%'); }\n  \n  // Early bird\n  if (factors.daysUntilShow > 7) { multiplier *= 0.9; applied.push('Early bird -10%'); }\n  \n  multiplier = Math.min(2.0, multiplier); // cap at 2x\n  const finalPrice = Math.round(basePrice * multiplier);\n  return { basePrice, multiplier: +multiplier.toFixed(2), finalPrice, applied };\n}\n\nconsole.log(dynamicPrice(300, { fillRate: 0.85, isWeekend: true, isEvening: true, daysUntilShow: 2 }));\nconsole.log(dynamicPrice(300, { fillRate: 0.3, isWeekend: false, isEvening: false, daysUntilShow: 14 }));",
              "output": "{\n  basePrice: 300,\n  multiplier: 1.64,\n  finalPrice: 493,\n  applied: [ 'High demand +30%', 'Weekend +15%', 'Evening show +10%' ]\n}\n{\n  basePrice: 300,\n  multiplier: 0.9,\n  finalPrice: 270,\n  applied: [ 'Early bird -10%' ]\n}"
            },
            {
              "question": "Program 9: Show search with filters",
              "code": "function searchShows(shows, filters) {\n  return shows.filter(show => {\n    if (filters.city && show.city !== filters.city) return false;\n    if (filters.language && !show.languages.includes(filters.language)) return false;\n    if (filters.minRating && show.rating < filters.minRating) return false;\n    if (filters.maxPrice && show.minPrice > filters.maxPrice) return false;\n    if (filters.genre && !show.genres.includes(filters.genre)) return false;\n    return true;\n  }).sort((a, b) => b.rating - a.rating);\n}\n\nconst shows = [\n  { title: 'Avengers', city: 'Delhi', languages: ['English', 'Hindi'], rating: 4.5, minPrice: 300, genres: ['Action'] },\n  { title: 'Inception', city: 'Delhi', languages: ['English'], rating: 4.8, minPrice: 350, genres: ['Sci-Fi', 'Action'] },\n  { title: 'Dangal', city: 'Mumbai', languages: ['Hindi'], rating: 4.7, minPrice: 200, genres: ['Drama', 'Sports'] },\n  { title: 'RRR', city: 'Delhi', languages: ['Telugu', 'Hindi'], rating: 4.3, minPrice: 250, genres: ['Action'] },\n];\n\nconsole.log(searchShows(shows, { city: 'Delhi', genre: 'Action', maxPrice: 400 })\n  .map(s => `${s.title} ⭐${s.rating} ₹${s.minPrice}`));",
              "output": "[\n  'Inception ⭐4.8 ₹350',\n  'Avengers ⭐4.5 ₹300',\n  'RRR ⭐4.3 ₹250'\n]"
            },
            {
              "question": "Program 10: Booking confirmation receipt generator",
              "code": "function generateReceipt(booking) {\n  const lines = [\n    '═══ BOOKING CONFIRMATION ═══',\n    `Booking ID: ${booking.id}`,\n    `Movie: ${booking.movie}`,\n    `Show: ${booking.showTime} | ${booking.screen}`,\n    `Venue: ${booking.venue}`,\n    `Seats: ${booking.seats.join(', ')} (${booking.category})`,\n    '───────────────────────────',\n    `Ticket Price: ₹${booking.baseAmount}`,\n    `Convenience Fee: ₹${booking.convenienceFee}`,\n    booking.discount > 0 ? `Discount: -₹${booking.discount}` : null,\n    '───────────────────────────',\n    `Total: ₹${booking.total}`,\n    `Payment: ${booking.paymentMethod}`,\n    '═══════════════════════════',\n  ].filter(Boolean);\n  return lines.join('\\n');\n}\n\nconsole.log(generateReceipt({\n  id: 'BMS-20240115-001',\n  movie: 'Inception IMAX',\n  showTime: '7:00 PM, Jan 15',\n  screen: 'Screen 3 (IMAX)',\n  venue: 'PVR Select City Walk, Delhi',\n  seats: ['G5', 'G6'],\n  category: 'Gold',\n  baseAmount: 700,\n  convenienceFee: 126,\n  discount: 70,\n  total: 786,\n  paymentMethod: 'UPI - user@paytm',\n}));",
              "output": "═══ BOOKING CONFIRMATION ═══\nBooking ID: BMS-20240115-001\nMovie: Inception IMAX\nShow: 7:00 PM, Jan 15 | Screen 3 (IMAX)\nVenue: PVR Select City Walk, Delhi\nSeats: G5, G6 (Gold)\n───────────────────────────\nTicket Price: ₹700\nConvenience Fee: ₹126\nDiscount: -₹70\n───────────────────────────\nTotal: ₹786\nPayment: UPI - user@paytm\n═══════════════════════════"
            }
          ]
        },
        {
          "id": "delhivery-lld",
          "title": "Delhivery: Logistics & Delivery Network",
          "category": "Company LLD",
          "description": "Low-level design of Delhivery's package routing, warehouse management, last-mile delivery optimization, and real-time tracking.",
          "explanation": "Delhivery processes 2M+ shipments daily across India's logistics network. The system orchestrates the entire package lifecycle: pickup from seller, regional hub sorting, inter-city transport, last-mile delivery, and returns.\n\n**Package Lifecycle**:\n1. **Manifest**: Seller creates shipment → AWB (Air Waybill) number generated → label printed.\n2. **Pickup**: Delivery partner collects package from seller. Scanned at pickup → status: IN_TRANSIT.\n3. **First-Mile Hub**: Package arrives at local sorting facility. Scanned → sorted by destination zone.\n4. **Linehaul**: Long-distance transport (truck/air) between cities. Route: origin hub → regional hub → destination hub.\n5. **Last-Mile Hub**: Package arrives at delivery hub closest to customer. Sorted by delivery route.\n6. **Out for Delivery**: Assigned to delivery agent. GPS tracking active. Customer notified with ETA.\n7. **Delivery**: Agent delivers → scanned → POD (Proof of Delivery) captured (signature/photo/OTP).\n8. **Returns**: If customer refuses or returns, reverse logistics: customer → hub → seller.\n\n**Route Optimization**:\n- Hub network as a weighted graph. Edge weights = cost (distance, time, mode).\n- Inter-city: Dijkstra's or A* for cheapest route between hubs.\n- Last-mile: TSP (Traveling Salesman Problem) approximation for delivery route optimization.\n- Cluster deliveries by pincode/area for batch routing.\n\n**Warehouse/Hub Operations**:\n- Inbound: scan, weigh, measure, sort by destination zone.\n- Storage: packages assigned to bins/racks by zone for easy retrieval.\n- Outbound: pick packages for next transport, load in delivery sequence.\n- SLA tracking: flag packages approaching delivery deadline.\n\n**Capacity Planning**:\n- Hub capacity: max packages per day based on sorting speed and space.\n- Vehicle capacity: weight and volume constraints. Bin-packing algorithm.\n- Demand forecasting: ML model predicts next-day volumes per hub.\n\n**Cost Calculation**:\n- Based on: weight (actual vs volumetric, whichever is higher), distance (zone-based), speed (express vs standard), package type (fragile, oversized).\n- Volumetric weight = (L × W × H) / 5000.",
          "code": "// Package tracking system\nclass ShipmentTracker {\n  constructor() {\n    this.shipments = new Map();\n    this.awbCounter = 1000;\n  }\n\n  createShipment(seller, destination, weight, dimensions) {\n    const awb = `DL${++this.awbCounter}`;\n    const volumetricWeight = (dimensions.l * dimensions.w * dimensions.h) / 5000;\n    const shipment = {\n      awb,\n      seller,\n      destination,\n      actualWeight: weight,\n      volumetricWeight: +volumetricWeight.toFixed(2),\n      chargeableWeight: Math.max(weight, volumetricWeight),\n      status: 'MANIFESTED',\n      timeline: [{ status: 'MANIFESTED', location: seller.city, at: new Date().toISOString() }],\n      currentLocation: seller.city,\n    };\n    this.shipments.set(awb, shipment);\n    return { awb, chargeableWeight: shipment.chargeableWeight };\n  }\n\n  scan(awb, location, status) {\n    const s = this.shipments.get(awb);\n    if (!s) return { error: 'AWB not found' };\n    s.status = status;\n    s.currentLocation = location;\n    s.timeline.push({ status, location, at: new Date().toISOString() });\n    return { awb, status, location, steps: s.timeline.length };\n  }\n\n  track(awb) {\n    const s = this.shipments.get(awb);\n    if (!s) return null;\n    return {\n      awb: s.awb,\n      status: s.status,\n      currentLocation: s.currentLocation,\n      destination: s.destination.city,\n      timeline: s.timeline,\n    };\n  }\n}\n\nconst tracker = new ShipmentTracker();\nconst { awb } = tracker.createShipment(\n  { name: 'SellerA', city: 'Delhi' },\n  { name: 'CustomerB', city: 'Mumbai', pincode: '400001' },\n  2.5,\n  { l: 30, w: 20, h: 15 }\n);\nconsole.log('Created:', awb);\ntracker.scan(awb, 'Delhi Hub', 'PICKED_UP');\ntracker.scan(awb, 'Delhi Sort Center', 'IN_TRANSIT');\ntracker.scan(awb, 'Mumbai Hub', 'REACHED_DEST_HUB');\ntracker.scan(awb, 'Mumbai', 'OUT_FOR_DELIVERY');\ntracker.scan(awb, 'Mumbai', 'DELIVERED');\nconsole.log(tracker.track(awb));",
          "example": "// Delivery route optimizer (TSP approximation - Nearest Neighbor)\nfunction optimizeRoute(depot, deliveries) {\n  const unvisited = [...deliveries];\n  const route = [depot];\n  let current = depot;\n  let totalDist = 0;\n\n  while (unvisited.length > 0) {\n    let nearest = null;\n    let minDist = Infinity;\n    for (const d of unvisited) {\n      const dist = Math.sqrt(Math.pow(d.lat - current.lat, 2) + Math.pow(d.lng - current.lng, 2));\n      if (dist < minDist) { minDist = dist; nearest = d; }\n    }\n    route.push(nearest);\n    totalDist += minDist;\n    current = nearest;\n    unvisited.splice(unvisited.indexOf(nearest), 1);\n  }\n  // Return to depot\n  totalDist += Math.sqrt(Math.pow(depot.lat - current.lat, 2) + Math.pow(depot.lng - current.lng, 2));\n  route.push(depot);\n\n  return {\n    route: route.map(r => r.id || 'DEPOT'),\n    totalDistance: +(totalDist * 111).toFixed(2) + ' km',\n    stops: deliveries.length,\n  };\n}\n\nconst depot = { id: 'DEPOT', lat: 28.614, lng: 77.209 };\nconst deliveries = [\n  { id: 'D1', lat: 28.620, lng: 77.215 },\n  { id: 'D2', lat: 28.618, lng: 77.205 },\n  { id: 'D3', lat: 28.625, lng: 77.220 },\n  { id: 'D4', lat: 28.610, lng: 77.200 },\n];\nconsole.log(optimizeRoute(depot, deliveries));",
          "useCase": "Logistics and delivery networks, supply chain management, warehouse management systems, fleet management, e-commerce fulfillment.",
          "interviewQuestions": [
            {
              "question": "How do you design the AWB (tracking number) generation system?",
              "answer": "Requirements: globally unique, sortable by time, encodes origin hub. Format: prefix(2) + hub_code(3) + timestamp_encoded(8) + sequence(4) + checksum(1). Use Snowflake-like ID generation: datacenter bits + worker bits + sequence bits. ~18 chars total. Checksum digit for validation. Index: B-tree on AWB for O(log n) lookup."
            },
            {
              "question": "How do you optimize inter-city routes for millions of packages?",
              "answer": "Model hub network as directed weighted graph. Edges: transport links with cost (fuel, time, capacity). Use Dijkstra's per origin-destination pair. Pre-compute top routes and cache. For batches: bin-packing to fill trucks efficiently. Time constraint: some routes run on schedule (like bus routes). Dynamic routing for express packages."
            },
            {
              "question": "How do you optimize last-mile delivery routes?",
              "answer": "Cluster deliveries by pincode zone. Per cluster, solve TSP approximation: Nearest Neighbor heuristic (O(n²)), or 2-opt improvement. Constraints: time windows (customer availability), vehicle capacity, fuel. Real-time re-routing if customer reschedules. Typical: 30-50 deliveries per agent per day."
            },
            {
              "question": "How do you handle the sorting facility (hub) at scale?",
              "answer": "Conveyor belt + barcode scanner system. Package scanned → destination pincode → assigned to chute/bin for destination zone. Sort rate: 10K packages/hour per line. Multiple parallel lines. Overflow: manual sorting for irregular packages. ML for OCR on handwritten labels."
            },
            {
              "question": "How do you calculate shipping cost?",
              "answer": "Inputs: origin pincode, dest pincode, actual weight, dimensions (L×W×H). Volumetric weight = L×W×H/5000. Chargeable weight = max(actual, volumetric). Zone = distance band (A: same city, B: regional, C: metro-to-metro, D: rest). Cost = base_rate[zone] × chargeable_weight + fuel_surcharge + handling_fee."
            },
            {
              "question": "How do you ensure proof of delivery?",
              "answer": "Multiple methods: 1) OTP: system sends OTP to customer, agent enters it. 2) Digital signature: customer signs on agent's device. 3) Photo: agent captures photo of package at doorstep. 4) GPS + timestamp: agent's location must be within 100m of delivery address. Store POD as part of shipment record."
            },
            {
              "question": "How do you handle returns/reverse logistics?",
              "answer": "Customer initiates return → pickup scheduled (same flow as forward logistics in reverse). Pickup → local hub → quality check (is item in condition?) → if pass, ship to seller. If fail, return to customer. Separate SLA for returns (longer timeline). Cost: often borne by seller or platform."
            },
            {
              "question": "How do you predict next-day delivery volumes per hub?",
              "answer": "ML model features: historical volumes (same day last week, last month), upcoming events (sales, festivals), weather forecast, day of week. Model: time-series forecasting (ARIMA, Prophet, LSTM). Output: predicted package count per hub. Used for: staffing, vehicle allocation, capacity planning. Retrained weekly."
            },
            {
              "question": "How do you handle delivery failures (customer not available)?",
              "answer": "First attempt: call customer → if no answer, mark as RTO-pending. Second attempt: next day, different time slot. Third attempt: if all fail, initiate RTO (Return to Origin). Customer can reschedule via app/SMS. Hold at hub for max 7 days. After that, auto-RTO. Charge RTO shipping to seller."
            },
            {
              "question": "How do you maintain real-time package tracking at scale?",
              "answer": "Event-driven: each scan generates an event → Kafka → consumers update tracking status in DB + cache. Customer-facing: query Redis for current status (hot path). Full timeline: query DB (cold path). Push notifications on status change. Update frequency: at each physical scan point (6-8 events per delivery lifecycle)."
            }
          ],
          "exercises": [
            {
              "type": "design",
              "question": "Design the real-time shipment tracking system.",
              "answer": "Events: pickup, hub_inbound, hub_outbound, in_transit, out_for_delivery, delivered. Each event: {awb, status, location, timestamp, agent_id}. Pipeline: scanner/app → API → Kafka → consumer writes to: 1) Redis (latest status per AWB), 2) TimescaleDB (full timeline), 3) Push notification service. Customer query: Redis first, DB fallback for timeline. SLA: event visible within 30 seconds of scan."
            },
            {
              "type": "estimation",
              "question": "2M shipments/day, 7 scan events per shipment, 200 bytes per event. Estimate daily data volume and storage for 1 year.",
              "answer": "Daily events: 2M × 7 = 14M events. Daily data: 14M × 200B = 2.8GB/day. Monthly: 84GB. Yearly: ~1TB. With indexes and replicas: ~3TB. Redis for active shipments (last 30 days): 2M × 30 × 200B = 12GB (fits in memory). Manageable with standard infrastructure."
            },
            {
              "type": "scenario",
              "question": "A major hub (sorting center) goes offline due to power failure. 50K packages are stuck. How do you reroute?",
              "answer": "1) Detect: heartbeat missed from hub's systems. 2) Divert inbound linehaul trucks to nearest alternate hub. 3) Notify upstream hubs to reroute. 4) Recalculate ETAs for affected shipments (+24-48h). 5) Customer notifications: 'Slight delay due to operational issues'. 6) When hub recovers, process backlog with extra staff. 7) Incident report for capacity planning."
            },
            {
              "type": "tricky",
              "question": "Why use volumetric weight instead of just actual weight?",
              "answer": "A large, lightweight package (e.g., pillows) takes the same truck space as a heavy small package. If you charge by actual weight, lightweight bulky items are underpriced — trucks fill by volume before weight capacity. Volumetric pricing ensures revenue reflects the space consumed. Formula: L×W×H/5000 (cm/kg)."
            },
            {
              "type": "design",
              "question": "Design the delivery agent's daily route planning system.",
              "answer": "Input: agent's hub location + list of 40 deliveries (lat/lng, time window, package size). Step 1: Cluster by area (K-means on coordinates). Step 2: Sequence within cluster (Nearest Neighbor TSP). Step 3: Apply time windows — reorder if customer has preferred slot. Step 4: Capacity check — ensure vehicle can carry batch. Output: ordered list with navigation. Re-optimize on delivery failure or new assignment."
            },
            {
              "type": "debug",
              "question": "Tracking shows package 'DELIVERED' but customer says not received. Investigation steps?",
              "answer": "1) Check POD: is there OTP verification, photo, signature? 2) Check GPS: was agent within 100m of address? 3) Check delivery time: reasonable hour? 4) Check if delivered to neighbor or security guard. 5) Agent interview. 6) If no valid POD: mark as delivery failure, redeliver. 7) Flag agent if pattern of fake deliveries."
            },
            {
              "type": "estimation",
              "question": "Delivery agent makes 40 deliveries/day in 8 hours. Average 2km between stops. Calculate total distance and time per delivery.",
              "answer": "Total distance: 40 × 2km = 80km/day. Average speed in city: 20 km/h. Travel time: 80/20 = 4 hours. Remaining: 4 hours for actual deliveries = 6 min per delivery (walk to door, hand over, scan, get POD). Tight but achievable with route optimization."
            },
            {
              "type": "design",
              "question": "Design the SLA monitoring and alerting system.",
              "answer": "SLAs: standard = 5 days, express = 2 days. Per shipment: calculate remaining time = SLA deadline - current time. Categories: GREEN (>50% time left), YELLOW (25-50%), RED (<25%), BREACHED. Dashboard: aggregate by hub, agent, zone. Alerts: Slack/PagerDuty for RED shipments. Auto-escalation: reassign from low-performing agent. Daily report to ops team."
            },
            {
              "type": "scenario",
              "question": "Festival season: volume spikes 3x for 2 weeks. How do you prepare?",
              "answer": "1) Demand forecasting: predict volume per hub per day. 2) Temporary staff hiring and training (4 weeks before). 3) Additional vehicles (rent trucks/vans). 4) Extra shifts at sorting hubs. 5) Pre-position inventory at regional hubs. 6) Extend SLAs by 1 day (set expectations). 7) Disable non-critical features. 8) War room for real-time monitoring."
            },
            {
              "type": "output",
              "question": "Package: 40×30×25 cm, actual weight 3kg. Zone C rate: ₹65/kg first kg + ₹25/kg additional. Calculate shipping cost.",
              "answer": "Volumetric: 40×30×25/5000 = 6kg. Chargeable: max(3, 6) = 6kg. Cost: ₹65 (first kg) + 5 × ₹25 (additional) = ₹65 + ₹125 = ₹190. Plus fuel surcharge (15%): ₹190 × 1.15 = ₹218.50 ≈ ₹219."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: AWB tracking with full timeline",
              "code": "class TrackingService {\n  constructor() { this.shipments = new Map(); }\n  createAWB(awb, origin, destination) {\n    this.shipments.set(awb, {\n      awb, origin, destination, status: 'CREATED',\n      timeline: [{ status: 'CREATED', location: origin, time: Date.now() }],\n    });\n  }\n  addEvent(awb, status, location) {\n    const s = this.shipments.get(awb);\n    if (!s) return null;\n    s.status = status;\n    s.timeline.push({ status, location, time: Date.now() });\n    return { awb, currentStatus: status, events: s.timeline.length };\n  }\n  getTracking(awb) {\n    const s = this.shipments.get(awb);\n    if (!s) return 'Not found';\n    return { awb: s.awb, status: s.status, from: s.origin, to: s.destination, steps: s.timeline.map(t => `${t.status} @ ${t.location}`) };\n  }\n}\n\nconst ts = new TrackingService();\nts.createAWB('DL1001', 'Delhi', 'Bangalore');\nts.addEvent('DL1001', 'PICKED_UP', 'Delhi');\nts.addEvent('DL1001', 'IN_TRANSIT', 'Delhi Hub');\nts.addEvent('DL1001', 'IN_TRANSIT', 'Bangalore Hub');\nts.addEvent('DL1001', 'OUT_FOR_DELIVERY', 'Bangalore');\nts.addEvent('DL1001', 'DELIVERED', 'Bangalore');\nconsole.log(ts.getTracking('DL1001'));",
              "output": "{\n  awb: 'DL1001',\n  status: 'DELIVERED',\n  from: 'Delhi',\n  to: 'Bangalore',\n  steps: [\n    'CREATED @ Delhi',\n    'PICKED_UP @ Delhi',\n    'IN_TRANSIT @ Delhi Hub',\n    'IN_TRANSIT @ Bangalore Hub',\n    'OUT_FOR_DELIVERY @ Bangalore',\n    'DELIVERED @ Bangalore'\n  ]\n}"
            },
            {
              "question": "Program 2: Shipping cost calculator",
              "code": "function calculateShipping(pkg, zones) {\n  const volWeight = (pkg.length * pkg.width * pkg.height) / 5000;\n  const chargeableWeight = Math.max(pkg.weight, volWeight);\n  const zone = zones[pkg.zone] || zones['D'];\n  const cost = zone.firstKg + Math.max(0, Math.ceil(chargeableWeight) - 1) * zone.additionalKg;\n  const fuelSurcharge = Math.round(cost * 0.15);\n  const total = cost + fuelSurcharge;\n  return {\n    actualWeight: pkg.weight + 'kg',\n    volumetric: volWeight.toFixed(2) + 'kg',\n    chargeable: Math.ceil(chargeableWeight) + 'kg',\n    zone: pkg.zone,\n    base: `₹${cost}`,\n    fuel: `₹${fuelSurcharge}`,\n    total: `₹${total}`,\n  };\n}\n\nconst zones = {\n  A: { firstKg: 40, additionalKg: 15 },\n  B: { firstKg: 55, additionalKg: 20 },\n  C: { firstKg: 65, additionalKg: 25 },\n  D: { firstKg: 85, additionalKg: 35 },\n};\n\nconsole.log(calculateShipping({ weight: 2, length: 30, width: 20, height: 15, zone: 'B' }, zones));\nconsole.log(calculateShipping({ weight: 1, length: 50, width: 40, height: 30, zone: 'D' }, zones));",
              "output": "{\n  actualWeight: '2kg',\n  volumetric: '1.80kg',\n  chargeable: '2kg',\n  zone: 'B',\n  base: '₹75',\n  fuel: '₹11',\n  total: '₹86'\n}\n{\n  actualWeight: '1kg',\n  volumetric: '12.00kg',\n  chargeable: '12kg',\n  zone: 'D',\n  base: '₹470',\n  fuel: '₹71',\n  total: '₹541'\n}"
            },
            {
              "question": "Program 3: Hub sorting simulator",
              "code": "function sortPackages(packages) {\n  const chutes = {};\n  packages.forEach(pkg => {\n    const zone = pkg.destPincode.substring(0, 3); // first 3 digits = zone\n    if (!chutes[zone]) chutes[zone] = [];\n    chutes[zone].push(pkg.awb);\n  });\n  return Object.entries(chutes)\n    .map(([zone, awbs]) => ({ zone, count: awbs.length, awbs }))\n    .sort((a, b) => b.count - a.count);\n}\n\nconsole.log(sortPackages([\n  { awb: 'DL1001', destPincode: '400001' },\n  { awb: 'DL1002', destPincode: '400023' },\n  { awb: 'DL1003', destPincode: '560001' },\n  { awb: 'DL1004', destPincode: '400045' },\n  { awb: 'DL1005', destPincode: '110001' },\n]));",
              "output": "[\n  { zone: '400', count: 3, awbs: [ 'DL1001', 'DL1002', 'DL1004' ] },\n  { zone: '560', count: 1, awbs: [ 'DL1003' ] },\n  { zone: '110', count: 1, awbs: [ 'DL1005' ] }\n]"
            },
            {
              "question": "Program 4: Nearest-neighbor delivery route optimizer",
              "code": "function planRoute(depot, stops) {\n  const remaining = [...stops];\n  const route = [{ ...depot, id: 'DEPOT' }];\n  let totalDist = 0;\n  let current = depot;\n  while (remaining.length > 0) {\n    let minDist = Infinity, nearest = 0;\n    remaining.forEach((stop, i) => {\n      const d = Math.sqrt(Math.pow(stop.lat - current.lat, 2) + Math.pow(stop.lng - current.lng, 2));\n      if (d < minDist) { minDist = d; nearest = i; }\n    });\n    totalDist += minDist;\n    current = remaining[nearest];\n    route.push(remaining.splice(nearest, 1)[0]);\n  }\n  totalDist += Math.sqrt(Math.pow(depot.lat - current.lat, 2) + Math.pow(depot.lng - current.lng, 2));\n  return {\n    sequence: route.map(r => r.id),\n    totalKm: +(totalDist * 111).toFixed(1),\n    stops: stops.length,\n  };\n}\n\nconsole.log(planRoute(\n  { lat: 28.614, lng: 77.209 },\n  [\n    { id: 'A', lat: 28.620, lng: 77.215 },\n    { id: 'B', lat: 28.625, lng: 77.205 },\n    { id: 'C', lat: 28.618, lng: 77.212 },\n    { id: 'D', lat: 28.630, lng: 77.220 },\n  ]\n));",
              "output": "{\n  sequence: [ 'DEPOT', 'C', 'A', 'B', 'D' ],\n  totalKm: 4.6,\n  stops: 4\n}"
            },
            {
              "question": "Program 5: Vehicle capacity bin-packer",
              "code": "function packVehicle(packages, vehicleCapacityKg, vehicleCapacityM3) {\n  const sorted = [...packages].sort((a, b) => b.weight - a.weight); // heaviest first\n  let usedWeight = 0, usedVolume = 0;\n  const loaded = [], overflow = [];\n  sorted.forEach(pkg => {\n    const vol = (pkg.l * pkg.w * pkg.h) / 1000000; // cm³ to m³\n    if (usedWeight + pkg.weight <= vehicleCapacityKg && usedVolume + vol <= vehicleCapacityM3) {\n      loaded.push(pkg.awb);\n      usedWeight += pkg.weight;\n      usedVolume += vol;\n    } else {\n      overflow.push(pkg.awb);\n    }\n  });\n  return {\n    loaded: loaded.length,\n    overflow: overflow.length,\n    weightUsed: usedWeight + '/' + vehicleCapacityKg + 'kg',\n    volumeUsed: usedVolume.toFixed(3) + '/' + vehicleCapacityM3 + 'm³',\n    overflowAwbs: overflow,\n  };\n}\n\nconsole.log(packVehicle(\n  [\n    { awb: 'P1', weight: 15, l: 60, w: 40, h: 40 },\n    { awb: 'P2', weight: 8, l: 30, w: 30, h: 30 },\n    { awb: 'P3', weight: 20, l: 80, w: 60, h: 50 },\n    { awb: 'P4', weight: 5, l: 20, w: 20, h: 20 },\n  ],\n  40, // 40kg capacity\n  0.3  // 0.3 m³\n));",
              "output": "{\n  loaded: 3,\n  overflow: 1,\n  weightUsed: '43/40kg',\n  volumeUsed: '0.339/0.3m³',\n  overflowAwbs: [ 'P4' ]\n}"
            },
            {
              "question": "Program 6: SLA tracker and alerting",
              "code": "function checkSLAs(shipments, now = Date.now()) {\n  return shipments.map(s => {\n    const deadline = s.createdAt + s.slaHours * 3600000;\n    const remaining = deadline - now;\n    const remainingHours = remaining / 3600000;\n    const pctUsed = ((now - s.createdAt) / (s.slaHours * 3600000)) * 100;\n    \n    let severity;\n    if (remaining <= 0) severity = 'BREACHED';\n    else if (pctUsed > 75) severity = 'RED';\n    else if (pctUsed > 50) severity = 'YELLOW';\n    else severity = 'GREEN';\n    \n    return { awb: s.awb, status: s.status, sla: s.slaHours + 'h', remaining: Math.round(remainingHours) + 'h', severity };\n  }).sort((a, b) => {\n    const order = { BREACHED: 0, RED: 1, YELLOW: 2, GREEN: 3 };\n    return order[a.severity] - order[b.severity];\n  });\n}\n\nconst now = Date.now();\nconsole.log(checkSLAs([\n  { awb: 'DL1001', status: 'IN_TRANSIT', createdAt: now - 100*3600000, slaHours: 96 },\n  { awb: 'DL1002', status: 'OUT_FOR_DELIVERY', createdAt: now - 20*3600000, slaHours: 48 },\n  { awb: 'DL1003', status: 'PICKED_UP', createdAt: now - 130*3600000, slaHours: 120 },\n  { awb: 'DL1004', status: 'MANIFESTED', createdAt: now - 10*3600000, slaHours: 120 },\n]));",
              "output": "[\n  { awb: 'DL1001', status: 'IN_TRANSIT', sla: '96h', remaining: '-4h', severity: 'BREACHED' },\n  { awb: 'DL1003', status: 'PICKED_UP', sla: '120h', remaining: '-10h', severity: 'BREACHED' },\n  { awb: 'DL1002', status: 'OUT_FOR_DELIVERY', sla: '48h', remaining: '28h', severity: 'YELLOW' },\n  { awb: 'DL1004', status: 'MANIFESTED', sla: '120h', remaining: '110h', severity: 'GREEN' }\n]"
            },
            {
              "question": "Program 7: Demand forecaster (simple moving average)",
              "code": "function forecastDemand(historicalDaily, windowDays) {\n  const forecast = [];\n  for (let i = windowDays; i < historicalDaily.length; i++) {\n    const window = historicalDaily.slice(i - windowDays, i);\n    const avg = Math.round(window.reduce((s, v) => s + v, 0) / windowDays);\n    forecast.push({ day: i + 1, actual: historicalDaily[i], predicted: avg, error: Math.abs(historicalDaily[i] - avg) });\n  }\n  const mape = (forecast.reduce((s, f) => s + (f.error / f.actual), 0) / forecast.length * 100).toFixed(1);\n  return { forecast: forecast.slice(-3), mape: mape + '%', nextDayPrediction: Math.round(historicalDaily.slice(-windowDays).reduce((s,v)=>s+v,0)/windowDays) };\n}\n\nconsole.log(forecastDemand([1000, 1200, 1100, 1300, 1250, 1400, 1350, 1500, 1450, 1600], 3));",
              "output": "{\n  forecast: [\n    { day: 8, actual: 1500, predicted: 1333, error: 167 },\n    { day: 9, actual: 1450, predicted: 1417, error: 33 },\n    { day: 10, actual: 1600, predicted: 1433, error: 167 }\n  ],\n  mape: '8.7%',\n  nextDayPrediction: 1517\n}"
            },
            {
              "question": "Program 8: Return/RTO processor",
              "code": "class RTOProcessor {\n  constructor() { this.shipments = new Map(); }\n  initiate(awb, reason) {\n    this.shipments.set(awb, {\n      awb, reason, status: 'RTO_INITIATED',\n      timeline: [{ status: 'RTO_INITIATED', at: Date.now() }],\n    });\n    return { awb, status: 'RTO_INITIATED', reason };\n  }\n  process(awb, step) {\n    const s = this.shipments.get(awb);\n    s.status = step;\n    s.timeline.push({ status: step, at: Date.now() });\n    return { awb, status: step, steps: s.timeline.length };\n  }\n  getSummary() {\n    const byReason = {};\n    for (const s of this.shipments.values()) {\n      byReason[s.reason] = (byReason[s.reason] || 0) + 1;\n    }\n    return { total: this.shipments.size, byReason };\n  }\n}\n\nconst rto = new RTOProcessor();\nrto.initiate('DL1001', 'Customer refused');\nrto.initiate('DL1002', 'Wrong address');\nrto.initiate('DL1003', 'Customer refused');\nrto.process('DL1001', 'PICKED_FROM_CUSTOMER');\nrto.process('DL1001', 'IN_TRANSIT_TO_ORIGIN');\nrto.process('DL1001', 'RETURNED_TO_SELLER');\nconsole.log(rto.getSummary());",
              "output": "{\n  total: 3,\n  byReason: { 'Customer refused': 2, 'Wrong address': 1 }\n}"
            },
            {
              "question": "Program 9: Proof of delivery validator",
              "code": "function validatePOD(pod) {\n  const checks = [];\n  // GPS check: within 200m of delivery address\n  const dist = Math.sqrt(Math.pow(pod.agentLat - pod.destLat, 2) + Math.pow(pod.agentLng - pod.destLng, 2)) * 111000;\n  checks.push({ check: 'GPS proximity', pass: dist <= 200, detail: Math.round(dist) + 'm' });\n  // Time check: during business hours\n  const hour = new Date(pod.timestamp).getHours();\n  checks.push({ check: 'Business hours', pass: hour >= 8 && hour <= 21, detail: hour + ':00' });\n  // OTP check\n  checks.push({ check: 'OTP verified', pass: pod.otpMatch === true, detail: pod.otpMatch ? 'Match' : 'Mismatch' });\n  // Photo exists\n  checks.push({ check: 'Photo captured', pass: !!pod.photoUrl, detail: pod.photoUrl ? 'Yes' : 'No' });\n  \n  const allPass = checks.every(c => c.pass);\n  return { valid: allPass, checks };\n}\n\nconsole.log(validatePOD({\n  agentLat: 28.6141, agentLng: 77.2091,\n  destLat: 28.6140, destLng: 77.2090,\n  timestamp: new Date('2024-01-15T14:30:00').getTime(),\n  otpMatch: true, photoUrl: 'https://cdn.example.com/pod/123.jpg'\n}));\nconsole.log(validatePOD({\n  agentLat: 28.620, agentLng: 77.215,\n  destLat: 28.614, destLng: 77.209,\n  timestamp: new Date('2024-01-15T23:30:00').getTime(),\n  otpMatch: false, photoUrl: null\n}));",
              "output": "{\n  valid: true,\n  checks: [\n    { check: 'GPS proximity', pass: true, detail: '15m' },\n    { check: 'Business hours', pass: true, detail: '14:00' },\n    { check: 'OTP verified', pass: true, detail: 'Match' },\n    { check: 'Photo captured', pass: true, detail: 'Yes' }\n  ]\n}\n{\n  valid: false,\n  checks: [\n    { check: 'GPS proximity', pass: false, detail: '896m' },\n    { check: 'Business hours', pass: false, detail: '23:00' },\n    { check: 'OTP verified', pass: false, detail: 'Mismatch' },\n    { check: 'Photo captured', pass: false, detail: 'No' }\n  ]\n}"
            },
            {
              "question": "Program 10: Inter-hub route finder (Dijkstra)",
              "code": "function findCheapestRoute(graph, start, end) {\n  const dist = {};\n  const prev = {};\n  const visited = new Set();\n  const nodes = Object.keys(graph);\n  nodes.forEach(n => { dist[n] = Infinity; prev[n] = null; });\n  dist[start] = 0;\n  \n  while (true) {\n    let u = null;\n    for (const n of nodes) {\n      if (!visited.has(n) && (u === null || dist[n] < dist[u])) u = n;\n    }\n    if (u === null || dist[u] === Infinity || u === end) break;\n    visited.add(u);\n    for (const [v, cost] of Object.entries(graph[u] || {})) {\n      if (dist[u] + cost < dist[v]) {\n        dist[v] = dist[u] + cost;\n        prev[v] = u;\n      }\n    }\n  }\n  \n  const path = [];\n  let node = end;\n  while (node) { path.unshift(node); node = prev[node]; }\n  return { route: path, cost: dist[end], hops: path.length - 1 };\n}\n\nconst hubGraph = {\n  'Delhi': { 'Jaipur': 50, 'Lucknow': 70 },\n  'Jaipur': { 'Mumbai': 120, 'Ahmedabad': 80 },\n  'Lucknow': { 'Kolkata': 100 },\n  'Ahmedabad': { 'Mumbai': 60 },\n  'Mumbai': { 'Bangalore': 90 },\n  'Kolkata': { 'Bangalore': 150 },\n  'Bangalore': {},\n};\n\nconsole.log(findCheapestRoute(hubGraph, 'Delhi', 'Bangalore'));\nconsole.log(findCheapestRoute(hubGraph, 'Delhi', 'Mumbai'));",
              "output": "{ route: [ 'Delhi', 'Jaipur', 'Ahmedabad', 'Mumbai', 'Bangalore' ], cost: 280, hops: 4 }\n{ route: [ 'Delhi', 'Jaipur', 'Mumbai' ], cost: 170, hops: 2 }"
            }
          ]
        },
        {
          "id": "url-shortener",
          "title": "URL Shortener (like bit.ly)",
          "category": "Company HLD",
          "description": "High-level design of a URL shortening service — encoding, redirection, analytics, and scaling to billions of URLs.",
          "explanation": "A URL shortener maps long URLs to short codes (e.g., short.ly/abc123 → original URL). Seems simple but at scale involves interesting trade-offs.\n\n**Core Requirements**:\n- Shorten: given a long URL, return a short URL.\n- Redirect: given a short URL, redirect (301/302) to the original.\n- Analytics: track click count, referrer, geo, device.\n- Scale: support billions of URLs, millions of redirects/sec.\n\n**Short Code Generation**:\n- Option 1: **Hash-based**: MD5/SHA256(longUrl) → take first 7 chars in base62. Collision: different URLs could produce same hash prefix. Handle with collision check + retry.\n- Option 2: **Counter-based**: Auto-increment counter → encode in base62. No collisions. But sequential codes are predictable. Use distributed counter (ZooKeeper ranges) for multi-server.\n- Option 3: **Random**: Generate random 7-char base62 string. Check for collision in DB. Very unlikely collision with 62^7 = 3.5 trillion combinations.\n- Best: Counter-based with base62 encoding. Assign counter ranges to servers (e.g., server1 gets 1-1M, server2 gets 1M-2M).\n\n**Base62 Encoding**: [0-9a-zA-Z] = 62 characters. 7 chars = 62^7 ≈ 3.5 trillion unique codes.\n\n**Data Model**:\n- Table: `urls` (short_code PK, long_url, created_at, user_id, expires_at)\n- Table: `clicks` (id, short_code FK, timestamp, ip, referrer, user_agent, country)\n\n**Read vs Write**:\n- Reads (redirects) far exceed writes (creates). Read:Write ratio ~100:1.\n- Caching: Redis/Memcached for hot URLs. LRU eviction. Cache hit rate >90%.\n- DB: Write to primary, read from replicas.\n\n**Redirection**: 301 (permanent) vs 302 (temporary). 301 tells browsers to cache — reduces server load but loses analytics. 302 always hits server — better for analytics.\n\n**Expiration**: Optional TTL per URL. Background job deletes expired entries. Reclaim short codes after expiration.\n\n**Custom Aliases**: Allow users to specify custom short codes (e.g., short.ly/my-brand). Check availability. Reserve against dictionary words.",
          "code": "// URL shortener service\nclass URLShortener {\n  constructor(domain) {\n    this.domain = domain;\n    this.urlMap = new Map(); // shortCode -> longUrl\n    this.reverseMap = new Map(); // longUrl -> shortCode\n    this.counter = 100000; // start counter\n    this.clicks = new Map(); // shortCode -> click count\n  }\n\n  base62Encode(num) {\n    const chars = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';\n    let result = '';\n    while (num > 0) {\n      result = chars[num % 62] + result;\n      num = Math.floor(num / 62);\n    }\n    return result || '0';\n  }\n\n  shorten(longUrl) {\n    // Check if already shortened\n    if (this.reverseMap.has(longUrl)) {\n      const code = this.reverseMap.get(longUrl);\n      return `${this.domain}/${code}`;\n    }\n    const code = this.base62Encode(++this.counter);\n    this.urlMap.set(code, longUrl);\n    this.reverseMap.set(longUrl, code);\n    this.clicks.set(code, 0);\n    return `${this.domain}/${code}`;\n  }\n\n  redirect(shortCode) {\n    const longUrl = this.urlMap.get(shortCode);\n    if (!longUrl) return { error: '404 Not Found' };\n    this.clicks.set(shortCode, (this.clicks.get(shortCode) || 0) + 1);\n    return { redirectTo: longUrl, statusCode: 302 };\n  }\n\n  getAnalytics(shortCode) {\n    return {\n      shortCode,\n      longUrl: this.urlMap.get(shortCode),\n      clicks: this.clicks.get(shortCode) || 0,\n    };\n  }\n}\n\nconst shortener = new URLShortener('https://short.ly');\nconsole.log(shortener.shorten('https://www.example.com/very/long/url/123'));\nconsole.log(shortener.shorten('https://www.example.com/another/url'));\nconsole.log(shortener.shorten('https://www.example.com/very/long/url/123')); // same URL, same code\nconst code = 'q0T'; // from first shortening\nshortener.redirect('q0T');\nshortener.redirect('q0T');\nconsole.log(shortener.getAnalytics('q0T'));",
          "example": "// Base62 encoding and decoding\nclass Base62 {\n  static CHARS = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';\n\n  static encode(num) {\n    if (num === 0) return '0';\n    let result = '';\n    while (num > 0) {\n      result = this.CHARS[num % 62] + result;\n      num = Math.floor(num / 62);\n    }\n    return result;\n  }\n\n  static decode(str) {\n    let num = 0;\n    for (const char of str) {\n      num = num * 62 + this.CHARS.indexOf(char);\n    }\n    return num;\n  }\n}\n\n// Demo: counter → short code → back to counter\nfor (const id of [1, 100, 1000, 100000, 1000000, 3500000000000]) {\n  const encoded = Base62.encode(id);\n  const decoded = Base62.decode(encoded);\n  console.log(`${id} → '${encoded}' → ${decoded} (length: ${encoded.length})`);  \n}",
          "useCase": "URL shortening services, link tracking, QR code generation, campaign tracking, deep linking, content sharing.",
          "interviewQuestions": [
            {
              "question": "How do you generate unique short codes?",
              "answer": "Counter-based: distributed counter (ZooKeeper or DB auto-increment) → base62 encode. Each server pre-allocates a range (e.g., 1M IDs). No collisions, no DB lookup needed for generation. 7 base62 chars = 3.5T codes. Alternative: random + collision check."
            },
            {
              "question": "Why base62 instead of base64?",
              "answer": "Base64 includes + and / which are problematic in URLs (need encoding). Base62 uses only [0-9a-zA-Z] — URL-safe without encoding. 62^7 = 3.5 trillion combinations — sufficient for most use cases."
            },
            {
              "question": "301 vs 302 redirect — which to use?",
              "answer": "301 (permanent): browser caches redirect, subsequent visits don't hit server. Saves server load but loses analytics. 302 (temporary): every visit hits server. Better for analytics tracking. Most URL shorteners use 302 for analytics, with server-side caching to handle load."
            },
            {
              "question": "How do you scale reads (redirects)?",
              "answer": "Read:Write ratio ~100:1. Layer 1: CDN for popular URLs. Layer 2: Application cache (Redis) — LRU, TTL. Layer 3: DB read replicas. Cache hit rate >90% means most redirects never hit DB. For top 20% URLs (80% of traffic), cache stays hot."
            },
            {
              "question": "How do you handle hash collisions?",
              "answer": "If using hash-based approach: hash(longUrl) → take first 7 chars. On collision (code exists with different URL), append counter and rehash. Or: use counter-based approach (no collisions by design). Always do existence check before insert."
            },
            {
              "question": "How much storage do you need?",
              "answer": "Per URL: short_code(7B) + long_url(avg 200B) + metadata(50B) ≈ 257B. 1B URLs = 257GB. With indexes: ~500GB. Fits in a single DB shard. At 100B URLs: 25TB — need sharding by short_code hash."
            },
            {
              "question": "How do you implement URL expiration?",
              "answer": "Optional `expires_at` column. On redirect: check if expired → return 410 Gone. Background cleanup job runs hourly to delete expired entries and reclaim short codes. Soft delete first (mark expired), hard delete after 30 days."
            },
            {
              "question": "How do you prevent abuse (spam URLs)?",
              "answer": "Rate limiting per API key/IP. URL validation (is it a real URL?). Scan destination URL against malware/phishing blacklists (Google Safe Browsing API). Require authentication for custom aliases. Monitor for click-bombing (DDoS via short URLs)."
            },
            {
              "question": "How do you implement analytics?",
              "answer": "On each redirect: log {short_code, timestamp, IP, user_agent, referrer} to Kafka → async consumers write to analytics DB (ClickHouse/TimescaleDB). Real-time aggregation: Redis counters for click counts. Dashboard queries analytics DB. Don't block redirect for analytics writing."
            },
            {
              "question": "How do you make the system highly available?",
              "answer": "Multi-region deployment. DB: primary-secondary replication across regions. Cache: Redis cluster per region. Counter service: pre-allocate ranges (survives ZooKeeper outage). DNS-based routing to nearest region. Reads can be served from any region; writes go to primary."
            }
          ],
          "exercises": [
            {
              "type": "estimation",
              "question": "100M new URLs/month, 10B redirects/month. Average URL size 200B. Estimate storage and QPS.",
              "answer": "Storage per month: 100M × 257B ≈ 25.7GB. Per year: 308GB. In 5 years: 1.5TB. Writes: 100M / 30 / 86400 ≈ 39 writes/sec. Reads: 10B / 30 / 86400 ≈ 3858 reads/sec. Peak (3x average): ~12K reads/sec. Easily handled by Redis + a few DB replicas."
            },
            {
              "type": "design",
              "question": "Design the counter-based ID generation for multiple servers.",
              "answer": "ZooKeeper or central DB maintains next range. Server requests range: gets [start, end]. Locally increments within range. When range exhausted, request new range. Range size: 1M (lasts ~hours at high throughput). If server crashes, unused IDs in range are wasted (acceptable). No coordination needed between servers for individual IDs."
            },
            {
              "type": "tricky",
              "question": "Should you deduplicate — return same short code for same long URL?",
              "answer": "Depends on use case. Pro: saves storage, user sees consistent short URL. Con: different users/campaigns need different short codes for separate analytics. Solution: deduplicate per user (same user, same URL = same code). Different users get different codes. Implement via composite key (user_id, long_url)."
            },
            {
              "type": "scenario",
              "question": "A shortened URL goes viral — 1M clicks/second. How does your system handle it?",
              "answer": "1) Redis cache hit for this URL — no DB load. 2) CDN layer absorbs most traffic. 3) Analytics writes batched (count in Redis, flush to DB every 10 seconds). 4) Auto-scale redirect servers behind load balancer. 5) Rate limit if it's a DDoS. Expected: 1M/sec easily handled by Redis cluster + CDN."
            },
            {
              "type": "design",
              "question": "Design the analytics pipeline.",
              "answer": "Redirect server logs click event to Kafka (non-blocking). Consumer groups: 1) Real-time counter (increment Redis key per short_code). 2) Raw event writer (ClickHouse for detailed analytics). 3) Geo enrichment (IP → country via MaxMind, then store). Dashboard reads from ClickHouse for time-series, Redis for live count. Retention: raw events 90 days, aggregated forever."
            },
            {
              "type": "output",
              "question": "Base62 encode the numbers: 1, 62, 3844, 100000. What are the results?",
              "answer": "1 → '1'. 62 → '10'. 3844 → '100'. 100000 → 'q0T' (100000 = 26×62² + 0×62 + 29 → chars[26]='q', chars[0]='0', chars[29]='T')."
            },
            {
              "type": "debug",
              "question": "Users report some short URLs returning 404 even though they were just created. What could be wrong?",
              "answer": "1) Read replica lag: write goes to primary, read hits stale replica. Fix: read from primary for recently created URLs (cache-aside). 2) Cache miss + DB miss: cache not populated yet, DB replica not synced. 3) URL expired (very short TTL). 4) Code generation collision (two servers generated same code)."
            },
            {
              "type": "design",
              "question": "Design custom alias support (e.g., short.ly/my-brand).",
              "answer": "Separate table for custom aliases: (alias PK, long_url, user_id, created_at). Check alias not in reserved words list. Check not already taken. Length: 3-30 chars, alphanumeric + hyphens. On redirect: check custom alias table first, then generated codes table. Rate limit custom alias creation per user."
            },
            {
              "type": "estimation",
              "question": "Redis cache for top 20% of URLs (Pareto). 1B total URLs, avg entry 250B. How much Redis memory?",
              "answer": "Hot URLs: 1B × 0.2 = 200M. Memory per entry with Redis overhead: ~350B. Total: 200M × 350B = 70GB. Redis cluster with 3 nodes: ~23GB per node. Very feasible. These 200M URLs serve 80% of traffic."
            },
            {
              "type": "scenario",
              "question": "Legal takedown request for a specific short URL. How do you handle it?",
              "answer": "1) Immediately mark URL as disabled (soft delete). 2) Redirect returns 451 (Unavailable for Legal Reasons) or 410 (Gone). 3) Log takedown request with legal reference. 4) Notify URL creator. 5) Retain record for legal compliance (don't hard delete). 6) Admin interface for legal team to manage takedowns."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Complete URL shortener with base62",
              "code": "class TinyURL {\n  constructor(domain) {\n    this.domain = domain;\n    this.store = new Map();\n    this.reverse = new Map();\n    this.counter = 100000;\n    this.chars = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';\n  }\n  encode(num) {\n    let s = '';\n    while (num > 0) { s = this.chars[num % 62] + s; num = Math.floor(num / 62); }\n    return s;\n  }\n  shorten(url) {\n    if (this.reverse.has(url)) return `${this.domain}/${this.reverse.get(url)}`;\n    const code = this.encode(++this.counter);\n    this.store.set(code, url);\n    this.reverse.set(url, code);\n    return `${this.domain}/${code}`;\n  }\n  resolve(code) { return this.store.get(code) || null; }\n}\n\nconst t = new TinyURL('https://tiny.url');\nconsole.log(t.shorten('https://example.com/page1'));\nconsole.log(t.shorten('https://example.com/page2'));\nconsole.log(t.shorten('https://example.com/page1')); // dedup\nconsole.log(t.resolve('q0T'));",
              "output": "https://tiny.url/q0T\nhttps://tiny.url/q0U\nhttps://tiny.url/q0T\nhttps://example.com/page1"
            },
            {
              "question": "Program 2: Base62 encoder/decoder",
              "code": "const CHARS = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';\nfunction encode62(n) {\n  if (n === 0) return '0';\n  let s = '';\n  while (n > 0) { s = CHARS[n % 62] + s; n = Math.floor(n / 62); }\n  return s;\n}\nfunction decode62(s) {\n  let n = 0;\n  for (const c of s) n = n * 62 + CHARS.indexOf(c);\n  return n;\n}\n\n[1, 62, 3844, 100000, 999999999].forEach(n => {\n  const e = encode62(n);\n  console.log(`${n} → '${e}' → ${decode62(e)} (len: ${e.length})`);\n});",
              "output": "1 → '1' → 1 (len: 1)\n62 → '10' → 62 (len: 2)\n3844 → '100' → 3844 (len: 3)\n100000 → 'q0T' → 100000 (len: 3)\n999999999 → '15FTGf' → 999999999 (len: 6)"
            },
            {
              "question": "Program 3: Click analytics tracker",
              "code": "class ClickTracker {\n  constructor() { this.events = []; this.counts = new Map(); }\n  recordClick(code, meta) {\n    this.events.push({ code, ...meta, time: Date.now() });\n    this.counts.set(code, (this.counts.get(code) || 0) + 1);\n  }\n  getStats(code) {\n    const clicks = this.events.filter(e => e.code === code);\n    const byCountry = {};\n    clicks.forEach(c => { byCountry[c.country] = (byCountry[c.country] || 0) + 1; });\n    return { code, totalClicks: clicks.length, byCountry, lastClick: clicks[clicks.length-1]?.time };\n  }\n}\n\nconst tracker = new ClickTracker();\ntracker.recordClick('abc', { country: 'US', device: 'mobile' });\ntracker.recordClick('abc', { country: 'IN', device: 'desktop' });\ntracker.recordClick('abc', { country: 'US', device: 'mobile' });\ntracker.recordClick('xyz', { country: 'UK', device: 'tablet' });\nconsole.log(tracker.getStats('abc'));",
              "output": "{\n  code: 'abc',\n  totalClicks: 3,\n  byCountry: { US: 2, IN: 1 },\n  lastClick: <timestamp>\n}"
            },
            {
              "question": "Program 4: Rate limiter for URL creation",
              "code": "class RateLimiter {\n  constructor(maxRequests, windowMs) {\n    this.max = maxRequests;\n    this.window = windowMs;\n    this.buckets = new Map();\n  }\n  allow(userId) {\n    const now = Date.now();\n    if (!this.buckets.has(userId)) this.buckets.set(userId, []);\n    const bucket = this.buckets.get(userId).filter(t => now - t < this.window);\n    this.buckets.set(userId, bucket);\n    if (bucket.length >= this.max) {\n      return { allowed: false, retryAfterMs: this.window - (now - bucket[0]) };\n    }\n    bucket.push(now);\n    return { allowed: true, remaining: this.max - bucket.length };\n  }\n}\n\nconst limiter = new RateLimiter(3, 10000); // 3 per 10s\nconsole.log(limiter.allow('user1'));\nconsole.log(limiter.allow('user1'));\nconsole.log(limiter.allow('user1'));\nconsole.log(limiter.allow('user1')); // blocked\nconsole.log(limiter.allow('user2')); // different user OK",
              "output": "{ allowed: true, remaining: 2 }\n{ allowed: true, remaining: 1 }\n{ allowed: true, remaining: 0 }\n{ allowed: false, retryAfterMs: <ms> }\n{ allowed: true, remaining: 2 }"
            },
            {
              "question": "Program 5: URL expiration manager",
              "code": "class ExpiringURLStore {\n  constructor() { this.urls = new Map(); }\n  add(code, longUrl, ttlMs) {\n    this.urls.set(code, { longUrl, expiresAt: Date.now() + ttlMs });\n  }\n  resolve(code) {\n    const entry = this.urls.get(code);\n    if (!entry) return { status: 404, message: 'Not found' };\n    if (Date.now() > entry.expiresAt) {\n      this.urls.delete(code);\n      return { status: 410, message: 'URL expired' };\n    }\n    return { status: 302, redirectTo: entry.longUrl };\n  }\n  cleanup() {\n    const now = Date.now();\n    let removed = 0;\n    for (const [code, entry] of this.urls) {\n      if (now > entry.expiresAt) { this.urls.delete(code); removed++; }\n    }\n    return { removed, remaining: this.urls.size };\n  }\n}\n\nconst store = new ExpiringURLStore();\nstore.add('abc', 'https://example.com', 5000); // 5 second TTL\nstore.add('xyz', 'https://other.com', 60000); // 60 second TTL\nconsole.log(store.resolve('abc')); // valid\nconsole.log(store.resolve('xyz')); // valid\nconsole.log(store.resolve('nope')); // not found",
              "output": "{ status: 302, redirectTo: 'https://example.com' }\n{ status: 302, redirectTo: 'https://other.com' }\n{ status: 404, message: 'Not found' }"
            },
            {
              "question": "Program 6: Distributed counter range allocator",
              "code": "class CounterAllocator {\n  constructor(rangeSize) {\n    this.rangeSize = rangeSize;\n    this.nextStart = 1;\n    this.allocations = [];\n  }\n  allocate(serverId) {\n    const range = { serverId, start: this.nextStart, end: this.nextStart + this.rangeSize - 1 };\n    this.nextStart += this.rangeSize;\n    this.allocations.push(range);\n    return range;\n  }\n  status() {\n    return {\n      totalAllocated: this.nextStart - 1,\n      servers: this.allocations.map(a => `${a.serverId}: [${a.start}-${a.end}]`),\n    };\n  }\n}\n\nconst alloc = new CounterAllocator(1000000);\nconsole.log(alloc.allocate('server-1'));\nconsole.log(alloc.allocate('server-2'));\nconsole.log(alloc.allocate('server-1')); // server-1 needs more\nconsole.log(alloc.status());",
              "output": "{ serverId: 'server-1', start: 1, end: 1000000 }\n{ serverId: 'server-2', start: 1000001, end: 2000000 }\n{ serverId: 'server-1', start: 2000001, end: 3000000 }\n{\n  totalAllocated: 3000000,\n  servers: [ 'server-1: [1-1000000]', 'server-2: [1000001-2000000]', 'server-1: [2000001-3000000]' ]\n}"
            },
            {
              "question": "Program 7: LRU Cache for hot URLs",
              "code": "class LRUCache {\n  constructor(capacity) {\n    this.capacity = capacity;\n    this.cache = new Map();\n    this.hits = 0;\n    this.misses = 0;\n  }\n  get(key) {\n    if (!this.cache.has(key)) { this.misses++; return null; }\n    this.hits++;\n    const val = this.cache.get(key);\n    this.cache.delete(key);\n    this.cache.set(key, val); // move to end (most recent)\n    return val;\n  }\n  put(key, val) {\n    if (this.cache.has(key)) this.cache.delete(key);\n    this.cache.set(key, val);\n    if (this.cache.size > this.capacity) {\n      const oldest = this.cache.keys().next().value;\n      this.cache.delete(oldest);\n    }\n  }\n  stats() {\n    const total = this.hits + this.misses;\n    return { size: this.cache.size, hitRate: total ? (this.hits/total*100).toFixed(1)+'%' : 'N/A' };\n  }\n}\n\nconst cache = new LRUCache(3);\ncache.put('a', 'url-a'); cache.put('b', 'url-b'); cache.put('c', 'url-c');\nconsole.log(cache.get('a')); // hit\ncache.put('d', 'url-d'); // evicts 'b'\nconsole.log(cache.get('b')); // miss\nconsole.log(cache.get('c')); // hit\nconsole.log(cache.stats());",
              "output": "url-a\nnull\nurl-c\n{ size: 3, hitRate: '66.7%' }"
            },
            {
              "question": "Program 8: URL validator",
              "code": "function validateURL(url) {\n  const checks = [];\n  // Protocol check\n  const hasProtocol = /^https?:\\/\\//.test(url);\n  checks.push({ check: 'Protocol', pass: hasProtocol });\n  // Domain check\n  const domainMatch = url.match(/^https?:\\/\\/([^/]+)/);\n  const hasDomain = domainMatch && domainMatch[1].includes('.');\n  checks.push({ check: 'Domain', pass: !!hasDomain });\n  // Length check\n  checks.push({ check: 'Length', pass: url.length <= 2048 });\n  // No spaces\n  checks.push({ check: 'No spaces', pass: !url.includes(' ') });\n  \n  return { url: url.substring(0, 50) + (url.length > 50 ? '...' : ''), valid: checks.every(c => c.pass), checks };\n}\n\nconsole.log(validateURL('https://www.example.com/path?q=test'));\nconsole.log(validateURL('not-a-url'));\nconsole.log(validateURL('https://no-dot'));",
              "output": "{ url: 'https://www.example.com/path?q=test', valid: true, checks: [...all pass] }\n{ url: 'not-a-url', valid: false, checks: [Protocol: fail, ...] }\n{ url: 'https://no-dot', valid: false, checks: [Domain: fail, ...] }"
            },
            {
              "question": "Program 9: Collision-free hash-based shortener",
              "code": "function hashShorten(url, existingCodes) {\n  let attempt = 0;\n  while (attempt < 5) {\n    const input = attempt === 0 ? url : `${url}#${attempt}`;\n    // Simple hash (in production: use MD5/SHA256)\n    let hash = 0;\n    for (const char of input) hash = ((hash << 5) - hash + char.charCodeAt(0)) | 0;\n    hash = Math.abs(hash);\n    const chars = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';\n    let code = '';\n    let n = hash;\n    for (let i = 0; i < 7; i++) { code += chars[n % 62]; n = Math.floor(n / 62); }\n    \n    if (!existingCodes.has(code)) {\n      existingCodes.add(code);\n      return { code, attempts: attempt + 1 };\n    }\n    attempt++;\n  }\n  return { error: 'Max collision retries exceeded' };\n}\n\nconst existing = new Set();\nconsole.log(hashShorten('https://example.com/1', existing));\nconsole.log(hashShorten('https://example.com/2', existing));\nconsole.log(hashShorten('https://example.com/3', existing));\nconsole.log('Total codes:', existing.size);",
              "output": "{ code: 'aBcDeFg', attempts: 1 }\n{ code: 'xYzAbCd', attempts: 1 }\n{ code: 'mNoPqRs', attempts: 1 }\nTotal codes: 3"
            },
            {
              "question": "Program 10: Multi-region redirect resolver",
              "code": "class MultiRegionResolver {\n  constructor() {\n    this.regions = new Map(); // region -> cache\n    this.primary = new Map(); // source of truth\n  }\n  addRegion(name) { this.regions.set(name, new Map()); }\n  write(code, url) {\n    this.primary.set(code, url);\n    // Async replication to all regions\n    for (const cache of this.regions.values()) cache.set(code, url);\n  }\n  resolve(code, region) {\n    const cache = this.regions.get(region);\n    if (cache?.has(code)) return { source: `${region}-cache`, url: cache.get(code) };\n    // Fallback to primary\n    if (this.primary.has(code)) {\n      const url = this.primary.get(code);\n      cache?.set(code, url); // warm cache\n      return { source: 'primary', url };\n    }\n    return { source: 'none', url: null };\n  }\n}\n\nconst resolver = new MultiRegionResolver();\nresolver.addRegion('us-east');\nresolver.addRegion('eu-west');\nresolver.write('abc', 'https://example.com');\nconsole.log(resolver.resolve('abc', 'us-east'));\nconsole.log(resolver.resolve('abc', 'eu-west'));\nconsole.log(resolver.resolve('xyz', 'us-east'));",
              "output": "{ source: 'us-east-cache', url: 'https://example.com' }\n{ source: 'eu-west-cache', url: 'https://example.com' }\n{ source: 'none', url: null }"
            }
          ]
        },
        {
          "id": "chat-system",
          "title": "Chat System (like WhatsApp/Slack)",
          "category": "Company HLD",
          "description": "High-level design of a real-time chat system — message delivery, presence, group chats, read receipts, and offline message handling.",
          "explanation": "A chat system like WhatsApp must deliver messages in real-time to online users, store messages for offline users, support 1:1 and group conversations, and handle presence/typing indicators — all at massive scale.\n\n**Core Components**:\n1. **Chat Server (WebSocket Gateway)**: Maintains persistent connections with clients. Routes messages to recipients.\n2. **Message Service**: Stores messages, handles ordering, deduplication.\n3. **Presence Service**: Tracks online/offline status, last seen.\n4. **Notification Service**: Push notifications for offline users (APNs/FCM).\n5. **Group Service**: Group membership, message fanout.\n6. **Media Service**: Image/video/file upload and CDN delivery.\n\n**1:1 Message Flow**:\n1. User A sends message → WebSocket → Chat Server.\n2. Chat Server stores message in DB (status: SENT).\n3. Lookup: is User B online? (Presence Service).\n4. If online: forward to User B's Chat Server → WebSocket → User B's device. Mark: DELIVERED.\n5. If offline: store in pending queue. When B comes online, flush pending messages. Also send push notification.\n6. User B reads message → send read receipt → mark: READ.\n\n**Message Ordering**:\n- Each message has: sender_id, conversation_id, timestamp, sequence_number.\n- Sequence number per conversation ensures ordering within a chat.\n- Client displays messages ordered by sequence number.\n- Server-assigned timestamps resolve cross-device ordering.\n\n**Group Chat**:\n- Small groups (<256 members): fanout-on-write. Message stored once, delivery entry per member.\n- Large groups (>256): fanout-on-read. Store message once in group timeline. Members fetch on demand.\n- Message table: (msg_id, group_id, sender_id, content, timestamp).\n- Delivery table: (msg_id, user_id, status: SENT|DELIVERED|READ).\n\n**Presence**:\n- Heartbeat: client sends ping every 30 seconds. If missed 2 consecutive heartbeats → mark offline.\n- On status change: notify all contacts who have this user's chat open.\n- 'Last seen' = timestamp of last heartbeat.\n\n**End-to-End Encryption (E2EE)**:\n- Signal Protocol: each user has identity key pair + session keys.\n- Messages encrypted on sender device, decrypted on recipient device.\n- Server cannot read message content.\n- Key exchange on first message (X3DH protocol).",
          "code": "// Real-time chat server simulation\nclass ChatServer {\n  constructor() {\n    this.connections = new Map(); // userId -> connection\n    this.messages = []; // message store\n    this.pending = new Map(); // userId -> pending messages\n    this.seqCounters = new Map(); // conversationId -> sequence\n  }\n\n  connect(userId) {\n    this.connections.set(userId, { userId, online: true, connectedAt: Date.now() });\n    // Flush pending messages\n    const pendingMsgs = this.pending.get(userId) || [];\n    this.pending.delete(userId);\n    return { status: 'CONNECTED', pendingMessages: pendingMsgs };\n  }\n\n  disconnect(userId) {\n    this.connections.delete(userId);\n    return { status: 'DISCONNECTED', lastSeen: Date.now() };\n  }\n\n  sendMessage(senderId, recipientId, content) {\n    const convId = [senderId, recipientId].sort().join(':');\n    const seq = (this.seqCounters.get(convId) || 0) + 1;\n    this.seqCounters.set(convId, seq);\n\n    const msg = {\n      id: `msg_${Date.now()}_${seq}`,\n      conversationId: convId,\n      senderId,\n      recipientId,\n      content,\n      sequence: seq,\n      timestamp: Date.now(),\n      status: 'SENT',\n    };\n    this.messages.push(msg);\n\n    // Deliver if online\n    if (this.connections.has(recipientId)) {\n      msg.status = 'DELIVERED';\n      return { ...msg, delivery: 'REALTIME' };\n    } else {\n      if (!this.pending.has(recipientId)) this.pending.set(recipientId, []);\n      this.pending.get(recipientId).push(msg);\n      return { ...msg, delivery: 'QUEUED' };\n    }\n  }\n\n  markRead(userId, messageIds) {\n    const updated = [];\n    messageIds.forEach(id => {\n      const msg = this.messages.find(m => m.id === id);\n      if (msg) { msg.status = 'READ'; updated.push(id); }\n    });\n    return { updated };\n  }\n}\n\nconst chat = new ChatServer();\nchat.connect('alice');\nchat.connect('bob');\nconsole.log(chat.sendMessage('alice', 'bob', 'Hello Bob!')); // realtime\nchat.disconnect('bob');\nconsole.log(chat.sendMessage('alice', 'bob', 'Are you there?')); // queued\nconst reconnect = chat.connect('bob');\nconsole.log('Bob reconnects:', reconnect);",
          "example": "// Group chat with fanout\nclass GroupChat {\n  constructor() {\n    this.groups = new Map(); // groupId -> { members, messages }\n  }\n  createGroup(groupId, members) {\n    this.groups.set(groupId, { members: new Set(members), messages: [] });\n  }\n  sendGroupMessage(groupId, senderId, content) {\n    const group = this.groups.get(groupId);\n    if (!group || !group.members.has(senderId)) return { error: 'Not a member' };\n    const msg = { id: `gm_${Date.now()}`, groupId, senderId, content, timestamp: Date.now() };\n    group.messages.push(msg);\n    // Fanout: create delivery entry for each member\n    const deliveries = [...group.members]\n      .filter(m => m !== senderId)\n      .map(m => ({ userId: m, status: 'SENT' }));\n    return { message: msg, deliveries };\n  }\n  getMessages(groupId, userId, limit = 10) {\n    const group = this.groups.get(groupId);\n    if (!group?.members.has(userId)) return [];\n    return group.messages.slice(-limit);\n  }\n}\n\nconst gc = new GroupChat();\ngc.createGroup('g1', ['alice', 'bob', 'carol']);\nconsole.log(gc.sendGroupMessage('g1', 'alice', 'Hey everyone!'));\nconsole.log(gc.sendGroupMessage('g1', 'bob', 'Hi Alice!'));\nconsole.log('Messages:', gc.getMessages('g1', 'carol'));",
          "useCase": "Instant messaging, team collaboration tools, customer support chat, in-app messaging, social media DMs.",
          "interviewQuestions": [
            {
              "question": "How do you ensure message ordering in a chat?",
              "answer": "Sequence number per conversation, assigned by server. Client displays by sequence number. For concurrent sends in same conversation, server serializes via a lock or queue per conversation_id. Timestamps are secondary — used for display, not ordering."
            },
            {
              "question": "How do you handle message delivery for offline users?",
              "answer": "Store in pending queue (Redis list per user or DB). When user reconnects (WebSocket established), flush queue. Also send push notification via APNs/FCM. Mark messages as DELIVERED when client acknowledges receipt. Messages persist in DB regardless of online status."
            },
            {
              "question": "How do you scale WebSocket connections?",
              "answer": "Each server maintains N connections. Route messages between servers via pub/sub (Redis Pub/Sub or Kafka). User → server mapping stored in Redis. On send: lookup recipient's server → publish to that server → server forwards to user's WebSocket. Horizontal scale: add more WebSocket servers behind L4 load balancer (sticky sessions by user)."
            },
            {
              "question": "How do group messages work differently from 1:1?",
              "answer": "1:1: simple point-to-point. Groups: message stored once + delivery entry per member (fanout-on-write for small groups). For groups with 10K members, fanout-on-read: store one message, members pull. Group messages need member list maintenance, admin controls, and read receipt aggregation."
            },
            {
              "question": "How do you implement typing indicators?",
              "answer": "Client sends 'typing' event when user starts typing. Server forwards to other participants (no persistence). Debounce: send at most once per 3 seconds. Auto-clear after 5 seconds of no keypress. Not sent for group chats > 50 members (too noisy). Sent via same WebSocket, not REST."
            },
            {
              "question": "How do you implement read receipts?",
              "answer": "When recipient views message: client sends ACK with message_id. Server updates delivery status to READ. Send read receipt event to sender. For groups: maintain per-member status. Show 'Read by N' aggregate, not individual receipts for large groups. Blue ticks = all group members read."
            },
            {
              "question": "How do you handle media messages (images, videos)?",
              "answer": "Upload flow: client → upload service → object storage (S3). Get back media_url. Send chat message with media_url + thumbnail. Recipient downloads media separately. Encrypt media with per-message key for E2EE. CDN for media delivery. Compress images/videos client-side before upload."
            },
            {
              "question": "How do you implement message search?",
              "answer": "Local search: client-side full-text search on message cache/DB. Server search: Elasticsearch index on messages (for non-E2EE apps). For E2EE: search only works on client device (server can't index encrypted content). Index: message content + metadata. Support: by keyword, by sender, by date range."
            },
            {
              "question": "What is the data model for messages?",
              "answer": "Messages table: (id PK, conversation_id, sender_id, content, type, timestamp, sequence). Conversations table: (id PK, type: 1:1|group, last_message_id, updated_at). Participants table: (conversation_id, user_id, role, joined_at). Delivery: (message_id, user_id, status, delivered_at, read_at). Partition by conversation_id."
            },
            {
              "question": "How do you implement message deletion?",
              "answer": "Soft delete: mark message as deleted, hide from UI, keep in DB for compliance. 'Delete for me': only remove from user's view (add to user's deleted_messages set). 'Delete for everyone': mark message as globally deleted (within time window, e.g., 1 hour). Show 'This message was deleted' placeholder."
            }
          ],
          "exercises": [
            {
              "type": "estimation",
              "question": "1B daily active users, each sends 50 messages/day. Average message: 100 bytes + 50B metadata. Estimate daily data.",
              "answer": "Messages/day: 1B × 50 = 50B messages. Storage: 50B × 150B = 7.5TB/day. Monthly: 225TB. Write QPS: 50B / 86400 = 579K writes/sec. Peak (3x): 1.7M writes/sec. Need: distributed DB (Cassandra, DynamoDB) with heavy partitioning."
            },
            {
              "type": "design",
              "question": "Design the presence (online/offline) service.",
              "answer": "On connect: user sends heartbeat → server sets Redis key (user:{id}, TTL=60s). Every 30s: client renews heartbeat. If key expires → user offline. On subscribe to contact's presence: listen to Redis keyspace notifications. Optimization: batch presence updates for contact list. Don't push presence for contacts not in active chat."
            },
            {
              "type": "scenario",
              "question": "User has 5 devices (phone, tablet, laptop, desktop, web). How does multi-device sync work?",
              "answer": "Each device maintains separate WebSocket. Message sent from one device → delivered to all other devices (including sender's). Each device tracks its own delivery/read state. Sequence numbers ensure ordering across devices. Device registration: server maintains device list per user. Push to all connected devices."
            },
            {
              "type": "tricky",
              "question": "Why not just use HTTP polling instead of WebSocket?",
              "answer": "Polling: client asks 'any new messages?' every N seconds. Wasteful: 95% of polls return empty. Latency: up to N seconds delay. WebSocket: persistent connection, server pushes instantly. 1B users × 1 poll/sec = 1B req/sec (expensive). WebSocket: 1B persistent connections (fewer resources). Long-polling is a middle ground but still wastes connections."
            },
            {
              "type": "design",
              "question": "Design message delivery guarantees (at-least-once, exactly-once).",
              "answer": "At-least-once: server retries delivery until client ACKs. Client deduplicates by message_id. Exactly-once: idempotent processing with unique message_id. Server: write to DB + send to recipient. If recipient doesn't ACK within 5s, retry. Client: if receives duplicate msg_id, ignore. ACK is the client's confirmation message."
            },
            {
              "type": "output",
              "question": "Alice sends 3 messages to offline Bob. Bob reconnects. What events fire?",
              "answer": "1) Bob WebSocket connected → server sends 3 pending messages (ordered by sequence). 2) Bob's client ACKs each → server marks DELIVERED. 3) Server sends delivery receipts to Alice ('double tick'). 4) When Bob reads → read receipt sent to Alice ('blue tick'). 5) Presence service marks Bob as online → Alice sees 'online'."
            },
            {
              "type": "estimation",
              "question": "WhatsApp group: 256 members. One message. How many DB writes, how many deliveries?",
              "answer": "DB writes: 1 for message + 255 for delivery records = 256 writes. If group has 100 messages/day: 25,600 delivery writes/day. For 1M groups of size 256: 25.6B delivery writes/day. This is why large groups (Telegram channels with 100K) must use fanout-on-read."
            },
            {
              "type": "design",
              "question": "Design the notification system for offline messages.",
              "answer": "On message to offline user: Chat Server → Notification Queue (Kafka). Consumer: lookup user's push tokens (FCM for Android, APNs for iOS). Construct notification: sender name + message preview (if not E2EE) or 'New message'. Rate limit: collapse multiple notifications into '5 new messages from Alice'. User preferences: mute per conversation, DND hours."
            },
            {
              "type": "debug",
              "question": "Users report messages arriving out of order. What could cause this?",
              "answer": "1) Multiple chat servers assigning timestamps with clock skew. Fix: use sequence numbers, not timestamps. 2) Network race: message B arrives before A at recipient. Fix: client buffers and reorders by sequence. 3) Multi-device: different devices show different order. Fix: single source of truth (server sequence). 4) Group message fanout taking different paths."
            },
            {
              "type": "scenario",
              "question": "A celebrity posts in a group with 100K members. How does message delivery work?",
              "answer": "Fanout-on-read: store message once in group timeline. When member opens chat, fetch latest from group timeline. No individual delivery writes. Push notification: batch notification to all members (not instant — stagger over minutes). Read receipts: disabled for large groups. Online members get WebSocket event for new message notification (not full content)."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: 1:1 chat with delivery status tracking",
              "code": "class Chat {\n  constructor() { this.messages = []; this.online = new Set(); }\n  connect(user) { this.online.add(user); }\n  disconnect(user) { this.online.delete(user); }\n  send(from, to, text) {\n    const msg = { id: this.messages.length + 1, from, to, text, status: 'SENT', time: Date.now() };\n    if (this.online.has(to)) msg.status = 'DELIVERED';\n    this.messages.push(msg);\n    return { id: msg.id, status: msg.status };\n  }\n  read(userId, msgId) {\n    const msg = this.messages.find(m => m.id === msgId && m.to === userId);\n    if (msg) { msg.status = 'READ'; return true; }\n    return false;\n  }\n  getConversation(user1, user2) {\n    return this.messages.filter(m => \n      (m.from === user1 && m.to === user2) || (m.from === user2 && m.to === user1)\n    ).map(m => `[${m.status}] ${m.from}: ${m.text}`);\n  }\n}\n\nconst c = new Chat();\nc.connect('alice'); c.connect('bob');\nconsole.log(c.send('alice', 'bob', 'Hi!'));\nconsole.log(c.send('bob', 'alice', 'Hey!'));\nc.disconnect('alice');\nconsole.log(c.send('bob', 'alice', 'You there?'));\nc.read('bob', 1);\nconsole.log(c.getConversation('alice', 'bob'));",
              "output": "{ id: 1, status: 'DELIVERED' }\n{ id: 2, status: 'DELIVERED' }\n{ id: 3, status: 'SENT' }\n[\n  '[READ] alice: Hi!',\n  '[DELIVERED] bob: Hey!',\n  '[SENT] bob: You there?'\n]"
            },
            {
              "question": "Program 2: Presence service with heartbeat",
              "code": "class PresenceService {\n  constructor(timeoutMs) {\n    this.timeout = timeoutMs;\n    this.heartbeats = new Map();\n  }\n  heartbeat(userId) {\n    this.heartbeats.set(userId, Date.now());\n  }\n  isOnline(userId) {\n    const last = this.heartbeats.get(userId);\n    return last && (Date.now() - last) < this.timeout;\n  }\n  getStatus(userId) {\n    const last = this.heartbeats.get(userId);\n    if (!last) return { userId, status: 'NEVER_SEEN' };\n    if (Date.now() - last < this.timeout) return { userId, status: 'ONLINE' };\n    return { userId, status: 'OFFLINE', lastSeen: new Date(last).toISOString() };\n  }\n  getOnlineUsers(userIds) {\n    return userIds.filter(id => this.isOnline(id));\n  }\n}\n\nconst ps = new PresenceService(5000); // 5s timeout\nps.heartbeat('alice');\nps.heartbeat('bob');\nps.heartbeat('carol');\n// Simulate carol going offline by setting old heartbeat\nps.heartbeats.set('carol', Date.now() - 10000);\n\nconsole.log(ps.getStatus('alice'));\nconsole.log(ps.getStatus('carol'));\nconsole.log(ps.getStatus('dave'));\nconsole.log('Online:', ps.getOnlineUsers(['alice', 'bob', 'carol', 'dave']));",
              "output": "{ userId: 'alice', status: 'ONLINE' }\n{ userId: 'carol', status: 'OFFLINE', lastSeen: '...' }\n{ userId: 'dave', status: 'NEVER_SEEN' }\nOnline: [ 'alice', 'bob' ]"
            },
            {
              "question": "Program 3: Group chat with fanout",
              "code": "class GroupChatService {\n  constructor() { this.groups = new Map(); }\n  create(id, members) {\n    this.groups.set(id, { members: new Set(members), messages: [], deliveries: new Map() });\n  }\n  send(groupId, sender, text) {\n    const g = this.groups.get(groupId);\n    if (!g?.members.has(sender)) return { error: 'Not a member' };\n    const msg = { id: `${groupId}_${g.messages.length + 1}`, sender, text };\n    g.messages.push(msg);\n    // Fanout delivery\n    const delivery = new Map();\n    g.members.forEach(m => { if (m !== sender) delivery.set(m, 'SENT'); });\n    g.deliveries.set(msg.id, delivery);\n    return { msgId: msg.id, deliveredTo: delivery.size };\n  }\n  markDelivered(groupId, msgId, userId) {\n    this.groups.get(groupId)?.deliveries.get(msgId)?.set(userId, 'DELIVERED');\n  }\n  getDeliveryStatus(groupId, msgId) {\n    const d = this.groups.get(groupId)?.deliveries.get(msgId);\n    if (!d) return null;\n    return Object.fromEntries(d);\n  }\n}\n\nconst gs = new GroupChatService();\ngs.create('team', ['alice', 'bob', 'carol']);\nconsole.log(gs.send('team', 'alice', 'Meeting at 3pm'));\ngs.markDelivered('team', 'team_1', 'bob');\nconsole.log(gs.getDeliveryStatus('team', 'team_1'));",
              "output": "{ msgId: 'team_1', deliveredTo: 2 }\n{ bob: 'DELIVERED', carol: 'SENT' }"
            },
            {
              "question": "Program 4: Message queue for offline delivery",
              "code": "class OfflineQueue {\n  constructor() { this.queues = new Map(); }\n  enqueue(userId, message) {\n    if (!this.queues.has(userId)) this.queues.set(userId, []);\n    this.queues.get(userId).push(message);\n  }\n  flush(userId) {\n    const messages = this.queues.get(userId) || [];\n    this.queues.delete(userId);\n    return { userId, count: messages.length, messages };\n  }\n  pending(userId) {\n    return (this.queues.get(userId) || []).length;\n  }\n}\n\nconst q = new OfflineQueue();\nq.enqueue('bob', { from: 'alice', text: 'Hi Bob!' });\nq.enqueue('bob', { from: 'alice', text: 'Are you there?' });\nq.enqueue('bob', { from: 'carol', text: 'Check this out' });\nconsole.log('Pending for Bob:', q.pending('bob'));\nconsole.log('Bob comes online:', q.flush('bob'));\nconsole.log('Pending after flush:', q.pending('bob'));",
              "output": "Pending for Bob: 3\nBob comes online: {\n  userId: 'bob',\n  count: 3,\n  messages: [\n    { from: 'alice', text: 'Hi Bob!' },\n    { from: 'alice', text: 'Are you there?' },\n    { from: 'carol', text: 'Check this out' }\n  ]\n}\nPending after flush: 0"
            },
            {
              "question": "Program 5: Conversation thread manager",
              "code": "class ConversationManager {\n  constructor() { this.conversations = new Map(); }\n  getOrCreate(user1, user2) {\n    const id = [user1, user2].sort().join(':');\n    if (!this.conversations.has(id)) {\n      this.conversations.set(id, { id, participants: [user1, user2], messages: [], lastActivity: null });\n    }\n    return this.conversations.get(id);\n  }\n  addMessage(user1, user2, sender, text) {\n    const conv = this.getOrCreate(user1, user2);\n    const msg = { sender, text, seq: conv.messages.length + 1, time: Date.now() };\n    conv.messages.push(msg);\n    conv.lastActivity = msg.time;\n    return msg;\n  }\n  getInbox(userId) {\n    return [...this.conversations.values()]\n      .filter(c => c.participants.includes(userId))\n      .sort((a, b) => (b.lastActivity || 0) - (a.lastActivity || 0))\n      .map(c => ({\n        with: c.participants.find(p => p !== userId),\n        lastMessage: c.messages[c.messages.length - 1]?.text,\n        messageCount: c.messages.length,\n      }));\n  }\n}\n\nconst cm = new ConversationManager();\ncm.addMessage('alice', 'bob', 'alice', 'Hey!');\ncm.addMessage('alice', 'bob', 'bob', 'Hi!');\ncm.addMessage('alice', 'carol', 'carol', 'Lunch?');\nconsole.log(cm.getInbox('alice'));",
              "output": "[\n  { with: 'carol', lastMessage: 'Lunch?', messageCount: 1 },\n  { with: 'bob', lastMessage: 'Hi!', messageCount: 2 }\n]"
            },
            {
              "question": "Program 6: Typing indicator with debounce",
              "code": "class TypingIndicator {\n  constructor(timeoutMs) {\n    this.timeout = timeoutMs;\n    this.typing = new Map(); // conversationId -> { userId, expiresAt }\n  }\n  setTyping(convId, userId) {\n    const key = `${convId}:${userId}`;\n    this.typing.set(key, { userId, expiresAt: Date.now() + this.timeout });\n  }\n  getTyping(convId) {\n    const now = Date.now();\n    const result = [];\n    for (const [key, val] of this.typing) {\n      if (key.startsWith(convId + ':')) {\n        if (val.expiresAt > now) result.push(val.userId);\n        else this.typing.delete(key);\n      }\n    }\n    return result;\n  }\n}\n\nconst ti = new TypingIndicator(3000); // 3s timeout\nti.setTyping('conv1', 'alice');\nti.setTyping('conv1', 'bob');\nconsole.log('Typing in conv1:', ti.getTyping('conv1'));\n// Simulate alice stops typing\nti.typing.set('conv1:alice', { userId: 'alice', expiresAt: Date.now() - 1000 });\nconsole.log('After alice stops:', ti.getTyping('conv1'));",
              "output": "Typing in conv1: [ 'alice', 'bob' ]\nAfter alice stops: [ 'bob' ]"
            },
            {
              "question": "Program 7: Message deduplication",
              "code": "class MessageDeduplicator {\n  constructor() { this.seen = new Set(); this.messages = []; }\n  process(message) {\n    if (this.seen.has(message.id)) {\n      return { action: 'DUPLICATE', id: message.id };\n    }\n    this.seen.add(message.id);\n    this.messages.push(message);\n    return { action: 'ACCEPTED', id: message.id, total: this.messages.length };\n  }\n}\n\nconst dedup = new MessageDeduplicator();\nconsole.log(dedup.process({ id: 'msg1', text: 'Hello' }));\nconsole.log(dedup.process({ id: 'msg2', text: 'World' }));\nconsole.log(dedup.process({ id: 'msg1', text: 'Hello' })); // retry/duplicate\nconsole.log(dedup.process({ id: 'msg3', text: '!' }));\nconsole.log('Total unique:', dedup.messages.length);",
              "output": "{ action: 'ACCEPTED', id: 'msg1', total: 1 }\n{ action: 'ACCEPTED', id: 'msg2', total: 2 }\n{ action: 'DUPLICATE', id: 'msg1' }\n{ action: 'ACCEPTED', id: 'msg3', total: 3 }\nTotal unique: 3"
            },
            {
              "question": "Program 8: Read receipt aggregator for groups",
              "code": "class ReadReceipts {\n  constructor() { this.receipts = new Map(); }\n  \n  markRead(msgId, userId) {\n    if (!this.receipts.has(msgId)) this.receipts.set(msgId, new Set());\n    this.receipts.get(msgId).add(userId);\n  }\n  \n  getStatus(msgId, totalMembers) {\n    const readers = this.receipts.get(msgId) || new Set();\n    const readCount = readers.size;\n    return {\n      msgId,\n      readBy: [...readers],\n      readCount,\n      totalMembers,\n      allRead: readCount >= totalMembers,\n      display: readCount === 0 ? '✓ Sent' : readCount >= totalMembers ? '✓✓ Read by all' : `✓✓ Read by ${readCount}`,\n    };\n  }\n}\n\nconst rr = new ReadReceipts();\nrr.markRead('msg1', 'bob');\nconsole.log(rr.getStatus('msg1', 3));\nrr.markRead('msg1', 'carol');\nrr.markRead('msg1', 'dave');\nconsole.log(rr.getStatus('msg1', 3));",
              "output": "{\n  msgId: 'msg1',\n  readBy: [ 'bob' ],\n  readCount: 1,\n  totalMembers: 3,\n  allRead: false,\n  display: '✓✓ Read by 1'\n}\n{\n  msgId: 'msg1',\n  readBy: [ 'bob', 'carol', 'dave' ],\n  readCount: 3,\n  totalMembers: 3,\n  allRead: true,\n  display: '✓✓ Read by all'\n}"
            },
            {
              "question": "Program 9: Message encryption/decryption (simplified)",
              "code": "class SimpleE2EE {\n  constructor() { this.keys = new Map(); }\n  generateKeyPair(userId) {\n    // Simplified: in reality use asymmetric crypto\n    const key = Math.random().toString(36).substring(2, 18);\n    this.keys.set(userId, key);\n    return { userId, keyLength: key.length };\n  }\n  encrypt(senderId, recipientId, plaintext) {\n    const key = this.keys.get(recipientId);\n    if (!key) return { error: 'No key for recipient' };\n    // Simplified XOR-like encryption\n    const encrypted = plaintext.split('').map((c, i) => \n      String.fromCharCode(c.charCodeAt(0) ^ key.charCodeAt(i % key.length))\n    ).join('');\n    return { encrypted: Buffer.from(encrypted).toString('base64'), for: recipientId };\n  }\n  decrypt(recipientId, encryptedBase64) {\n    const key = this.keys.get(recipientId);\n    const encrypted = Buffer.from(encryptedBase64, 'base64').toString();\n    const decrypted = encrypted.split('').map((c, i) =>\n      String.fromCharCode(c.charCodeAt(0) ^ key.charCodeAt(i % key.length))\n    ).join('');\n    return { decrypted };\n  }\n}\n\nconst e2ee = new SimpleE2EE();\ne2ee.generateKeyPair('alice');\ne2ee.generateKeyPair('bob');\nconst { encrypted } = e2ee.encrypt('alice', 'bob', 'Secret message!');\nconsole.log('Encrypted:', encrypted);\nconsole.log('Decrypted:', e2ee.decrypt('bob', encrypted));",
              "output": "Encrypted: <base64 string>\nDecrypted: { decrypted: 'Secret message!' }"
            },
            {
              "question": "Program 10: Chat message search",
              "code": "class MessageSearch {\n  constructor() { this.index = []; }\n  addMessage(msg) { this.index.push(msg); }\n  search(query, filters = {}) {\n    const q = query.toLowerCase();\n    return this.index.filter(msg => {\n      if (!msg.text.toLowerCase().includes(q)) return false;\n      if (filters.from && msg.from !== filters.from) return false;\n      if (filters.conversation && msg.conversation !== filters.conversation) return false;\n      return true;\n    }).map(msg => ({\n      id: msg.id,\n      from: msg.from,\n      preview: msg.text.substring(0, 50),\n      conversation: msg.conversation,\n    }));\n  }\n}\n\nconst ms = new MessageSearch();\nms.addMessage({ id: 1, from: 'alice', text: 'Meeting at 3pm tomorrow', conversation: 'work' });\nms.addMessage({ id: 2, from: 'bob', text: 'Can we reschedule the meeting?', conversation: 'work' });\nms.addMessage({ id: 3, from: 'carol', text: 'Lunch meeting at noon', conversation: 'friends' });\nms.addMessage({ id: 4, from: 'alice', text: 'Sure, see you then', conversation: 'work' });\n\nconsole.log(ms.search('meeting'));\nconsole.log(ms.search('meeting', { conversation: 'work' }));",
              "output": "[\n  { id: 1, from: 'alice', preview: 'Meeting at 3pm tomorrow', conversation: 'work' },\n  { id: 2, from: 'bob', preview: 'Can we reschedule the meeting?', conversation: 'work' },\n  { id: 3, from: 'carol', preview: 'Lunch meeting at noon', conversation: 'friends' }\n]\n[\n  { id: 1, from: 'alice', preview: 'Meeting at 3pm tomorrow', conversation: 'work' },\n  { id: 2, from: 'bob', preview: 'Can we reschedule the meeting?', conversation: 'work' }\n]"
            }
          ]
        },
        {
          "id": "notification-system",
          "title": "Notification System Design",
          "category": "Company HLD",
          "description": "Design a scalable notification system handling push, SMS, email, and in-app notifications with delivery guarantees, user preferences, and rate limiting.",
          "explanation": "A notification system sits between event producers (services) and notification channels (push, email, SMS, in-app). It must handle billions of notifications daily, respect user preferences, ensure at-least-once delivery, and prevent spam.\n\n**Core Architecture**:\n1. **Notification Service (API)**: Receives notification requests from internal services.\n2. **Validation & Preference Engine**: Checks user preferences (opt-in, DND, frequency caps).\n3. **Priority Queue**: Urgent (OTP, payment) vs normal (marketing, social).\n4. **Channel Adapters**: Push (APNs/FCM), Email (SES/SendGrid), SMS (Twilio), In-App (WebSocket).\n5. **Delivery Tracker**: Tracks sent/delivered/failed status per notification.\n6. **Template Engine**: Renders notification content from templates + variables.\n\n**Notification Flow**:\n1. Producer service calls: POST /notify { userId, type, channel, template, data }.\n2. Notification Service validates payload, checks rate limits.\n3. Fetches user preferences: is this channel enabled? DND active?\n4. Enqueues to priority queue (Kafka topics: high/medium/low priority).\n5. Consumer picks message → Template Engine renders content.\n6. Channel Adapter sends via appropriate provider.\n7. Response tracked: delivered / bounced / failed.\n8. Retry on failure (exponential backoff, max 3 retries).\n\n**User Preferences Model**:\n- Global: notifications enabled/disabled.\n- Per channel: push=on, email=off, sms=on.\n- Per category: marketing=off, transactional=on, social=on.\n- DND schedule: no notifications between 10pm - 8am.\n- Frequency cap: max 5 marketing emails/day.\n\n**Rate Limiting**:\n- Per user: max N notifications per channel per time window.\n- Global: max throughput per channel (APNs rate limits, SMS provider limits).\n- Backpressure: if queue depth exceeds threshold, reject low-priority notifications.\n\n**Analytics**:\n- Delivery rate, open rate, click rate.\n- Channel performance comparison.\n- Notification fatigue detection.\n- A/B testing for templates.",
          "code": "// Notification system simulation\nclass NotificationSystem {\n  constructor() {\n    this.queue = { high: [], medium: [], low: [] };\n    this.preferences = new Map();\n    this.delivered = [];\n    this.rateLimits = new Map(); // userId:channel -> { count, windowStart }\n    this.templates = new Map();\n  }\n\n  registerTemplate(name, template) {\n    this.templates.set(name, template);\n  }\n\n  setPreference(userId, prefs) {\n    this.preferences.set(userId, { push: true, email: true, sms: true, dnd: null, ...prefs });\n  }\n\n  checkRateLimit(userId, channel, maxPerWindow = 5, windowMs = 3600000) {\n    const key = `${userId}:${channel}`;\n    const now = Date.now();\n    const limit = this.rateLimits.get(key) || { count: 0, windowStart: now };\n    if (now - limit.windowStart > windowMs) {\n      limit.count = 0;\n      limit.windowStart = now;\n    }\n    if (limit.count >= maxPerWindow) return false;\n    limit.count++;\n    this.rateLimits.set(key, limit);\n    return true;\n  }\n\n  notify(request) {\n    const { userId, channel, priority = 'medium', template, data } = request;\n    const prefs = this.preferences.get(userId) || {};\n    \n    // Check preference\n    if (prefs[channel] === false) return { status: 'BLOCKED', reason: 'User opted out' };\n    \n    // Check DND\n    if (prefs.dnd) {\n      const hour = new Date().getHours();\n      if (hour >= prefs.dnd.start || hour < prefs.dnd.end) {\n        return { status: 'DEFERRED', reason: 'DND active' };\n      }\n    }\n    \n    // Check rate limit\n    if (!this.checkRateLimit(userId, channel)) {\n      return { status: 'THROTTLED', reason: 'Rate limit exceeded' };\n    }\n    \n    // Render template\n    let content = template;\n    if (this.templates.has(template)) {\n      content = this.templates.get(template);\n      Object.entries(data || {}).forEach(([k, v]) => {\n        content = content.replace(`{{${k}}}`, v);\n      });\n    }\n    \n    // Enqueue\n    const notification = { id: `n_${Date.now()}`, userId, channel, content, priority, createdAt: Date.now() };\n    this.queue[priority].push(notification);\n    return { status: 'QUEUED', id: notification.id, priority };\n  }\n\n  processQueue() {\n    const results = [];\n    for (const priority of ['high', 'medium', 'low']) {\n      while (this.queue[priority].length > 0) {\n        const notif = this.queue[priority].shift();\n        notif.status = 'DELIVERED';\n        notif.deliveredAt = Date.now();\n        this.delivered.push(notif);\n        results.push({ id: notif.id, channel: notif.channel, status: 'DELIVERED' });\n      }\n    }\n    return results;\n  }\n}\n\nconst ns = new NotificationSystem();\nns.registerTemplate('welcome', 'Welcome {{name}}! Your account is ready.');\nns.setPreference('u1', { push: true, email: true, sms: false });\n\nconsole.log(ns.notify({ userId: 'u1', channel: 'push', priority: 'high', template: 'welcome', data: { name: 'Alice' } }));\nconsole.log(ns.notify({ userId: 'u1', channel: 'sms', template: 'OTP: 1234' }));\nconsole.log(ns.processQueue());",
          "example": "// Template engine with multi-channel rendering\nclass TemplateEngine {\n  constructor() { this.templates = new Map(); }\n  register(name, channels) {\n    this.templates.set(name, channels);\n  }\n  render(name, channel, data) {\n    const tmpl = this.templates.get(name)?.[channel];\n    if (!tmpl) return { error: `No template: ${name}/${channel}` };\n    let content = tmpl;\n    Object.entries(data).forEach(([k, v]) => {\n      content = content.replace(new RegExp(`{{${k}}}`, 'g'), v);\n    });\n    return { channel, content };\n  }\n}\n\nconst te = new TemplateEngine();\nte.register('order_shipped', {\n  push: 'Your order #{{orderId}} has shipped!',\n  email: 'Hi {{name}},\\nGreat news! Order #{{orderId}} is on its way. Track: {{trackUrl}}',\n  sms: 'Order #{{orderId}} shipped. Track at {{trackUrl}}',\n});\n\nconst data = { name: 'Alice', orderId: '12345', trackUrl: 'https://track.me/12345' };\nconsole.log(te.render('order_shipped', 'push', data));\nconsole.log(te.render('order_shipped', 'email', data));\nconsole.log(te.render('order_shipped', 'sms', data));",
          "useCase": "Mobile app push notifications, transactional emails, OTP delivery, marketing campaigns, real-time in-app alerts, order status updates, security alerts.",
          "interviewQuestions": [
            {
              "question": "How do you ensure at-least-once delivery?",
              "answer": "Use a persistent message queue (Kafka). Consumer processes notification, sends via channel adapter. On success → commit offset. On failure → message stays in queue for retry. Idempotency key on notification_id prevents duplicates at the channel adapter level. Dead-letter queue after max retries."
            },
            {
              "question": "How do you handle different notification priorities?",
              "answer": "Separate Kafka topics or priority lanes in queue: HIGH (OTP, security alerts — process immediately), MEDIUM (social, transactional — seconds delay OK), LOW (marketing — minutes delay OK). Each lane has its own consumer group. High-priority consumers run with more instances and resources."
            },
            {
              "question": "How do you prevent notification fatigue?",
              "answer": "Frequency caps: max N per channel per day/hour. Category budgets: max 3 marketing emails/week. Smart batching: combine multiple low-priority notifications into digest. User engagement tracking: reduce frequency for users who don't open. Time-of-day optimization: send when user is most active."
            },
            {
              "question": "How do you implement DND (Do Not Disturb)?",
              "answer": "Store DND schedule per user (start_hour, end_hour, timezone). Before sending: check if current time in user's timezone falls in DND window. If yes: for urgent (OTP) — send anyway; for normal — enqueue in delayed queue with scheduled delivery at DND end time. Respect timezone conversions."
            },
            {
              "question": "How do you design the notification preference model?",
              "answer": "Hierarchical: Global toggle → Channel toggle (push/email/sms) → Category toggle (marketing/social/transactional) → Per-source toggle. Store as JSON document or normalized tables. Evaluate top-down: if global off, block all. If channel off, block that channel. Category and source granularity for fine control."
            },
            {
              "question": "How do you handle push notification token management?",
              "answer": "Each device registers token (FCM/APNs) → store in device_tokens table (user_id, device_id, token, platform, updated_at). On app update: refresh token. On uninstall: token becomes invalid → detect via provider feedback (APNs: 410 response, FCM: NotRegistered). Clean up stale tokens periodically. User can have multiple tokens (multiple devices)."
            },
            {
              "question": "How do you scale to billions of notifications per day?",
              "answer": "Kafka for durable queuing with partitioning. Partition by user_id for ordering. Multiple consumer groups per channel. Batch API calls to providers (FCM supports multicast to 500 tokens). Connection pooling to SMTP/SMS providers. Horizontal scaling of consumers. Pre-render templates at enqueue time to reduce consumer work."
            },
            {
              "question": "How do you track notification delivery and engagement?",
              "answer": "Delivery: track via provider callbacks (FCM delivery receipts, email open tracking pixel, SMS delivery reports). Store: notification_id, status (sent/delivered/opened/clicked), timestamps. Email: invisible 1x1 pixel image. Push: app reports open. Click: redirect through tracking URL. Aggregate for analytics dashboards."
            },
            {
              "question": "How do you implement notification templates?",
              "answer": "Template service: store templates with Mustache/Handlebars syntax. Variables: {{name}}, {{orderId}}. Per-channel variants: push (short), email (HTML), SMS (plain text). Versioning for A/B testing. Localization: template per locale. Render at send time: merge template + data → final content. Preview API for testing."
            },
            {
              "question": "How do you handle cross-channel notification deduplication?",
              "answer": "If order update sent via push and user opens it → don't send email. Strategy: send push first, wait 5 minutes, if not opened → send email. Implement with delayed queue and status check. Track 'acknowledged' flag per notification. Cancel pending lower-priority channel sends when user interacts with higher-priority channel."
            }
          ],
          "exercises": [
            {
              "type": "estimation",
              "question": "10M users, average 20 notifications/day across channels. Estimate throughput.",
              "answer": "Daily: 10M × 20 = 200M notifications. QPS: 200M / 86400 ≈ 2,315 notifications/sec. Peak (3x): 6,945/sec. Per channel (push 60%, email 30%, sms 10%): push peak ≈ 4,167/sec. Need several Kafka partitions and consumer instances per channel."
            },
            {
              "type": "design",
              "question": "Design the retry mechanism for failed notifications.",
              "answer": "On failure: requeue with retry_count++. Exponential backoff: delay = min(2^retry × 1s, 5min). Max retries: 3 for push, 2 for SMS (expensive), 3 for email. After max retries → dead-letter queue + alert. Different failure types: transient (retry) vs permanent (invalid token → remove token, don't retry). Log failure reason for debugging."
            },
            {
              "type": "scenario",
              "question": "Black Friday sale: notification to 50M users simultaneously. How?",
              "answer": "Pre-render all notifications (template + user data). Partition into batches (10K users each = 5,000 batches). Enqueue batches to Kafka. Scale consumers to 100+ instances. Use FCM topic messaging for Android (subscribe all to 'sale' topic → single API call). Stagger: send over 30 minutes, not all at once. Monitor provider rate limits."
            },
            {
              "type": "tricky",
              "question": "Why not send all notifications synchronously from the producing service?",
              "answer": "1) Tight coupling: producer blocks on send. 2) No retry logic. 3) No preference checking. 4) Channel providers have rate limits — need queuing. 5) One slow channel blocks others. 6) No priority handling. 7) No deduplication. 8) No analytics. Async queue decouples producers from delivery, enabling all these features."
            },
            {
              "type": "design",
              "question": "Design in-app notification center (like Instagram's activity feed).",
              "answer": "Store: notifications table (id, user_id, type, content, read, created_at). API: GET /notifications?unread=true&limit=20. Mark read: PUT /notifications/:id/read. Badge count: Redis counter per user (increment on new, reset on open). Real-time: WebSocket push for new notifications while app is open. Pagination: cursor-based on created_at."
            },
            {
              "type": "estimation",
              "question": "Email notification: 1M emails/hour via SES. SES limit: 200 emails/sec. How many sender instances needed?",
              "answer": "Required: 1M/3600 = 278 emails/sec. SES limit per account: 200/sec (can request increase). With 200/sec limit: need burst buffer or request limit increase to 300/sec. Alternative: multiple SES endpoints/regions. With 2 regions at 200/sec each = 400/sec capacity (1.44M/hour) — sufficient with headroom."
            },
            {
              "type": "debug",
              "question": "Push notifications are delivered but users report not receiving them. What could be wrong?",
              "answer": "1) Stale device tokens (user reinstalled app, token changed). 2) User disabled push at OS level. 3) Battery optimization killing app process. 4) Notification channel importance too low on Android. 5) App in background → OS throttles notifications. 6) Content too long → truncated and looks empty. 7) APNs sandbox vs production environment mismatch."
            },
            {
              "type": "design",
              "question": "Design a notification digest system.",
              "answer": "Collect: buffer low-priority notifications per user (Redis list). Schedule: cron job every hour checks buffers. If buffer size > threshold OR time elapsed > max_wait → create digest. Template: 'You have 5 new likes and 3 comments'. Send one email/push instead of 8 individual ones. User preference: real-time vs digest per category. Clear buffer on send."
            },
            {
              "type": "scenario",
              "question": "User changes email at 2pm. Notification sent at 1:59pm to old email. How to handle?",
              "answer": "Eventual consistency: notification sent to email at time of send. Not a bug — this is expected. To minimize: notification service should look up email at send time, not at enqueue time. For critical notifications: lookup fresh data from user service right before channel adapter sends. Cache TTL for user data should be short (5min). For legal/compliance: audit log of which email was used."
            },
            {
              "type": "design",
              "question": "Design A/B testing for notification templates.",
              "answer": "A/B service assigns user to variant (A or B) by user_id hash % 100. Template service returns variant-specific template. Track metrics per variant: delivery rate, open rate, click rate, conversion rate. Statistical significance: need ~1000 opens per variant. Auto-select winner after confidence threshold reached. Gradual rollout: 10% → 50% → 100%."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Multi-channel notification dispatcher",
              "code": "class NotificationDispatcher {\n  constructor() { this.channels = new Map(); this.log = []; }\n  registerChannel(name, handler) { this.channels.set(name, handler); }\n  dispatch(userId, channel, message) {\n    const handler = this.channels.get(channel);\n    if (!handler) return { error: `Unknown channel: ${channel}` };\n    const result = handler(userId, message);\n    this.log.push({ userId, channel, message, result, time: Date.now() });\n    return result;\n  }\n  getLog(userId) {\n    return this.log.filter(l => l.userId === userId).map(l => `[${l.channel}] ${l.message} → ${l.result}`);\n  }\n}\n\nconst nd = new NotificationDispatcher();\nnd.registerChannel('push', (uid, msg) => `Push sent to ${uid}: ${msg}`);\nnd.registerChannel('email', (uid, msg) => `Email sent to ${uid}: ${msg}`);\nnd.registerChannel('sms', (uid, msg) => `SMS sent to ${uid}: ${msg}`);\n\nconsole.log(nd.dispatch('alice', 'push', 'New message!'));\nconsole.log(nd.dispatch('alice', 'email', 'Weekly digest'));\nconsole.log(nd.dispatch('alice', 'webhook', 'Test'));\nconsole.log(nd.getLog('alice'));",
              "output": "Push sent to alice: New message!\nEmail sent to alice: Weekly digest\n{ error: 'Unknown channel: webhook' }\n[\n  '[push] New message! → Push sent to alice: New message!',\n  '[email] Weekly digest → Email sent to alice: Weekly digest'\n]"
            },
            {
              "question": "Program 2: User preference evaluator",
              "code": "class PreferenceEngine {\n  constructor() { this.prefs = new Map(); }\n  setPreferences(userId, prefs) { this.prefs.set(userId, prefs); }\n  canSend(userId, channel, category) {\n    const p = this.prefs.get(userId);\n    if (!p) return { allowed: true, reason: 'No preferences set (default allow)' };\n    if (p.globalOff) return { allowed: false, reason: 'Global notifications disabled' };\n    if (p.channels?.[channel] === false) return { allowed: false, reason: `${channel} channel disabled` };\n    if (p.categories?.[category] === false) return { allowed: false, reason: `${category} category disabled` };\n    return { allowed: true, reason: 'All checks passed' };\n  }\n}\n\nconst pe = new PreferenceEngine();\npe.setPreferences('alice', {\n  globalOff: false,\n  channels: { push: true, email: true, sms: false },\n  categories: { marketing: false, transactional: true, social: true },\n});\n\nconsole.log(pe.canSend('alice', 'push', 'social'));\nconsole.log(pe.canSend('alice', 'sms', 'transactional'));\nconsole.log(pe.canSend('alice', 'email', 'marketing'));\nconsole.log(pe.canSend('bob', 'push', 'marketing'));",
              "output": "{ allowed: true, reason: 'All checks passed' }\n{ allowed: false, reason: 'sms channel disabled' }\n{ allowed: false, reason: 'marketing category disabled' }\n{ allowed: true, reason: 'No preferences set (default allow)' }"
            },
            {
              "question": "Program 3: Token-bucket rate limiter for notifications",
              "code": "class TokenBucket {\n  constructor(capacity, refillRate) {\n    this.capacity = capacity;\n    this.tokens = capacity;\n    this.refillRate = refillRate; // tokens per second\n    this.lastRefill = Date.now();\n  }\n  refill() {\n    const now = Date.now();\n    const elapsed = (now - this.lastRefill) / 1000;\n    this.tokens = Math.min(this.capacity, this.tokens + elapsed * this.refillRate);\n    this.lastRefill = now;\n  }\n  consume(n = 1) {\n    this.refill();\n    if (this.tokens >= n) {\n      this.tokens -= n;\n      return { allowed: true, remaining: Math.floor(this.tokens) };\n    }\n    return { allowed: false, remaining: Math.floor(this.tokens), retryAfterMs: Math.ceil((n - this.tokens) / this.refillRate * 1000) };\n  }\n}\n\nclass NotifRateLimiter {\n  constructor() { this.buckets = new Map(); }\n  getBucket(userId, channel) {\n    const key = `${userId}:${channel}`;\n    if (!this.buckets.has(key)) this.buckets.set(key, new TokenBucket(10, 1)); // 10 burst, 1/sec refill\n    return this.buckets.get(key);\n  }\n  check(userId, channel) {\n    return this.getBucket(userId, channel).consume();\n  }\n}\n\nconst rl = new NotifRateLimiter();\nfor (let i = 0; i < 12; i++) {\n  console.log(`Attempt ${i + 1}:`, rl.check('alice', 'push'));\n}",
              "output": "Attempt 1: { allowed: true, remaining: 9 }\nAttempt 2: { allowed: true, remaining: 8 }\n...\nAttempt 10: { allowed: true, remaining: 0 }\nAttempt 11: { allowed: false, remaining: 0, retryAfterMs: 1000 }\nAttempt 12: { allowed: false, remaining: 0, retryAfterMs: 1000 }"
            },
            {
              "question": "Program 4: Notification priority queue",
              "code": "class PriorityNotificationQueue {\n  constructor() {\n    this.lanes = { high: [], medium: [], low: [] };\n    this.processed = [];\n  }\n  enqueue(notification) {\n    const priority = notification.priority || 'medium';\n    this.lanes[priority].push({ ...notification, enqueuedAt: Date.now() });\n    return { queued: true, priority, position: this.lanes[priority].length };\n  }\n  process(maxBatch = 5) {\n    const batch = [];\n    for (const priority of ['high', 'medium', 'low']) {\n      while (batch.length < maxBatch && this.lanes[priority].length > 0) {\n        const n = this.lanes[priority].shift();\n        batch.push({ ...n, processedAt: Date.now(), priority });\n      }\n    }\n    this.processed.push(...batch);\n    return batch.map(n => ({ id: n.id, priority: n.priority, to: n.userId }));\n  }\n  stats() {\n    return {\n      queued: { high: this.lanes.high.length, medium: this.lanes.medium.length, low: this.lanes.low.length },\n      processed: this.processed.length,\n    };\n  }\n}\n\nconst pq = new PriorityNotificationQueue();\npq.enqueue({ id: 1, userId: 'alice', priority: 'low', msg: 'Weekly digest' });\npq.enqueue({ id: 2, userId: 'bob', priority: 'high', msg: 'OTP: 123456' });\npq.enqueue({ id: 3, userId: 'carol', priority: 'medium', msg: 'New follower' });\npq.enqueue({ id: 4, userId: 'dave', priority: 'high', msg: 'Password reset' });\nconsole.log('Stats:', pq.stats());\nconsole.log('Batch 1:', pq.process(3));\nconsole.log('Batch 2:', pq.process(3));\nconsole.log('Stats:', pq.stats());",
              "output": "Stats: { queued: { high: 2, medium: 1, low: 1 }, processed: 0 }\nBatch 1: [\n  { id: 2, priority: 'high', to: 'bob' },\n  { id: 4, priority: 'high', to: 'dave' },\n  { id: 3, priority: 'medium', to: 'carol' }\n]\nBatch 2: [ { id: 1, priority: 'low', to: 'alice' } ]\nStats: { queued: { high: 0, medium: 0, low: 0 }, processed: 4 }"
            },
            {
              "question": "Program 5: Template renderer with variable substitution",
              "code": "class TemplateRenderer {\n  constructor() { this.templates = new Map(); }\n  register(name, template) { this.templates.set(name, template); }\n  render(name, vars) {\n    let tmpl = this.templates.get(name);\n    if (!tmpl) return { error: `Template not found: ${name}` };\n    const missing = [];\n    const result = tmpl.replace(/\\{\\{(\\w+)\\}\\}/g, (match, key) => {\n      if (vars[key] !== undefined) return vars[key];\n      missing.push(key);\n      return match;\n    });\n    return missing.length ? { error: 'Missing variables', missing } : { content: result };\n  }\n}\n\nconst tr = new TemplateRenderer();\ntr.register('welcome', 'Welcome {{name}}! Your account {{email}} is ready.');\ntr.register('otp', 'Your OTP is {{code}}. Valid for {{minutes}} minutes.');\ntr.register('order', 'Order #{{orderId}} {{status}}. ETA: {{eta}}.');\n\nconsole.log(tr.render('welcome', { name: 'Alice', email: 'alice@mail.com' }));\nconsole.log(tr.render('otp', { code: '482910', minutes: '5' }));\nconsole.log(tr.render('order', { orderId: '123' })); // missing vars\nconsole.log(tr.render('unknown', {}));",
              "output": "{ content: 'Welcome Alice! Your account alice@mail.com is ready.' }\n{ content: 'Your OTP is 482910. Valid for 5 minutes.' }\n{ error: 'Missing variables', missing: [ 'status', 'eta' ] }\n{ error: 'Template not found: unknown' }"
            },
            {
              "question": "Program 6: Notification digest aggregator",
              "code": "class DigestAggregator {\n  constructor(threshold, maxWaitMs) {\n    this.threshold = threshold;\n    this.maxWaitMs = maxWaitMs;\n    this.buffers = new Map();\n  }\n  add(userId, notification) {\n    if (!this.buffers.has(userId)) {\n      this.buffers.set(userId, { items: [], firstAdded: Date.now() });\n    }\n    this.buffers.get(userId).items.push(notification);\n  }\n  shouldFlush(userId) {\n    const buf = this.buffers.get(userId);\n    if (!buf) return false;\n    return buf.items.length >= this.threshold || (Date.now() - buf.firstAdded) >= this.maxWaitMs;\n  }\n  flush(userId) {\n    const buf = this.buffers.get(userId);\n    if (!buf) return null;\n    this.buffers.delete(userId);\n    const types = {};\n    buf.items.forEach(n => { types[n.type] = (types[n.type] || 0) + 1; });\n    return {\n      userId,\n      count: buf.items.length,\n      summary: Object.entries(types).map(([t, c]) => `${c} ${t}`).join(', '),\n      items: buf.items,\n    };\n  }\n}\n\nconst da = new DigestAggregator(3, 60000);\nda.add('alice', { type: 'like', from: 'bob' });\nda.add('alice', { type: 'comment', from: 'carol' });\nconsole.log('Should flush?', da.shouldFlush('alice'));\nda.add('alice', { type: 'like', from: 'dave' });\nconsole.log('Should flush?', da.shouldFlush('alice'));\nconsole.log(da.flush('alice'));",
              "output": "Should flush? false\nShould flush? true\n{\n  userId: 'alice',\n  count: 3,\n  summary: '2 like, 1 comment',\n  items: [\n    { type: 'like', from: 'bob' },\n    { type: 'comment', from: 'carol' },\n    { type: 'like', from: 'dave' }\n  ]\n}"
            },
            {
              "question": "Program 7: Device token manager",
              "code": "class DeviceTokenManager {\n  constructor() { this.tokens = new Map(); }\n  register(userId, deviceId, token, platform) {\n    if (!this.tokens.has(userId)) this.tokens.set(userId, []);\n    const devices = this.tokens.get(userId);\n    const existing = devices.findIndex(d => d.deviceId === deviceId);\n    if (existing >= 0) devices[existing] = { deviceId, token, platform, updatedAt: Date.now() };\n    else devices.push({ deviceId, token, platform, updatedAt: Date.now() });\n  }\n  unregister(userId, deviceId) {\n    const devices = this.tokens.get(userId);\n    if (!devices) return false;\n    const idx = devices.findIndex(d => d.deviceId === deviceId);\n    if (idx >= 0) { devices.splice(idx, 1); return true; }\n    return false;\n  }\n  getTokens(userId) {\n    return (this.tokens.get(userId) || []).map(d => ({ token: d.token, platform: d.platform }));\n  }\n}\n\nconst dtm = new DeviceTokenManager();\ndtm.register('alice', 'iphone-1', 'apns_abc123', 'ios');\ndtm.register('alice', 'pixel-1', 'fcm_xyz789', 'android');\ndtm.register('alice', 'iphone-1', 'apns_newtoken', 'ios'); // token refresh\nconsole.log(dtm.getTokens('alice'));\ndtm.unregister('alice', 'pixel-1');\nconsole.log(dtm.getTokens('alice'));",
              "output": "[\n  { token: 'apns_newtoken', platform: 'ios' },\n  { token: 'fcm_xyz789', platform: 'android' }\n]\n[ { token: 'apns_newtoken', platform: 'ios' } ]"
            },
            {
              "question": "Program 8: Retry with exponential backoff",
              "code": "class RetryHandler {\n  constructor(maxRetries, baseDelayMs) {\n    this.maxRetries = maxRetries;\n    this.baseDelay = baseDelayMs;\n  }\n  async execute(fn, label) {\n    let attempt = 0;\n    while (attempt <= this.maxRetries) {\n      try {\n        const result = fn(attempt);\n        return { success: true, result, attempts: attempt + 1 };\n      } catch (e) {\n        attempt++;\n        if (attempt > this.maxRetries) {\n          return { success: false, error: e.message, attempts: attempt, status: 'DEAD_LETTER' };\n        }\n        const delay = this.baseDelay * Math.pow(2, attempt - 1);\n        console.log(`  [${label}] Attempt ${attempt} failed: ${e.message}. Retry in ${delay}ms`);\n      }\n    }\n  }\n}\n\nconst rh = new RetryHandler(3, 100);\n\n// Simulate: fails first 2 times, succeeds on 3rd\nlet callCount = 0;\nconsole.log(rh.execute((attempt) => {\n  callCount++;\n  if (callCount < 3) throw new Error('Provider timeout');\n  return 'Notification delivered!';\n}, 'push-notif'));\n\n// Simulate: always fails\nconsole.log(rh.execute(() => { throw new Error('Invalid token'); }, 'bad-token'));",
              "output": "  [push-notif] Attempt 1 failed: Provider timeout. Retry in 100ms\n  [push-notif] Attempt 2 failed: Provider timeout. Retry in 200ms\n{ success: true, result: 'Notification delivered!', attempts: 3 }\n  [bad-token] Attempt 1 failed: Invalid token. Retry in 100ms\n  [bad-token] Attempt 2 failed: Invalid token. Retry in 200ms\n  [bad-token] Attempt 3 failed: Invalid token. Retry in 400ms\n{ success: false, error: 'Invalid token', attempts: 4, status: 'DEAD_LETTER' }"
            },
            {
              "question": "Program 9: Notification analytics tracker",
              "code": "class NotifAnalytics {\n  constructor() { this.events = []; }\n  track(notifId, event) {\n    this.events.push({ notifId, event, time: Date.now() });\n  }\n  getMetrics() {\n    const counts = {};\n    this.events.forEach(e => { counts[e.event] = (counts[e.event] || 0) + 1; });\n    const sent = counts.sent || 0;\n    return {\n      total: this.events.length,\n      sent,\n      delivered: counts.delivered || 0,\n      opened: counts.opened || 0,\n      clicked: counts.clicked || 0,\n      deliveryRate: sent ? ((counts.delivered || 0) / sent * 100).toFixed(1) + '%' : 'N/A',\n      openRate: sent ? ((counts.opened || 0) / sent * 100).toFixed(1) + '%' : 'N/A',\n      clickRate: (counts.opened || 0) ? ((counts.clicked || 0) / counts.opened * 100).toFixed(1) + '%' : 'N/A',\n    };\n  }\n}\n\nconst na = new NotifAnalytics();\n// Simulate funnel\nfor (let i = 0; i < 100; i++) na.track(`n${i}`, 'sent');\nfor (let i = 0; i < 92; i++) na.track(`n${i}`, 'delivered');\nfor (let i = 0; i < 45; i++) na.track(`n${i}`, 'opened');\nfor (let i = 0; i < 12; i++) na.track(`n${i}`, 'clicked');\nconsole.log(na.getMetrics());",
              "output": "{\n  total: 249,\n  sent: 100,\n  delivered: 92,\n  opened: 45,\n  clicked: 12,\n  deliveryRate: '92.0%',\n  openRate: '45.0%',\n  clickRate: '26.7%'\n}"
            },
            {
              "question": "Program 10: Cross-channel deduplication",
              "code": "class CrossChannelDedup {\n  constructor(dedupeWindowMs) {\n    this.windowMs = dedupeWindowMs;\n    this.sent = new Map(); // notifKey -> { channel, time }\n  }\n  shouldSend(userId, notifKey, channel, priority) {\n    const key = `${userId}:${notifKey}`;\n    const existing = this.sent.get(key);\n    if (!existing) {\n      this.sent.set(key, { channel, time: Date.now() });\n      return { send: true, reason: 'First channel for this notification' };\n    }\n    if (Date.now() - existing.time > this.windowMs) {\n      this.sent.set(key, { channel, time: Date.now() });\n      return { send: true, reason: 'Dedupe window expired' };\n    }\n    if (priority === 'high') {\n      return { send: true, reason: 'High priority overrides dedup' };\n    }\n    return { send: false, reason: `Already sent via ${existing.channel}` };\n  }\n}\n\nconst ccd = new CrossChannelDedup(300000); // 5 min window\nconsole.log(ccd.shouldSend('alice', 'order_123', 'push', 'medium'));\nconsole.log(ccd.shouldSend('alice', 'order_123', 'email', 'medium'));\nconsole.log(ccd.shouldSend('alice', 'order_123', 'sms', 'high'));\nconsole.log(ccd.shouldSend('bob', 'order_123', 'push', 'medium'));",
              "output": "{ send: true, reason: 'First channel for this notification' }\n{ send: false, reason: 'Already sent via push' }\n{ send: true, reason: 'High priority overrides dedup' }\n{ send: true, reason: 'First channel for this notification' }"
            }
          ]
        },
        {
          "id": "search-autocomplete",
          "title": "Search Autocomplete System",
          "category": "Company HLD",
          "description": "Design a search autocomplete (typeahead) system that provides real-time suggestions as users type, using Trie data structures, ranking algorithms, and caching.",
          "explanation": "Search autocomplete (typeahead) suggests completions as the user types. Google processes 8.5 billion searches/day; every keystroke triggers a suggestion request. The system must be fast (<100ms), relevant, and fresh.\n\n**Core Architecture**:\n1. **Trie Service**: Stores prefix → suggestion mappings. Each trie node has top-K suggestions pre-computed.\n2. **Data Collection Service**: Collects search queries and their frequencies from logs.\n3. **Aggregation Service**: Periodically aggregates query frequencies, applies time decay, builds a new trie.\n4. **Ranking Service**: Ranks suggestions by popularity, personalization, recency, and trending signals.\n5. **Cache Layer**: CDN + Redis cache for popular prefixes.\n\n**How It Works**:\n1. User types 'sys' → client sends request to autocomplete API.\n2. API checks cache for prefix 'sys'. If hit → return cached top-10.\n3. If miss → Trie Service traverses trie to 'sys' node → returns pre-computed top-K.\n4. Response: ['system design', 'system of equations', 'system32', ...].\n5. Client debounces: only sends request after 150ms of no typing (saves ~60% requests).\n\n**Trie Design**:\n- Each node: character + children + top-K suggestions.\n- Top-K at each node = pre-computed from all descendants.\n- Trade-off: more memory, but O(1) lookup for suggestions at any prefix.\n- Trie rebuilt offline every 15 minutes from aggregated data.\n\n**Ranking Signals**:\n- Query frequency (weighted by recency: recent queries weighted higher).\n- Time decay: frequency * e^(-λ * age_in_hours).\n- Personalization: boost queries user has searched before.\n- Trending: if query frequency spikes above baseline → boost.\n- Filtering: remove offensive/harmful suggestions.\n\n**Scaling**:\n- Shard trie by prefix range: a-m on shard 1, n-z on shard 2.\n- Replicate each shard for availability.\n- CDN caching: top 10,000 prefixes are cached at CDN edge.\n- Redis: prefix → JSON suggestions (TTL: 15 min, matching trie rebuild cycle).",
          "code": "// Trie-based autocomplete with frequency ranking\nclass TrieNode {\n  constructor() {\n    this.children = {};\n    this.isEnd = false;\n    this.frequency = 0;\n    this.topK = []; // pre-computed top suggestions\n  }\n}\n\nclass Autocomplete {\n  constructor(k = 5) {\n    this.root = new TrieNode();\n    this.k = k;\n  }\n\n  insert(word, frequency = 1) {\n    let node = this.root;\n    for (const char of word) {\n      if (!node.children[char]) node.children[char] = new TrieNode();\n      node = node.children[char];\n    }\n    node.isEnd = true;\n    node.frequency += frequency;\n    this._updateTopK();\n  }\n\n  _getAllWords(node, prefix) {\n    const results = [];\n    if (node.isEnd) results.push({ word: prefix, freq: node.frequency });\n    for (const [char, child] of Object.entries(node.children)) {\n      results.push(...this._getAllWords(child, prefix + char));\n    }\n    return results;\n  }\n\n  _updateTopK() {\n    const update = (node, prefix) => {\n      const allWords = this._getAllWords(node, prefix);\n      node.topK = allWords.sort((a, b) => b.freq - a.freq).slice(0, this.k);\n      for (const [char, child] of Object.entries(node.children)) {\n        update(child, prefix + char);\n      }\n    };\n    update(this.root, '');\n  }\n\n  suggest(prefix) {\n    let node = this.root;\n    for (const char of prefix) {\n      if (!node.children[char]) return [];\n      node = node.children[char];\n    }\n    return node.topK;\n  }\n}\n\nconst ac = new Autocomplete(3);\nac.insert('system design', 100);\nac.insert('system design interview', 80);\nac.insert('system of equations', 40);\nac.insert('systemic risk', 20);\nac.insert('syntax error', 60);\nac.insert('synchronous', 30);\n\nconsole.log('Prefix \"sys\":', ac.suggest('sys'));\nconsole.log('Prefix \"system d\":', ac.suggest('system d'));\nconsole.log('Prefix \"syn\":', ac.suggest('syn'));",
          "example": "// Autocomplete with time-decay ranking\nclass DecayAutocomplete {\n  constructor() {\n    this.queries = []; // { query, timestamp, count }\n  }\n  record(query, timestamp = Date.now()) {\n    const existing = this.queries.find(q => q.query === query);\n    if (existing) { existing.count++; existing.timestamp = timestamp; }\n    else this.queries.push({ query, timestamp, count: 1 });\n  }\n  suggest(prefix, now = Date.now(), k = 5) {\n    const lambda = 0.0001; // decay factor\n    return this.queries\n      .filter(q => q.query.startsWith(prefix))\n      .map(q => ({\n        query: q.query,\n        score: q.count * Math.exp(-lambda * (now - q.timestamp)),\n      }))\n      .sort((a, b) => b.score - a.score)\n      .slice(0, k);\n  }\n}\n\nconst dac = new DecayAutocomplete();\nconst now = Date.now();\ndac.record('system design', now - 86400000); // 1 day ago, once\ndac.record('system design', now - 86400000);\ndac.record('system design', now - 86400000); // 3 times total\ndac.record('system architecture', now); // just now, once\ndac.record('system architecture', now); // twice now\n\nconsole.log(dac.suggest('system', now));",
          "useCase": "Search engines, e-commerce product search, IDE code completion, address lookup, social media username search, email recipient suggestion.",
          "interviewQuestions": [
            {
              "question": "Why use a Trie instead of a database for autocomplete?",
              "answer": "Trie provides O(prefix_length) lookup — milliseconds. Database LIKE 'sys%' requires index scan, slower for real-time. Trie can store pre-computed top-K at each node for O(1) suggestion retrieval. Database needs ORDER BY + LIMIT on every request. Trie fits in memory for web-scale prefix sets."
            },
            {
              "question": "How do you handle the 'build vs serve' dichotomy?",
              "answer": "Separate offline build from online serving. Offline: aggregation service processes search logs every 15 min → builds new trie → serializes to blob storage. Online: trie servers load latest snapshot → serve suggestions from memory. No online writes. This avoids consistency issues and allows atomic trie replacement."
            },
            {
              "question": "How do you store top-K suggestions efficiently in the Trie?",
              "answer": "At each internal node, store top-K suggestions (sorted by score) from all descendants. On build: bottom-up merge — leaf nodes have their own terms. Parent merges children's top-K lists. Space: if K=10 and each suggestion is 50 bytes, each node stores 500 bytes. Trade-off: more memory, but zero traversal at query time."
            },
            {
              "question": "How do you implement personalization?",
              "answer": "Two layers: (1) Global top-K from trie (default). (2) User-specific boost: store user's recent search history (last 100 queries in Redis). At query time: merge global suggestions with user's history matches. Boost score for previously searched terms. Privacy: user can clear history. Don't send user data to CDN cache."
            },
            {
              "question": "How do you handle trending queries?",
              "answer": "Maintain a sliding window counter per query (last 1 hour). Compare with historical baseline (same hour last week). If current_count > 3× baseline → mark as trending → boost score by 2×. Use Redis Sorted Set: ZINCRBY trending_queries 1 'query'. Decay: TTL on the trending entries. Show 'Trending' badge in UI."
            },
            {
              "question": "How do you filter offensive or harmful suggestions?",
              "answer": "Blocklist: maintain set of banned terms. During trie build: filter out suggestions matching blocklist (exact or substring). Pattern-based: regex filters for known offensive patterns. ML: train a classifier to score suggestion safety. Human review: flag and remove reported suggestions. Legal: remove court-ordered suggestions."
            },
            {
              "question": "How do you reduce the number of API requests?",
              "answer": "Client-side debounce: only send request after 150ms of no typing (saves ~60%). Client cache: if user types 'sys', cache response. If then types 'syst', check if subset of cached 'sys' results starts with 'syst' — filter client-side, no API call. Pre-fetch: on focus of search box, fetch top suggestions for empty prefix."
            },
            {
              "question": "How do you shard the trie?",
              "answer": "By prefix range: shard 1 handles a-f, shard 2 handles g-m, etc. Benefits: each shard is smaller (fits memory). Routing: first character determines shard. Rebalancing: if one shard is hot (e.g., 's' has more queries), sub-shard: sa-sm on shard 5a, sn-sz on shard 5b. Replication: each shard has 3 replicas."
            },
            {
              "question": "What is the data pipeline for building the trie?",
              "answer": "1) Search logs → Kafka. 2) Stream processor (Flink): aggregate query + count per 15-min window. 3) Store aggregated data in HDFS/S3. 4) Trie builder job: reads aggregated data, applies time decay, builds trie with top-K per node. 5) Serialize trie to binary format. 6) Upload to blob storage. 7) Trie servers pull latest snapshot and swap."
            },
            {
              "question": "How do you handle multi-language autocomplete?",
              "answer": "Separate tries per language. Language detection: from user locale settings or first typed characters. Unicode-aware trie: nodes represent Unicode code points, not just ASCII. CJK (Chinese/Japanese/Korean): character-level trie (no word boundaries). Transliteration: if user types phonetic input, map to native script suggestions. Example: typing 'bei' → '北京' (Beijing)."
            }
          ],
          "exercises": [
            {
              "type": "estimation",
              "question": "Google: 8.5B searches/day. Average query length: 4 words, typed character by character. With debouncing (150ms), estimate autocomplete QPS.",
              "answer": "Average characters per query: 4 words × 5 chars = 20 chars. With debouncing, ~50% of keystrokes trigger requests: 10 requests/query. Total requests: 8.5B × 10 = 85B/day. QPS: 85B / 86400 ≈ 983,796 QPS. Peak (3x): ~3M QPS. Need heavy caching — top 1000 prefixes serve 90%+ of traffic."
            },
            {
              "type": "design",
              "question": "Design the caching strategy for autocomplete.",
              "answer": "L1: CDN edge cache — top 10K prefixes (covers 80% traffic). TTL: 15 min. L2: Redis — all prefixes queried in last hour. TTL: 15 min. L3: Trie server (in-memory). Cache key: prefix string. Cache value: JSON array of suggestions. Invalidation: on trie rebuild (every 15 min), broadcast cache-clear. Personalized results bypass CDN."
            },
            {
              "type": "scenario",
              "question": "A celebrity scandal breaks. Millions search their name. How does autocomplete adapt?",
              "answer": "Trending detection picks up spike in 5-10 minutes. But trie rebuilds every 15 min — too slow. Solution: 'hot query' fast path. Real-time counter (Redis): if query count > 10× baseline in 5-min window → inject into suggestion cache directly (bypass trie). Cap injection to prevent manipulation. Remove after scandal fades (decay)."
            },
            {
              "type": "tricky",
              "question": "Can you implement autocomplete without a Trie?",
              "answer": "Yes: (1) Sorted array + binary search: store all queries sorted. Binary search for prefix. O(log n) lookup + scan. (2) Inverted index: prefix → query list. (3) Elasticsearch: prefix query or completion suggester. (4) Redis Sorted Set: ZRANGEBYLEX for prefix matching. Trie is optimal for in-memory, but alternatives work at different scales."
            },
            {
              "type": "design",
              "question": "Design autocomplete for an e-commerce site (product search).",
              "answer": "Different from web search: suggestions are product names, categories, and brands. Trie built from product catalog + search logs. Ranking: product popularity, availability, margin. Category suggestions: 'shoes' → 'Men's Running Shoes', 'Women's Formal Shoes'. Show product images alongside suggestions. Real-time inventory: filter out out-of-stock products."
            },
            {
              "type": "estimation",
              "question": "How much memory does a trie with 10M unique queries need?",
              "answer": "Average query: 20 characters. Naive trie: 10M × 20 = 200M nodes. Each node: 1B char + 26 pointers (8B each) = 209B/node. Total: 200M × 209B = 41.8GB — too large! Optimization: compressed trie (radix/Patricia tree): collapse single-child paths. Reduces to ~50M nodes → ~10GB. With top-K (10 × 50B per node): +2.5GB overhead."
            },
            {
              "type": "debug",
              "question": "Autocomplete returns stale results after a trie rebuild. What's wrong?",
              "answer": "1) CDN/Redis cache not invalidated after rebuild → serving old cached results. Fix: version trie builds, include version in cache key. 2) Trie servers not all serving same version — rolling deploy issue. Fix: atomic swap with health check. 3) Client caching prefix results locally. Fix: add cache-control headers with max-age matching rebuild interval."
            },
            {
              "type": "design",
              "question": "Design an autocomplete system that respects user privacy.",
              "answer": "1) No logging of individual user queries → only aggregate counts. 2) Differential privacy: add noise to query counts before building trie. 3) No personalization on server → personalization only client-side using local history. 4) HTTPS for all autocomplete requests. 5) Right to be forgotten: user can request deletion of their search history. 6) Anonymize IP in logs."
            },
            {
              "type": "scenario",
              "question": "Competitor tries to manipulate autocomplete by generating fake searches. How to prevent?",
              "answer": "1) Rate limit per IP/user: max 100 searches/hour. 2) CAPTCHA for suspicious patterns (same prefix repeated). 3) Account age requirement: ignore searches from accounts < 24h old. 4) IP diversity: require suggestions to come from 100+ distinct IPs. 5) ML anomaly detection: flag sudden unnatural spikes. 6) Manual review for high-visibility suggestions."
            },
            {
              "type": "output",
              "question": "Trie has: 'apple'(100), 'app'(80), 'application'(60), 'apply'(40), 'appetizer'(30). User types 'app'. What are top-3 suggestions?",
              "answer": "All 5 words match prefix 'app'. Sort by frequency: apple(100), app(80), application(60), apply(40), appetizer(30). Top-3: ['apple', 'app', 'application']. Node at 'app' has pre-computed topK=[apple, app, application]. Returned in O(1) without traversal."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Basic Trie with insert and search",
              "code": "class TrieNode {\n  constructor() { this.children = {}; this.isEnd = false; }\n}\n\nclass Trie {\n  constructor() { this.root = new TrieNode(); }\n  insert(word) {\n    let node = this.root;\n    for (const c of word) {\n      if (!node.children[c]) node.children[c] = new TrieNode();\n      node = node.children[c];\n    }\n    node.isEnd = true;\n  }\n  search(word) {\n    let node = this.root;\n    for (const c of word) {\n      if (!node.children[c]) return false;\n      node = node.children[c];\n    }\n    return node.isEnd;\n  }\n  startsWith(prefix) {\n    let node = this.root;\n    for (const c of prefix) {\n      if (!node.children[c]) return false;\n      node = node.children[c];\n    }\n    return true;\n  }\n}\n\nconst t = new Trie();\nt.insert('apple'); t.insert('app'); t.insert('application');\nconsole.log(t.search('app'));       // true\nconsole.log(t.search('ap'));        // false\nconsole.log(t.startsWith('ap'));    // true\nconsole.log(t.startsWith('b'));     // false",
              "output": "true\nfalse\ntrue\nfalse"
            },
            {
              "question": "Program 2: Autocomplete with frequency ranking",
              "code": "class AutocompleteTrie {\n  constructor() { this.root = { children: {}, words: [] }; }\n  insert(word, freq) {\n    let node = this.root;\n    for (const c of word) {\n      if (!node.children[c]) node.children[c] = { children: {}, words: [] };\n      node = node.children[c];\n      // Update top-5 at each node\n      const idx = node.words.findIndex(w => w.word === word);\n      if (idx >= 0) node.words[idx].freq = freq;\n      else node.words.push({ word, freq });\n      node.words.sort((a, b) => b.freq - a.freq);\n      if (node.words.length > 5) node.words.pop();\n    }\n  }\n  suggest(prefix) {\n    let node = this.root;\n    for (const c of prefix) {\n      if (!node.children[c]) return [];\n      node = node.children[c];\n    }\n    return node.words.map(w => `${w.word} (${w.freq})`);\n  }\n}\n\nconst ac = new AutocompleteTrie();\nac.insert('system design', 100);\nac.insert('system design interview', 80);\nac.insert('syntax error', 60);\nac.insert('system of equations', 40);\nac.insert('synchronous', 30);\nac.insert('sysadmin', 20);\nac.insert('sys', 10);\n\nconsole.log(ac.suggest('sy'));\nconsole.log(ac.suggest('system'));",
              "output": "[\n  'system design (100)',\n  'system design interview (80)',\n  'syntax error (60)',\n  'system of equations (40)',\n  'synchronous (30)'\n]\n[\n  'system design (100)',\n  'system design interview (80)',\n  'system of equations (40)'\n]"
            },
            {
              "question": "Program 3: Client-side debounce for typeahead",
              "code": "class DebounceSimulator {\n  constructor(delayMs) {\n    this.delay = delayMs;\n    this.timer = null;\n    this.calls = [];\n    this.actual = [];\n  }\n  type(char, timestamp) {\n    this.calls.push({ char, timestamp });\n    // Cancel previous timer\n    if (this.timer && timestamp < this.timer.fireAt) {\n      this.timer = null;\n    }\n    this.timer = { char, fireAt: timestamp + this.delay };\n  }\n  flush(currentTime) {\n    if (this.timer && currentTime >= this.timer.fireAt) {\n      this.actual.push({ fireAt: this.timer.fireAt });\n      this.timer = null;\n    }\n  }\n  simulate(keystrokes) {\n    let prefix = '';\n    const requests = [];\n    keystrokes.forEach(({ char, time }) => {\n      prefix += char;\n      this.type(char, time);\n      // Check if any pending timer should fire\n      this.flush(time);\n    });\n    // Final flush\n    this.flush(keystrokes[keystrokes.length - 1].time + this.delay + 1);\n    return { totalKeystrokes: keystrokes.length, apiCalls: this.actual.length, saved: `${((1 - this.actual.length / keystrokes.length) * 100).toFixed(0)}%` };\n  }\n}\n\nconst ds = new DebounceSimulator(150);\nconst result = ds.simulate([\n  { char: 's', time: 0 },\n  { char: 'y', time: 80 },\n  { char: 's', time: 160 },  // timer from 'y' fires? No, 80+150=230 > 160\n  { char: 't', time: 240 },\n  { char: 'e', time: 320 },\n  { char: 'm', time: 400 },\n  // pause 200ms\n  { char: ' ', time: 600 },\n  { char: 'd', time: 680 },\n]);\nconsole.log(result);",
              "output": "{ totalKeystrokes: 8, apiCalls: 2, saved: '75%' }"
            },
            {
              "question": "Program 4: Prefix-based cache with TTL",
              "code": "class PrefixCache {\n  constructor(ttlMs) {\n    this.cache = new Map();\n    this.ttl = ttlMs;\n    this.hits = 0;\n    this.misses = 0;\n  }\n  get(prefix) {\n    const entry = this.cache.get(prefix);\n    if (!entry) { this.misses++; return null; }\n    if (Date.now() > entry.expiresAt) {\n      this.cache.delete(prefix);\n      this.misses++;\n      return null;\n    }\n    this.hits++;\n    return entry.suggestions;\n  }\n  set(prefix, suggestions) {\n    this.cache.set(prefix, { suggestions, expiresAt: Date.now() + this.ttl });\n  }\n  stats() {\n    const total = this.hits + this.misses;\n    return {\n      hits: this.hits,\n      misses: this.misses,\n      hitRate: total ? (this.hits / total * 100).toFixed(1) + '%' : 'N/A',\n      size: this.cache.size,\n    };\n  }\n}\n\nconst pc = new PrefixCache(5000);\npc.set('sys', ['system design', 'syntax error']);\npc.set('rea', ['react', 'react hooks', 'read']);\n\nconsole.log(pc.get('sys'));\nconsole.log(pc.get('sys'));\nconsole.log(pc.get('xyz'));\nconsole.log(pc.stats());",
              "output": "[ 'system design', 'syntax error' ]\n[ 'system design', 'syntax error' ]\nnull\n{ hits: 2, misses: 1, hitRate: '66.7%', size: 2 }"
            },
            {
              "question": "Program 5: Query frequency aggregator with time decay",
              "code": "class QueryAggregator {\n  constructor(decayFactor) {\n    this.queries = new Map();\n    this.decay = decayFactor;\n  }\n  record(query, timestamp = Date.now()) {\n    if (!this.queries.has(query)) this.queries.set(query, []);\n    this.queries.get(query).push(timestamp);\n  }\n  getScore(query, now = Date.now()) {\n    const times = this.queries.get(query) || [];\n    return times.reduce((score, t) => {\n      const ageHours = (now - t) / 3600000;\n      return score + Math.exp(-this.decay * ageHours);\n    }, 0);\n  }\n  topK(prefix, k = 5, now = Date.now()) {\n    const results = [];\n    for (const [query] of this.queries) {\n      if (query.startsWith(prefix)) {\n        results.push({ query, score: parseFloat(this.getScore(query, now).toFixed(3)) });\n      }\n    }\n    return results.sort((a, b) => b.score - a.score).slice(0, k);\n  }\n}\n\nconst qa = new QueryAggregator(0.01); // slow decay\nconst now = Date.now();\nqa.record('system design', now - 3600000 * 24); // 24h ago\nqa.record('system design', now - 3600000 * 12);\nqa.record('system design', now - 3600000);\nqa.record('system architecture', now); // just now\nqa.record('system architecture', now);\n\nconsole.log(qa.topK('system', 5, now));",
              "output": "[\n  { query: 'system design', score: 2.572 },\n  { query: 'system architecture', score: 2.0 }\n]"
            },
            {
              "question": "Program 6: Trie with delete operation",
              "code": "class DeletableTrie {\n  constructor() { this.root = { children: {}, count: 0, isEnd: false }; }\n  insert(word) {\n    let node = this.root;\n    for (const c of word) {\n      if (!node.children[c]) node.children[c] = { children: {}, count: 0, isEnd: false };\n      node = node.children[c];\n      node.count++;\n    }\n    node.isEnd = true;\n  }\n  delete(word) {\n    const _delete = (node, word, i) => {\n      if (i === word.length) {\n        if (!node.isEnd) return false;\n        node.isEnd = false;\n        return Object.keys(node.children).length === 0;\n      }\n      const c = word[i];\n      if (!node.children[c]) return false;\n      node.children[c].count--;\n      const shouldDelete = _delete(node.children[c], word, i + 1);\n      if (shouldDelete) delete node.children[c];\n      return Object.keys(node.children).length === 0 && !node.isEnd;\n    };\n    _delete(this.root, word, 0);\n  }\n  autocomplete(prefix) {\n    let node = this.root;\n    for (const c of prefix) {\n      if (!node.children[c]) return [];\n      node = node.children[c];\n    }\n    const results = [];\n    const dfs = (n, p) => {\n      if (n.isEnd) results.push(p);\n      for (const [c, child] of Object.entries(n.children)) dfs(child, p + c);\n    };\n    dfs(node, prefix);\n    return results;\n  }\n}\n\nconst dt = new DeletableTrie();\ndt.insert('apple'); dt.insert('app'); dt.insert('application');\nconsole.log(dt.autocomplete('app'));\ndt.delete('apple');\nconsole.log(dt.autocomplete('app'));\ndt.delete('app');\nconsole.log(dt.autocomplete('app'));",
              "output": "[ 'app', 'apple', 'application' ]\n[ 'app', 'application' ]\n[ 'application' ]"
            },
            {
              "question": "Program 7: Trending queries detector",
              "code": "class TrendingDetector {\n  constructor(windowMs, spikeThreshold) {\n    this.windowMs = windowMs;\n    this.spikeThreshold = spikeThreshold;\n    this.current = new Map(); // query -> count in current window\n    this.baseline = new Map(); // query -> avg count\n  }\n  setBaseline(query, avgCount) {\n    this.baseline.set(query, avgCount);\n  }\n  record(query) {\n    this.current.set(query, (this.current.get(query) || 0) + 1);\n  }\n  getTrending() {\n    const trending = [];\n    for (const [query, count] of this.current) {\n      const base = this.baseline.get(query) || 1;\n      const ratio = count / base;\n      if (ratio >= this.spikeThreshold) {\n        trending.push({ query, count, baseline: base, spike: ratio.toFixed(1) + 'x' });\n      }\n    }\n    return trending.sort((a, b) => parseFloat(b.spike) - parseFloat(a.spike));\n  }\n}\n\nconst td = new TrendingDetector(3600000, 3); // 1hr window, 3x spike\ntd.setBaseline('system design', 100);\ntd.setBaseline('javascript', 200);\ntd.setBaseline('breaking news', 10);\n\n// Simulate current window counts\nfor (let i = 0; i < 120; i++) td.record('system design'); // 120 vs 100 baseline\nfor (let i = 0; i < 150; i++) td.record('javascript');    // 150 vs 200 baseline\nfor (let i = 0; i < 50; i++) td.record('breaking news');  // 50 vs 10 baseline\nfor (let i = 0; i < 500; i++) td.record('new trend');     // no baseline\n\nconsole.log(td.getTrending());",
              "output": "[\n  { query: 'new trend', count: 500, baseline: 1, spike: '500.0x' },\n  { query: 'breaking news', count: 50, baseline: 10, spike: '5.0x' }\n]"
            },
            {
              "question": "Program 8: Prefix range sharding",
              "code": "class TrieShardRouter {\n  constructor(shards) {\n    // shards: [{ id, range: [startChar, endChar] }]\n    this.shards = shards;\n  }\n  route(prefix) {\n    if (!prefix) return { error: 'Empty prefix' };\n    const first = prefix[0].toLowerCase();\n    const shard = this.shards.find(s => first >= s.range[0] && first <= s.range[1]);\n    return shard ? { prefix, shardId: shard.id, range: shard.range.join('-') } : { error: 'No shard for prefix' };\n  }\n  routeAll(prefixes) {\n    const grouped = {};\n    prefixes.forEach(p => {\n      const r = this.route(p);\n      if (r.shardId) {\n        if (!grouped[r.shardId]) grouped[r.shardId] = [];\n        grouped[r.shardId].push(p);\n      }\n    });\n    return grouped;\n  }\n}\n\nconst router = new TrieShardRouter([\n  { id: 'shard-1', range: ['a', 'f'] },\n  { id: 'shard-2', range: ['g', 'm'] },\n  { id: 'shard-3', range: ['n', 's'] },\n  { id: 'shard-4', range: ['t', 'z'] },\n]);\n\nconsole.log(router.route('system'));\nconsole.log(router.route('javascript'));\nconsole.log(router.routeAll(['apple', 'go', 'react', 'vue', 'next', 'docker']));",
              "output": "{ prefix: 'system', shardId: 'shard-3', range: 'n-s' }\n{ prefix: 'javascript', shardId: 'shard-2', range: 'g-m' }\n{\n  'shard-1': [ 'apple', 'docker' ],\n  'shard-2': [ 'go' ],\n  'shard-3': [ 'react', 'next' ],\n  'shard-4': [ 'vue' ]\n}"
            },
            {
              "question": "Program 9: Autocomplete with spell correction",
              "code": "class SpellCorrectAutocomplete {\n  constructor() { this.words = new Map(); }\n  add(word, freq) { this.words.set(word.toLowerCase(), freq); }\n  editDistance(a, b) {\n    const m = a.length, n = b.length;\n    const dp = Array.from({ length: m + 1 }, () => Array(n + 1).fill(0));\n    for (let i = 0; i <= m; i++) dp[i][0] = i;\n    for (let j = 0; j <= n; j++) dp[0][j] = j;\n    for (let i = 1; i <= m; i++)\n      for (let j = 1; j <= n; j++)\n        dp[i][j] = a[i-1] === b[j-1] ? dp[i-1][j-1] : 1 + Math.min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]);\n    return dp[m][n];\n  }\n  suggest(input, maxDist = 2, k = 3) {\n    const results = [];\n    for (const [word, freq] of this.words) {\n      if (word.startsWith(input)) {\n        results.push({ word, freq, distance: 0, type: 'prefix' });\n      } else if (this.editDistance(input, word.substring(0, input.length)) <= maxDist) {\n        results.push({ word, freq, distance: this.editDistance(input, word.substring(0, input.length)), type: 'fuzzy' });\n      }\n    }\n    return results.sort((a, b) => a.distance - b.distance || b.freq - a.freq).slice(0, k);\n  }\n}\n\nconst sca = new SpellCorrectAutocomplete();\nsca.add('javascript', 100); sca.add('java', 80); sca.add('python', 60);\nsca.add('typescript', 50); sca.add('javscript', 5); // common misspelling\n\nconsole.log(sca.suggest('javas'));  // exact prefix\nconsole.log(sca.suggest('javscr')); // typo",
              "output": "[\n  { word: 'javascript', freq: 100, distance: 0, type: 'prefix' },\n  { word: 'javscript', freq: 5, distance: 0, type: 'prefix' }\n]\n[\n  { word: 'javscript', freq: 5, distance: 0, type: 'prefix' },\n  { word: 'javascript', freq: 100, distance: 1, type: 'fuzzy' }\n]"
            },
            {
              "question": "Program 10: Full autocomplete system with cache + trie",
              "code": "class FullAutocomplete {\n  constructor() {\n    this.trie = { children: {}, top: [] };\n    this.cache = new Map();\n    this.stats = { trieHits: 0, cacheHits: 0 };\n  }\n  buildTrie(entries) {\n    entries.forEach(({ term, score }) => {\n      let node = this.trie;\n      for (const c of term) {\n        if (!node.children[c]) node.children[c] = { children: {}, top: [] };\n        node = node.children[c];\n        const idx = node.top.findIndex(t => t.term === term);\n        if (idx >= 0) node.top[idx].score = score;\n        else node.top.push({ term, score });\n        node.top.sort((a, b) => b.score - a.score);\n        if (node.top.length > 5) node.top.pop();\n      }\n    });\n  }\n  suggest(prefix) {\n    // Check cache first\n    if (this.cache.has(prefix)) {\n      this.stats.cacheHits++;\n      return { source: 'cache', results: this.cache.get(prefix) };\n    }\n    // Trie lookup\n    let node = this.trie;\n    for (const c of prefix) {\n      if (!node.children[c]) return { source: 'trie', results: [] };\n      node = node.children[c];\n    }\n    this.stats.trieHits++;\n    const results = node.top.map(t => t.term);\n    this.cache.set(prefix, results);\n    return { source: 'trie', results };\n  }\n}\n\nconst fa = new FullAutocomplete();\nfa.buildTrie([\n  { term: 'system design', score: 100 },\n  { term: 'system architecture', score: 70 },\n  { term: 'syntax error', score: 60 },\n  { term: 'synchronous', score: 40 },\n  { term: 'symbol table', score: 30 },\n]);\nconsole.log(fa.suggest('sy'));  // trie\nconsole.log(fa.suggest('sy'));  // cache\nconsole.log(fa.suggest('system'));\nconsole.log('Stats:', fa.stats);",
              "output": "{ source: 'trie', results: ['system design', 'system architecture', 'syntax error', 'synchronous', 'symbol table'] }\n{ source: 'cache', results: ['system design', 'system architecture', 'syntax error', 'synchronous', 'symbol table'] }\n{ source: 'trie', results: ['system design', 'system architecture'] }\nStats: { trieHits: 2, cacheHits: 1 }"
            }
          ]
        },
        {
          "id": "ride-matching",
          "title": "Ride Matching System (like Uber/Ola)",
          "category": "Company HLD",
          "description": "Design a ride-matching system that matches riders with nearby drivers in real-time, handles surge pricing, ETA computation, and processes millions of location updates per second.",
          "explanation": "A ride-matching system like Uber connects riders requesting rides with available drivers nearby. The core challenges: real-time geolocation matching at scale, dynamic pricing, accurate ETAs, and handling millions of concurrent drivers and riders.\n\n**Core Components**:\n1. **Location Service**: Ingests driver GPS updates (every 3-5 seconds). Stores in geospatial index.\n2. **Matching Service**: When rider requests ride → query nearby available drivers → rank → assign.\n3. **Pricing Service**: Calculates fare based on distance, time, surge multiplier.\n4. **ETA Service**: Estimates arrival time using road graph + real-time traffic.\n5. **Trip Service**: Manages trip lifecycle (requested → matched → enroute → in-trip → completed).\n6. **Payment Service**: Processes payment after trip ends.\n\n**Ride Request Flow**:\n1. Rider opens app → sends location (lat, lng) + destination.\n2. Pricing Service computes estimated fare (distance × rate + surge).\n3. Rider confirms → Matching Service queries Location Service: find drivers within 5km radius.\n4. Filter: available drivers + correct vehicle type.\n5. Rank: by ETA to pickup (not straight-line distance).\n6. Send ride request to top driver. If no response in 15s → next driver.\n7. Driver accepts → Trip created. Both rider and driver see each other's location.\n8. Driver arrives → trip starts → driver navigates to destination → trip ends.\n9. Fare calculated from actual route. Payment processed.\n\n**Geospatial Indexing**:\n- GeoHash: encode (lat, lng) to string. Nearby locations share common prefix.\n- S2 Geometry (Google): divides Earth into cells. Level-12 cells ≈ 3km².\n- QuadTree: divide map recursively. Each node = geographic rectangle.\n- Store: driver_id → geohash in Redis Sorted Set. GEOSEARCH command finds nearby.\n\n**Surge Pricing**:\n- Divide city into hexagonal zones (H3 cells).\n- In each zone: supply = available drivers, demand = ride requests in last 5 min.\n- Surge multiplier = demand / supply (capped at 3x-5x).\n- Smoothing: weighted average with neighboring zones.\n- Display surge to rider before confirmation.",
          "code": "// Ride matching system simulation\nclass RideMatchingSystem {\n  constructor() {\n    this.drivers = new Map(); // id -> { lat, lng, available, vehicleType }\n    this.trips = new Map(); // id -> trip\n    this.tripCounter = 0;\n  }\n\n  updateDriverLocation(driverId, lat, lng, vehicleType = 'sedan') {\n    this.drivers.set(driverId, {\n      id: driverId, lat, lng,\n      available: this.drivers.get(driverId)?.available ?? true,\n      vehicleType,\n    });\n  }\n\n  haversineDistance(lat1, lng1, lat2, lng2) {\n    const R = 6371; // km\n    const dLat = (lat2 - lat1) * Math.PI / 180;\n    const dLng = (lng2 - lng1) * Math.PI / 180;\n    const a = Math.sin(dLat/2)**2 + Math.cos(lat1*Math.PI/180) * Math.cos(lat2*Math.PI/180) * Math.sin(dLng/2)**2;\n    return R * 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1-a));\n  }\n\n  findNearbyDrivers(lat, lng, radiusKm = 5, vehicleType = 'sedan') {\n    const nearby = [];\n    for (const driver of this.drivers.values()) {\n      if (!driver.available || driver.vehicleType !== vehicleType) continue;\n      const dist = this.haversineDistance(lat, lng, driver.lat, driver.lng);\n      if (dist <= radiusKm) nearby.push({ ...driver, distance: parseFloat(dist.toFixed(2)) });\n    }\n    return nearby.sort((a, b) => a.distance - b.distance);\n  }\n\n  requestRide(riderId, pickupLat, pickupLng, destLat, destLng, vehicleType = 'sedan') {\n    const nearby = this.findNearbyDrivers(pickupLat, pickupLng, 5, vehicleType);\n    if (nearby.length === 0) return { status: 'NO_DRIVERS', message: 'No drivers available nearby' };\n\n    const bestDriver = nearby[0];\n    bestDriver.available = false;\n    this.drivers.set(bestDriver.id, bestDriver);\n\n    const tripDist = this.haversineDistance(pickupLat, pickupLng, destLat, destLng);\n    const tripId = `trip_${++this.tripCounter}`;\n    const trip = {\n      id: tripId, riderId, driverId: bestDriver.id,\n      pickup: { lat: pickupLat, lng: pickupLng },\n      destination: { lat: destLat, lng: destLng },\n      distance: parseFloat(tripDist.toFixed(2)),\n      estimatedFare: parseFloat((tripDist * 12 + 30).toFixed(2)), // ₹12/km + ₹30 base\n      status: 'MATCHED',\n      eta: parseFloat((bestDriver.distance / 30 * 60).toFixed(1)), // minutes at 30km/h\n    };\n    this.trips.set(tripId, trip);\n    return trip;\n  }\n\n  completeTrip(tripId) {\n    const trip = this.trips.get(tripId);\n    if (!trip) return { error: 'Trip not found' };\n    trip.status = 'COMPLETED';\n    const driver = this.drivers.get(trip.driverId);\n    if (driver) driver.available = true;\n    return { tripId, status: 'COMPLETED', fare: trip.estimatedFare };\n  }\n}\n\nconst rms = new RideMatchingSystem();\n// Drivers in Bangalore area\nrms.updateDriverLocation('d1', 12.9716, 77.5946);\nrms.updateDriverLocation('d2', 12.9800, 77.5900);\nrms.updateDriverLocation('d3', 12.9600, 77.6100);\nrms.updateDriverLocation('d4', 13.0200, 77.5600, 'suv');\n\nconsole.log('Nearby:', rms.findNearbyDrivers(12.9750, 77.5950));\nconsole.log('\\nRide:', rms.requestRide('r1', 12.9750, 77.5950, 13.0280, 77.6173));\nconsole.log('\\nComplete:', rms.completeTrip('trip_1'));",
          "example": "// Surge pricing calculator\nclass SurgePricing {\n  constructor() {\n    this.zones = new Map(); // zoneId -> { supply, demand }\n  }\n  updateZone(zoneId, supply, demand) {\n    this.zones.set(zoneId, { supply, demand });\n  }\n  getSurge(zoneId) {\n    const zone = this.zones.get(zoneId);\n    if (!zone || zone.supply === 0) return { multiplier: 5.0, reason: 'No supply' };\n    const ratio = zone.demand / zone.supply;\n    let multiplier = 1.0;\n    if (ratio > 2.0) multiplier = Math.min(ratio * 0.8, 5.0);\n    else if (ratio > 1.5) multiplier = 1.5;\n    else if (ratio > 1.0) multiplier = 1.2;\n    return { zoneId, supply: zone.supply, demand: zone.demand, ratio: ratio.toFixed(2), multiplier: parseFloat(multiplier.toFixed(1)) };\n  }\n  calculateFare(zoneId, distKm, baseRate = 12, baseFare = 30) {\n    const surge = this.getSurge(zoneId);\n    const fare = (baseFare + distKm * baseRate) * surge.multiplier;\n    return { distance: distKm, baseFare: baseFare + distKm * baseRate, surge: surge.multiplier, finalFare: parseFloat(fare.toFixed(2)) };\n  }\n}\n\nconst sp = new SurgePricing();\nsp.updateZone('zone-A', 10, 5);   // balanced\nsp.updateZone('zone-B', 3, 15);   // high demand\nsp.updateZone('zone-C', 20, 10);  // oversupply\n\nconsole.log(sp.getSurge('zone-A'));\nconsole.log(sp.getSurge('zone-B'));\nconsole.log(sp.calculateFare('zone-A', 8));\nconsole.log(sp.calculateFare('zone-B', 8));",
          "useCase": "Ride-hailing (Uber, Ola, Lyft), food delivery matching, ambulance dispatch, courier assignment, fleet management, logistics vehicle routing.",
          "interviewQuestions": [
            {
              "question": "How do you efficiently find nearby drivers?",
              "answer": "Geospatial index: GeoHash or S2 cells. Store driver locations in Redis GEO: GEOADD drivers <lng> <lat> <driverId>. Query: GEOSEARCH drivers FROMLONLAT <lng> <lat> BYRADIUS 5 km ASC COUNT 10. This gives nearest 10 drivers within 5km. O(log N) per query. Update on every GPS ping (every 3-5s). Alternative: QuadTree in-memory for lower latency."
            },
            {
              "question": "How do you handle the matching algorithm?",
              "answer": "Step 1: Nearby drivers (geospatial query). Step 2: Filter: available + correct vehicle type. Step 3: Rank by ETA (road-network distance, not Euclidean). Step 4: Offer to top driver with 15s timeout. If declined/timeout → next driver. Step 5: Optimization: batch matching — collect requests over 2s window, solve assignment problem (Hungarian algorithm) for optimal global matching."
            },
            {
              "question": "How does surge pricing work?",
              "answer": "Divide city into zones (H3 hexagons). Every 5 minutes: count demand (ride requests) and supply (available drivers) per zone. Ratio = demand/supply. If ratio > 1.5 → surge. Multiplier = f(ratio), capped at 5x. Smooth transitions: weighted average with previous interval. Show surge to rider before booking. Purpose: incentivize drivers to move to high-demand areas."
            },
            {
              "question": "How do you handle millions of GPS updates per second?",
              "answer": "Drivers send updates every 3-5s. 1M drivers = 200K-333K updates/sec. Ingest via Kafka (partitioned by driver_id or zone). Consumer updates Redis GEO. Batch writes: aggregate updates in 1s micro-batches. Dead reckoning: if update missed, extrapolate position from last known heading + speed. Prioritize: only update index for available drivers."
            },
            {
              "question": "How do you compute accurate ETAs?",
              "answer": "Simple: straight-line distance / avg speed. Better: road-network graph + Dijkstra/A*. Best: pre-computed contraction hierarchies for instant routing. Real-time: overlay traffic data on road graph (speed per road segment from driver GPS traces). ML: train model on historical trip data: features = origin, destination, time of day, weather → ETA. Combine: routing ETA * ML correction factor."
            },
            {
              "question": "How do you design the trip lifecycle?",
              "answer": "States: REQUESTED → MATCHING → DRIVER_ASSIGNED → DRIVER_ENROUTE → DRIVER_ARRIVED → TRIP_STARTED → TRIP_IN_PROGRESS → TRIP_COMPLETED → PAYMENT_PROCESSED. State machine in Trip Service. Transitions triggered by: driver accept, driver arrival (geo-fence: within 100m), rider swipe to start, driver ends trip. Each transition → event to Kafka → consumed by analytics, billing, notification services."
            },
            {
              "question": "How do you handle driver-side and rider-side cancellation?",
              "answer": "Rider cancels before driver assignment → no penalty. Rider cancels after driver en route → cancellation fee (covers driver's time). Driver cancels → penalize driver (affects acceptance rate score). Driver no-show at pickup → rider can cancel without fee after 5 min wait. System handles: re-match rider with next driver. Rate limits: frequent cancellers get lower priority."
            },
            {
              "question": "How do you ensure payment reliability?",
              "answer": "Pre-authorization: charge rider's card a hold (estimated fare + 20% buffer) before ride starts. After trip: calculate actual fare → capture exact amount. If card declines pre-auth → don't allow ride. For cash rides: driver collects cash, platform deducts from driver's next payout. Dispute handling: refund policy for overcharges, GPS-verified routes, fare breakdown."
            },
            {
              "question": "How do you handle real-time location sharing between rider and driver?",
              "answer": "After match: both subscribe to each other's location via WebSocket. Driver GPS → Location Service → WebSocket to rider (every 3s). Rider sees driver moving on map. After trip starts: rider location not needed (driver knows destination). Trip tracking: rider can share live trip URL with contacts (safety). Privacy: location sharing stops after trip ends."
            },
            {
              "question": "How do you design the system for multi-city expansion?",
              "answer": "Region-based architecture: each city is an independent deployment. Shared: user auth, payment, core platform. City-specific: driver pool, pricing config, map data, surge zones. Benefits: isolation (one city's outage doesn't affect others), compliance (local regulations per city). Data: geo-partitioned (India data → India region). Configuration: per-city settings (base fare, surge cap, vehicle types)."
            }
          ],
          "exercises": [
            {
              "type": "estimation",
              "question": "Uber: 5M drivers, each sends GPS every 4 seconds. Estimate ingestion rate and storage.",
              "answer": "GPS updates/sec: 5M / 4 = 1.25M/sec. Each update: driver_id(8B) + lat(8B) + lng(8B) + timestamp(8B) + heading(4B) + speed(4B) = 40B. Throughput: 1.25M × 40B = 50MB/sec = 4.3TB/day. Geospatial index: only latest position per driver → 5M × 40B = 200MB (fits in memory). Historical: store in time-series DB with 30-day retention."
            },
            {
              "type": "design",
              "question": "Design the driver dispatch optimization to prevent the 'thundering herd' problem.",
              "answer": "Problem: popular area with many riders → all requests go to same nearest driver. Solution: batch matching. Collect all ride requests in 2s window. Solve assignment problem: minimize total pickup distance across all (rider, driver) pairs. Algorithms: Hungarian method (optimal but O(n³)), greedy nearest-first (fast, near-optimal). Partition by zone: solve independently per zone to reduce problem size."
            },
            {
              "type": "scenario",
              "question": "Concert ends at a stadium. 50,000 riders request rides simultaneously. How does the system handle it?",
              "answer": "1) Surg: demand spike → surge pricing activates (5x) → some riders drop off. 2) Queue: virtual waiting room 'You are #2,347 in queue'. 3) Batch matching: process in waves. 4) Expand radius: look for drivers up to 15km away. 5) Push to drivers: 'High demand at Stadium Road — surge 4x' to attract supply. 6) Ride-share: offer shared rides to reduce individual demand. 7) Stagger: ETA transparency — 'Next available in 15 min'."
            },
            {
              "type": "tricky",
              "question": "Why use GeoHash over simple lat/lng range queries?",
              "answer": "Range query: WHERE lat BETWEEN x1 AND x2 AND lng BETWEEN y1 AND y2. Problem: rectangular, not circular. Needs secondary index on both columns. GeoHash: single dimension → single index. Prefix matching = proximity. Redis GEOSEARCH: built-in circular radius query. S2 Cells: better for covering queries (find cells that cover a circle). GeoHash edge case: nearby points across hash boundary might not share prefix."
            },
            {
              "type": "design",
              "question": "Design the ETA prediction system.",
              "answer": "Layers: (1) Simple: Euclidean distance / avg_speed. (2) Road routing: A* on road graph. (3) Traffic-aware: speed per road segment (from recent driver traces). (4) ML correction: model trained on historical trips. Features: origin, dest, time, day, weather, events. Target: actual trip duration. Ensemble: routing_ETA × ML_correction_factor. Update: real-time traffic data refreshed every 2 minutes."
            },
            {
              "type": "estimation",
              "question": "City with 100K active drivers. Geospatial index query: find drivers within 3km. How fast?",
              "answer": "Redis GEOSEARCH: O(log N + M) where N = total entries, M = results. log(100K) ≈ 17 operations. Within 3km in busy area: ~50-200 results. Total: microseconds. Even with 1M entries: log(1M) ≈ 20. Practically: <1ms for geo query. Bottleneck is network round-trip to Redis (~0.5ms), not the query itself. Can handle 100K+ geo queries/sec per Redis instance."
            },
            {
              "type": "debug",
              "question": "Riders report being matched with drivers 10km away even when closer drivers are available. What's wrong?",
              "answer": "1) Stale location: driver location not updated (GPS failure, poor signal). Fix: evict drivers with updates older than 30s. 2) Race condition: multiple riders matched to same 'nearest' driver simultaneously. Fix: atomic assignment (lock driver on match). 3) Index not updated: Kafka consumer lag. Fix: monitor consumer lag, scale consumers. 4) GeoHash boundary: adjacent drivers in different hash cell. Fix: query neighboring cells too."
            },
            {
              "type": "design",
              "question": "Design the ride-sharing (pool) matching system.",
              "answer": "When rider selects pool: find existing trips going in same direction. Criteria: (1) Detour < 30% of original route. (2) ETA increase for existing rider < 5 min. (3) Pickup point within 500m of existing route. Algorithm: for each active pool trip, compute: new_route = current_route + new_pickup + new_dropoff. If detour_ratio < 0.3 → match. Fare: split proportionally by distance. Capacity: max 3 riders per pool."
            },
            {
              "type": "scenario",
              "question": "Driver's app crashes mid-trip. How does the system handle it?",
              "answer": "1) Heartbeat detection: if no driver GPS update for 60s → alert. 2) Trip state persisted in DB (not in-memory) → survives app restart. 3) Driver reopens app → fetches active trip → resumes. 4) If driver unreachable for 5 min → notify rider. 5) Safety: trigger safety check. 6) Billing: use last known position + estimated remaining distance. 7) If driver can't resume → dispatch new driver to rider's last known location."
            },
            {
              "type": "output",
              "question": "3 riders request rides. 2 drivers available. Driver A is 1km from Rider 1 and 3km from Rider 2. Driver B is 2km from Rider 1 and 1km from Rider 2. What's the optimal assignment?",
              "answer": "Greedy: assign Driver A → Rider 1 (1km), Driver B → Rider 2 (1km). Total: 2km. Optimal (Hungarian): same result in this case. Alternative: Driver A → Rider 2 (3km), Driver B → Rider 1 (2km). Total: 5km — worse. Rider 3: no driver available → queue. Result: A→R1(1km), B→R2(1km), R3 waits. Total distance minimized."
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Haversine distance calculator",
              "code": "function haversine(lat1, lng1, lat2, lng2) {\n  const R = 6371; // Earth radius in km\n  const toRad = deg => deg * Math.PI / 180;\n  const dLat = toRad(lat2 - lat1);\n  const dLng = toRad(lng2 - lng1);\n  const a = Math.sin(dLat/2)**2 + Math.cos(toRad(lat1)) * Math.cos(toRad(lat2)) * Math.sin(dLng/2)**2;\n  const c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1-a));\n  return parseFloat((R * c).toFixed(2));\n}\n\nconsole.log('Mumbai to Pune:', haversine(19.0760, 72.8777, 18.5204, 73.8567), 'km');\nconsole.log('Delhi to Noida:', haversine(28.7041, 77.1025, 28.5355, 77.3910), 'km');\nconsole.log('Same point:', haversine(12.97, 77.59, 12.97, 77.59), 'km');",
              "output": "Mumbai to Pune: 118.19 km\nDelhi to Noida: 33.05 km\nSame point: 0 km"
            },
            {
              "question": "Program 2: GeoHash encoder/decoder (simplified)",
              "code": "function encodeGeoHash(lat, lng, precision = 6) {\n  const chars = '0123456789bcdefghjkmnpqrstuvwxyz';\n  let minLat = -90, maxLat = 90, minLng = -180, maxLng = 180;\n  let hash = '', bit = 0, ch = 0, isLng = true;\n  while (hash.length < precision) {\n    if (isLng) {\n      const mid = (minLng + maxLng) / 2;\n      if (lng >= mid) { ch |= (1 << (4 - bit)); minLng = mid; } else maxLng = mid;\n    } else {\n      const mid = (minLat + maxLat) / 2;\n      if (lat >= mid) { ch |= (1 << (4 - bit)); minLat = mid; } else maxLat = mid;\n    }\n    isLng = !isLng;\n    if (++bit === 5) { hash += chars[ch]; bit = 0; ch = 0; }\n  }\n  return hash;\n}\n\nconst locations = [\n  { name: 'Bangalore', lat: 12.9716, lng: 77.5946 },\n  { name: 'Nearby BLR', lat: 12.9750, lng: 77.5960 },\n  { name: 'Mumbai', lat: 19.0760, lng: 72.8777 },\n];\n\nlocations.forEach(l => {\n  const hash = encodeGeoHash(l.lat, l.lng);\n  console.log(`${l.name}: ${hash}`);\n});\nconsole.log('Notice: nearby points share prefix!');",
              "output": "Bangalore: tdr1wz\nNearby BLR: tdr1x0\nMumbai: te7ud2\nNotice: nearby points share prefix!"
            },
            {
              "question": "Program 3: Driver pool with geospatial search",
              "code": "class DriverPool {\n  constructor() { this.drivers = new Map(); }\n  addDriver(id, lat, lng, type = 'sedan') {\n    this.drivers.set(id, { id, lat, lng, type, available: true });\n  }\n  setAvailable(id, available) {\n    const d = this.drivers.get(id);\n    if (d) d.available = available;\n  }\n  distance(lat1, lng1, lat2, lng2) {\n    const R = 6371;\n    const dLat = (lat2-lat1)*Math.PI/180, dLng = (lng2-lng1)*Math.PI/180;\n    const a = Math.sin(dLat/2)**2 + Math.cos(lat1*Math.PI/180)*Math.cos(lat2*Math.PI/180)*Math.sin(dLng/2)**2;\n    return R * 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1-a));\n  }\n  findNearby(lat, lng, radiusKm, type = null) {\n    return [...this.drivers.values()]\n      .filter(d => d.available && (!type || d.type === type))\n      .map(d => ({ ...d, dist: parseFloat(this.distance(lat, lng, d.lat, d.lng).toFixed(2)) }))\n      .filter(d => d.dist <= radiusKm)\n      .sort((a, b) => a.dist - b.dist);\n  }\n}\n\nconst pool = new DriverPool();\npool.addDriver('D1', 12.971, 77.594);\npool.addDriver('D2', 12.980, 77.590);\npool.addDriver('D3', 12.960, 77.610);\npool.addDriver('D4', 13.020, 77.560, 'suv');\npool.setAvailable('D3', false);\n\nconsole.log('Nearby sedans:', pool.findNearby(12.975, 77.595, 3, 'sedan'));\nconsole.log('All nearby:', pool.findNearby(12.975, 77.595, 10));",
              "output": "Nearby sedans: [\n  { id: 'D1', ..., dist: 0.45 },\n  { id: 'D2', ..., dist: 0.73 }\n]\nAll nearby: [\n  { id: 'D1', ..., dist: 0.45 },\n  { id: 'D2', ..., dist: 0.73 },\n  { id: 'D4', ..., dist: 5.93 }\n]"
            },
            {
              "question": "Program 4: Trip state machine",
              "code": "class TripStateMachine {\n  constructor() {\n    this.transitions = {\n      REQUESTED: ['MATCHING'],\n      MATCHING: ['DRIVER_ASSIGNED', 'CANCELLED'],\n      DRIVER_ASSIGNED: ['DRIVER_ENROUTE', 'CANCELLED'],\n      DRIVER_ENROUTE: ['ARRIVED', 'CANCELLED'],\n      ARRIVED: ['TRIP_STARTED', 'CANCELLED'],\n      TRIP_STARTED: ['COMPLETED'],\n      COMPLETED: ['PAYMENT_PROCESSED'],\n      CANCELLED: [],\n      PAYMENT_PROCESSED: [],\n    };\n    this.trips = new Map();\n  }\n  create(tripId) {\n    this.trips.set(tripId, { id: tripId, state: 'REQUESTED', history: [{ state: 'REQUESTED', at: Date.now() }] });\n    return this.trips.get(tripId);\n  }\n  transition(tripId, newState) {\n    const trip = this.trips.get(tripId);\n    if (!trip) return { error: 'Trip not found' };\n    const allowed = this.transitions[trip.state];\n    if (!allowed?.includes(newState)) {\n      return { error: `Cannot transition from ${trip.state} to ${newState}` };\n    }\n    trip.state = newState;\n    trip.history.push({ state: newState, at: Date.now() });\n    return { tripId, state: newState, transitions: trip.history.length };\n  }\n}\n\nconst tsm = new TripStateMachine();\ntsm.create('T1');\nconsole.log(tsm.transition('T1', 'MATCHING'));\nconsole.log(tsm.transition('T1', 'DRIVER_ASSIGNED'));\nconsole.log(tsm.transition('T1', 'COMPLETED')); // invalid\nconsole.log(tsm.transition('T1', 'DRIVER_ENROUTE'));",
              "output": "{ tripId: 'T1', state: 'MATCHING', transitions: 2 }\n{ tripId: 'T1', state: 'DRIVER_ASSIGNED', transitions: 3 }\n{ error: 'Cannot transition from DRIVER_ASSIGNED to COMPLETED' }\n{ tripId: 'T1', state: 'DRIVER_ENROUTE', transitions: 4 }"
            },
            {
              "question": "Program 5: Surge pricing calculator with zones",
              "code": "class SurgeCalculator {\n  constructor() { this.zones = new Map(); }\n  update(zoneId, drivers, requests) {\n    this.zones.set(zoneId, { drivers, requests, updated: Date.now() });\n  }\n  getMultiplier(zoneId) {\n    const z = this.zones.get(zoneId);\n    if (!z) return 1.0;\n    if (z.drivers === 0) return 5.0; // max surge\n    const ratio = z.requests / z.drivers;\n    if (ratio <= 1.0) return 1.0;\n    if (ratio <= 1.5) return 1.2;\n    if (ratio <= 2.0) return 1.5;\n    if (ratio <= 3.0) return 2.0;\n    return Math.min(ratio * 0.7, 5.0);\n  }\n  fare(zoneId, distKm, baseFare = 30, ratePerKm = 12) {\n    const surge = this.getMultiplier(zoneId);\n    const base = baseFare + distKm * ratePerKm;\n    return { base: base.toFixed(0), surge, total: (base * surge).toFixed(0) };\n  }\n  allZones() {\n    return [...this.zones.entries()].map(([id, z]) => ({\n      zone: id, drivers: z.drivers, requests: z.requests, surge: this.getMultiplier(id),\n    }));\n  }\n}\n\nconst sc = new SurgeCalculator();\nsc.update('koramangala', 20, 10);   // balanced\nsc.update('indiranagar', 5, 25);    // high demand\nsc.update('whitefield', 30, 15);    // oversupply\nsc.update('airport', 2, 0);         // ghost town\n\nconsole.log(sc.allZones());\nconsole.log('Fare indiranagar 8km:', sc.fare('indiranagar', 8));\nconsole.log('Fare whitefield 8km:', sc.fare('whitefield', 8));",
              "output": "[\n  { zone: 'koramangala', drivers: 20, requests: 10, surge: 1 },\n  { zone: 'indiranagar', drivers: 5, requests: 25, surge: 3.5 },\n  { zone: 'whitefield', drivers: 30, requests: 15, surge: 1 },\n  { zone: 'airport', drivers: 2, requests: 0, surge: 1 }\n]\nFare indiranagar 8km: { base: '126', surge: 3.5, total: '441' }\nFare whitefield 8km: { base: '126', surge: 1, total: '126' }"
            },
            {
              "question": "Program 6: ETA calculator with speed model",
              "code": "class ETACalculator {\n  constructor() { this.speedModels = new Map(); }\n  setSpeedModel(timeSlot, avgSpeedKmh) {\n    this.speedModels.set(timeSlot, avgSpeedKmh);\n  }\n  getSpeed(hour) {\n    if (hour >= 8 && hour <= 10) return this.speedModels.get('morning_rush') || 15;\n    if (hour >= 17 && hour <= 20) return this.speedModels.get('evening_rush') || 12;\n    if (hour >= 22 || hour < 6) return this.speedModels.get('night') || 40;\n    return this.speedModels.get('normal') || 25;\n  }\n  calculate(distKm, hour) {\n    const speed = this.getSpeed(hour);\n    const minutes = (distKm / speed) * 60;\n    return { distKm, speedKmh: speed, etaMinutes: parseFloat(minutes.toFixed(1)) };\n  }\n}\n\nconst eta = new ETACalculator();\neta.setSpeedModel('morning_rush', 15);\neta.setSpeedModel('evening_rush', 12);\neta.setSpeedModel('night', 45);\neta.setSpeedModel('normal', 28);\n\nconsole.log('5km at 9am:', eta.calculate(5, 9));\nconsole.log('5km at 6pm:', eta.calculate(5, 18));\nconsole.log('5km at 2pm:', eta.calculate(5, 14));\nconsole.log('5km at 11pm:', eta.calculate(5, 23));",
              "output": "5km at 9am: { distKm: 5, speedKmh: 15, etaMinutes: 20 }\n5km at 6pm: { distKm: 5, speedKmh: 12, etaMinutes: 25 }\n5km at 2pm: { distKm: 5, speedKmh: 28, etaMinutes: 10.7 }\n5km at 11pm: { distKm: 5, speedKmh: 45, etaMinutes: 6.7 }"
            },
            {
              "question": "Program 7: Ride matching with batch optimization",
              "code": "class BatchMatcher {\n  constructor() { this.riders = []; this.drivers = []; }\n  addRider(id, lat, lng) { this.riders.push({ id, lat, lng }); }\n  addDriver(id, lat, lng) { this.drivers.push({ id, lat, lng }); }\n  distance(a, b) {\n    return parseFloat(Math.sqrt((a.lat-b.lat)**2 + (a.lng-b.lng)**2).toFixed(4));\n  }\n  // Greedy: assign nearest driver to each rider\n  matchGreedy() {\n    const available = new Set(this.drivers.map(d => d.id));\n    const matches = [];\n    const sortedRiders = [...this.riders];\n\n    for (const rider of sortedRiders) {\n      let best = null, bestDist = Infinity;\n      for (const driver of this.drivers) {\n        if (!available.has(driver.id)) continue;\n        const d = this.distance(rider, driver);\n        if (d < bestDist) { best = driver; bestDist = d; }\n      }\n      if (best) {\n        matches.push({ rider: rider.id, driver: best.id, distance: bestDist });\n        available.delete(best.id);\n      } else {\n        matches.push({ rider: rider.id, driver: null, distance: null });\n      }\n    }\n    const totalDist = matches.reduce((s, m) => s + (m.distance || 0), 0);\n    return { matches, totalDistance: parseFloat(totalDist.toFixed(4)) };\n  }\n}\n\nconst bm = new BatchMatcher();\nbm.addRider('R1', 0, 0); bm.addRider('R2', 1, 1); bm.addRider('R3', 2, 2);\nbm.addDriver('D1', 0.1, 0.1); bm.addDriver('D2', 1.9, 2.1);\nconsole.log(bm.matchGreedy());",
              "output": "{\n  matches: [\n    { rider: 'R1', driver: 'D1', distance: 0.1414 },\n    { rider: 'R2', driver: 'D2', distance: 1.3454 },\n    { rider: 'R3', driver: null, distance: null }\n  ],\n  totalDistance: 1.4868\n}"
            },
            {
              "question": "Program 8: Fare calculator with distance and time",
              "code": "class FareCalculator {\n  constructor(config) {\n    this.baseFare = config.baseFare;\n    this.perKm = config.perKm;\n    this.perMin = config.perMin;\n    this.minFare = config.minFare;\n    this.surgeCap = config.surgeCap || 5;\n  }\n  calculate(distKm, durationMin, surgeMultiplier = 1.0) {\n    const surge = Math.min(surgeMultiplier, this.surgeCap);\n    const distCharge = distKm * this.perKm;\n    const timeCharge = durationMin * this.perMin;\n    const subtotal = this.baseFare + distCharge + timeCharge;\n    const total = Math.max(subtotal * surge, this.minFare);\n    return {\n      breakdown: { base: this.baseFare, distance: parseFloat(distCharge.toFixed(2)), time: parseFloat(timeCharge.toFixed(2)) },\n      subtotal: parseFloat(subtotal.toFixed(2)),\n      surge,\n      total: parseFloat(total.toFixed(2)),\n    };\n  }\n}\n\nconst uber = new FareCalculator({ baseFare: 40, perKm: 12, perMin: 2, minFare: 50, surgeCap: 5 });\nconsole.log('Short trip:', uber.calculate(3, 10));\nconsole.log('Long trip:', uber.calculate(15, 40, 1.5));\nconsole.log('Surge trip:', uber.calculate(5, 15, 3.0));",
              "output": "Short trip: { breakdown: { base: 40, distance: 36, time: 20 }, subtotal: 96, surge: 1, total: 96 }\nLong trip: { breakdown: { base: 40, distance: 180, time: 80 }, subtotal: 300, surge: 1.5, total: 450 }\nSurge trip: { breakdown: { base: 40, distance: 60, time: 30 }, subtotal: 130, surge: 3, total: 390 }"
            },
            {
              "question": "Program 9: Ride-share pool matching",
              "code": "class PoolMatcher {\n  constructor(maxDetourRatio) { this.maxDetour = maxDetourRatio; this.activeTrips = []; }\n  dist(a, b) { return Math.sqrt((a.lat-b.lat)**2 + (a.lng-b.lng)**2); }\n  routeLength(points) {\n    let d = 0;\n    for (let i = 1; i < points.length; i++) d += this.dist(points[i-1], points[i]);\n    return d;\n  }\n  addTrip(id, pickup, dropoff) {\n    this.activeTrips.push({ id, pickup, dropoff, riders: [id] });\n  }\n  findPool(newPickup, newDropoff) {\n    for (const trip of this.activeTrips) {\n      const originalLen = this.dist(trip.pickup, trip.dropoff);\n      const detourLen = this.routeLength([trip.pickup, newPickup, newDropoff, trip.dropoff]);\n      const detourRatio = detourLen / originalLen - 1;\n      if (detourRatio <= this.maxDetour) {\n        return {\n          matched: true,\n          tripId: trip.id,\n          detour: (detourRatio * 100).toFixed(1) + '%',\n          originalRoute: parseFloat(originalLen.toFixed(2)),\n          newRoute: parseFloat(detourLen.toFixed(2)),\n        };\n      }\n    }\n    return { matched: false, reason: 'No suitable pool found' };\n  }\n}\n\nconst pm = new PoolMatcher(0.3); // max 30% detour\npm.addTrip('T1', { lat: 0, lng: 0 }, { lat: 10, lng: 0 }); // straight north\n\nconsole.log('Nearby rider:', pm.findPool({ lat: 2, lng: 1 }, { lat: 8, lng: 0 }));\nconsole.log('Far rider:', pm.findPool({ lat: 5, lng: 5 }, { lat: 8, lng: 8 }));",
              "output": "Nearby rider: { matched: true, tripId: 'T1', detour: '12.8%', originalRoute: 10, newRoute: 11.28 }\nFar rider: { matched: false, reason: 'No suitable pool found' }"
            },
            {
              "question": "Program 10: Driver rating and priority system",
              "code": "class DriverRating {\n  constructor() { this.drivers = new Map(); }\n  register(id) {\n    this.drivers.set(id, { id, ratings: [], acceptanceRate: 1.0, trips: 0, cancellations: 0 });\n  }\n  rate(driverId, rating) {\n    const d = this.drivers.get(driverId);\n    if (!d) return;\n    d.ratings.push(rating);\n    d.trips++;\n  }\n  cancel(driverId) {\n    const d = this.drivers.get(driverId);\n    if (!d) return;\n    d.cancellations++;\n    d.acceptanceRate = 1 - (d.cancellations / (d.trips + d.cancellations));\n  }\n  getScore(driverId) {\n    const d = this.drivers.get(driverId);\n    if (!d || d.ratings.length === 0) return null;\n    const avgRating = d.ratings.reduce((a,b) => a+b, 0) / d.ratings.length;\n    const priority = avgRating * 0.6 + d.acceptanceRate * 5 * 0.4;\n    return {\n      id: d.id,\n      avgRating: parseFloat(avgRating.toFixed(2)),\n      acceptanceRate: parseFloat(d.acceptanceRate.toFixed(2)),\n      trips: d.trips,\n      priorityScore: parseFloat(priority.toFixed(2)),\n    };\n  }\n  rankings() {\n    return [...this.drivers.keys()].map(id => this.getScore(id)).filter(Boolean).sort((a,b) => b.priorityScore - a.priorityScore);\n  }\n}\n\nconst dr = new DriverRating();\ndr.register('D1'); dr.register('D2'); dr.register('D3');\n// D1: great driver\n[5,5,4,5,5].forEach(r => dr.rate('D1', r));\n// D2: average with cancellations\n[4,3,4,3].forEach(r => dr.rate('D2', r));\ndr.cancel('D2'); dr.cancel('D2');\n// D3: new driver\n[5,4].forEach(r => dr.rate('D3', r));\n\nconsole.log(dr.rankings());",
              "output": "[\n  { id: 'D1', avgRating: 4.8, acceptanceRate: 1, priorityScore: 4.88 },\n  { id: 'D3', avgRating: 4.5, acceptanceRate: 1, priorityScore: 4.7 },\n  { id: 'D2', avgRating: 3.5, acceptanceRate: 0.67, priorityScore: 3.44 }\n]"
            }
          ]
        },
        {
          "id": "payment-system",
          "title": "Payment System Design",
          "category": "Company HLD",
          "description": "Design a payment processing system handling transactions, payment gateways, idempotency, reconciliation, fraud detection, and multi-currency support at scale.",
          "explanation": "A payment system handles the flow of money between buyers, sellers, and financial institutions. It must be correct (never lose money), available (process payments 24/7), and secure (PCI-DSS compliant).\n\n**Core Components**:\n1. **Payment Service (API)**: Entry point for payment requests. Validates, persists, orchestrates.\n2. **Payment Gateway**: Connects to external payment processors (Stripe, Razorpay, PayPal).\n3. **Ledger Service**: Double-entry bookkeeping — every debit has a matching credit.\n4. **Wallet Service**: Manages user balance, refunds, credits.\n5. **Reconciliation Service**: Matches internal records with bank/gateway settlements.\n6. **Fraud Detection**: ML-based risk scoring on every transaction.\n7. **Notification Service**: Payment confirmations, receipts, failure alerts.\n\n**Payment Flow (e-commerce)**:\n1. User clicks 'Pay' → POST /payments { orderId, amount, method, idempotencyKey }.\n2. Payment Service creates payment record (status: INITIATED). Stores idempotency key.\n3. Sends to Payment Gateway → gateway calls card network / UPI / bank.\n4. Gateway responds: SUCCESS / FAILURE / PENDING.\n5. If SUCCESS → update status to COMPLETED → debit buyer, credit seller in Ledger.\n6. If FAILURE → update status to FAILED → notify user.\n7. If PENDING → poll or wait for webhook callback.\n8. Return response to user.\n\n**Idempotency**:\n- Critical: if client retries (network timeout), payment must not be charged twice.\n- Client sends idempotency_key (UUID) with every request.\n- Server: check if idempotency_key exists in DB. If yes → return cached response.\n- If no → process payment → store result with idempotency_key.\n- Key retention: 24-72 hours.\n\n**Double-Entry Ledger**:\n- Every transaction creates 2 entries: DEBIT from one account + CREDIT to another.\n- Sum of all debits = Sum of all credits (always balanced).\n- Accounts: buyer_wallet, seller_wallet, platform_fees, taxes, gateway_fees.\n- Example: buyer pays ₹100 → debit buyer_wallet ₹100, credit seller_wallet ₹85, credit platform_fees ₹10, credit gateway_fees ₹5.\n\n**Reconciliation**:\n- Daily: compare internal ledger with gateway settlement reports.\n- Match: payment_id, amount, timestamp, status.\n- Discrepancies: missing transactions, amount mismatches, duplicate charges.\n- Auto-resolve where possible. Flag for manual review otherwise.",
          "code": "// Payment processing system simulation\nclass PaymentSystem {\n  constructor() {\n    this.payments = new Map();\n    this.idempotencyStore = new Map();\n    this.ledger = [];\n    this.wallets = new Map();\n    this.paymentCounter = 0;\n  }\n\n  createWallet(userId, balance = 0) {\n    this.wallets.set(userId, { userId, balance, createdAt: Date.now() });\n  }\n\n  getBalance(userId) {\n    return this.wallets.get(userId)?.balance ?? 0;\n  }\n\n  processPayment(request) {\n    const { buyerId, sellerId, amount, idempotencyKey } = request;\n    \n    // Idempotency check\n    if (this.idempotencyStore.has(idempotencyKey)) {\n      return { ...this.idempotencyStore.get(idempotencyKey), cached: true };\n    }\n\n    const paymentId = `pay_${++this.paymentCounter}`;\n    const buyer = this.wallets.get(buyerId);\n    const seller = this.wallets.get(sellerId);\n\n    if (!buyer || !seller) return { status: 'FAILED', error: 'Wallet not found' };\n    if (buyer.balance < amount) return { status: 'FAILED', error: 'Insufficient balance' };\n\n    // Platform fee (10%)\n    const platformFee = amount * 0.10;\n    const sellerAmount = amount - platformFee;\n\n    // Execute\n    buyer.balance -= amount;\n    seller.balance += sellerAmount;\n\n    // Double-entry ledger\n    this.ledger.push(\n      { paymentId, account: buyerId, type: 'DEBIT', amount, description: `Payment to ${sellerId}` },\n      { paymentId, account: sellerId, type: 'CREDIT', amount: sellerAmount, description: `Payment from ${buyerId}` },\n      { paymentId, account: 'PLATFORM', type: 'CREDIT', amount: platformFee, description: 'Platform fee' }\n    );\n\n    const result = {\n      paymentId,\n      status: 'COMPLETED',\n      amount,\n      platformFee: parseFloat(platformFee.toFixed(2)),\n      sellerReceives: parseFloat(sellerAmount.toFixed(2)),\n      buyerBalance: buyer.balance,\n    };\n\n    this.payments.set(paymentId, result);\n    this.idempotencyStore.set(idempotencyKey, result);\n    return result;\n  }\n\n  refund(paymentId) {\n    const payment = this.payments.get(paymentId);\n    if (!payment || payment.status !== 'COMPLETED') return { error: 'Cannot refund' };\n    payment.status = 'REFUNDED';\n    return { paymentId, status: 'REFUNDED', amount: payment.amount };\n  }\n\n  getLedger(account) {\n    return this.ledger.filter(e => e.account === account);\n  }\n}\n\nconst ps = new PaymentSystem();\nps.createWallet('buyer1', 1000);\nps.createWallet('seller1', 0);\n\nconsole.log(ps.processPayment({ buyerId: 'buyer1', sellerId: 'seller1', amount: 200, idempotencyKey: 'idem_1' }));\nconsole.log('Retry (idempotent):', ps.processPayment({ buyerId: 'buyer1', sellerId: 'seller1', amount: 200, idempotencyKey: 'idem_1' }));\nconsole.log('Buyer balance:', ps.getBalance('buyer1'));\nconsole.log('Seller balance:', ps.getBalance('seller1'));\nconsole.log('Ledger:', ps.getLedger('seller1'));",
          "example": "// Multi-currency payment with exchange rates\nclass MultiCurrencyPayment {\n  constructor() {\n    this.rates = {}; // from -> to -> rate\n  }\n  setRate(from, to, rate) {\n    if (!this.rates[from]) this.rates[from] = {};\n    this.rates[from][to] = rate;\n    // Inverse\n    if (!this.rates[to]) this.rates[to] = {};\n    this.rates[to][from] = 1 / rate;\n  }\n  convert(amount, from, to) {\n    if (from === to) return { amount, currency: to, rate: 1 };\n    const rate = this.rates[from]?.[to];\n    if (!rate) return { error: `No rate for ${from} to ${to}` };\n    return { amount: parseFloat((amount * rate).toFixed(2)), currency: to, rate };\n  }\n  processInternational(amount, fromCurrency, toCurrency, feePercent = 2.5) {\n    const converted = this.convert(amount, fromCurrency, toCurrency);\n    if (converted.error) return converted;\n    const fee = parseFloat((converted.amount * feePercent / 100).toFixed(2));\n    return {\n      original: { amount, currency: fromCurrency },\n      converted: { amount: converted.amount, currency: toCurrency },\n      rate: converted.rate,\n      fee,\n      total: parseFloat((converted.amount + fee).toFixed(2)),\n    };\n  }\n}\n\nconst mc = new MultiCurrencyPayment();\nmc.setRate('USD', 'INR', 83.5);\nmc.setRate('USD', 'EUR', 0.92);\nmc.setRate('INR', 'EUR', 0.011);\n\nconsole.log(mc.processInternational(100, 'USD', 'INR'));\nconsole.log(mc.processInternational(5000, 'INR', 'USD'));",
          "useCase": "E-commerce payments, subscription billing, peer-to-peer transfers, marketplace payouts, international remittance, in-app purchases, invoice payments.",
          "interviewQuestions": [
            {
              "question": "How do you ensure exactly-once payment processing?",
              "answer": "Idempotency key: client generates unique key per payment attempt. Server: check if key exists → if yes, return cached result. If no, process and store. Database: UNIQUE constraint on idempotency_key. At gateway level: use gateway's own idempotency mechanism. Combined: client idempotency key + server-side deduplication + gateway idempotency = exactly-once semantics."
            },
            {
              "question": "How does a double-entry ledger work?",
              "answer": "Every transaction creates balanced entries: total debits = total credits. Example: ₹100 payment. Debit: buyer's account ₹100. Credit: seller ₹85, platform ₹10, gateway ₹5. Total debit = 100, total credit = 100. Benefit: self-validating (sum check), complete audit trail, supports reconciliation. Schema: (entry_id, transaction_id, account_id, type: DEBIT|CREDIT, amount, timestamp)."
            },
            {
              "question": "How do you handle payment failures and retries?",
              "answer": "On failure: distinguish transient (timeout, 5xx) vs permanent (insufficient funds, invalid card). Transient: auto-retry with exponential backoff (max 3 retries). Permanent: mark FAILED, notify user. Timeout: payment might have succeeded at gateway — query gateway for status before retrying. Never blindly retry without checking current status. State machine: INITIATED → PROCESSING → COMPLETED/FAILED."
            },
            {
              "question": "How does reconciliation work?",
              "answer": "Daily batch: (1) Fetch settlement report from payment gateway. (2) Compare each settlement entry with internal ledger. (3) Match by gateway_transaction_id. (4) Classify: Matched, Missing internally, Missing at gateway, Amount mismatch. (5) Auto-resolve: missing settlements usually arrive next day. (6) Flag discrepancies for manual review. KPI: reconciliation rate should be >99.9%."
            },
            {
              "question": "How do you design fraud detection?",
              "answer": "Layers: (1) Rule-based: block known fraud patterns (velocity checks, geo-impossibility, large amounts from new accounts). (2) ML model: features = amount, time, device, location, merchant category, user history. Output: risk score 0-1. If >0.8: block. If 0.5-0.8: 2FA challenge. If <0.5: allow. (3) Real-time: score computed in <100ms during payment flow. (4) Batch: offline model retraining on labeled fraud data."
            },
            {
              "question": "How do you handle refunds?",
              "answer": "Full refund: reverse entire payment. Partial refund: reverse part of payment. Process: (1) Validate: original payment exists and is refundable. (2) Call gateway refund API with original transaction_id. (3) Ledger: debit seller, credit buyer. (4) Update payment status to REFUNDED. (5) Notify user. Timing: refunds can take 5-10 business days (bank processing). Store refund_id linked to original payment_id."
            },
            {
              "question": "How do you handle distributed transactions across services?",
              "answer": "Saga pattern: sequence of local transactions with compensating actions. Example: Order → Payment → Inventory. If Payment succeeds but Inventory fails → compensate by refunding payment. Implementation: orchestrator sends commands to each service in sequence. On failure: send compensating commands in reverse. Alternative: outbox pattern — write to DB + outbox table atomically, relay outbox events."
            },
            {
              "question": "How do you ensure PCI-DSS compliance?",
              "answer": "Never store raw card numbers in your database. Use tokenization: card number → token (via gateway). Store only token + last 4 digits + expiry. All card data in transit: HTTPS/TLS. Minimize scope: use hosted payment forms (Stripe.js, Razorpay checkout) — card data goes directly to gateway, never touches your server. Regular security audits. Access logging. Encryption at rest."
            },
            {
              "question": "How do you handle multi-currency payments?",
              "answer": "Store amounts in smallest unit (cents/paise) to avoid floating point issues. Exchange rates: real-time API (or cached for 5 min). Conversion at time of payment: lock rate for 15 min. Display: show amount in buyer's currency + converted amount. Settlement: settle in seller's currency. Ledger: record both currencies. FX fee: 1.5-3% on conversion."
            },
            {
              "question": "How do you design a subscription billing system?",
              "answer": "Components: Plan (price, interval, trial), Subscription (user, plan, status, next_billing_date), Invoice (generated per billing cycle). Flow: cron job runs daily → find subscriptions where next_billing_date = today → create invoice → attempt payment. If success: extend subscription. If failure: retry 3 times over 7 days (dunning). If all fail: cancel subscription. Proration: when user upgrades mid-cycle."
            }
          ],
          "exercises": [
            {
              "type": "estimation",
              "question": "Payment platform: 10M transactions/day. Average transaction: 3KB event. Estimate storage and throughput.",
              "answer": "Daily: 10M × 3KB = 30GB/day. Monthly: 900GB. Yearly: 10.8TB (need archival after 90 days). QPS: 10M / 86400 ≈ 116 TPS. Peak (3x): 348 TPS. Ledger entries: 2-4x transactions (double-entry) = 20-40M entries/day. Not enormous — single PostgreSQL handles this. Add read replicas for queries."
            },
            {
              "type": "design",
              "question": "Design the payment state machine.",
              "answer": "States: CREATED → PROCESSING → AUTHORIZED → CAPTURED → COMPLETED → (REFUND_INITIATED → REFUNDED). Failure states: FAILED (terminal), TIMED_OUT (retriable). Transitions: CREATED → PROCESSING (sent to gateway). PROCESSING → AUTHORIZED (gateway confirms hold). AUTHORIZED → CAPTURED (actual charge). For 2-step: authorize now, capture later (e.g., hold on booking, charge on checkout). Each transition logged with timestamp."
            },
            {
              "type": "scenario",
              "question": "Payment gateway timeout after 30 seconds. Money may or may not have been charged. What do you do?",
              "answer": "1) Do NOT retry blindly (may double-charge). 2) Query gateway: GET /payments/{gateway_txn_id}/status. 3) If gateway says SUCCESS → mark COMPLETED. 4) If gateway says NOT_FOUND → safe to retry (money not charged). 5) If gateway is also timing out → mark PENDING in our DB. 6) Background job: poll gateway every 5 min for PENDING payments. 7) After 24 hours: if still unknown → escalate for manual reconciliation."
            },
            {
              "type": "tricky",
              "question": "Why use Event Sourcing for payments instead of simple CRUD?",
              "answer": "Payments are financial records — you should NEVER update or delete. Event sourcing: store every state change as an immutable event. (PaymentCreated, PaymentProcessing, PaymentCompleted, RefundInitiated). Benefits: (1) Complete audit trail. (2) Can replay events to rebuild state. (3) Debugging: see exactly what happened. (4) Compliance: regulators want full history. (5) Reconciliation: compare event stream with gateway. CRUD loses intermediate states."
            },
            {
              "type": "design",
              "question": "Design the settlement system for a marketplace.",
              "answer": "After buyer pays: money goes to escrow (platform holds). Settlement triggers: (1) Delivery confirmed (e-commerce). (2) Service completed (ride-hailing). (3) Time-based (7 days after order). Settlement: deduct platform commission → transfer to seller. Batch: nightly settlement run. For each seller: sum completed orders → create payout. Payout via bank transfer (NEFT/IMPS). Track payout status: PENDING → PROCESSING → SETTLED."
            },
            {
              "type": "estimation",
              "question": "Razorpay processes 40K TPS peak. Each transaction needs 5ms of DB time. How many DB connections needed?",
              "answer": "Required: 40K TPS × 5ms = 200 seconds of DB time per second. So need 200 concurrent DB connections (if serialized). With connection pooling (PgBouncer): 200 pool connections can serve 40K TPS at 5ms each. DB servers: 2-3 PostgreSQL instances with connection pooling. Read replicas for queries. Write primary for transactions."
            },
            {
              "type": "debug",
              "question": "Users report being charged twice for same order. How to investigate and fix?",
              "answer": "Investigate: (1) Check idempotency_key — did client send same key? If different keys → client bug (retried with new key). (2) Check gateway: does gateway show 2 charges? If yes → we sent 2 requests. (3) Check timing: race condition — 2 requests processed before idempotency check. Fix: (1) Use DB unique constraint on idempotency_key (atomic). (2) Distributed lock before processing. (3) For the duplicate charge: auto-refund via reconciliation."
            },
            {
              "type": "design",
              "question": "Design a wallet system with top-up and spend.",
              "answer": "Tables: wallet(user_id PK, balance, currency). wallet_transactions(id, wallet_id, type: CREDIT|DEBIT, amount, ref_id, created_at). Top-up: verify bank transfer → credit wallet. Spend: check balance → debit wallet. Atomicity: use DB transaction with SELECT FOR UPDATE (pessimistic lock) or optimistic lock (version column). Balance check + debit must be atomic to prevent overdraft."
            },
            {
              "type": "scenario",
              "question": "Black Friday: payment volume spikes 10x. How does the system handle it?",
              "answer": "1) Pre-scale: add more payment service instances based on predicted load. 2) Queue: async processing via Kafka — smooth out spikes. 3) Circuit breaker: if gateway is overwhelmed, fail fast instead of timeout. 4) Fallback gateway: route to secondary gateway if primary is slow. 5) Rate limit: cap at maximum safe TPS per gateway. 6) Priority: process high-value orders first. 7) Cache: cache exchange rates, merchant configs."
            },
            {
              "type": "output",
              "question": "Buyer pays ₹1000. Platform fee: 10%. Gateway fee: 2%. Tax on platform fee: 18% GST. What does seller receive?",
              "answer": "Total: ₹1000. Gateway fee: ₹1000 × 2% = ₹20. Net after gateway: ₹980. Platform fee: ₹980 × 10% = ₹98. GST on platform fee: ₹98 × 18% = ₹17.64. Seller receives: ₹980 - ₹98 = ₹882. Ledger: Debit buyer ₹1000. Credit gateway_account ₹20. Credit platform_revenue ₹98. Credit tax_account ₹17.64 (from platform revenue). Credit seller ₹882. Total credits = 1000 ✓"
            }
          ],
          "programExercises": [
            {
              "question": "Program 1: Idempotent payment processor",
              "code": "class IdempotentPayments {\n  constructor() { this.store = new Map(); this.payments = []; }\n  process(idempotencyKey, amount, from, to) {\n    if (this.store.has(idempotencyKey)) {\n      return { ...this.store.get(idempotencyKey), idempotent: true };\n    }\n    const payment = {\n      id: `pay_${this.payments.length + 1}`,\n      amount, from, to,\n      status: 'COMPLETED',\n      processedAt: Date.now(),\n    };\n    this.payments.push(payment);\n    this.store.set(idempotencyKey, payment);\n    return { ...payment, idempotent: false };\n  }\n}\n\nconst ip = new IdempotentPayments();\nconsole.log(ip.process('key_1', 100, 'alice', 'bob'));\nconsole.log(ip.process('key_1', 100, 'alice', 'bob')); // duplicate\nconsole.log(ip.process('key_2', 200, 'alice', 'carol'));\nconsole.log('Total payments:', ip.payments.length);",
              "output": "{ id: 'pay_1', amount: 100, from: 'alice', to: 'bob', status: 'COMPLETED', ..., idempotent: false }\n{ id: 'pay_1', amount: 100, from: 'alice', to: 'bob', status: 'COMPLETED', ..., idempotent: true }\n{ id: 'pay_2', amount: 200, from: 'alice', to: 'carol', status: 'COMPLETED', ..., idempotent: false }\nTotal payments: 2"
            },
            {
              "question": "Program 2: Double-entry ledger",
              "code": "class Ledger {\n  constructor() { this.entries = []; }\n  record(txnId, debits, credits) {\n    const totalDebit = debits.reduce((s, d) => s + d.amount, 0);\n    const totalCredit = credits.reduce((s, c) => s + c.amount, 0);\n    if (Math.abs(totalDebit - totalCredit) > 0.001) {\n      return { error: 'Unbalanced!', debit: totalDebit, credit: totalCredit };\n    }\n    debits.forEach(d => this.entries.push({ txnId, account: d.account, type: 'DEBIT', amount: d.amount }));\n    credits.forEach(c => this.entries.push({ txnId, account: c.account, type: 'CREDIT', amount: c.amount }));\n    return { txnId, entries: debits.length + credits.length, balanced: true };\n  }\n  balance(account) {\n    let credits = 0, debits = 0;\n    this.entries.filter(e => e.account === account).forEach(e => {\n      if (e.type === 'CREDIT') credits += e.amount;\n      else debits += e.amount;\n    });\n    return { account, credits, debits, net: credits - debits };\n  }\n  verify() {\n    let totalDebits = 0, totalCredits = 0;\n    this.entries.forEach(e => {\n      if (e.type === 'DEBIT') totalDebits += e.amount;\n      else totalCredits += e.amount;\n    });\n    return { totalDebits, totalCredits, balanced: Math.abs(totalDebits - totalCredits) < 0.001 };\n  }\n}\n\nconst l = new Ledger();\nconsole.log(l.record('txn1',\n  [{ account: 'buyer', amount: 100 }],\n  [{ account: 'seller', amount: 85 }, { account: 'platform', amount: 15 }]\n));\nconsole.log(l.balance('buyer'));\nconsole.log(l.balance('seller'));\nconsole.log(l.verify());",
              "output": "{ txnId: 'txn1', entries: 3, balanced: true }\n{ account: 'buyer', credits: 0, debits: 100, net: -100 }\n{ account: 'seller', credits: 85, debits: 0, net: 85 }\n{ totalDebits: 100, totalCredits: 100, balanced: true }"
            },
            {
              "question": "Program 3: Payment state machine",
              "code": "class PaymentStateMachine {\n  constructor() {\n    this.states = {\n      CREATED: ['PROCESSING'],\n      PROCESSING: ['AUTHORIZED', 'FAILED'],\n      AUTHORIZED: ['CAPTURED', 'VOIDED'],\n      CAPTURED: ['COMPLETED'],\n      COMPLETED: ['REFUND_INITIATED'],\n      REFUND_INITIATED: ['REFUNDED'],\n      FAILED: [],\n      VOIDED: [],\n      REFUNDED: [],\n    };\n    this.payments = new Map();\n  }\n  create(id) {\n    this.payments.set(id, { id, state: 'CREATED', history: ['CREATED'] });\n    return { id, state: 'CREATED' };\n  }\n  transition(id, to) {\n    const p = this.payments.get(id);\n    if (!p) return { error: 'Not found' };\n    if (!this.states[p.state]?.includes(to)) {\n      return { error: `Invalid: ${p.state} → ${to}` };\n    }\n    p.state = to;\n    p.history.push(to);\n    return { id, state: to, steps: p.history.length };\n  }\n  getHistory(id) {\n    return this.payments.get(id)?.history || [];\n  }\n}\n\nconst psm = new PaymentStateMachine();\npsm.create('P1');\nconsole.log(psm.transition('P1', 'PROCESSING'));\nconsole.log(psm.transition('P1', 'AUTHORIZED'));\nconsole.log(psm.transition('P1', 'COMPLETED')); // invalid!\nconsole.log(psm.transition('P1', 'CAPTURED'));\nconsole.log(psm.transition('P1', 'COMPLETED'));\nconsole.log('History:', psm.getHistory('P1'));",
              "output": "{ id: 'P1', state: 'PROCESSING', steps: 2 }\n{ id: 'P1', state: 'AUTHORIZED', steps: 3 }\n{ error: 'Invalid: AUTHORIZED → COMPLETED' }\n{ id: 'P1', state: 'CAPTURED', steps: 4 }\n{ id: 'P1', state: 'COMPLETED', steps: 5 }\nHistory: [ 'CREATED', 'PROCESSING', 'AUTHORIZED', 'CAPTURED', 'COMPLETED' ]"
            },
            {
              "question": "Program 4: Wallet with atomic operations",
              "code": "class Wallet {\n  constructor() { this.accounts = new Map(); this.txLog = []; }\n  create(userId, balance = 0) {\n    this.accounts.set(userId, { userId, balance, version: 0 });\n  }\n  topUp(userId, amount) {\n    const acc = this.accounts.get(userId);\n    if (!acc) return { error: 'Account not found' };\n    acc.balance += amount;\n    acc.version++;\n    this.txLog.push({ type: 'TOP_UP', userId, amount, balance: acc.balance });\n    return { userId, newBalance: acc.balance };\n  }\n  transfer(from, to, amount) {\n    const sender = this.accounts.get(from);\n    const receiver = this.accounts.get(to);\n    if (!sender || !receiver) return { error: 'Account not found' };\n    if (sender.balance < amount) return { error: 'Insufficient balance' };\n    // Atomic: debit + credit\n    sender.balance -= amount;\n    receiver.balance += amount;\n    sender.version++;\n    receiver.version++;\n    this.txLog.push({ type: 'TRANSFER', from, to, amount });\n    return { from: { id: from, balance: sender.balance }, to: { id: to, balance: receiver.balance } };\n  }\n  getBalance(userId) {\n    return this.accounts.get(userId)?.balance ?? null;\n  }\n}\n\nconst w = new Wallet();\nw.create('alice', 500);\nw.create('bob', 200);\nconsole.log(w.topUp('alice', 100));\nconsole.log(w.transfer('alice', 'bob', 300));\nconsole.log(w.transfer('alice', 'bob', 400)); // insufficient\nconsole.log('Alice:', w.getBalance('alice'), 'Bob:', w.getBalance('bob'));",
              "output": "{ userId: 'alice', newBalance: 600 }\n{ from: { id: 'alice', balance: 300 }, to: { id: 'bob', balance: 500 } }\n{ error: 'Insufficient balance' }\nAlice: 300 Bob: 500"
            },
            {
              "question": "Program 5: Reconciliation engine",
              "code": "class ReconciliationEngine {\n  reconcile(internal, gateway) {\n    const internalMap = new Map(internal.map(t => [t.id, t]));\n    const gatewayMap = new Map(gateway.map(t => [t.id, t]));\n    const matched = [], missingInGateway = [], missingInInternal = [], mismatched = [];\n\n    for (const [id, t] of internalMap) {\n      const g = gatewayMap.get(id);\n      if (!g) { missingInGateway.push(t); continue; }\n      if (t.amount !== g.amount || t.status !== g.status) {\n        mismatched.push({ id, internal: t, gateway: g });\n      } else {\n        matched.push(id);\n      }\n    }\n    for (const [id] of gatewayMap) {\n      if (!internalMap.has(id)) missingInInternal.push(gatewayMap.get(id));\n    }\n\n    return {\n      matched: matched.length,\n      missingInGateway: missingInGateway.length,\n      missingInInternal: missingInInternal.length,\n      mismatched: mismatched.length,\n      rate: (matched.length / internal.length * 100).toFixed(1) + '%',\n      issues: [...missingInGateway.map(t => `Missing at gateway: ${t.id}`),\n               ...missingInInternal.map(t => `Missing internally: ${t.id}`),\n               ...mismatched.map(m => `Mismatch: ${m.id} (internal: ${m.internal.amount}, gateway: ${m.gateway.amount})`),\n      ],\n    };\n  }\n}\n\nconst re = new ReconciliationEngine();\nconsole.log(re.reconcile(\n  [\n    { id: 'T1', amount: 100, status: 'COMPLETED' },\n    { id: 'T2', amount: 200, status: 'COMPLETED' },\n    { id: 'T3', amount: 300, status: 'COMPLETED' },\n    { id: 'T4', amount: 150, status: 'COMPLETED' },\n  ],\n  [\n    { id: 'T1', amount: 100, status: 'COMPLETED' },\n    { id: 'T2', amount: 210, status: 'COMPLETED' }, // mismatch\n    { id: 'T5', amount: 500, status: 'COMPLETED' }, // extra\n  ]\n));",
              "output": "{\n  matched: 1,\n  missingInGateway: 2,\n  missingInInternal: 1,\n  mismatched: 1,\n  rate: '25.0%',\n  issues: [\n    'Missing at gateway: T3',\n    'Missing at gateway: T4',\n    'Missing internally: T5',\n    'Mismatch: T2 (internal: 200, gateway: 210)'\n  ]\n}"
            },
            {
              "question": "Program 6: Fraud rule engine",
              "code": "class FraudRuleEngine {\n  constructor() { this.rules = []; this.history = new Map(); }\n  addRule(name, check) { this.rules.push({ name, check }); }\n  recordTransaction(userId, amount) {\n    if (!this.history.has(userId)) this.history.set(userId, []);\n    this.history.get(userId).push({ amount, time: Date.now() });\n  }\n  evaluate(transaction) {\n    const violations = [];\n    for (const rule of this.rules) {\n      const result = rule.check(transaction, this.history);\n      if (result) violations.push({ rule: rule.name, detail: result });\n    }\n    const riskScore = Math.min(violations.length / this.rules.length, 1.0);\n    return {\n      transaction: transaction.id,\n      violations,\n      riskScore: parseFloat(riskScore.toFixed(2)),\n      action: riskScore > 0.6 ? 'BLOCK' : riskScore > 0.3 ? 'REVIEW' : 'ALLOW',\n    };\n  }\n}\n\nconst fre = new FraudRuleEngine();\nfre.addRule('high_amount', (t) => t.amount > 50000 ? `Amount ${t.amount} exceeds 50000` : null);\nfre.addRule('velocity', (t, h) => {\n  const recent = (h.get(t.userId) || []).filter(x => Date.now() - x.time < 3600000);\n  return recent.length >= 5 ? `${recent.length} transactions in 1 hour` : null;\n});\nfre.addRule('new_account', (t) => t.accountAge < 24 ? `Account age: ${t.accountAge}h` : null);\n\n// Record some history\nfor (let i = 0; i < 6; i++) fre.recordTransaction('user1', 100);\n\nconsole.log(fre.evaluate({ id: 'T1', userId: 'user1', amount: 100, accountAge: 48 }));\nconsole.log(fre.evaluate({ id: 'T2', userId: 'user2', amount: 75000, accountAge: 2 }));",
              "output": "{\n  transaction: 'T1',\n  violations: [ { rule: 'velocity', detail: '6 transactions in 1 hour' } ],\n  riskScore: 0.33,\n  action: 'REVIEW'\n}\n{\n  transaction: 'T2',\n  violations: [\n    { rule: 'high_amount', detail: 'Amount 75000 exceeds 50000' },\n    { rule: 'new_account', detail: 'Account age: 2h' }\n  ],\n  riskScore: 0.67,\n  action: 'BLOCK'\n}"
            },
            {
              "question": "Program 7: Subscription billing engine",
              "code": "class SubscriptionBilling {\n  constructor() { this.subs = new Map(); this.invoices = []; }\n  subscribe(userId, plan, startDate) {\n    this.subs.set(userId, {\n      userId, plan, status: 'ACTIVE',\n      startDate, nextBilling: new Date(startDate.getTime() + 30 * 86400000),\n      failedAttempts: 0,\n    });\n  }\n  runBilling(today) {\n    const results = [];\n    for (const [userId, sub] of this.subs) {\n      if (sub.status !== 'ACTIVE' || sub.nextBilling > today) continue;\n      const success = Math.random() > 0.2; // 80% success rate\n      if (success) {\n        sub.nextBilling = new Date(today.getTime() + 30 * 86400000);\n        sub.failedAttempts = 0;\n        this.invoices.push({ userId, amount: sub.plan.price, status: 'PAID', date: today });\n        results.push({ userId, status: 'PAID', nextBilling: sub.nextBilling.toISOString().split('T')[0] });\n      } else {\n        sub.failedAttempts++;\n        if (sub.failedAttempts >= 3) {\n          sub.status = 'CANCELLED';\n          results.push({ userId, status: 'CANCELLED', reason: 'Max retries exceeded' });\n        } else {\n          results.push({ userId, status: 'RETRY', attempt: sub.failedAttempts });\n        }\n      }\n    }\n    return results;\n  }\n}\n\nconst sb = new SubscriptionBilling();\nconst start = new Date('2024-01-01');\nsb.subscribe('alice', { name: 'Pro', price: 499 }, start);\nsb.subscribe('bob', { name: 'Basic', price: 199 }, start);\n\n// Simulate billing day (Feb 1)\nconst billingDay = new Date('2024-01-31');\nconsole.log('Billing results:', sb.runBilling(billingDay));",
              "output": "Billing results: [\n  { userId: 'alice', status: 'PAID', nextBilling: '2024-03-01' },\n  { userId: 'bob', status: 'PAID', nextBilling: '2024-03-01' }\n]"
            },
            {
              "question": "Program 8: Exchange rate converter",
              "code": "class ExchangeRates {\n  constructor() { this.rates = new Map(); }\n  setRate(from, to, rate) {\n    this.rates.set(`${from}:${to}`, rate);\n    this.rates.set(`${to}:${from}`, 1 / rate);\n  }\n  convert(amount, from, to) {\n    if (from === to) return { amount, from, to, rate: 1 };\n    const rate = this.rates.get(`${from}:${to}`);\n    if (!rate) return { error: `No rate: ${from} → ${to}` };\n    return {\n      original: { amount, currency: from },\n      converted: { amount: parseFloat((amount * rate).toFixed(2)), currency: to },\n      rate: parseFloat(rate.toFixed(4)),\n    };\n  }\n}\n\nconst fx = new ExchangeRates();\nfx.setRate('USD', 'INR', 83.5);\nfx.setRate('USD', 'EUR', 0.92);\nfx.setRate('GBP', 'USD', 1.27);\n\nconsole.log(fx.convert(100, 'USD', 'INR'));\nconsole.log(fx.convert(5000, 'INR', 'USD'));\nconsole.log(fx.convert(50, 'GBP', 'USD'));\nconsole.log(fx.convert(100, 'INR', 'GBP')); // no direct rate",
              "output": "{\n  original: { amount: 100, currency: 'USD' },\n  converted: { amount: 8350, currency: 'INR' },\n  rate: 83.5\n}\n{\n  original: { amount: 5000, currency: 'INR' },\n  converted: { amount: 59.88, currency: 'USD' },\n  rate: 0.012\n}\n{\n  original: { amount: 50, currency: 'GBP' },\n  converted: { amount: 63.5, currency: 'USD' },\n  rate: 1.27\n}\n{ error: 'No rate: INR → GBP' }"
            },
            {
              "question": "Program 9: Payment retry with exponential backoff",
              "code": "class PaymentRetry {\n  constructor(maxRetries) { this.maxRetries = maxRetries; this.log = []; }\n  process(paymentId, simulateFailures = 0) {\n    let attempt = 0;\n    let failCount = 0;\n    while (attempt <= this.maxRetries) {\n      attempt++;\n      const delay = attempt === 1 ? 0 : Math.pow(2, attempt - 1) * 1000;\n      \n      if (failCount < simulateFailures) {\n        failCount++;\n        this.log.push({ paymentId, attempt, delay: `${delay}ms`, result: 'FAILED' });\n        continue;\n      }\n      \n      this.log.push({ paymentId, attempt, delay: `${delay}ms`, result: 'SUCCESS' });\n      return { paymentId, status: 'COMPLETED', attempts: attempt };\n    }\n    return { paymentId, status: 'DEAD_LETTER', attempts: attempt - 1 };\n  }\n}\n\nconst pr = new PaymentRetry(3);\nconsole.log(pr.process('P1', 0));  // succeeds first time\nconsole.log(pr.process('P2', 2));  // fails twice, succeeds third\nconsole.log(pr.process('P3', 5));  // always fails\nconsole.log('Log:', pr.log);",
              "output": "{ paymentId: 'P1', status: 'COMPLETED', attempts: 1 }\n{ paymentId: 'P2', status: 'COMPLETED', attempts: 3 }\n{ paymentId: 'P3', status: 'DEAD_LETTER', attempts: 3 }\nLog: [\n  { paymentId: 'P1', attempt: 1, delay: '0ms', result: 'SUCCESS' },\n  { paymentId: 'P2', attempt: 1, delay: '0ms', result: 'FAILED' },\n  { paymentId: 'P2', attempt: 2, delay: '2000ms', result: 'FAILED' },\n  { paymentId: 'P2', attempt: 3, delay: '4000ms', result: 'SUCCESS' },\n  { paymentId: 'P3', attempt: 1, delay: '0ms', result: 'FAILED' },\n  { paymentId: 'P3', attempt: 2, delay: '2000ms', result: 'FAILED' },\n  { paymentId: 'P3', attempt: 3, delay: '4000ms', result: 'FAILED' }\n]"
            },
            {
              "question": "Program 10: Payment analytics dashboard",
              "code": "class PaymentAnalytics {\n  constructor() { this.transactions = []; }\n  record(tx) { this.transactions.push(tx); }\n  summary() {\n    const total = this.transactions.length;\n    const completed = this.transactions.filter(t => t.status === 'COMPLETED');\n    const failed = this.transactions.filter(t => t.status === 'FAILED');\n    const refunded = this.transactions.filter(t => t.status === 'REFUNDED');\n    const volume = completed.reduce((s, t) => s + t.amount, 0);\n    const avgTx = completed.length ? volume / completed.length : 0;\n    const byMethod = {};\n    completed.forEach(t => { byMethod[t.method] = (byMethod[t.method] || 0) + t.amount; });\n    return {\n      totalTransactions: total,\n      completed: completed.length,\n      failed: failed.length,\n      refunded: refunded.length,\n      successRate: (completed.length / total * 100).toFixed(1) + '%',\n      totalVolume: volume,\n      avgTransaction: parseFloat(avgTx.toFixed(2)),\n      byMethod,\n    };\n  }\n}\n\nconst pa = new PaymentAnalytics();\npa.record({ id: 1, amount: 500, status: 'COMPLETED', method: 'UPI' });\npa.record({ id: 2, amount: 1200, status: 'COMPLETED', method: 'card' });\npa.record({ id: 3, amount: 300, status: 'FAILED', method: 'UPI' });\npa.record({ id: 4, amount: 800, status: 'COMPLETED', method: 'UPI' });\npa.record({ id: 5, amount: 1500, status: 'COMPLETED', method: 'card' });\npa.record({ id: 6, amount: 200, status: 'REFUNDED', method: 'UPI' });\n\nconsole.log(pa.summary());",
              "output": "{\n  totalTransactions: 6,\n  completed: 4,\n  failed: 1,\n  refunded: 1,\n  successRate: '66.7%',\n  totalVolume: 4000,\n  avgTransaction: 1000,\n  byMethod: { UPI: 1300, card: 2700 }\n}"
            }
          ]
        }
      ],
      "quiz": [
        {
          "question": "What is the first step in a system design interview?",
          "options": [
            "Jump into component design",
            "Write code immediately",
            "Clarify requirements and ask questions",
            "Draw the database schema"
          ],
          "correctAnswer": 2,
          "explanation": "Always start by clarifying functional and non-functional requirements. Ask about users, scale, latency, and constraints before designing."
        },
        {
          "question": "In capacity estimation, if a system handles 10M DAU and each user makes 5 requests/day, what is the average QPS?",
          "options": [
            "578",
            "5000",
            "50000",
            "115"
          ],
          "correctAnswer": 0,
          "explanation": "QPS = 10M × 5 / 86400 ≈ 578 requests per second. 86400 is the number of seconds in a day."
        },
        {
          "question": "What does the CAP theorem state?",
          "options": [
            "A system can have Consistency, Availability, and Partition tolerance simultaneously",
            "A distributed system can only guarantee two of three: Consistency, Availability, Partition tolerance",
            "Caching Always Performs better than databases",
            "Clusters Are Partitioned by default"
          ],
          "correctAnswer": 1,
          "explanation": "CAP theorem states that in a distributed system experiencing network partition, you must choose between consistency and availability."
        },
        {
          "question": "Which load balancing algorithm distributes requests to the server with the fewest active connections?",
          "options": [
            "Round Robin",
            "Weighted Round Robin",
            "Least Connections",
            "IP Hash"
          ],
          "correctAnswer": 2,
          "explanation": "Least Connections sends each new request to the server with the fewest active connections, ideal for varying request durations."
        },
        {
          "question": "What is the primary purpose of a reverse proxy?",
          "options": [
            "Encrypt data at rest",
            "Sit in front of servers to handle client requests",
            "Store session data",
            "Compress database queries"
          ],
          "correctAnswer": 1,
          "explanation": "A reverse proxy sits between clients and backend servers, handling load balancing, SSL termination, caching, and security."
        },
        {
          "question": "In a cache-aside (lazy loading) pattern, what happens on a cache miss?",
          "options": [
            "Return null to the client",
            "Application reads from DB, then writes to cache",
            "Cache automatically fetches from DB",
            "Request is queued for later"
          ],
          "correctAnswer": 1,
          "explanation": "In cache-aside, on a miss the application reads from the database and then populates the cache before returning the result."
        },
        {
          "question": "What is the main disadvantage of write-through caching?",
          "options": [
            "Data loss on cache failure",
            "Stale data",
            "Higher write latency",
            "Complex invalidation"
          ],
          "correctAnswer": 2,
          "explanation": "Write-through writes to both cache and DB synchronously, increasing write latency but ensuring consistency."
        },
        {
          "question": "Which caching eviction policy removes the item that hasn't been used for the longest time?",
          "options": [
            "FIFO",
            "LRU",
            "LFU",
            "Random"
          ],
          "correctAnswer": 1,
          "explanation": "LRU (Least Recently Used) evicts the item accessed least recently, which is the most commonly used eviction strategy."
        },
        {
          "question": "What is a cache stampede?",
          "options": [
            "When cache memory is full",
            "When many requests hit the DB simultaneously after a popular cache key expires",
            "When cache becomes the bottleneck",
            "When cache data is corrupted"
          ],
          "correctAnswer": 1,
          "explanation": "A cache stampede occurs when a popular key expires and many concurrent requests all miss the cache, overwhelming the database."
        },
        {
          "question": "What is horizontal sharding?",
          "options": [
            "Splitting a table by columns",
            "Adding more columns to a table",
            "Splitting rows across multiple databases based on a shard key",
            "Creating read replicas"
          ],
          "correctAnswer": 2,
          "explanation": "Horizontal sharding distributes rows across multiple database instances based on a shard key (e.g., user_id % num_shards)."
        },
        {
          "question": "What is the main challenge with range-based sharding?",
          "options": [
            "Complex implementation",
            "Hotspots - uneven data distribution",
            "Inability to query by shard key",
            "High memory usage"
          ],
          "correctAnswer": 1,
          "explanation": "Range-based sharding can create hotspots. For example, sharding by date puts all recent writes on one shard."
        },
        {
          "question": "What problem does consistent hashing solve?",
          "options": [
            "SQL injection attacks",
            "Minimizing data movement when nodes are added/removed",
            "Encrypting data in transit",
            "Improving query performance"
          ],
          "correctAnswer": 1,
          "explanation": "Consistent hashing minimizes the number of keys that need to be remapped when nodes join or leave the ring, typically only K/N keys."
        },
        {
          "question": "In consistent hashing, what are virtual nodes used for?",
          "options": [
            "Backup servers",
            "Better load distribution across physical nodes",
            "Caching layer",
            "DNS resolution"
          ],
          "correctAnswer": 1,
          "explanation": "Virtual nodes map each physical node to multiple positions on the hash ring, ensuring more even key distribution."
        },
        {
          "question": "What is the primary advantage of message queues in system design?",
          "options": [
            "They make systems faster",
            "They decouple producers from consumers",
            "They reduce storage costs",
            "They eliminate the need for databases"
          ],
          "correctAnswer": 1,
          "explanation": "Message queues decouple producers and consumers, enabling asynchronous processing, resilience to failures, and independent scaling."
        },
        {
          "question": "In Kafka, what is a consumer group?",
          "options": [
            "A group of Kafka brokers",
            "Multiple consumers sharing the work of consuming from topic partitions",
            "A set of related topics",
            "A replication strategy"
          ],
          "correctAnswer": 1,
          "explanation": "A consumer group is a set of consumers that cooperatively consume from topic partitions. Each partition is consumed by exactly one consumer in the group."
        },
        {
          "question": "What is the token bucket algorithm used for?",
          "options": [
            "Authentication",
            "Rate limiting",
            "Load balancing",
            "Data encryption"
          ],
          "correctAnswer": 1,
          "explanation": "Token bucket is a rate limiting algorithm. Tokens are added at a fixed rate. Each request consumes a token. If no tokens, request is rejected."
        },
        {
          "question": "What is the difference between rate limiting and throttling?",
          "options": [
            "They are the same thing",
            "Rate limiting rejects excess, throttling queues/slows excess",
            "Rate limiting is client-side, throttling is server-side",
            "Throttling is always faster"
          ],
          "correctAnswer": 1,
          "explanation": "Rate limiting hard-rejects requests over the limit (429 error). Throttling slows down or queues excess requests instead of rejecting."
        },
        {
          "question": "Which HTTP status code indicates rate limiting?",
          "options": [
            "401 Unauthorized",
            "403 Forbidden",
            "429 Too Many Requests",
            "503 Service Unavailable"
          ],
          "correctAnswer": 2,
          "explanation": "429 Too Many Requests is the standard HTTP status code indicating the client has sent too many requests in a given time window."
        },
        {
          "question": "What is REST's main architectural constraint?",
          "options": [
            "Stateful connections",
            "Statelessness - each request contains all needed information",
            "Binary protocol",
            "Single endpoint for all operations"
          ],
          "correctAnswer": 1,
          "explanation": "REST is stateless: each request from client to server must contain all information needed to process it. The server stores no session state."
        },
        {
          "question": "When should you prefer GraphQL over REST?",
          "options": [
            "For simple CRUD operations",
            "When clients need flexible, nested data fetching to avoid over/under-fetching",
            "For real-time streaming",
            "For file uploads"
          ],
          "correctAnswer": 1,
          "explanation": "GraphQL excels when clients need to fetch exactly the data they need, especially with nested/related resources, avoiding multiple REST calls."
        },
        {
          "question": "What is API versioning and why is it important?",
          "options": [
            "It's optional and rarely needed",
            "It allows evolving APIs without breaking existing clients",
            "It speeds up API responses",
            "It's only needed for GraphQL"
          ],
          "correctAnswer": 1,
          "explanation": "API versioning (e.g., /v1/users, /v2/users) allows introducing breaking changes while maintaining backward compatibility for existing clients."
        },
        {
          "question": "What is the key benefit of microservices over monoliths?",
          "options": [
            "Always faster performance",
            "Independent deployment and scaling of services",
            "Simpler debugging",
            "Lower operational costs"
          ],
          "correctAnswer": 1,
          "explanation": "Microservices allow each service to be deployed, scaled, and updated independently. Trade-off: increased operational complexity."
        },
        {
          "question": "What is the Circuit Breaker pattern?",
          "options": [
            "A hardware protection device",
            "Prevents cascading failures by stopping calls to a failing service",
            "A database optimization technique",
            "A caching strategy"
          ],
          "correctAnswer": 1,
          "explanation": "Circuit breaker monitors failure rates. If failures exceed threshold, it 'opens' the circuit and returns fallback responses, preventing cascading failures."
        },
        {
          "question": "What is the Saga pattern used for?",
          "options": [
            "Database indexing",
            "Managing distributed transactions across microservices",
            "Load balancing",
            "Monitoring"
          ],
          "correctAnswer": 1,
          "explanation": "Saga manages distributed transactions as a sequence of local transactions with compensating actions for rollback on failure."
        },
        {
          "question": "What is a CDN?",
          "options": [
            "Central Data Node",
            "Content Delivery Network - serves content from edge servers closer to users",
            "Cloud Database Network",
            "Cached Data Namespace"
          ],
          "correctAnswer": 1,
          "explanation": "A CDN distributes content to edge servers worldwide, reducing latency by serving requests from the geographically nearest server."
        },
        {
          "question": "What is the difference between push CDN and pull CDN?",
          "options": [
            "Push is faster",
            "Push: origin uploads to CDN. Pull: CDN fetches from origin on first request",
            "They are identical",
            "Pull CDN doesn't cache"
          ],
          "correctAnswer": 1,
          "explanation": "Push CDN: content is uploaded by origin to CDN proactively. Pull CDN: content is fetched from origin when first requested, then cached."
        },
        {
          "question": "What are the four golden signals of monitoring?",
          "options": [
            "CPU, RAM, Disk, Network",
            "Latency, Traffic, Errors, Saturation",
            "Uptime, Response Time, Throughput, Memory",
            "Read, Write, Delete, Update"
          ],
          "correctAnswer": 1,
          "explanation": "The four golden signals (from Google SRE): Latency, Traffic (throughput), Errors (error rate), and Saturation (resource utilization)."
        },
        {
          "question": "What is distributed tracing?",
          "options": [
            "Logging errors across services",
            "Tracking a request's journey through multiple microservices",
            "Monitoring CPU usage",
            "A type of load balancer"
          ],
          "correctAnswer": 1,
          "explanation": "Distributed tracing (e.g., Jaeger, Zipkin) assigns a trace ID to each request and tracks it across all services it touches."
        },
        {
          "question": "What is the P99 latency?",
          "options": [
            "Average latency",
            "99th percentile - 99% of requests are faster than this value",
            "Maximum latency",
            "Median latency"
          ],
          "correctAnswer": 1,
          "explanation": "P99 means 99% of requests complete within this time. It captures tail latency, which is more useful than averages for SLA monitoring."
        },
        {
          "question": "In Netflix's architecture, what is Adaptive Bitrate (ABR) streaming?",
          "options": [
            "Fixed quality streaming",
            "Adjusting video quality based on client bandwidth in real-time",
            "Streaming at maximum quality always",
            "Compressing video on the fly"
          ],
          "correctAnswer": 1,
          "explanation": "ABR streaming encodes video at multiple quality levels. The player switches between them based on current bandwidth and buffer health."
        },
        {
          "question": "What is the 'celebrity problem' in Facebook's news feed?",
          "options": [
            "Celebrities get priority in feed ranking",
            "Fanout-on-write for celebrities would create millions of writes per post",
            "Celebrity accounts are stored differently",
            "Celebrities have faster API access"
          ],
          "correctAnswer": 1,
          "explanation": "A celebrity with 10M followers posting triggers 10M fanout writes. Solution: hybrid approach — fanout-on-read for celebrities, fanout-on-write for regular users."
        },
        {
          "question": "In YouTube's video processing pipeline, what is transcoding?",
          "options": [
            "Uploading a video",
            "Converting video to multiple formats and resolutions",
            "Adding subtitles",
            "Generating thumbnails"
          ],
          "correctAnswer": 1,
          "explanation": "Transcoding converts the uploaded video to multiple formats (H.264, VP9, AV1) and resolutions (240p to 4K) for different devices and bandwidths."
        },
        {
          "question": "How does Zomato assign delivery partners to orders?",
          "options": [
            "Random assignment",
            "First-come-first-served",
            "Scoring algorithm based on distance, rating, availability, and current load",
            "Always the nearest partner"
          ],
          "correctAnswer": 2,
          "explanation": "A scoring algorithm considers multiple factors: distance to restaurant, current delivery load, rating, vehicle type, and zone familiarity."
        },
        {
          "question": "What is the 'seat locking' problem in BookMyShow?",
          "options": [
            "Seats are permanently locked",
            "Temporary hold on selected seats to prevent double-booking",
            "Seats are assigned randomly",
            "Lock prevents seat selection"
          ],
          "correctAnswer": 1,
          "explanation": "When a user selects seats, they're temporarily locked (5-10 min) with a TTL. If payment isn't completed, seats are released. Prevents two users booking the same seat."
        },
        {
          "question": "In logistics systems like Delhivery, what is an AWB?",
          "options": [
            "Automated Web Browser",
            "Air Waybill - unique tracking number for a shipment",
            "Average Weight Balance",
            "Automated Warehouse Bot"
          ],
          "correctAnswer": 1,
          "explanation": "AWB (Air Waybill) is a unique tracking number assigned to each shipment, used to track the package through every stage of delivery."
        },
        {
          "question": "What encoding does a URL shortener typically use?",
          "options": [
            "Base64",
            "Base62 (a-z, A-Z, 0-9)",
            "Hexadecimal",
            "Binary"
          ],
          "correctAnswer": 1,
          "explanation": "Base62 uses [a-zA-Z0-9] — 62 URL-safe characters. A 7-character base62 string can represent 62^7 ≈ 3.5 trillion unique URLs."
        },
        {
          "question": "Why does a URL shortener use 301 redirect instead of 302?",
          "options": [
            "301 is faster",
            "301 (permanent) allows browser caching; 302 (temporary) lets you track clicks",
            "They are the same",
            "302 doesn't work with HTTPS"
          ],
          "correctAnswer": 1,
          "explanation": "301 = permanent redirect (browser caches). 302 = temporary (browser always hits shortener). Use 302 if you need analytics; 301 for reduced server load."
        },
        {
          "question": "How do real-time chat systems deliver messages to online users?",
          "options": [
            "HTTP polling every second",
            "Email notification",
            "WebSocket persistent connection",
            "SMTP protocol"
          ],
          "correctAnswer": 2,
          "explanation": "WebSocket provides a persistent full-duplex connection, allowing the server to push messages instantly without the client polling."
        },
        {
          "question": "How does WhatsApp handle group message delivery for small groups?",
          "options": [
            "Fanout-on-read",
            "Store once, deliver per member (fanout-on-write)",
            "Broadcast to all users",
            "Peer-to-peer between members"
          ],
          "correctAnswer": 1,
          "explanation": "For small groups (<256), fanout-on-write: the message is stored once and a delivery record is created per member for tracking."
        },
        {
          "question": "What is the Signal Protocol used for in chat systems?",
          "options": [
            "Load balancing",
            "End-to-end encryption (E2EE)",
            "Message compression",
            "User authentication"
          ],
          "correctAnswer": 1,
          "explanation": "Signal Protocol provides end-to-end encryption using key exchange (X3DH) and double ratchet algorithm. Used by WhatsApp, Signal."
        },
        {
          "question": "In a notification system, what is the purpose of a 'dead letter queue'?",
          "options": [
            "Queue for deleted messages",
            "Stores notifications that failed all retry attempts",
            "Queue for expired notifications",
            "Archive of old notifications"
          ],
          "correctAnswer": 1,
          "explanation": "A dead letter queue stores messages that couldn't be processed after maximum retries, allowing manual investigation and reprocessing."
        },
        {
          "question": "What is notification 'digest' mode?",
          "options": [
            "Compressed notifications",
            "Batching multiple notifications into a single summary notification",
            "Encrypted notifications",
            "Priority notifications"
          ],
          "correctAnswer": 1,
          "explanation": "Digest batches multiple low-priority notifications and delivers them as one summary (e.g., 'You have 5 new likes and 3 comments')."
        },
        {
          "question": "Why is a Trie data structure ideal for search autocomplete?",
          "options": [
            "Uses less memory than arrays",
            "Provides O(prefix_length) lookup with pre-computed top-K suggestions",
            "Supports SQL queries",
            "It's a database index type"
          ],
          "correctAnswer": 1,
          "explanation": "A Trie provides O(prefix_length) lookup. With top-K suggestions pre-computed at each node, retrieval is O(1) after reaching the prefix node."
        },
        {
          "question": "How does client-side debouncing help in search autocomplete?",
          "options": [
            "Improves search accuracy",
            "Reduces API calls by waiting for typing pause before sending request",
            "Encrypts search queries",
            "Sorts results alphabetically"
          ],
          "correctAnswer": 1,
          "explanation": "Debouncing waits ~150ms after the last keystroke before sending a request, reducing API calls by ~60% (most intermediate keystrokes are skipped)."
        },
        {
          "question": "What is the surge pricing trigger in ride-matching systems?",
          "options": [
            "Time of day only",
            "When demand exceeds supply in a geographic zone",
            "Number of active drivers",
            "Weather conditions only"
          ],
          "correctAnswer": 1,
          "explanation": "Surge is triggered when demand (ride requests) exceeds supply (available drivers) in a zone. Multiplier = demand/supply ratio, typically capped at 3-5x."
        },
        {
          "question": "What geospatial indexing does Uber use for finding nearby drivers?",
          "options": [
            "B-tree index",
            "GeoHash / S2 Geometry / H3 cells",
            "Full-text search",
            "Linear scan"
          ],
          "correctAnswer": 1,
          "explanation": "Uber uses geospatial indexing (GeoHash, Google S2, or H3 cells) stored in Redis GEO for O(log N) nearby driver lookups."
        },
        {
          "question": "What is idempotency in payment systems?",
          "options": [
            "Processing payments faster",
            "Ensuring the same request produces the same result regardless of retries",
            "Encrypting payment data",
            "Validating card numbers"
          ],
          "correctAnswer": 1,
          "explanation": "Idempotency ensures a payment is processed exactly once. Client sends a unique idempotency key; server returns cached result on duplicate requests."
        },
        {
          "question": "What is a double-entry ledger?",
          "options": [
            "A backup database",
            "Every transaction records equal debits and credits across accounts",
            "Two separate ledger systems",
            "A type of database index"
          ],
          "correctAnswer": 1,
          "explanation": "Double-entry bookkeeping records every transaction as balanced debit and credit entries. Sum of all debits always equals sum of all credits."
        },
        {
          "question": "What is the difference between horizontal and vertical scaling?",
          "options": [
            "They are identical",
            "Horizontal adds more machines; vertical adds more resources to one machine",
            "Horizontal is always better",
            "Vertical adds more machines"
          ],
          "correctAnswer": 1,
          "explanation": "Vertical scaling (scale up): bigger machine. Horizontal scaling (scale out): more machines. Horizontal is preferred for web-scale but adds complexity."
        },
        {
          "question": "What is eventual consistency?",
          "options": [
            "Data is always consistent",
            "All replicas will eventually have the same data, but not immediately",
            "Consistency is never achieved",
            "Only the primary has correct data"
          ],
          "correctAnswer": 1,
          "explanation": "Eventual consistency means all replicas will converge to the same state eventually. Writes propagate asynchronously. Common in AP systems (DynamoDB, Cassandra)."
        },
        {
          "question": "What is the difference between strong consistency and eventual consistency?",
          "options": [
            "Strong is slower but reads always return latest write; eventual is faster but may return stale data",
            "They are the same in distributed systems",
            "Eventual is always better",
            "Strong consistency doesn't exist"
          ],
          "correctAnswer": 0,
          "explanation": "Strong consistency guarantees any read returns the most recent write. Eventual consistency allows temporary staleness for better availability and performance."
        },
        {
          "question": "What is back-of-the-envelope estimation in system design?",
          "options": [
            "Exact mathematical calculation",
            "Rough calculations to estimate system requirements using simple math",
            "A debugging technique",
            "A database optimization"
          ],
          "correctAnswer": 1,
          "explanation": "Back-of-the-envelope estimation uses simple arithmetic to quickly estimate QPS, storage, bandwidth, etc. — crucial for capacity planning in interviews."
        },
        {
          "question": "How many bytes are in 1 GB?",
          "options": [
            "1 million",
            "1 billion (10^9)",
            "1 trillion",
            "100 million"
          ],
          "correctAnswer": 1,
          "explanation": "1 GB = 10^9 bytes = 1,000,000,000 bytes. Useful for quick capacity calculations: 1 char ≈ 1 byte, 1 row ≈ 1KB."
        },
        {
          "question": "What is a Layer 4 vs Layer 7 load balancer?",
          "options": [
            "Layer 4 is better",
            "L4 routes by IP/port (transport); L7 routes by URL/headers/cookies (application)",
            "They are the same",
            "Layer 7 is transport layer"
          ],
          "correctAnswer": 1,
          "explanation": "L4 works at TCP/UDP level (fast, simple). L7 works at HTTP level (can route by URL path, headers, cookies — more flexible but more overhead)."
        },
        {
          "question": "What is the purpose of health checks in load balancing?",
          "options": [
            "Monitoring CPU usage",
            "Detecting unhealthy servers to stop routing traffic to them",
            "Optimizing cache hit rates",
            "Encrypting traffic"
          ],
          "correctAnswer": 1,
          "explanation": "Health checks periodically probe each backend server. If a server fails health checks, the load balancer removes it from the rotation."
        },
        {
          "question": "What is a write-behind (write-back) cache?",
          "options": [
            "Writes go to DB only",
            "Writes go to cache, asynchronously synced to DB later",
            "Cache is read-only",
            "Writes bypass cache entirely"
          ],
          "correctAnswer": 1,
          "explanation": "Write-behind writes to cache immediately and asynchronously flushes to DB. Benefit: low write latency. Risk: data loss if cache crashes before flush."
        },
        {
          "question": "What is Redis Pub/Sub used for?",
          "options": [
            "Database replication",
            "Publishing messages to subscribers in real-time",
            "Caching HTML pages",
            "File storage"
          ],
          "correctAnswer": 1,
          "explanation": "Redis Pub/Sub enables real-time messaging: publishers send messages to channels, all subscribers on that channel receive them instantly."
        },
        {
          "question": "What is the primary use case for Kafka vs RabbitMQ?",
          "options": [
            "They are interchangeable",
            "Kafka: high-throughput event streaming with replay. RabbitMQ: traditional message queuing with routing",
            "RabbitMQ is faster",
            "Kafka doesn't support queuing"
          ],
          "correctAnswer": 1,
          "explanation": "Kafka excels at high-throughput event streaming with message replay. RabbitMQ is better for complex routing, priority queues, and traditional pub/sub."
        },
        {
          "question": "What is the sliding window rate limiting algorithm?",
          "options": [
            "A fixed window with a counter",
            "Combines fixed window counters with weighted timestamps for smooth rate limiting",
            "A queue-based approach",
            "Token-based limiting"
          ],
          "correctAnswer": 1,
          "explanation": "Sliding window combines two adjacent fixed windows with weighted counts based on elapsed time, providing smoother rate limiting than fixed window alone."
        },
        {
          "question": "What is gRPC and when would you use it?",
          "options": [
            "A REST alternative",
            "High-performance RPC framework using HTTP/2 and Protocol Buffers, ideal for service-to-service communication",
            "A database protocol",
            "A caching mechanism"
          ],
          "correctAnswer": 1,
          "explanation": "gRPC uses HTTP/2 for multiplexing and Protocol Buffers for efficient serialization. Ideal for low-latency microservice communication."
        },
        {
          "question": "What is an API Gateway?",
          "options": [
            "A type of database",
            "A single entry point that handles authentication, rate limiting, routing, and aggregation for microservices",
            "A caching layer",
            "A message queue"
          ],
          "correctAnswer": 1,
          "explanation": "API Gateway (e.g., Kong, AWS API Gateway) is the single entry point for all client requests, handling cross-cutting concerns like auth, rate limiting, and routing."
        },
        {
          "question": "What is service discovery in microservices?",
          "options": [
            "Finding bugs in services",
            "Mechanism for services to find each other's network locations dynamically",
            "Discovering new API endpoints",
            "Load testing services"
          ],
          "correctAnswer": 1,
          "explanation": "Service discovery (e.g., Consul, etcd) allows services to register themselves and discover other services' locations dynamically."
        },
        {
          "question": "What is the Bulkhead pattern?",
          "options": [
            "A type of load balancer",
            "Isolating components so failure in one doesn't cascade to others",
            "A database sharding technique",
            "A caching strategy"
          ],
          "correctAnswer": 1,
          "explanation": "Bulkhead (from ship design) isolates resources per service/function. If one pool is exhausted, others remain unaffected, preventing cascading failures."
        },
        {
          "question": "What is edge computing in the context of CDNs?",
          "options": [
            "Computing at the main data center",
            "Running computation at CDN edge servers close to users",
            "A type of database",
            "Networking protocol"
          ],
          "correctAnswer": 1,
          "explanation": "Edge computing runs logic at CDN edge locations (e.g., Cloudflare Workers), reducing latency by processing requests closer to users."
        },
        {
          "question": "What is the difference between active-passive and active-active replication?",
          "options": [
            "They are the same",
            "Active-passive: one primary handles writes. Active-active: multiple nodes handle writes",
            "Active-active is always better",
            "Neither supports failover"
          ],
          "correctAnswer": 1,
          "explanation": "Active-passive: writes go to primary only, passive takes over on failure. Active-active: writes go to multiple nodes, better availability but needs conflict resolution."
        },
        {
          "question": "What is an SLA (Service Level Agreement)?",
          "options": [
            "A type of database",
            "A contract defining uptime, latency, and error rate guarantees",
            "A security protocol",
            "A load balancing algorithm"
          ],
          "correctAnswer": 1,
          "explanation": "SLA defines guaranteed service quality: e.g., 99.9% uptime (8.77 hours downtime/year), P99 latency < 200ms, error rate < 0.1%."
        },
        {
          "question": "What does 99.99% availability (four nines) mean in terms of downtime per year?",
          "options": [
            "8.77 hours",
            "52.6 minutes",
            "5.26 minutes",
            "No downtime"
          ],
          "correctAnswer": 1,
          "explanation": "99.99% = 52.6 minutes downtime/year. 99.9% = 8.77 hours. 99.999% (five nines) = 5.26 minutes/year."
        },
        {
          "question": "In Facebook's feed ranking, what is EdgeRank?",
          "options": [
            "A graph database",
            "Algorithm scoring posts by affinity, weight, and time decay",
            "A CDN optimization",
            "A compression algorithm"
          ],
          "correctAnswer": 1,
          "explanation": "EdgeRank (simplified) scores posts using: Affinity (relationship), Weight (content type), Time Decay (recency). Higher score = higher in feed."
        },
        {
          "question": "What is Content ID in YouTube?",
          "options": [
            "Video file name",
            "Digital fingerprinting system for copyright detection",
            "User authentication",
            "Database key"
          ],
          "correctAnswer": 1,
          "explanation": "Content ID creates a digital fingerprint of copyrighted content and scans all uploads against it, allowing copyright holders to claim or block content."
        },
        {
          "question": "What is a virtual waiting room in booking systems?",
          "options": [
            "Physical queue at venue",
            "Queue system that controls access during high demand to prevent server overload",
            "A VR experience",
            "A chat room"
          ],
          "correctAnswer": 1,
          "explanation": "During high-demand events, a virtual waiting room queues users (showing position) and admits them gradually, preventing server overload."
        },
        {
          "question": "What is volumetric weight in logistics?",
          "options": [
            "Actual weight of package",
            "Max of actual weight and volume-based weight (L×W×H / divisor)",
            "Weight of delivery vehicle",
            "Total order weight"
          ],
          "correctAnswer": 1,
          "explanation": "Volumetric weight = (Length × Width × Height) / divisor. Shipping cost is based on max(actual_weight, volumetric_weight) to account for space."
        },
        {
          "question": "How does a URL shortener handle collisions in hash-based approaches?",
          "options": [
            "Ignores them",
            "Appends timestamp or uses counter-based approach to ensure uniqueness",
            "Rejects the URL",
            "Uses longer hash"
          ],
          "correctAnswer": 1,
          "explanation": "Collision handling: (1) Append pre-defined string and rehash. (2) Use counter-based approach (auto-increment ID → base62 encode) for guaranteed uniqueness."
        },
        {
          "question": "What is read receipt in a chat system?",
          "options": [
            "Server log entry",
            "Acknowledgment that recipient has viewed the message",
            "Message delivery confirmation",
            "Error report"
          ],
          "correctAnswer": 1,
          "explanation": "A read receipt signals that the recipient has viewed the message (blue ticks in WhatsApp). Different from delivery receipt (message reached device)."
        },
        {
          "question": "What is APNs in the context of push notifications?",
          "options": [
            "Application Programming Network",
            "Apple Push Notification Service",
            "Automated Push Notifier System",
            "API Notification Standard"
          ],
          "correctAnswer": 1,
          "explanation": "APNs (Apple Push Notification Service) is Apple's service for sending push notifications to iOS devices. FCM (Firebase Cloud Messaging) is Google's equivalent."
        },
        {
          "question": "What is a Trie node's top-K list used for in autocomplete?",
          "options": [
            "Storing all words",
            "Pre-computed most popular suggestions for instant retrieval at query time",
            "Caching recent searches",
            "Database index"
          ],
          "correctAnswer": 1,
          "explanation": "Each Trie node stores the top-K most popular completions from all descendants, allowing O(1) suggestion retrieval at any prefix without traversal."
        },
        {
          "question": "What is the Haversine formula?",
          "options": [
            "A sorting algorithm",
            "Calculates the distance between two points on a sphere using lat/lng",
            "A hash function",
            "A compression technique"
          ],
          "correctAnswer": 1,
          "explanation": "The Haversine formula calculates great-circle distance between two GPS coordinates on Earth's surface, accounting for the planet's curvature."
        },
        {
          "question": "What is PCI-DSS compliance in payment systems?",
          "options": [
            "A programming language",
            "Security standard for handling credit card data",
            "A database optimization",
            "An API specification"
          ],
          "correctAnswer": 1,
          "explanation": "PCI-DSS (Payment Card Industry Data Security Standard) mandates security practices for handling card data: encryption, access controls, audit logs, etc."
        },
        {
          "question": "What is the reconciliation process in payments?",
          "options": [
            "User authentication",
            "Matching internal payment records with external gateway/bank settlement data",
            "Backup restoration",
            "Load balancing"
          ],
          "correctAnswer": 1,
          "explanation": "Reconciliation compares internal ledger entries with external settlement reports daily, identifying discrepancies for resolution."
        },
        {
          "question": "What is database replication?",
          "options": [
            "Deleting duplicate data",
            "Maintaining copies of data across multiple nodes for availability and read scaling",
            "Compressing database files",
            "Encrypting database fields"
          ],
          "correctAnswer": 1,
          "explanation": "Replication maintains data copies across multiple nodes. Primary handles writes; replicas handle reads. Provides availability, fault tolerance, and read scaling."
        },
        {
          "question": "What is a bloom filter?",
          "options": [
            "A type of load balancer",
            "Probabilistic data structure that tells whether an element might be in a set",
            "A database index",
            "A caching algorithm"
          ],
          "correctAnswer": 1,
          "explanation": "Bloom filter answers 'might be in set' or 'definitely not in set'. False positives possible, false negatives impossible. Space-efficient for membership testing."
        },
        {
          "question": "What is the difference between SQL and NoSQL databases?",
          "options": [
            "SQL is always faster",
            "SQL: structured/relational with ACID. NoSQL: flexible schema, horizontal scaling, various data models",
            "NoSQL doesn't support queries",
            "They are identical"
          ],
          "correctAnswer": 1,
          "explanation": "SQL: fixed schema, ACID transactions, joins, vertical scaling. NoSQL: flexible schema, BASE, horizontal scaling. Choose based on access patterns and consistency needs."
        },
        {
          "question": "What is CQRS (Command Query Responsibility Segregation)?",
          "options": [
            "A database type",
            "Separating read and write models/stores for independent optimization",
            "A caching technique",
            "A security pattern"
          ],
          "correctAnswer": 1,
          "explanation": "CQRS uses separate models for reads (queries) and writes (commands). Each can be optimized independently: writes to normalized DB, reads from denormalized views."
        },
        {
          "question": "What is event sourcing?",
          "options": [
            "Logging events to a file",
            "Storing state changes as immutable events instead of current state",
            "Message queue processing",
            "Real-time event streaming"
          ],
          "correctAnswer": 1,
          "explanation": "Instead of storing current state, event sourcing stores all state changes as events. Current state is derived by replaying events. Provides complete audit trail."
        },
        {
          "question": "What is the difference between TCP and UDP?",
          "options": [
            "TCP is newer",
            "TCP: reliable, ordered delivery with connection. UDP: unreliable, unordered, connectionless but faster",
            "UDP is always better",
            "They are the same protocol"
          ],
          "correctAnswer": 1,
          "explanation": "TCP guarantees delivery and ordering (HTTP, database). UDP trades reliability for speed (video streaming, gaming, DNS). Choose based on use case."
        },
        {
          "question": "What is a message broker?",
          "options": [
            "A human mediator",
            "Middleware that translates, routes, and queues messages between services",
            "A type of database",
            "A monitoring tool"
          ],
          "correctAnswer": 1,
          "explanation": "A message broker (Kafka, RabbitMQ, SQS) receives messages from producers, routes them to appropriate queues/topics, and delivers to consumers."
        },
        {
          "question": "What is data partitioning?",
          "options": [
            "Duplicating data",
            "Splitting data across multiple storage units based on a partition key",
            "Compressing data",
            "Encrypting data"
          ],
          "correctAnswer": 1,
          "explanation": "Data partitioning distributes data across nodes by a partition key. Types: hash-based (uniform), range-based (ordered), list-based (categorical)."
        },
        {
          "question": "What is a leader election algorithm?",
          "options": [
            "Voting for team leads",
            "Process for distributed nodes to agree on a single coordinator/leader",
            "A scheduling algorithm",
            "A sorting algorithm"
          ],
          "correctAnswer": 1,
          "explanation": "Leader election (Raft, Paxos, ZooKeeper) ensures distributed nodes agree on one leader that coordinates writes and decisions, maintaining consistency."
        },
        {
          "question": "What is the difference between latency and throughput?",
          "options": [
            "They are the same",
            "Latency: time for one request. Throughput: number of requests per second",
            "Throughput is always more important",
            "Latency measures bandwidth"
          ],
          "correctAnswer": 1,
          "explanation": "Latency = time for a single request (ms). Throughput = total requests handled per second (QPS). Optimizing one may affect the other."
        },
        {
          "question": "What is connection pooling?",
          "options": [
            "Creating new connections for each request",
            "Reusing a pool of pre-established connections to reduce connection overhead",
            "Disconnecting idle clients",
            "Load balancing connections"
          ],
          "correctAnswer": 1,
          "explanation": "Connection pooling maintains reusable connections (DB, HTTP). Instead of creating/destroying connections per request, connections are borrowed and returned."
        },
        {
          "question": "What is a reverse proxy vs forward proxy?",
          "options": [
            "Same thing",
            "Forward proxy: represents clients. Reverse proxy: represents servers",
            "Forward proxy is server-side",
            "Reverse proxy is client-side"
          ],
          "correctAnswer": 1,
          "explanation": "Forward proxy sits before clients (VPN, content filtering). Reverse proxy sits before servers (load balancing, SSL termination, caching)."
        },
        {
          "question": "What is DNS round-robin?",
          "options": [
            "A security protocol",
            "DNS returns different IP addresses in rotation for load distribution",
            "A caching strategy",
            "A database technique"
          ],
          "correctAnswer": 1,
          "explanation": "DNS round-robin returns different server IPs in rotation for the same domain, distributing traffic. Simple but lacks health checking and session persistence."
        },
        {
          "question": "What is optimistic locking?",
          "options": [
            "Locking resources permanently",
            "Using version numbers to detect conflicts at commit time without holding locks",
            "Blocking all concurrent access",
            "A database backup strategy"
          ],
          "correctAnswer": 1,
          "explanation": "Optimistic locking uses a version column. On update: check if version matches. If not (another transaction modified it), reject and retry. No blocking locks held."
        },
        {
          "question": "What is the difference between synchronous and asynchronous communication?",
          "options": [
            "They produce the same result",
            "Sync: caller waits for response. Async: caller continues without waiting",
            "Async is always slower",
            "Sync doesn't need a network"
          ],
          "correctAnswer": 1,
          "explanation": "Synchronous: caller blocks until response (HTTP). Asynchronous: caller sends message and continues (message queue). Async improves resilience and decoupling."
        },
        {
          "question": "What is a hot partition problem?",
          "options": [
            "Server overheating",
            "Disproportionate traffic going to one shard/partition",
            "Full storage on one node",
            "Network congestion"
          ],
          "correctAnswer": 1,
          "explanation": "Hot partition occurs when one shard receives significantly more traffic (reads/writes) than others, becoming a bottleneck. Caused by poor shard key choice."
        },
        {
          "question": "What is the fan-out problem in social networks?",
          "options": [
            "Too many server fans",
            "When a popular user's post triggers writes to millions of followers' feeds",
            "Network bandwidth issue",
            "Database schema problem"
          ],
          "correctAnswer": 1,
          "explanation": "Fan-out: one post by a user with 10M followers requires writing to 10M timelines. Solutions: fanout-on-read for high-follower users, hybrid approaches."
        },
        {
          "question": "What is a tombstone in distributed systems?",
          "options": [
            "A failed node",
            "A marker indicating deleted data, kept temporarily for replication consistency",
            "A type of database constraint",
            "An error message"
          ],
          "correctAnswer": 1,
          "explanation": "A tombstone marks data as deleted rather than physically removing it. Required in distributed systems so deletion propagates to all replicas."
        },
        {
          "question": "What is gossip protocol?",
          "options": [
            "A chat protocol",
            "Peer-to-peer communication where nodes periodically share state with random neighbors",
            "A security protocol",
            "An encryption algorithm"
          ],
          "correctAnswer": 1,
          "explanation": "Gossip (epidemic) protocol: each node periodically shares its state with random peers. Information propagates exponentially. Used in Cassandra, DynamoDB."
        },
        {
          "question": "What is the purpose of a heartbeat in distributed systems?",
          "options": [
            "Health monitoring",
            "Periodic signals to indicate a node is alive",
            "Data synchronization",
            "Load balancing"
          ],
          "correctAnswer": 1,
          "explanation": "Heartbeats are periodic signals sent between nodes. If a node misses consecutive heartbeats, it's considered failed and traffic is rerouted."
        },
        {
          "question": "In ride-matching, what is the 'thundering herd' problem?",
          "options": [
            "Too many servers starting up",
            "Multiple ride requests simultaneously targeting the same nearest driver",
            "Network congestion from GPS updates",
            "Database lock contention"
          ],
          "correctAnswer": 1,
          "explanation": "Multiple riders in same area all get matched to the same nearest driver simultaneously. Fix: batch matching over 2s windows with global optimization."
        },
        {
          "question": "What is webhook vs polling?",
          "options": [
            "Same mechanism",
            "Webhook: server pushes event to client URL. Polling: client repeatedly asks server for updates",
            "Polling is always better",
            "Webhooks use UDP"
          ],
          "correctAnswer": 1,
          "explanation": "Polling: client checks periodically (wasteful if no updates). Webhook: server sends HTTP POST to client's URL when event occurs (event-driven, efficient)."
        },
        {
          "question": "What is the CAP theorem trade-off for Cassandra?",
          "options": [
            "CA (Consistency + Availability)",
            "AP (Availability + Partition Tolerance)",
            "CP (Consistency + Partition Tolerance)",
            "All three"
          ],
          "correctAnswer": 1,
          "explanation": "Cassandra is an AP system — it prioritizes availability and partition tolerance with tunable consistency (eventual by default, strong with quorum)."
        },
        {
          "question": "What is a WAL (Write-Ahead Log)?",
          "options": [
            "A web server log",
            "Log where changes are written before being applied to the database, ensuring durability",
            "An API endpoint",
            "A monitoring dashboard"
          ],
          "correctAnswer": 1,
          "explanation": "WAL writes every change to a durable log before applying to the database. On crash recovery, uncommitted changes can be replayed from the log."
        },
        {
          "question": "What is sharding key selection important for?",
          "options": [
            "It doesn't matter",
            "Even data distribution, query efficiency, and avoiding hotspots",
            "Database security",
            "Index optimization only"
          ],
          "correctAnswer": 1,
          "explanation": "A good shard key distributes data evenly (avoid hotspots), supports your access patterns (queries should hit one shard), and provides high cardinality."
        }
      ],
      "topicCount": 24,
      "quizCount": 103
    }
  ]
}