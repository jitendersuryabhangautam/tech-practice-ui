{
  "id": "url-shortener",
  "title": "URL Shortener (like bit.ly)",
  "category": "Company HLD",
  "description": "High-level design of a URL shortening service — encoding, redirection, analytics, and scaling to billions of URLs.",
  "explanation": "A URL shortener maps long URLs to short codes (e.g., short.ly/abc123 → original URL). Seems simple but at scale involves interesting trade-offs.\n\n**Core Requirements**:\n- Shorten: given a long URL, return a short URL.\n- Redirect: given a short URL, redirect (301/302) to the original.\n- Analytics: track click count, referrer, geo, device.\n- Scale: support billions of URLs, millions of redirects/sec.\n\n**Short Code Generation**:\n- Option 1: **Hash-based**: MD5/SHA256(longUrl) → take first 7 chars in base62. Collision: different URLs could produce same hash prefix. Handle with collision check + retry.\n- Option 2: **Counter-based**: Auto-increment counter → encode in base62. No collisions. But sequential codes are predictable. Use distributed counter (ZooKeeper ranges) for multi-server.\n- Option 3: **Random**: Generate random 7-char base62 string. Check for collision in DB. Very unlikely collision with 62^7 = 3.5 trillion combinations.\n- Best: Counter-based with base62 encoding. Assign counter ranges to servers (e.g., server1 gets 1-1M, server2 gets 1M-2M).\n\n**Base62 Encoding**: [0-9a-zA-Z] = 62 characters. 7 chars = 62^7 ≈ 3.5 trillion unique codes.\n\n**Data Model**:\n- Table: `urls` (short_code PK, long_url, created_at, user_id, expires_at)\n- Table: `clicks` (id, short_code FK, timestamp, ip, referrer, user_agent, country)\n\n**Read vs Write**:\n- Reads (redirects) far exceed writes (creates). Read:Write ratio ~100:1.\n- Caching: Redis/Memcached for hot URLs. LRU eviction. Cache hit rate >90%.\n- DB: Write to primary, read from replicas.\n\n**Redirection**: 301 (permanent) vs 302 (temporary). 301 tells browsers to cache — reduces server load but loses analytics. 302 always hits server — better for analytics.\n\n**Expiration**: Optional TTL per URL. Background job deletes expired entries. Reclaim short codes after expiration.\n\n**Custom Aliases**: Allow users to specify custom short codes (e.g., short.ly/my-brand). Check availability. Reserve against dictionary words.",
  "code": "// URL shortener service\nclass URLShortener {\n  constructor(domain) {\n    this.domain = domain;\n    this.urlMap = new Map(); // shortCode -> longUrl\n    this.reverseMap = new Map(); // longUrl -> shortCode\n    this.counter = 100000; // start counter\n    this.clicks = new Map(); // shortCode -> click count\n  }\n\n  base62Encode(num) {\n    const chars = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';\n    let result = '';\n    while (num > 0) {\n      result = chars[num % 62] + result;\n      num = Math.floor(num / 62);\n    }\n    return result || '0';\n  }\n\n  shorten(longUrl) {\n    // Check if already shortened\n    if (this.reverseMap.has(longUrl)) {\n      const code = this.reverseMap.get(longUrl);\n      return `${this.domain}/${code}`;\n    }\n    const code = this.base62Encode(++this.counter);\n    this.urlMap.set(code, longUrl);\n    this.reverseMap.set(longUrl, code);\n    this.clicks.set(code, 0);\n    return `${this.domain}/${code}`;\n  }\n\n  redirect(shortCode) {\n    const longUrl = this.urlMap.get(shortCode);\n    if (!longUrl) return { error: '404 Not Found' };\n    this.clicks.set(shortCode, (this.clicks.get(shortCode) || 0) + 1);\n    return { redirectTo: longUrl, statusCode: 302 };\n  }\n\n  getAnalytics(shortCode) {\n    return {\n      shortCode,\n      longUrl: this.urlMap.get(shortCode),\n      clicks: this.clicks.get(shortCode) || 0,\n    };\n  }\n}\n\nconst shortener = new URLShortener('https://short.ly');\nconsole.log(shortener.shorten('https://www.example.com/very/long/url/123'));\nconsole.log(shortener.shorten('https://www.example.com/another/url'));\nconsole.log(shortener.shorten('https://www.example.com/very/long/url/123')); // same URL, same code\nconst code = 'q0T'; // from first shortening\nshortener.redirect('q0T');\nshortener.redirect('q0T');\nconsole.log(shortener.getAnalytics('q0T'));",
  "example": "// Base62 encoding and decoding\nclass Base62 {\n  static CHARS = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';\n\n  static encode(num) {\n    if (num === 0) return '0';\n    let result = '';\n    while (num > 0) {\n      result = this.CHARS[num % 62] + result;\n      num = Math.floor(num / 62);\n    }\n    return result;\n  }\n\n  static decode(str) {\n    let num = 0;\n    for (const char of str) {\n      num = num * 62 + this.CHARS.indexOf(char);\n    }\n    return num;\n  }\n}\n\n// Demo: counter → short code → back to counter\nfor (const id of [1, 100, 1000, 100000, 1000000, 3500000000000]) {\n  const encoded = Base62.encode(id);\n  const decoded = Base62.decode(encoded);\n  console.log(`${id} → '${encoded}' → ${decoded} (length: ${encoded.length})`);  \n}",
  "useCase": "URL shortening services, link tracking, QR code generation, campaign tracking, deep linking, content sharing.",
  "interviewQuestions": [
    { "question": "How do you generate unique short codes?", "answer": "Counter-based: distributed counter (ZooKeeper or DB auto-increment) → base62 encode. Each server pre-allocates a range (e.g., 1M IDs). No collisions, no DB lookup needed for generation. 7 base62 chars = 3.5T codes. Alternative: random + collision check." },
    { "question": "Why base62 instead of base64?", "answer": "Base64 includes + and / which are problematic in URLs (need encoding). Base62 uses only [0-9a-zA-Z] — URL-safe without encoding. 62^7 = 3.5 trillion combinations — sufficient for most use cases." },
    { "question": "301 vs 302 redirect — which to use?", "answer": "301 (permanent): browser caches redirect, subsequent visits don't hit server. Saves server load but loses analytics. 302 (temporary): every visit hits server. Better for analytics tracking. Most URL shorteners use 302 for analytics, with server-side caching to handle load." },
    { "question": "How do you scale reads (redirects)?", "answer": "Read:Write ratio ~100:1. Layer 1: CDN for popular URLs. Layer 2: Application cache (Redis) — LRU, TTL. Layer 3: DB read replicas. Cache hit rate >90% means most redirects never hit DB. For top 20% URLs (80% of traffic), cache stays hot." },
    { "question": "How do you handle hash collisions?", "answer": "If using hash-based approach: hash(longUrl) → take first 7 chars. On collision (code exists with different URL), append counter and rehash. Or: use counter-based approach (no collisions by design). Always do existence check before insert." },
    { "question": "How much storage do you need?", "answer": "Per URL: short_code(7B) + long_url(avg 200B) + metadata(50B) ≈ 257B. 1B URLs = 257GB. With indexes: ~500GB. Fits in a single DB shard. At 100B URLs: 25TB — need sharding by short_code hash." },
    { "question": "How do you implement URL expiration?", "answer": "Optional `expires_at` column. On redirect: check if expired → return 410 Gone. Background cleanup job runs hourly to delete expired entries and reclaim short codes. Soft delete first (mark expired), hard delete after 30 days." },
    { "question": "How do you prevent abuse (spam URLs)?", "answer": "Rate limiting per API key/IP. URL validation (is it a real URL?). Scan destination URL against malware/phishing blacklists (Google Safe Browsing API). Require authentication for custom aliases. Monitor for click-bombing (DDoS via short URLs)." },
    { "question": "How do you implement analytics?", "answer": "On each redirect: log {short_code, timestamp, IP, user_agent, referrer} to Kafka → async consumers write to analytics DB (ClickHouse/TimescaleDB). Real-time aggregation: Redis counters for click counts. Dashboard queries analytics DB. Don't block redirect for analytics writing." },
    { "question": "How do you make the system highly available?", "answer": "Multi-region deployment. DB: primary-secondary replication across regions. Cache: Redis cluster per region. Counter service: pre-allocate ranges (survives ZooKeeper outage). DNS-based routing to nearest region. Reads can be served from any region; writes go to primary." }
  ],
  "exercises": [
    { "type": "estimation", "question": "100M new URLs/month, 10B redirects/month. Average URL size 200B. Estimate storage and QPS.", "answer": "Storage per month: 100M × 257B ≈ 25.7GB. Per year: 308GB. In 5 years: 1.5TB. Writes: 100M / 30 / 86400 ≈ 39 writes/sec. Reads: 10B / 30 / 86400 ≈ 3858 reads/sec. Peak (3x average): ~12K reads/sec. Easily handled by Redis + a few DB replicas." },
    { "type": "design", "question": "Design the counter-based ID generation for multiple servers.", "answer": "ZooKeeper or central DB maintains next range. Server requests range: gets [start, end]. Locally increments within range. When range exhausted, request new range. Range size: 1M (lasts ~hours at high throughput). If server crashes, unused IDs in range are wasted (acceptable). No coordination needed between servers for individual IDs." },
    { "type": "tricky", "question": "Should you deduplicate — return same short code for same long URL?", "answer": "Depends on use case. Pro: saves storage, user sees consistent short URL. Con: different users/campaigns need different short codes for separate analytics. Solution: deduplicate per user (same user, same URL = same code). Different users get different codes. Implement via composite key (user_id, long_url)." },
    { "type": "scenario", "question": "A shortened URL goes viral — 1M clicks/second. How does your system handle it?", "answer": "1) Redis cache hit for this URL — no DB load. 2) CDN layer absorbs most traffic. 3) Analytics writes batched (count in Redis, flush to DB every 10 seconds). 4) Auto-scale redirect servers behind load balancer. 5) Rate limit if it's a DDoS. Expected: 1M/sec easily handled by Redis cluster + CDN." },
    { "type": "design", "question": "Design the analytics pipeline.", "answer": "Redirect server logs click event to Kafka (non-blocking). Consumer groups: 1) Real-time counter (increment Redis key per short_code). 2) Raw event writer (ClickHouse for detailed analytics). 3) Geo enrichment (IP → country via MaxMind, then store). Dashboard reads from ClickHouse for time-series, Redis for live count. Retention: raw events 90 days, aggregated forever." },
    { "type": "output", "question": "Base62 encode the numbers: 1, 62, 3844, 100000. What are the results?", "answer": "1 → '1'. 62 → '10'. 3844 → '100'. 100000 → 'q0T' (100000 = 26×62² + 0×62 + 29 → chars[26]='q', chars[0]='0', chars[29]='T')." },
    { "type": "debug", "question": "Users report some short URLs returning 404 even though they were just created. What could be wrong?", "answer": "1) Read replica lag: write goes to primary, read hits stale replica. Fix: read from primary for recently created URLs (cache-aside). 2) Cache miss + DB miss: cache not populated yet, DB replica not synced. 3) URL expired (very short TTL). 4) Code generation collision (two servers generated same code)." },
    { "type": "design", "question": "Design custom alias support (e.g., short.ly/my-brand).", "answer": "Separate table for custom aliases: (alias PK, long_url, user_id, created_at). Check alias not in reserved words list. Check not already taken. Length: 3-30 chars, alphanumeric + hyphens. On redirect: check custom alias table first, then generated codes table. Rate limit custom alias creation per user." },
    { "type": "estimation", "question": "Redis cache for top 20% of URLs (Pareto). 1B total URLs, avg entry 250B. How much Redis memory?", "answer": "Hot URLs: 1B × 0.2 = 200M. Memory per entry with Redis overhead: ~350B. Total: 200M × 350B = 70GB. Redis cluster with 3 nodes: ~23GB per node. Very feasible. These 200M URLs serve 80% of traffic." },
    { "type": "scenario", "question": "Legal takedown request for a specific short URL. How do you handle it?", "answer": "1) Immediately mark URL as disabled (soft delete). 2) Redirect returns 451 (Unavailable for Legal Reasons) or 410 (Gone). 3) Log takedown request with legal reference. 4) Notify URL creator. 5) Retain record for legal compliance (don't hard delete). 6) Admin interface for legal team to manage takedowns." }
  ],
  "programExercises": [
    {
      "question": "Program 1: Complete URL shortener with base62",
      "code": "class TinyURL {\n  constructor(domain) {\n    this.domain = domain;\n    this.store = new Map();\n    this.reverse = new Map();\n    this.counter = 100000;\n    this.chars = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';\n  }\n  encode(num) {\n    let s = '';\n    while (num > 0) { s = this.chars[num % 62] + s; num = Math.floor(num / 62); }\n    return s;\n  }\n  shorten(url) {\n    if (this.reverse.has(url)) return `${this.domain}/${this.reverse.get(url)}`;\n    const code = this.encode(++this.counter);\n    this.store.set(code, url);\n    this.reverse.set(url, code);\n    return `${this.domain}/${code}`;\n  }\n  resolve(code) { return this.store.get(code) || null; }\n}\n\nconst t = new TinyURL('https://tiny.url');\nconsole.log(t.shorten('https://example.com/page1'));\nconsole.log(t.shorten('https://example.com/page2'));\nconsole.log(t.shorten('https://example.com/page1')); // dedup\nconsole.log(t.resolve('q0T'));",
      "output": "https://tiny.url/q0T\nhttps://tiny.url/q0U\nhttps://tiny.url/q0T\nhttps://example.com/page1"
    },
    {
      "question": "Program 2: Base62 encoder/decoder",
      "code": "const CHARS = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';\nfunction encode62(n) {\n  if (n === 0) return '0';\n  let s = '';\n  while (n > 0) { s = CHARS[n % 62] + s; n = Math.floor(n / 62); }\n  return s;\n}\nfunction decode62(s) {\n  let n = 0;\n  for (const c of s) n = n * 62 + CHARS.indexOf(c);\n  return n;\n}\n\n[1, 62, 3844, 100000, 999999999].forEach(n => {\n  const e = encode62(n);\n  console.log(`${n} → '${e}' → ${decode62(e)} (len: ${e.length})`);\n});",
      "output": "1 → '1' → 1 (len: 1)\n62 → '10' → 62 (len: 2)\n3844 → '100' → 3844 (len: 3)\n100000 → 'q0T' → 100000 (len: 3)\n999999999 → '15FTGf' → 999999999 (len: 6)"
    },
    {
      "question": "Program 3: Click analytics tracker",
      "code": "class ClickTracker {\n  constructor() { this.events = []; this.counts = new Map(); }\n  recordClick(code, meta) {\n    this.events.push({ code, ...meta, time: Date.now() });\n    this.counts.set(code, (this.counts.get(code) || 0) + 1);\n  }\n  getStats(code) {\n    const clicks = this.events.filter(e => e.code === code);\n    const byCountry = {};\n    clicks.forEach(c => { byCountry[c.country] = (byCountry[c.country] || 0) + 1; });\n    return { code, totalClicks: clicks.length, byCountry, lastClick: clicks[clicks.length-1]?.time };\n  }\n}\n\nconst tracker = new ClickTracker();\ntracker.recordClick('abc', { country: 'US', device: 'mobile' });\ntracker.recordClick('abc', { country: 'IN', device: 'desktop' });\ntracker.recordClick('abc', { country: 'US', device: 'mobile' });\ntracker.recordClick('xyz', { country: 'UK', device: 'tablet' });\nconsole.log(tracker.getStats('abc'));",
      "output": "{\n  code: 'abc',\n  totalClicks: 3,\n  byCountry: { US: 2, IN: 1 },\n  lastClick: <timestamp>\n}"
    },
    {
      "question": "Program 4: Rate limiter for URL creation",
      "code": "class RateLimiter {\n  constructor(maxRequests, windowMs) {\n    this.max = maxRequests;\n    this.window = windowMs;\n    this.buckets = new Map();\n  }\n  allow(userId) {\n    const now = Date.now();\n    if (!this.buckets.has(userId)) this.buckets.set(userId, []);\n    const bucket = this.buckets.get(userId).filter(t => now - t < this.window);\n    this.buckets.set(userId, bucket);\n    if (bucket.length >= this.max) {\n      return { allowed: false, retryAfterMs: this.window - (now - bucket[0]) };\n    }\n    bucket.push(now);\n    return { allowed: true, remaining: this.max - bucket.length };\n  }\n}\n\nconst limiter = new RateLimiter(3, 10000); // 3 per 10s\nconsole.log(limiter.allow('user1'));\nconsole.log(limiter.allow('user1'));\nconsole.log(limiter.allow('user1'));\nconsole.log(limiter.allow('user1')); // blocked\nconsole.log(limiter.allow('user2')); // different user OK",
      "output": "{ allowed: true, remaining: 2 }\n{ allowed: true, remaining: 1 }\n{ allowed: true, remaining: 0 }\n{ allowed: false, retryAfterMs: <ms> }\n{ allowed: true, remaining: 2 }"
    },
    {
      "question": "Program 5: URL expiration manager",
      "code": "class ExpiringURLStore {\n  constructor() { this.urls = new Map(); }\n  add(code, longUrl, ttlMs) {\n    this.urls.set(code, { longUrl, expiresAt: Date.now() + ttlMs });\n  }\n  resolve(code) {\n    const entry = this.urls.get(code);\n    if (!entry) return { status: 404, message: 'Not found' };\n    if (Date.now() > entry.expiresAt) {\n      this.urls.delete(code);\n      return { status: 410, message: 'URL expired' };\n    }\n    return { status: 302, redirectTo: entry.longUrl };\n  }\n  cleanup() {\n    const now = Date.now();\n    let removed = 0;\n    for (const [code, entry] of this.urls) {\n      if (now > entry.expiresAt) { this.urls.delete(code); removed++; }\n    }\n    return { removed, remaining: this.urls.size };\n  }\n}\n\nconst store = new ExpiringURLStore();\nstore.add('abc', 'https://example.com', 5000); // 5 second TTL\nstore.add('xyz', 'https://other.com', 60000); // 60 second TTL\nconsole.log(store.resolve('abc')); // valid\nconsole.log(store.resolve('xyz')); // valid\nconsole.log(store.resolve('nope')); // not found",
      "output": "{ status: 302, redirectTo: 'https://example.com' }\n{ status: 302, redirectTo: 'https://other.com' }\n{ status: 404, message: 'Not found' }"
    },
    {
      "question": "Program 6: Distributed counter range allocator",
      "code": "class CounterAllocator {\n  constructor(rangeSize) {\n    this.rangeSize = rangeSize;\n    this.nextStart = 1;\n    this.allocations = [];\n  }\n  allocate(serverId) {\n    const range = { serverId, start: this.nextStart, end: this.nextStart + this.rangeSize - 1 };\n    this.nextStart += this.rangeSize;\n    this.allocations.push(range);\n    return range;\n  }\n  status() {\n    return {\n      totalAllocated: this.nextStart - 1,\n      servers: this.allocations.map(a => `${a.serverId}: [${a.start}-${a.end}]`),\n    };\n  }\n}\n\nconst alloc = new CounterAllocator(1000000);\nconsole.log(alloc.allocate('server-1'));\nconsole.log(alloc.allocate('server-2'));\nconsole.log(alloc.allocate('server-1')); // server-1 needs more\nconsole.log(alloc.status());",
      "output": "{ serverId: 'server-1', start: 1, end: 1000000 }\n{ serverId: 'server-2', start: 1000001, end: 2000000 }\n{ serverId: 'server-1', start: 2000001, end: 3000000 }\n{\n  totalAllocated: 3000000,\n  servers: [ 'server-1: [1-1000000]', 'server-2: [1000001-2000000]', 'server-1: [2000001-3000000]' ]\n}"
    },
    {
      "question": "Program 7: LRU Cache for hot URLs",
      "code": "class LRUCache {\n  constructor(capacity) {\n    this.capacity = capacity;\n    this.cache = new Map();\n    this.hits = 0;\n    this.misses = 0;\n  }\n  get(key) {\n    if (!this.cache.has(key)) { this.misses++; return null; }\n    this.hits++;\n    const val = this.cache.get(key);\n    this.cache.delete(key);\n    this.cache.set(key, val); // move to end (most recent)\n    return val;\n  }\n  put(key, val) {\n    if (this.cache.has(key)) this.cache.delete(key);\n    this.cache.set(key, val);\n    if (this.cache.size > this.capacity) {\n      const oldest = this.cache.keys().next().value;\n      this.cache.delete(oldest);\n    }\n  }\n  stats() {\n    const total = this.hits + this.misses;\n    return { size: this.cache.size, hitRate: total ? (this.hits/total*100).toFixed(1)+'%' : 'N/A' };\n  }\n}\n\nconst cache = new LRUCache(3);\ncache.put('a', 'url-a'); cache.put('b', 'url-b'); cache.put('c', 'url-c');\nconsole.log(cache.get('a')); // hit\ncache.put('d', 'url-d'); // evicts 'b'\nconsole.log(cache.get('b')); // miss\nconsole.log(cache.get('c')); // hit\nconsole.log(cache.stats());",
      "output": "url-a\nnull\nurl-c\n{ size: 3, hitRate: '66.7%' }"
    },
    {
      "question": "Program 8: URL validator",
      "code": "function validateURL(url) {\n  const checks = [];\n  // Protocol check\n  const hasProtocol = /^https?:\\/\\//.test(url);\n  checks.push({ check: 'Protocol', pass: hasProtocol });\n  // Domain check\n  const domainMatch = url.match(/^https?:\\/\\/([^/]+)/);\n  const hasDomain = domainMatch && domainMatch[1].includes('.');\n  checks.push({ check: 'Domain', pass: !!hasDomain });\n  // Length check\n  checks.push({ check: 'Length', pass: url.length <= 2048 });\n  // No spaces\n  checks.push({ check: 'No spaces', pass: !url.includes(' ') });\n  \n  return { url: url.substring(0, 50) + (url.length > 50 ? '...' : ''), valid: checks.every(c => c.pass), checks };\n}\n\nconsole.log(validateURL('https://www.example.com/path?q=test'));\nconsole.log(validateURL('not-a-url'));\nconsole.log(validateURL('https://no-dot'));",
      "output": "{ url: 'https://www.example.com/path?q=test', valid: true, checks: [...all pass] }\n{ url: 'not-a-url', valid: false, checks: [Protocol: fail, ...] }\n{ url: 'https://no-dot', valid: false, checks: [Domain: fail, ...] }"
    },
    {
      "question": "Program 9: Collision-free hash-based shortener",
      "code": "function hashShorten(url, existingCodes) {\n  let attempt = 0;\n  while (attempt < 5) {\n    const input = attempt === 0 ? url : `${url}#${attempt}`;\n    // Simple hash (in production: use MD5/SHA256)\n    let hash = 0;\n    for (const char of input) hash = ((hash << 5) - hash + char.charCodeAt(0)) | 0;\n    hash = Math.abs(hash);\n    const chars = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ';\n    let code = '';\n    let n = hash;\n    for (let i = 0; i < 7; i++) { code += chars[n % 62]; n = Math.floor(n / 62); }\n    \n    if (!existingCodes.has(code)) {\n      existingCodes.add(code);\n      return { code, attempts: attempt + 1 };\n    }\n    attempt++;\n  }\n  return { error: 'Max collision retries exceeded' };\n}\n\nconst existing = new Set();\nconsole.log(hashShorten('https://example.com/1', existing));\nconsole.log(hashShorten('https://example.com/2', existing));\nconsole.log(hashShorten('https://example.com/3', existing));\nconsole.log('Total codes:', existing.size);",
      "output": "{ code: 'aBcDeFg', attempts: 1 }\n{ code: 'xYzAbCd', attempts: 1 }\n{ code: 'mNoPqRs', attempts: 1 }\nTotal codes: 3"
    },
    {
      "question": "Program 10: Multi-region redirect resolver",
      "code": "class MultiRegionResolver {\n  constructor() {\n    this.regions = new Map(); // region -> cache\n    this.primary = new Map(); // source of truth\n  }\n  addRegion(name) { this.regions.set(name, new Map()); }\n  write(code, url) {\n    this.primary.set(code, url);\n    // Async replication to all regions\n    for (const cache of this.regions.values()) cache.set(code, url);\n  }\n  resolve(code, region) {\n    const cache = this.regions.get(region);\n    if (cache?.has(code)) return { source: `${region}-cache`, url: cache.get(code) };\n    // Fallback to primary\n    if (this.primary.has(code)) {\n      const url = this.primary.get(code);\n      cache?.set(code, url); // warm cache\n      return { source: 'primary', url };\n    }\n    return { source: 'none', url: null };\n  }\n}\n\nconst resolver = new MultiRegionResolver();\nresolver.addRegion('us-east');\nresolver.addRegion('eu-west');\nresolver.write('abc', 'https://example.com');\nconsole.log(resolver.resolve('abc', 'us-east'));\nconsole.log(resolver.resolve('abc', 'eu-west'));\nconsole.log(resolver.resolve('xyz', 'us-east'));",
      "output": "{ source: 'us-east-cache', url: 'https://example.com' }\n{ source: 'eu-west-cache', url: 'https://example.com' }\n{ source: 'none', url: null }"
    }
  ]
}
