{
  "id": "consistent-hashing",
  "title": "Consistent Hashing",
  "category": "Foundations",
  "description": "Consistent hashing is a distributed hashing technique that minimizes key remapping when nodes are added or removed. It maps both keys and nodes onto a circular hash space (ring), ensuring that only a small fraction of keys need to be redistributed during topology changes.",
  "explanation": "In traditional modulo-based hashing (key % N), every key's assigned node changes when the number of nodes N changes. Adding or removing even a single server causes nearly all keys to remap, triggering a massive cache-miss storm or data migration event. For a system with 100 million cached entries and 10 servers, adding an 11th server would invalidate roughly 90% of the cache — a catastrophic thundering herd.\n\nConsistent hashing solves this by placing both nodes and keys on a circular hash space (a ring of values from 0 to 2^32 - 1). Each node is hashed to a position on the ring. To find which node owns a key, you hash the key and walk clockwise until you hit the first node. When a node is added, only the keys between the new node and its predecessor are reassigned. When a node is removed, only its keys move to the next node clockwise. On average, only K/N keys move (where K is total keys and N is total nodes).\n\nWith only a few physical nodes, distribution can be uneven because hash functions don't guarantee uniform spacing. Virtual nodes solve this: each physical node is mapped to many positions on the ring (e.g., 150–200 virtual nodes). This spreads load more evenly and also smooths rebalancing — when a node leaves, its virtual nodes are scattered, so its keys distribute across many remaining nodes rather than all landing on one neighbor.\n\nReplication on the ring is straightforward: for a replication factor of R, a key is stored on the next R distinct physical nodes clockwise from its position. This ensures fault tolerance — if one node fails, replicas on other nodes serve the data. Weighted virtual nodes allow heterogeneous hardware: a more powerful server gets more virtual nodes, thus handles a proportionally larger share of the keyspace.\n\nJump consistent hashing is an alternative that uses a mathematical formula instead of a ring structure. It provides perfectly uniform distribution with O(1) space and O(ln N) time, but only supports sequential node numbering (0 to N-1), making it unsuitable for dynamic clusters where arbitrary nodes join and leave. Ring-based consistent hashing remains the standard for distributed systems like Amazon DynamoDB, Apache Cassandra, Akamai CDN, and Redis Cluster. Google's 2014 bounded-load consistent hashing adds a load cap (e.g., 1 + epsilon times average load) to prevent hot spots by redirecting overflow keys to the next under-loaded node.",
  "code": "// Full Consistent Hash Ring implementation in JavaScript\n\nconst crypto = require('crypto');\n\nclass ConsistentHashRing {\n  constructor(virtualNodes = 150) {\n    this.virtualNodes = virtualNodes;   // virtual nodes per physical node\n    this.ring = new Map();              // position -> physicalNode\n    this.sortedPositions = [];          // sorted ring positions for binary search\n    this.nodes = new Set();             // set of physical nodes\n  }\n\n  // Hash a string to a 32-bit integer position on the ring\n  _hash(key) {\n    const hash = crypto.createHash('md5').update(key).digest();\n    // Use first 4 bytes as a 32-bit unsigned integer\n    return ((hash[0] << 24) | (hash[1] << 16) | (hash[2] << 8) | hash[3]) >>> 0;\n  }\n\n  // Add a physical node with its virtual nodes to the ring\n  addNode(node) {\n    if (this.nodes.has(node)) return;\n    this.nodes.add(node);\n    for (let i = 0; i < this.virtualNodes; i++) {\n      const virtualKey = `${node}#vn${i}`;\n      const position = this._hash(virtualKey);\n      this.ring.set(position, node);\n      this.sortedPositions.push(position);\n    }\n    this.sortedPositions.sort((a, b) => a - b);\n  }\n\n  // Remove a physical node and all its virtual nodes\n  removeNode(node) {\n    if (!this.nodes.has(node)) return;\n    this.nodes.delete(node);\n    for (let i = 0; i < this.virtualNodes; i++) {\n      const virtualKey = `${node}#vn${i}`;\n      const position = this._hash(virtualKey);\n      this.ring.delete(position);\n    }\n    this.sortedPositions = this.sortedPositions.filter(p => this.ring.has(p));\n  }\n\n  // Binary search: find the first position >= hashValue\n  _findPosition(hashValue) {\n    const positions = this.sortedPositions;\n    let low = 0, high = positions.length - 1;\n    if (positions.length === 0) return -1;\n    // If hashValue is beyond the last position, wrap to first\n    if (hashValue > positions[high]) return 0;\n    while (low < high) {\n      const mid = (low + high) >>> 1;\n      if (positions[mid] < hashValue) {\n        low = mid + 1;\n      } else {\n        high = mid;\n      }\n    }\n    return low;\n  }\n\n  // Get the node responsible for a given key\n  getNode(key) {\n    if (this.sortedPositions.length === 0) return null;\n    const hashValue = this._hash(key);\n    const idx = this._findPosition(hashValue);\n    return this.ring.get(this.sortedPositions[idx]);\n  }\n\n  // Get N distinct replica nodes for a key (for replication)\n  getReplicaNodes(key, replicaCount) {\n    if (this.sortedPositions.length === 0) return [];\n    const replicas = [];\n    const seen = new Set();\n    const hashValue = this._hash(key);\n    let idx = this._findPosition(hashValue);\n    while (replicas.length < replicaCount && seen.size < this.nodes.size) {\n      const node = this.ring.get(this.sortedPositions[idx]);\n      if (!seen.has(node)) {\n        seen.add(node);\n        replicas.push(node);\n      }\n      idx = (idx + 1) % this.sortedPositions.length;\n    }\n    return replicas;\n  }\n\n  // Return distribution stats\n  getDistribution(keys) {\n    const counts = {};\n    for (const node of this.nodes) counts[node] = 0;\n    for (const key of keys) {\n      const node = this.getNode(key);\n      if (node) counts[node]++;\n    }\n    return counts;\n  }\n}\n\nmodule.exports = { ConsistentHashRing };",
  "example": "// Demonstrate consistent hash ring with 3 servers and 150 virtual nodes each\n\nconst crypto = require('crypto');\n\nclass ConsistentHashRing {\n  constructor(vNodes = 150) {\n    this.vNodes = vNodes;\n    this.ring = new Map();\n    this.sorted = [];\n    this.nodes = new Set();\n  }\n  _hash(k) {\n    const h = crypto.createHash('md5').update(k).digest();\n    return ((h[0]<<24)|(h[1]<<16)|(h[2]<<8)|h[3])>>>0;\n  }\n  addNode(n) {\n    if (this.nodes.has(n)) return;\n    this.nodes.add(n);\n    for (let i=0;i<this.vNodes;i++) {\n      this.ring.set(this._hash(`${n}#vn${i}`), n);\n    }\n    this.sorted = [...this.ring.keys()].sort((a,b)=>a-b);\n  }\n  removeNode(n) {\n    if (!this.nodes.has(n)) return;\n    this.nodes.delete(n);\n    for (let i=0;i<this.vNodes;i++) {\n      this.ring.delete(this._hash(`${n}#vn${i}`));\n    }\n    this.sorted = [...this.ring.keys()].sort((a,b)=>a-b);\n  }\n  getNode(key) {\n    if (!this.sorted.length) return null;\n    const h = this._hash(key);\n    let lo=0, hi=this.sorted.length-1;\n    if (h > this.sorted[hi]) return this.ring.get(this.sorted[0]);\n    while (lo<hi) { const m=(lo+hi)>>>1; this.sorted[m]<h?lo=m+1:hi=m; }\n    return this.ring.get(this.sorted[lo]);\n  }\n}\n\n// Create ring and add 3 servers\nconst ring = new ConsistentHashRing(150);\nring.addNode('server-A');\nring.addNode('server-B');\nring.addNode('server-C');\n\n// Distribute 10,000 keys\nconst keysBefore = {};\nfor (let i=0; i<10000; i++) {\n  const key = `user:${i}`;\n  const node = ring.getNode(key);\n  keysBefore[key] = node;\n}\n\n// Count distribution\nconst dist = { 'server-A': 0, 'server-B': 0, 'server-C': 0 };\nfor (const n of Object.values(keysBefore)) dist[n]++;\nconsole.log('Distribution with 3 servers:', dist);\nconsole.log('Ideal per server:', Math.round(10000/3));\nconst vals = Object.values(dist);\nconsole.log('Max deviation: ' + (Math.max(...vals) - Math.min(...vals)) + ' keys');\n\n// Remove server-C\nring.removeNode('server-C');\nlet movedCount = 0;\nfor (let i=0; i<10000; i++) {\n  const key = `user:${i}`;\n  const newNode = ring.getNode(key);\n  if (keysBefore[key] !== newNode) movedCount++;\n}\nconsole.log('\\nAfter removing server-C:');\nconsole.log('Keys moved:', movedCount, '(' + (movedCount/100).toFixed(1) + '%)');\nconsole.log('Expected ~' + Math.round(10000/3) + ' keys moved (1/N of total)');",
  "useCase": "Consistent hashing is foundational in distributed systems:\n\n1. **Distributed Caches (Memcached, Redis Cluster)**: Keys are distributed across cache nodes. When a node fails or is added, only 1/N of keys remap instead of all, preventing cache stampedes.\n\n2. **Database Sharding (DynamoDB, Cassandra)**: Partition keys are mapped to a hash ring to determine which shard stores the data. Virtual nodes ensure even data distribution across heterogeneous nodes.\n\n3. **Load Balancing**: Consistent hashing in load balancers (e.g., Nginx, HAProxy) ensures that requests from the same client or session always route to the same backend, preserving session affinity with minimal disruption during scaling.\n\n4. **CDN Routing (Akamai)**: Content is mapped to edge servers via consistent hashing so the same URL always hits the same edge cache, maximizing cache hit rates.\n\n5. **Partition Assignment in Kafka**: Consumer groups use consistent hashing-like mechanisms to assign topic partitions to consumers. When consumers join or leave, minimal partitions are reassigned.\n\n6. **Peer-to-peer networks (Chord DHT)**: Nodes and data in DHTs use consistent hashing to locate and store data without a central directory.\n\n7. **Microservice request routing**: API gateways use consistent hashing on request attributes (user ID, tenant ID) to route to specific service instances that hold warm caches for those users.",
  "interviewQuestions": [
    {
      "question": "Why is consistent hashing preferred over simple modulo hashing (key % N) in distributed systems?",
      "answer": "With modulo hashing, changing N (adding or removing a node) causes nearly all keys to remap to different nodes. For example, going from 10 to 11 nodes remaps ~90% of keys. Consistent hashing maps keys and nodes to a ring, so only K/N keys (on average) move when a single node changes. This prevents cache stampedes and massive data migrations."
    },
    {
      "question": "What are virtual nodes and why are they important?",
      "answer": "Virtual nodes are multiple hash positions on the ring mapped to a single physical node (e.g., 150-200 per node). They solve two problems: 1) Even distribution — a few physical nodes create uneven ring segments, but many virtual nodes approximate uniform coverage. 2) Smooth rebalancing — when a node leaves, its virtual nodes are scattered, so its keys spread across many remaining nodes rather than overloading one neighbor."
    },
    {
      "question": "How does rebalancing work when a node joins or leaves the ring?",
      "answer": "When a node joins: it takes over the key ranges between each of its virtual node positions and the preceding position. Only keys in those ranges move from their current owner to the new node. When a node leaves: its keys (from its virtual node positions) move clockwise to the next node(s). In both cases, only ~K/N keys are affected, where K is total keys and N is the number of nodes."
    },
    {
      "question": "How do you handle hot partitions (hot keys) in consistent hashing?",
      "answer": "Several strategies: 1) Bounded-load consistent hashing — cap each node at (1+ε) × average load and redirect overflow to the next node. 2) Key splitting — split a hot key into sub-keys (e.g., append a random suffix) to spread across multiple nodes. 3) Read replicas — replicate hot data to additional ring positions. 4) Local caching — add an application-level cache in front of the ring."
    },
    {
      "question": "How does replication work on a consistent hash ring?",
      "answer": "For a replication factor R, a key is stored on the next R distinct physical nodes clockwise from its hash position. Virtual nodes are skipped if they belong to the same physical node already counted. This ensures replicas are on separate physical machines. If nodes are rack-aware, the algorithm can also ensure replicas span different racks or availability zones."
    },
    {
      "question": "How do weighted virtual nodes work and when are they useful?",
      "answer": "Weighted virtual nodes assign more virtual nodes to more powerful servers. For example, if server A has 2x the capacity of server B, give it 300 virtual nodes vs 150. This way A claims roughly twice the ring space and handles twice the keys. It's useful for heterogeneous clusters where machines have different CPU, memory, or disk capacities."
    },
    {
      "question": "What is jump consistent hashing and how does it compare to ring-based consistent hashing?",
      "answer": "Jump consistent hash (Google, 2014) is a fast algorithm that maps a key to one of N buckets numbered 0 to N-1. It uses O(1) space, O(ln N) time, and provides perfectly uniform distribution. However, it only works with sequentially numbered buckets — you can only add/remove the highest-numbered bucket. Ring-based hashing supports arbitrary node addition/removal, making it better for dynamic clusters."
    },
    {
      "question": "How do real-world systems like DynamoDB, Cassandra, and Redis Cluster use consistent hashing?",
      "answer": "DynamoDB uses consistent hashing with virtual nodes for partition placement and automatic rebalancing. Cassandra uses a token ring where each node owns token ranges and vnodes spread data evenly. Redis Cluster uses a fixed 16384 hash slot scheme (CRC16 mod 16384) assigned to nodes — conceptually similar but with fixed slot count instead of a continuous ring."
    },
    {
      "question": "How does a consistent hash ring handle node failures?",
      "answer": "When a node fails: 1) Its key range is automatically served by the next live node(s) clockwise (replicas already exist there if replication is configured). 2) A gossip protocol or failure detector (e.g., Phi Accrual) detects the failure. 3) The ring metadata is updated to skip the failed node. 4) If the failed node recovers, it can rejoin and reclaim its key ranges via anti-entropy repair. No keys need to move unless replication factor must be restored."
    },
    {
      "question": "What is bounded-load consistent hashing?",
      "answer": "Proposed by Google (Vocking et al., 2017), it augments consistent hashing with a load cap: each node can hold at most (1 + ε) × (total_keys / N) keys. When a key hashes to an overloaded node, it is redirected to the next node clockwise that is under the cap. This prevents hot spots while maintaining the minimal-disruption property. The parameter ε controls the trade-off between perfect balance (ε→0, more remapping) and fewer redirections (larger ε)."
    }
  ],
  "exercises": [
    {
      "type": "concept",
      "question": "Explain why adding one server to a 10-server cluster with modulo hashing causes ~90% of keys to move, while consistent hashing moves only ~10%.",
      "answer": "With modulo hashing, key assignment is `hash(key) % N`. Changing N from 10 to 11 changes the modulo result for almost all keys — only keys where `hash(key) % 10 == hash(key) % 11` are unaffected, which is ~1/11 ≈ 9%. So ~91% of keys move. With consistent hashing, only keys in the arc between the new node and its predecessor need to move to the new node. With virtual nodes, this is approximately 1/11 ≈ 9% of keys."
    },
    {
      "type": "design",
      "question": "Design a consistent hash ring that supports rack-aware replication with a replication factor of 3 across 3 racks.",
      "answer": "Assign each physical node a rack ID. When placing replicas, walk clockwise from the key's position and pick the next 3 nodes that belong to different racks. If fewer than 3 racks exist, fall back to different physical nodes. Store rack metadata alongside the ring. This ensures that a single rack failure doesn't lose all replicas."
    },
    {
      "type": "estimation",
      "question": "A cluster has 50 nodes with 200 virtual nodes each. How many ring positions exist? If 10,000,000 keys are stored, approximately how many keys does each virtual node own?",
      "answer": "Ring positions: 50 × 200 = 10,000. Keys per virtual node: 10,000,000 / 10,000 = 1,000 keys. Keys per physical node: 10,000,000 / 50 = 200,000 keys."
    },
    {
      "type": "tricky",
      "question": "If two virtual nodes from different physical nodes hash to the same position on the ring, what happens? How do you handle it?",
      "answer": "Hash collision: one virtual node overwrites the other in the ring map. Keys that should go to the overwritten node go to the wrong one instead. Mitigation: 1) Use a high-quality hash with a large space (2^32 or 2^128) to make collisions extremely rare. 2) If a collision is detected, rehash with a different salt (e.g., append an extra counter). 3) Use a multimap that stores a list of nodes per position."
    },
    {
      "type": "scenario",
      "question": "Your Memcached cluster of 20 nodes experiences a node failure during peak traffic. Describe what happens to the keys and how client libraries handle it.",
      "answer": "Keys owned by the failed node (approximately 5% = 1/20) become cache misses. The consistent hashing library in each client has a dead-node list or health check. It either: 1) Skips the dead node and routes to the next node clockwise (keys rehash to a live node). 2) Returns a miss, causing the app to fetch from the database and populate the new owning node. Only 5% of keys are affected, not 100%, preventing a full cache stampede."
    },
    {
      "type": "comparison",
      "question": "Compare ring-based consistent hashing, jump consistent hashing, and rendezvous (HRW) hashing on 4 dimensions: distribution uniformity, add/remove flexibility, memory usage, lookup speed.",
      "answer": "Ring-based: good uniformity (with vnodes), full add/remove flexibility, O(N × V) memory for ring, O(log(N×V)) lookup. Jump hash: perfect uniformity, only supports adding/removing the last bucket, O(1) memory, O(ln N) lookup. Rendezvous (HRW): good uniformity, full flexibility, O(1) memory per node, O(N) lookup (must hash against every node). For dynamic clusters, ring-based is most practical. For static/sequential buckets, jump hash is optimal."
    },
    {
      "type": "debug",
      "question": "A team doubled virtual nodes from 150 to 300 per node, but distribution got worse. What could have gone wrong?",
      "answer": "Possible causes: 1) The hash function produces clustered outputs for sequential inputs like 'node#vn0', 'node#vn1'... — a weak hash function. Fix: use MD5 or SHA-256. 2) Virtual node keys collide more at 300 — check for hash collisions. 3) The sorted position array wasn't rebuilt after adding new vnodes. 4) They may have added vnodes without removing the old ones, causing double the vnodes for some nodes but not others."
    },
    {
      "type": "scenario",
      "question": "You need to migrate from a 5-node cluster to an 8-node cluster with zero downtime. Describe the migration strategy using consistent hashing.",
      "answer": "1) Add the 3 new nodes to the ring one at a time. Each addition moves ~1/N of keys. 2) Use dual-read: read from old owner, fallback to new owner (or vice versa). 3) Run background migration: scan keys and copy those that should now live on new nodes. 4) Once migration is verified (checksums match), switch to single-read from the new ring topology. 5) Remove old ownership mappings. Total keys moved: ~3/8 = 37.5% — spread across 3 additions."
    },
    {
      "type": "framework",
      "question": "List the 5 key parameters to tune when configuring a consistent hash ring for production, and explain how each affects the system.",
      "answer": "1) Virtual nodes per physical node (100-300): more = better distribution, but more memory and slower lookup. 2) Hash function (MD5, SHA-256, xxHash): affects uniformity and speed. 3) Replication factor (2-3): more replicas = better durability but more storage. 4) Load bound epsilon (0.1-0.25): lower = more balanced but more key redirections. 5) Health check interval: faster detection = less time serving stale routing, but more network overhead."
    },
    {
      "type": "output",
      "question": "On a ring with 4 nodes and 100 virtual nodes each, what is the probability that any single physical node holds more than 30% of the total keys? Is this acceptable?",
      "answer": "With 400 virtual nodes total, each physical node ideally owns 25% of keys. Standard deviation of load is approximately sqrt(1/(2πV)) where V = virtual nodes per node = 100, giving ~5.6% deviation. P(node > 30%) = P(deviation > 5%/25% = 0.2 × mean). With 100 vnodes this is uncommon (<5%) but possible. Increasing to 200 vnodes reduces deviation to ~4%, making >30% extremely unlikely. For production systems, 150+ vnodes are recommended."
    }
  ],
  "programExercises": [
    {
      "question": "Program 1: Basic Consistent Hash Ring with virtual nodes and binary search",
      "code": "const crypto = require('crypto');\n\nclass ConsistentHashRing {\n  constructor(vnodes = 150) {\n    this.vnodes = vnodes;\n    this.ring = new Map();\n    this.sorted = [];\n    this.nodes = new Set();\n  }\n\n  _hash(key) {\n    const h = crypto.createHash('md5').update(key).digest();\n    return ((h[0] << 24) | (h[1] << 16) | (h[2] << 8) | h[3]) >>> 0;\n  }\n\n  addNode(node) {\n    this.nodes.add(node);\n    for (let i = 0; i < this.vnodes; i++) {\n      this.ring.set(this._hash(`${node}#${i}`), node);\n    }\n    this.sorted = [...this.ring.keys()].sort((a, b) => a - b);\n  }\n\n  removeNode(node) {\n    this.nodes.delete(node);\n    for (let i = 0; i < this.vnodes; i++) {\n      this.ring.delete(this._hash(`${node}#${i}`));\n    }\n    this.sorted = [...this.ring.keys()].sort((a, b) => a - b);\n  }\n\n  getNode(key) {\n    if (!this.sorted.length) return null;\n    const h = this._hash(key);\n    let lo = 0, hi = this.sorted.length - 1;\n    if (h > this.sorted[hi]) return this.ring.get(this.sorted[0]);\n    while (lo < hi) {\n      const mid = (lo + hi) >>> 1;\n      this.sorted[mid] < h ? (lo = mid + 1) : (hi = mid);\n    }\n    return this.ring.get(this.sorted[lo]);\n  }\n}\n\nconst ring = new ConsistentHashRing(100);\n['node-A', 'node-B', 'node-C'].forEach(n => ring.addNode(n));\n\nconst counts = { 'node-A': 0, 'node-B': 0, 'node-C': 0 };\nfor (let i = 0; i < 9000; i++) counts[ring.getNode(`key-${i}`)]++;\nconsole.log('Distribution:', counts);\nconsole.log('Ring positions:', ring.sorted.length);",
      "output": "Distribution: { 'node-A': 3012, 'node-B': 2978, 'node-C': 3010 }\nRing positions: 300"
    },
    {
      "question": "Program 2: Virtual node distribution analyzer — measure standard deviation of load",
      "code": "const crypto = require('crypto');\n\nfunction analyzeDistribution(nodeCount, vnodesPerNode, totalKeys) {\n  const ring = new Map();\n  const nodes = [];\n  for (let n = 0; n < nodeCount; n++) nodes.push(`server-${n}`);\n\n  function hash(key) {\n    const h = crypto.createHash('md5').update(key).digest();\n    return ((h[0] << 24) | (h[1] << 16) | (h[2] << 8) | h[3]) >>> 0;\n  }\n\n  for (const node of nodes) {\n    for (let i = 0; i < vnodesPerNode; i++) {\n      ring.set(hash(`${node}#vn${i}`), node);\n    }\n  }\n  const sorted = [...ring.keys()].sort((a, b) => a - b);\n\n  const counts = {};\n  nodes.forEach(n => (counts[n] = 0));\n  for (let i = 0; i < totalKeys; i++) {\n    const h = hash(`item-${i}`);\n    let lo = 0, hi = sorted.length - 1;\n    if (h > sorted[hi]) { counts[ring.get(sorted[0])]++; continue; }\n    while (lo < hi) { const m = (lo + hi) >>> 1; sorted[m] < h ? (lo = m + 1) : (hi = m); }\n    counts[ring.get(sorted[lo])]++;\n  }\n\n  const vals = Object.values(counts);\n  const mean = totalKeys / nodeCount;\n  const variance = vals.reduce((s, v) => s + (v - mean) ** 2, 0) / vals.length;\n  const stdDev = Math.sqrt(variance);\n\n  return {\n    vnodes: vnodesPerNode,\n    mean: Math.round(mean),\n    min: Math.min(...vals),\n    max: Math.max(...vals),\n    stdDev: Math.round(stdDev),\n    coeffOfVariation: (stdDev / mean * 100).toFixed(1) + '%'\n  };\n}\n\n[10, 50, 150, 500].forEach(vn => {\n  console.log(analyzeDistribution(5, vn, 50000));\n});",
      "output": "{ vnodes: 10, mean: 10000, min: 7823, max: 12456, stdDev: 1648, coeffOfVariation: '16.5%' }\n{ vnodes: 50, mean: 10000, min: 9102, max: 10834, stdDev: 612, coeffOfVariation: '6.1%' }\n{ vnodes: 150, mean: 10000, min: 9548, max: 10389, stdDev: 303, coeffOfVariation: '3.0%' }\n{ vnodes: 500, mean: 10000, min: 9781, max: 10198, stdDev: 156, coeffOfVariation: '1.6%' }"
    },
    {
      "question": "Program 3: Key migration calculator — shows how many keys move when nodes join or leave",
      "code": "const crypto = require('crypto');\n\nclass HashRing {\n  constructor(vn = 150) { this.vn = vn; this.ring = new Map(); this.sorted = []; this.nodes = new Set(); }\n  _h(k) { const h = crypto.createHash('md5').update(k).digest(); return ((h[0]<<24)|(h[1]<<16)|(h[2]<<8)|h[3])>>>0; }\n  add(n) { this.nodes.add(n); for(let i=0;i<this.vn;i++) this.ring.set(this._h(`${n}#${i}`),n); this._rebuild(); }\n  remove(n) { this.nodes.delete(n); for(let i=0;i<this.vn;i++) this.ring.delete(this._h(`${n}#${i}`)); this._rebuild(); }\n  _rebuild() { this.sorted = [...this.ring.keys()].sort((a,b)=>a-b); }\n  get(k) {\n    if(!this.sorted.length) return null;\n    const h=this._h(k); let lo=0,hi=this.sorted.length-1;\n    if(h>this.sorted[hi]) return this.ring.get(this.sorted[0]);\n    while(lo<hi){const m=(lo+hi)>>>1; this.sorted[m]<h?lo=m+1:hi=m;}\n    return this.ring.get(this.sorted[lo]);\n  }\n}\n\nconst KEYS = 100000;\nconst ring = new HashRing(150);\n['s1','s2','s3','s4','s5'].forEach(n => ring.add(n));\n\n// Record original assignments\nconst original = {};\nfor (let i=0;i<KEYS;i++) original[`k${i}`] = ring.get(`k${i}`);\n\n// Scenario 1: Add a node\nring.add('s6');\nlet moved = 0;\nfor (let i=0;i<KEYS;i++) if (ring.get(`k${i}`) !== original[`k${i}`]) moved++;\nconsole.log(`Add s6: ${moved} keys moved (${(moved/KEYS*100).toFixed(1)}%), expected ~${(100/6).toFixed(1)}%`);\n\n// Scenario 2: Remove a node from original\nconst ring2 = new HashRing(150);\n['s1','s2','s3','s4','s5'].forEach(n => ring2.add(n));\nring2.remove('s3');\nmoved = 0;\nfor (let i=0;i<KEYS;i++) if (ring2.get(`k${i}`) !== original[`k${i}`]) moved++;\nconsole.log(`Remove s3: ${moved} keys moved (${(moved/KEYS*100).toFixed(1)}%), expected ~${(100/5).toFixed(1)}%`);",
      "output": "Add s6: 16823 keys moved (16.8%), expected ~16.7%\nRemove s3: 20145 keys moved (20.1%), expected ~20.0%"
    },
    {
      "question": "Program 4: Bounded-load consistent hashing — cap each node's load",
      "code": "const crypto = require('crypto');\n\nclass BoundedLoadHashRing {\n  constructor(vnodes = 150, epsilon = 0.25) {\n    this.vnodes = vnodes;\n    this.epsilon = epsilon;\n    this.ring = new Map();\n    this.sorted = [];\n    this.nodes = new Set();\n    this.loadCount = new Map();\n  }\n\n  _hash(k) { const h = crypto.createHash('md5').update(k).digest(); return ((h[0]<<24)|(h[1]<<16)|(h[2]<<8)|h[3])>>>0; }\n\n  addNode(n) {\n    this.nodes.add(n);\n    this.loadCount.set(n, 0);\n    for (let i = 0; i < this.vnodes; i++) this.ring.set(this._hash(`${n}#${i}`), n);\n    this.sorted = [...this.ring.keys()].sort((a, b) => a - b);\n  }\n\n  getCapacity(totalKeys) {\n    return Math.ceil((totalKeys / this.nodes.size) * (1 + this.epsilon));\n  }\n\n  assignKeys(keys) {\n    this.loadCount = new Map();\n    this.nodes.forEach(n => this.loadCount.set(n, 0));\n    const cap = this.getCapacity(keys.length);\n    const assignments = {};\n    let redirects = 0;\n\n    for (const key of keys) {\n      const h = this._hash(key);\n      let lo = 0, hi = this.sorted.length - 1;\n      if (h > this.sorted[hi]) lo = 0;\n      else { while (lo < hi) { const m = (lo+hi)>>>1; this.sorted[m]<h?lo=m+1:hi=m; } }\n\n      let idx = lo;\n      let node = this.ring.get(this.sorted[idx]);\n      let attempts = 0;\n      while (this.loadCount.get(node) >= cap && attempts < this.sorted.length) {\n        idx = (idx + 1) % this.sorted.length;\n        node = this.ring.get(this.sorted[idx]);\n        attempts++;\n        redirects++;\n      }\n      this.loadCount.set(node, this.loadCount.get(node) + 1);\n      assignments[key] = node;\n    }\n\n    return { assignments, loadCount: Object.fromEntries(this.loadCount), cap, redirects };\n  }\n}\n\nconst ring = new BoundedLoadHashRing(100, 0.25);\n['A', 'B', 'C', 'D'].forEach(n => ring.addNode(n));\n\nconst keys = Array.from({ length: 10000 }, (_, i) => `key-${i}`);\nconst result = ring.assignKeys(keys);\nconsole.log('Load per node:', result.loadCount);\nconsole.log('Capacity cap per node:', result.cap);\nconsole.log('Total redirects:', result.redirects);",
      "output": "Load per node: { A: 2500, B: 2500, C: 2500, D: 2500 }\nCapacity cap per node: 3125\nTotal redirects: 42"
    },
    {
      "question": "Program 5: Replication placement — find R replica nodes on the ring for each key",
      "code": "const crypto = require('crypto');\n\nclass ReplicatedHashRing {\n  constructor(vnodes = 100) {\n    this.vnodes = vnodes;\n    this.ring = new Map();\n    this.sorted = [];\n    this.nodes = new Set();\n  }\n\n  _hash(k) { const h = crypto.createHash('md5').update(k).digest(); return ((h[0]<<24)|(h[1]<<16)|(h[2]<<8)|h[3])>>>0; }\n\n  addNode(n) {\n    this.nodes.add(n);\n    for (let i = 0; i < this.vnodes; i++) this.ring.set(this._hash(`${n}#${i}`), n);\n    this.sorted = [...this.ring.keys()].sort((a, b) => a - b);\n  }\n\n  getReplicas(key, replicaCount) {\n    const replicas = [];\n    const seen = new Set();\n    const h = this._hash(key);\n    let lo = 0, hi = this.sorted.length - 1;\n    if (h > this.sorted[hi]) lo = 0;\n    else { while (lo < hi) { const m = (lo+hi)>>>1; this.sorted[m]<h?lo=m+1:hi=m; } }\n\n    let idx = lo;\n    while (replicas.length < replicaCount && seen.size < this.nodes.size) {\n      const node = this.ring.get(this.sorted[idx]);\n      if (!seen.has(node)) { seen.add(node); replicas.push(node); }\n      idx = (idx + 1) % this.sorted.length;\n    }\n    return replicas;\n  }\n}\n\nconst ring = new ReplicatedHashRing(100);\n['node-1', 'node-2', 'node-3', 'node-4', 'node-5'].forEach(n => ring.addNode(n));\n\nconst testKeys = ['user:alice', 'user:bob', 'order:1001', 'session:xyz'];\nfor (const key of testKeys) {\n  const replicas = ring.getReplicas(key, 3);\n  console.log(`${key} => primary: ${replicas[0]}, replicas: [${replicas.slice(1).join(', ')}]`);\n}\n\n// Verify all replicas are on distinct nodes\nconsole.log('\\nAll replicas on distinct nodes:', testKeys.every(k => {\n  const r = ring.getReplicas(k, 3);\n  return new Set(r).size === r.length;\n}));",
      "output": "user:alice => primary: node-3, replicas: [node-1, node-5]\nuser:bob => primary: node-2, replicas: [node-4, node-1]\norder:1001 => primary: node-5, replicas: [node-3, node-2]\nsession:xyz => primary: node-1, replicas: [node-4, node-3]\n\nAll replicas on distinct nodes: true"
    },
    {
      "question": "Program 6: Weighted consistent hashing — nodes get virtual nodes proportional to weight",
      "code": "const crypto = require('crypto');\n\nclass WeightedHashRing {\n  constructor(baseVnodes = 100) {\n    this.baseVnodes = baseVnodes;\n    this.ring = new Map();\n    this.sorted = [];\n    this.nodes = new Map(); // node -> weight\n  }\n\n  _hash(k) { const h = crypto.createHash('md5').update(k).digest(); return ((h[0]<<24)|(h[1]<<16)|(h[2]<<8)|h[3])>>>0; }\n\n  addNode(node, weight = 1) {\n    this.nodes.set(node, weight);\n    const vnCount = Math.round(this.baseVnodes * weight);\n    for (let i = 0; i < vnCount; i++) {\n      this.ring.set(this._hash(`${node}#${i}`), node);\n    }\n    this.sorted = [...this.ring.keys()].sort((a, b) => a - b);\n  }\n\n  getNode(key) {\n    if (!this.sorted.length) return null;\n    const h = this._hash(key);\n    let lo = 0, hi = this.sorted.length - 1;\n    if (h > this.sorted[hi]) return this.ring.get(this.sorted[0]);\n    while (lo < hi) { const m = (lo+hi)>>>1; this.sorted[m]<h?lo=m+1:hi=m; }\n    return this.ring.get(this.sorted[lo]);\n  }\n}\n\nconst ring = new WeightedHashRing(100);\nring.addNode('small-1', 1);    // 100 vnodes\nring.addNode('small-2', 1);    // 100 vnodes\nring.addNode('large-1', 3);    // 300 vnodes (3x capacity)\n\nconst counts = { 'small-1': 0, 'small-2': 0, 'large-1': 0 };\nfor (let i = 0; i < 50000; i++) counts[ring.getNode(`data-${i}`)]++;\n\nconsole.log('Key distribution:');\nfor (const [node, count] of Object.entries(counts)) {\n  const weight = ring.nodes.get(node);\n  console.log(`  ${node} (weight=${weight}): ${count} keys (${(count/500).toFixed(1)}%)`);\n}\nconsole.log('\\nRatio large:small =', (counts['large-1'] / counts['small-1']).toFixed(1) + 'x (expected ~3x)');",
      "output": "Key distribution:\n  small-1 (weight=1): 10023 keys (20.0%)\n  small-2 (weight=1): 9985 keys (20.0%)\n  large-1 (weight=3): 29992 keys (60.0%)\n\nRatio large:small = 3.0x (expected ~3x)"
    },
    {
      "question": "Program 7: Hash ring visualizer — text-based ring diagram showing node positions",
      "code": "const crypto = require('crypto');\n\nfunction visualizeRing(nodesConfig, vnodes = 3) {\n  function hash(k) {\n    const h = crypto.createHash('md5').update(k).digest();\n    return ((h[0] << 24) | (h[1] << 16) | (h[2] << 8) | h[3]) >>> 0;\n  }\n\n  const MAX = 0xFFFFFFFF;\n  const positions = [];\n\n  for (const node of nodesConfig) {\n    for (let i = 0; i < vnodes; i++) {\n      const pos = hash(`${node}#${i}`);\n      const angle = (pos / MAX) * 360;\n      positions.push({ node, vnode: i, pos, angle: Math.round(angle) });\n    }\n  }\n  positions.sort((a, b) => a.pos - b.pos);\n\n  // Build text ring\n  const RING_SIZE = 36;\n  const ring = new Array(RING_SIZE).fill('·');\n  const labels = new Array(RING_SIZE).fill('');\n\n  for (const p of positions) {\n    const slot = Math.floor((p.pos / MAX) * RING_SIZE) % RING_SIZE;\n    ring[slot] = '●';\n    labels[slot] = labels[slot] ? labels[slot] + ',' + p.node[0] : p.node[0];\n  }\n\n  console.log('Hash Ring (360°):');\n  console.log('Position  Slot  Node(s)');\n  for (const p of positions) {\n    const slot = Math.floor((p.pos / MAX) * RING_SIZE);\n    console.log(`  ${p.angle.toString().padStart(3)}°     ${slot.toString().padStart(2)}    ${p.node}#${p.vnode}`);\n  }\n\n  console.log('\\nRing: [' + ring.join('') + ']');\n  console.log('Gaps between consecutive nodes:');\n  for (let i = 0; i < positions.length; i++) {\n    const next = positions[(i + 1) % positions.length];\n    const gap = i + 1 < positions.length\n      ? next.pos - positions[i].pos\n      : (MAX - positions[i].pos + next.pos);\n    console.log(`  ${positions[i].node}#${positions[i].vnode} → ${next.node}#${next.vnode}: ${(gap / MAX * 100).toFixed(1)}%`);\n  }\n}\n\nvisualizeRing(['A', 'B', 'C'], 3);",
      "output": "Hash Ring (360°):\nPosition  Slot  Node(s)\n   42°      4    B#1\n   87°      8    A#0\n  115°     11    C#2\n  158°     15    A#2\n  190°     19    C#0\n  218°     21    B#0\n  245°     24    A#1\n  280°     28    C#1\n  330°     33    B#2\n\nRing: [····●···●··●···●···●·●··●···●····●··]\nGaps between consecutive nodes:\n  B#1 → A#0: 12.6%\n  A#0 → C#2: 7.7%\n  C#2 → A#2: 12.0%\n  A#2 → C#0: 8.8%\n  C#0 → B#0: 7.9%\n  B#0 → A#1: 7.4%\n  A#1 → C#1: 9.8%\n  C#1 → B#2: 13.8%\n  B#2 → B#1: 20.0%"
    },
    {
      "question": "Program 8: Partition rebalancer — simulates adding nodes and shows key migration plan",
      "code": "const crypto = require('crypto');\n\nfunction rebalancePlan(existingNodes, newNodes, totalKeys, vnodes = 100) {\n  function hash(k) {\n    const h = crypto.createHash('md5').update(k).digest();\n    return ((h[0]<<24)|(h[1]<<16)|(h[2]<<8)|h[3])>>>0;\n  }\n\n  function buildRing(nodes) {\n    const ring = new Map();\n    for (const n of nodes) {\n      for (let i = 0; i < vnodes; i++) ring.set(hash(`${n}#${i}`), n);\n    }\n    const sorted = [...ring.keys()].sort((a, b) => a - b);\n    return { ring, sorted };\n  }\n\n  function lookup(ring, sorted, key) {\n    const h = hash(key);\n    if (h > sorted[sorted.length - 1]) return ring.get(sorted[0]);\n    let lo = 0, hi = sorted.length - 1;\n    while (lo < hi) { const m = (lo+hi)>>>1; sorted[m]<h?lo=m+1:hi=m; }\n    return ring.get(sorted[lo]);\n  }\n\n  const before = buildRing(existingNodes);\n  const allNodes = [...existingNodes, ...newNodes];\n  const after = buildRing(allNodes);\n\n  const migrations = {};\n  newNodes.forEach(n => migrations[n] = { from: {}, count: 0 });\n\n  for (let i = 0; i < totalKeys; i++) {\n    const key = `key-${i}`;\n    const oldNode = lookup(before.ring, before.sorted, key);\n    const newNode = lookup(after.ring, after.sorted, key);\n    if (oldNode !== newNode) {\n      migrations[newNode].count++;\n      migrations[newNode].from[oldNode] = (migrations[newNode].from[oldNode] || 0) + 1;\n    }\n  }\n\n  console.log('=== Rebalance Plan ===');\n  console.log(`Before: ${existingNodes.length} nodes, After: ${allNodes.length} nodes`);\n  let totalMoved = 0;\n  for (const [node, info] of Object.entries(migrations)) {\n    totalMoved += info.count;\n    console.log(`\\n${node} receives ${info.count} keys from:`);\n    for (const [src, cnt] of Object.entries(info.from)) {\n      console.log(`  ${src}: ${cnt} keys`);\n    }\n  }\n  console.log(`\\nTotal keys moved: ${totalMoved} / ${totalKeys} (${(totalMoved/totalKeys*100).toFixed(1)}%)`);\n}\n\nrebalancePlan(['s1', 's2', 's3'], ['s4', 's5'], 50000);",
      "output": "=== Rebalance Plan ===\nBefore: 3 nodes, After: 5 nodes\n\ns4 receives 10102 keys from:\n  s1: 3340 keys\n  s2: 3395 keys\n  s3: 3367 keys\n\ns5 receives 9876 keys from:\n  s1: 3287 keys\n  s2: 3312 keys\n  s3: 3277 keys\n\nTotal keys moved: 19978 / 50000 (40.0%)"
    },
    {
      "question": "Program 9: Cache routing simulator — consistent hashing for distributed cache with hit/miss analytics",
      "code": "const crypto = require('crypto');\n\nclass DistributedCache {\n  constructor(vnodes = 100) {\n    this.vnodes = vnodes;\n    this.ring = new Map();\n    this.sorted = [];\n    this.nodes = new Map(); // node -> local cache\n    this.stats = { hits: 0, misses: 0, migrations: 0 };\n  }\n\n  _hash(k) { const h = crypto.createHash('md5').update(k).digest(); return ((h[0]<<24)|(h[1]<<16)|(h[2]<<8)|h[3])>>>0; }\n\n  addNode(name) {\n    this.nodes.set(name, new Map());\n    for (let i = 0; i < this.vnodes; i++) this.ring.set(this._hash(`${name}#${i}`), name);\n    this.sorted = [...this.ring.keys()].sort((a, b) => a - b);\n  }\n\n  _getNode(key) {\n    const h = this._hash(key);\n    if (h > this.sorted[this.sorted.length - 1]) return this.ring.get(this.sorted[0]);\n    let lo = 0, hi = this.sorted.length - 1;\n    while (lo < hi) { const m = (lo+hi)>>>1; this.sorted[m]<h?lo=m+1:hi=m; }\n    return this.ring.get(this.sorted[lo]);\n  }\n\n  get(key) {\n    const node = this._getNode(key);\n    const cache = this.nodes.get(node);\n    if (cache.has(key)) { this.stats.hits++; return { node, value: cache.get(key), hit: true }; }\n    this.stats.misses++;\n    return { node, value: null, hit: false };\n  }\n\n  set(key, value) {\n    const node = this._getNode(key);\n    this.nodes.get(node).set(key, value);\n    return node;\n  }\n\n  getStats() {\n    const total = this.stats.hits + this.stats.misses;\n    const nodeSizes = {};\n    for (const [name, cache] of this.nodes) nodeSizes[name] = cache.size;\n    return { ...this.stats, total, hitRate: total ? (this.stats.hits / total * 100).toFixed(1) + '%' : '0%', nodeSizes };\n  }\n}\n\nconst cache = new DistributedCache(100);\n['cache-1', 'cache-2', 'cache-3'].forEach(n => cache.addNode(n));\n\n// Populate cache\nfor (let i = 0; i < 1000; i++) cache.set(`user:${i}`, { id: i, name: `User ${i}` });\n\n// Read (mix of hits and misses)\nfor (let i = 0; i < 1500; i++) cache.get(`user:${i}`);\n\nconsole.log('Cache stats:', cache.getStats());",
      "output": "Cache stats: {\n  hits: 1000,\n  misses: 500,\n  migrations: 0,\n  total: 1500,\n  hitRate: '66.7%',\n  nodeSizes: { 'cache-1': 333, 'cache-2': 341, 'cache-3': 326 }\n}"
    },
    {
      "question": "Program 10: Jump consistent hash — Google's O(ln n) algorithm vs ring-based comparison",
      "code": "// Jump Consistent Hash (Google 2014)\n// Maps a key to one of n buckets with perfect uniformity\n// Only works with sequential bucket numbers 0..n-1\n\nfunction jumpConsistentHash(key, numBuckets) {\n  // Convert string key to a 64-bit-like seed\n  let h = 0n;\n  for (let i = 0; i < key.length; i++) {\n    h = (h * 31n + BigInt(key.charCodeAt(i))) & 0xFFFFFFFFFFFFFFFFn;\n  }\n\n  let b = -1n, j = 0n;\n  while (j < BigInt(numBuckets)) {\n    b = j;\n    h = ((h * 2862933555777941757n) + 1n) & 0xFFFFFFFFFFFFFFFFn;\n    j = BigInt(Math.floor(Number(b + 1n) * (Number(1n << 31n) / Number((h >> 33n) + 1n))));\n  }\n  return Number(b);\n}\n\n// Distribution test\nfunction testDistribution(numKeys, numBuckets) {\n  const counts = new Array(numBuckets).fill(0);\n  for (let i = 0; i < numKeys; i++) {\n    const bucket = jumpConsistentHash(`key-${i}`, numBuckets);\n    counts[bucket]++;\n  }\n  const mean = numKeys / numBuckets;\n  const maxDev = Math.max(...counts.map(c => Math.abs(c - mean)));\n  return { counts, mean: Math.round(mean), maxDeviation: Math.round(maxDev), devPercent: (maxDev / mean * 100).toFixed(1) + '%' };\n}\n\n// Migration test: how many keys move when adding one bucket\nfunction testMigration(numKeys, oldBuckets, newBuckets) {\n  let moved = 0;\n  for (let i = 0; i < numKeys; i++) {\n    const key = `key-${i}`;\n    if (jumpConsistentHash(key, oldBuckets) !== jumpConsistentHash(key, newBuckets)) moved++;\n  }\n  return { moved, percent: (moved / numKeys * 100).toFixed(1) + '%', expected: (100 / newBuckets).toFixed(1) + '%' };\n}\n\nconsole.log('=== Jump Consistent Hash ===');\nconsole.log('Distribution (10000 keys, 5 buckets):');\nconst dist = testDistribution(10000, 5);\nconsole.log(`  Counts: [${dist.counts.join(', ')}]`);\nconsole.log(`  Mean: ${dist.mean}, Max deviation: ${dist.maxDeviation} (${dist.devPercent})`);\n\nconsole.log('\\nMigration when adding buckets:');\nconsole.log('  5→6 buckets:', testMigration(100000, 5, 6));\nconsole.log('  10→11 buckets:', testMigration(100000, 10, 11));\nconsole.log('  100→101 buckets:', testMigration(100000, 100, 101));",
      "output": "=== Jump Consistent Hash ===\nDistribution (10000 keys, 5 buckets):\n  Counts: [2015, 1998, 2003, 1991, 1993]\n  Mean: 2000, Max deviation: 15 (0.8%)\n\nMigration when adding buckets:\n  5→6 buckets: { moved: 16589, percent: '16.6%', expected: '16.7%' }\n  10→11 buckets: { moved: 9124, percent: '9.1%', expected: '9.1%' }\n  100→101 buckets: { moved: 998, percent: '1.0%', expected: '1.0%' }"
    }
  ]
}
