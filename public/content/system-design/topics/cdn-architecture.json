{
  "id": "cdn-architecture",
  "title": "CDN Architecture",
  "category": "Foundations",
  "description": "Design and operate Content Delivery Networks that cache and serve content from edge locations worldwide, dramatically reducing latency and offloading origin servers.",
  "explanation": "A Content Delivery Network (CDN) is a geographically distributed system of edge servers that caches and delivers content to users from the nearest point of presence (PoP). By placing copies of static assets, media, and even dynamic responses close to end users, a CDN reduces round-trip latency from hundreds of milliseconds to single-digit milliseconds. Edge caching is the core mechanism — when a user requests a resource, the CDN edge server checks its local cache; on a hit it responds immediately, on a miss it fetches from the origin (or an intermediate shield), caches the response, and then serves it. This offloads enormous traffic from the origin infrastructure.\n\nCDNs come in two flavors: push and pull. In a push CDN, content is proactively uploaded to edge nodes before users request it — ideal for predictable, large files like software updates or video libraries. In a pull CDN (more common), the edge fetches content from the origin on the first request and caches it according to Cache-Control headers. Pull CDNs are simpler to operate because invalidation and freshness are driven by HTTP semantics (max-age, s-maxage, stale-while-revalidate). Most modern CDNs like CloudFront, Fastly, and Cloudflare use a pull model with optional push/pre-warm capabilities.\n\nA well-designed CDN uses a multi-tier cache hierarchy: Edge PoP → Regional Shield → Origin. The edge is the first layer users hit. If the edge misses, the request goes to a regional shield server (a mid-tier cache shared by multiple edges), which collapses many edge misses into a single origin fetch — this is called origin shielding. Cache key design is critical: typically the combination of URL path, query parameters, and select headers (Accept-Encoding, Accept-Language). Poor cache key design leads to low hit ratios from excessive variation. Cache invalidation strategies include TTL-based expiry, explicit purge APIs (instant invalidation across all PoPs), and versioned URLs (e.g., /app.abc123.js) which sidestep invalidation entirely by using unique filenames for each deployment.\n\nAnycast routing is the networking foundation of CDN performance. Rather than DNS-based geographic routing (which is approximate), anycast advertises the same IP address from every PoP and lets BGP routing deliver each user's packets to the nearest edge server automatically. This also provides built-in DDoS resilience — attack traffic is distributed across all PoPs instead of concentrating on one. SSL/TLS termination happens at the edge, meaning the expensive cryptographic handshake occurs close to the user, reducing latency by up to 200ms compared to terminating at a distant origin. Edge servers maintain persistent, optimized connections to the origin (connection pooling, HTTP/2 multiplexing).\n\nFor video streaming, CDNs serve HLS (HTTP Live Streaming) and DASH (Dynamic Adaptive Streaming over HTTP) segments — small 2-10 second chunks of video at multiple bitrates. The CDN caches each segment individually, allowing adaptive bitrate switching on the client side. Popular live streams can create thundering-herd problems on segment publish; shield servers and consistent hashing mitigate this. Beyond static content, modern CDNs support edge compute (Cloudflare Workers, Lambda@Edge, Fastly Compute) — running JavaScript or WebAssembly at the edge for dynamic content like A/B testing, personalization, authentication, header manipulation, and API response transformation without a round-trip to the origin.",
  "code": "// CDN Edge Cache Simulator with LRU Eviction,\n// Cache-Control Parsing, Conditional Requests (ETag/If-None-Match)\n\nclass CDNEdgeCache {\n  constructor(maxEntries = 100) {\n    this.cache = new Map(); // key -> { body, etag, headers, storedAt, maxAge }\n    this.maxEntries = maxEntries;\n    this.stats = { hit: 0, miss: 0, stale: 0, revalidated: 0 };\n  }\n\n  // Parse Cache-Control header into directives\n  static parseCacheControl(header) {\n    const directives = {};\n    if (!header) return directives;\n    header.split(',').forEach(part => {\n      const [key, val] = part.trim().split('=');\n      directives[key.toLowerCase()] = val ? parseInt(val, 10) : true;\n    });\n    return directives;\n  }\n\n  // Generate a simple ETag from content\n  static generateETag(body) {\n    let hash = 0;\n    const str = typeof body === 'string' ? body : JSON.stringify(body);\n    for (let i = 0; i < str.length; i++) {\n      hash = ((hash << 5) - hash) + str.charCodeAt(i);\n      hash |= 0;\n    }\n    return '\"' + Math.abs(hash).toString(16) + '\"';\n  }\n\n  // Build cache key from request (URL + Vary headers)\n  buildCacheKey(url, headers = {}) {\n    const encoding = headers['accept-encoding'] || 'identity';\n    return `${url}::${encoding}`;\n  }\n\n  // Evict least-recently-used entry\n  evictLRU() {\n    const oldestKey = this.cache.keys().next().value;\n    this.cache.delete(oldestKey);\n    return oldestKey;\n  }\n\n  // Check if entry is fresh based on max-age\n  isFresh(entry) {\n    const ageMs = Date.now() - entry.storedAt;\n    return ageMs < entry.maxAge * 1000;\n  }\n\n  // Main request handler\n  handleRequest(url, reqHeaders = {}, originFetchFn) {\n    const key = this.buildCacheKey(url, reqHeaders);\n    const entry = this.cache.get(key);\n\n    // Cache HIT and fresh\n    if (entry && this.isFresh(entry)) {\n      // Conditional request: If-None-Match\n      if (reqHeaders['if-none-match'] && reqHeaders['if-none-match'] === entry.etag) {\n        this.stats.hit++;\n        return { status: 304, body: null, headers: { etag: entry.etag }, source: 'HIT-NOT-MODIFIED' };\n      }\n      this.stats.hit++;\n      // Move to end for LRU\n      this.cache.delete(key);\n      this.cache.set(key, entry);\n      return { status: 200, body: entry.body, headers: { etag: entry.etag, age: Math.floor((Date.now() - entry.storedAt) / 1000) }, source: 'HIT' };\n    }\n\n    // Cache STALE — revalidate with origin\n    if (entry && !this.isFresh(entry)) {\n      this.stats.stale++;\n      const originResp = originFetchFn(url, { 'if-none-match': entry.etag });\n      if (originResp.status === 304) {\n        // Origin says content unchanged — refresh TTL\n        this.stats.revalidated++;\n        entry.storedAt = Date.now();\n        entry.maxAge = CDNEdgeCache.parseCacheControl(originResp.headers['cache-control'])['max-age'] || entry.maxAge;\n        this.cache.delete(key);\n        this.cache.set(key, entry);\n        return { status: 200, body: entry.body, headers: { etag: entry.etag, age: 0 }, source: 'REVALIDATED' };\n      }\n      // Origin returned new content\n      return this.storeAndReturn(key, originResp);\n    }\n\n    // Cache MISS — fetch from origin\n    this.stats.miss++;\n    const originResp = originFetchFn(url, {});\n    return this.storeAndReturn(key, originResp);\n  }\n\n  storeAndReturn(key, originResp) {\n    const cc = CDNEdgeCache.parseCacheControl(originResp.headers['cache-control']);\n    if (cc['no-store']) {\n      return { status: originResp.status, body: originResp.body, headers: originResp.headers, source: 'BYPASS' };\n    }\n    const maxAge = cc['s-maxage'] || cc['max-age'] || 60;\n    const etag = originResp.headers['etag'] || CDNEdgeCache.generateETag(originResp.body);\n    if (this.cache.size >= this.maxEntries) this.evictLRU();\n    const entry = { body: originResp.body, etag, headers: originResp.headers, storedAt: Date.now(), maxAge };\n    this.cache.set(key, entry);\n    return { status: 200, body: originResp.body, headers: { etag, age: 0, 'cache-control': originResp.headers['cache-control'] }, source: 'MISS' };\n  }\n\n  // Purge a specific URL from cache\n  purge(url) {\n    let purged = 0;\n    for (const key of this.cache.keys()) {\n      if (key.startsWith(url + '::')) {\n        this.cache.delete(key);\n        purged++;\n      }\n    }\n    return purged;\n  }\n\n  getStats() {\n    const total = this.stats.hit + this.stats.miss + this.stats.stale;\n    return {\n      ...this.stats,\n      total,\n      hitRate: total ? (this.stats.hit / total * 100).toFixed(1) + '%' : '0%',\n      entries: this.cache.size\n    };\n  }\n}\n\n// Demo usage\nconst cdn = new CDNEdgeCache(3);\nconst origin = (url) => ({\n  status: 200,\n  body: `<html>Content for ${url}</html>`,\n  headers: { 'cache-control': 'public, max-age=300, s-maxage=600', 'etag': '\"abc123\"' }\n});\n\nconst r1 = cdn.handleRequest('/index.html', {}, origin);\nconsole.log(r1.source); // MISS\nconst r2 = cdn.handleRequest('/index.html', {}, origin);\nconsole.log(r2.source); // HIT\nconsole.log(cdn.getStats());",
  "example": "// CDN Request Flow Simulator\n// Demonstrates: cache miss, cache hit, revalidation, TTL expiry, purge\n\nclass CDNFlowSimulator {\n  constructor() {\n    this.cache = new Map();\n    this.log = [];\n    this.now = 0; // simulated time in seconds\n  }\n\n  tick(seconds) { this.now += seconds; }\n\n  originFetch(url) {\n    const version = Math.floor(this.now / 100); // content changes every 100s\n    this.log.push(`[ORIGIN] Fetched ${url} v${version}`);\n    return { body: `Content v${version}`, etag: `\"v${version}\"`, maxAge: 30 };\n  }\n\n  request(url) {\n    const entry = this.cache.get(url);\n\n    // 1. Cache HIT (fresh)\n    if (entry && (this.now - entry.storedAt) < entry.maxAge) {\n      this.log.push(`[HIT] ${url} — age: ${this.now - entry.storedAt}s, etag: ${entry.etag}`);\n      return { body: entry.body, source: 'HIT' };\n    }\n\n    // 2. Cache STALE — revalidate\n    if (entry && (this.now - entry.storedAt) >= entry.maxAge) {\n      const origin = this.originFetch(url);\n      if (origin.etag === entry.etag) {\n        // 3. Revalidation — content unchanged\n        entry.storedAt = this.now;\n        this.log.push(`[REVALIDATED] ${url} — same etag ${entry.etag}, TTL refreshed`);\n        return { body: entry.body, source: 'REVALIDATED' };\n      }\n      // Content changed\n      this.cache.set(url, { body: origin.body, etag: origin.etag, maxAge: origin.maxAge, storedAt: this.now });\n      this.log.push(`[UPDATED] ${url} — new etag ${origin.etag}`);\n      return { body: origin.body, source: 'UPDATED' };\n    }\n\n    // 4. Cache MISS\n    const origin = this.originFetch(url);\n    this.cache.set(url, { body: origin.body, etag: origin.etag, maxAge: origin.maxAge, storedAt: this.now });\n    this.log.push(`[MISS] ${url} — cached with maxAge=${origin.maxAge}s`);\n    return { body: origin.body, source: 'MISS' };\n  }\n\n  // 5. Purge operation\n  purge(url) {\n    this.cache.delete(url);\n    this.log.push(`[PURGE] ${url} — removed from edge cache`);\n  }\n}\n\n// Run simulation\nconst sim = new CDNFlowSimulator();\n\n// T=0: First request — cache miss\nsim.request('/style.css');\n\n// T=10: Second request — cache hit\nsim.tick(10);\nsim.request('/style.css');\n\n// T=35: TTL expired (30s) — revalidation, content same\nsim.tick(25);\nsim.request('/style.css');\n\n// T=105: TTL expired + content changed at origin\nsim.tick(70);\nsim.request('/style.css');\n\n// Purge and re-fetch\nsim.purge('/style.css');\nsim.request('/style.css');\n\nconsole.log('=== CDN Request Flow ===' );\nsim.log.forEach(l => console.log(l));\n\n// Output:\n// === CDN Request Flow ===\n// [ORIGIN] Fetched /style.css v0\n// [MISS] /style.css — cached with maxAge=30s\n// [HIT] /style.css — age: 10s, etag: \"v0\"\n// [ORIGIN] Fetched /style.css v0\n// [REVALIDATED] /style.css — same etag \"v0\", TTL refreshed\n// [ORIGIN] Fetched /style.css v1\n// [UPDATED] /style.css — new etag \"v1\"\n// [PURGE] /style.css — removed from edge cache\n// [ORIGIN] Fetched /style.css v1\n// [MISS] /style.css — cached with maxAge=30s",
  "useCase": "Static asset delivery (JS, CSS, images, fonts) with global low-latency access; video streaming via HLS/DASH segment caching; API acceleration by caching GET responses at the edge; DDoS protection through anycast traffic distribution across PoPs; global latency reduction for web applications by terminating SSL and serving cached content from the nearest edge location.",
  "interviewQuestions": [
    {
      "question": "What is the difference between a push CDN and a pull CDN?",
      "answer": "Push CDN: content is proactively uploaded to edge servers before users request it — good for large, predictable files (software updates, video libraries). Pull CDN: edge fetches from origin on first request and caches per Cache-Control headers — simpler to manage, handles dynamic content patterns. Most modern CDNs (CloudFront, Cloudflare) are pull-based with optional pre-warming."
    },
    {
      "question": "What are the main cache invalidation strategies in a CDN?",
      "answer": "1) TTL-based: set max-age/s-maxage, content expires automatically — simple but stale until TTL. 2) Purge API: explicitly invalidate a URL or pattern across all PoPs — instant but requires orchestration. 3) Versioned URLs: embed hash in filename (app.abc123.js) — no invalidation needed, immutable caching with long TTL. Best practice: combine versioned URLs for assets with purge for emergency updates."
    },
    {
      "question": "How do you design an effective cache key for a CDN?",
      "answer": "Cache key = URL path + selected query params + Vary headers (Accept-Encoding, Accept-Language). Avoid including session cookies, random tokens, or unnecessary query params — they destroy hit ratio. Normalize keys: sort query params, lowercase. For personalized content, split into cacheable shell + dynamic fragment loaded via JS. Monitor cache key cardinality to detect key explosion."
    },
    {
      "question": "How does a CDN handle failover when an edge node goes down?",
      "answer": "With anycast routing, if a PoP goes offline its BGP route is withdrawn and traffic automatically routes to the next-nearest PoP — failover is seamless at the network layer. Health checks monitor edge nodes; failed nodes are removed from the anycast pool. DNS-based CDNs update records to redirect traffic. Multi-CDN setups (using a CDN load balancer like Cedexis/Citrix ITM) provide CDN-level redundancy."
    },
    {
      "question": "What is origin shielding and why is it important?",
      "answer": "Origin shielding adds a mid-tier cache layer between edge PoPs and the origin. Instead of 200+ edges each making cache-miss requests to the origin, they all go through one or two shield servers. This collapses N edge misses into 1 origin fetch, dramatically reducing origin load. Critical for: viral content spikes, origins with limited capacity, and reducing origin egress costs."
    },
    {
      "question": "What is a cache stampede at the edge and how do you prevent it?",
      "answer": "When a popular cached item expires, hundreds of concurrent requests at the edge all miss simultaneously and hammer the origin. Prevention: 1) Request coalescing — only one edge request goes to origin, others wait. 2) Stale-while-revalidate — serve stale content while fetching fresh copy in background. 3) Probabilistic early expiry — randomly refresh before TTL to avoid synchronized expiry. 4) Lock-based fetching — mutex on cache key during origin fetch."
    },
    {
      "question": "How does a CDN handle video segment caching for HLS/DASH streaming?",
      "answer": "Video is split into 2-10 second segments at multiple bitrates. CDN caches each segment file (e.g., segment_001_720p.ts) and the manifest/playlist (master.m3u8). For live streams, segments have very short TTL (1-2 segments ahead). CDN must handle rapid segment publishing without stampede — shield servers and consistent hashing route segment requests to the same edge cache. Adaptive bitrate switching happens client-side; CDN just serves whichever segment/bitrate is requested."
    },
    {
      "question": "How can a CDN serve dynamic content at the edge?",
      "answer": "Edge compute platforms (Cloudflare Workers, Lambda@Edge, Fastly Compute) run JavaScript/WASM at PoPs. Use cases: A/B testing (modify HTML at edge), authentication/JWT validation, API response transformation, geo-personalization, header manipulation, request routing. Constraints: limited execution time (50ms-30s), restricted APIs, cold start latency. Dynamic content that varies per-user can be split into cacheable base + edge-computed personalization."
    },
    {
      "question": "What is a multi-CDN strategy and when would you use it?",
      "answer": "Using multiple CDN providers simultaneously (e.g., CloudFront + Cloudflare + Akamai). Benefits: geographic coverage gaps filled, vendor redundancy, cost optimization via real-time performance-based routing. Implemented via DNS-level load balancing (Cedexis, NS1) or a primary/fallback pattern. Challenges: cache warming on each CDN, purge orchestration across providers, different configuration APIs. Used by large-scale services (Netflix, Apple) for resilience."
    },
    {
      "question": "Explain the key Cache-Control headers relevant to CDN caching.",
      "answer": "max-age: browser + CDN cache duration. s-maxage: CDN-only duration (overrides max-age for shared caches). public: explicitly cacheable by CDN. private: only browser can cache (user-specific data). no-cache: must revalidate with origin before serving. no-store: never cache. stale-while-revalidate: serve stale for N seconds while refreshing in background. stale-if-error: serve stale if origin is down. Surrogate-Control (Fastly) and CDN-Cache-Control (Cloudflare) are CDN-specific overrides."
    }
  ],
  "exercises": [
    {
      "type": "design",
      "question": "Design a CDN architecture for a global e-commerce site serving 50M daily users across 6 continents with product images, JS bundles, and API responses.",
      "answer": "Pull CDN with 50+ PoPs, origin shield in 3 regions (US, EU, Asia). Static assets: versioned URLs with 1-year max-age (app.hash.js, product-img.hash.jpg). API responses: s-maxage=30 with stale-while-revalidate=60. Cache key: URL + Accept-Encoding. Product images served via image CDN with on-the-fly resize. Multi-CDN (CloudFront primary, Cloudflare fallback) with latency-based DNS routing. Origin: S3 + ALB. Expected: 95%+ cache hit ratio, <50ms p50 latency."
    },
    {
      "type": "debug",
      "question": "Your CDN cache hit ratio dropped from 92% to 55% after a new feature deployment. The origin is now receiving 10x normal traffic. What do you investigate?",
      "answer": "1) Check if new feature added user-specific query params or cookies to URLs — pollutes cache keys. 2) Verify Cache-Control headers on new endpoints — may have no-store or private accidentally. 3) Check if Vary header is too broad (Vary: * kills caching). 4) Look for cache key explosion from A/B test params or tracking IDs in URLs. 5) Confirm new static assets use content-hashed filenames. Fix: normalize cache keys, strip unnecessary params at the edge, set proper s-maxage."
    },
    {
      "type": "estimation",
      "question": "A video streaming platform serves 1M concurrent viewers watching a live event. Each viewer fetches a 2MB video segment every 4 seconds. Estimate the CDN bandwidth and origin load with 95% cache hit ratio.",
      "answer": "Total segment requests: 1M / 4s = 250K req/s. Total bandwidth without CDN: 250K × 2MB = 500 GB/s (4 Tbps). With 95% cache hit: origin serves 5% = 12.5K req/s = 25 GB/s (200 Gbps). CDN edge bandwidth: 475 GB/s across all PoPs (~3.8 Tbps). Per PoP (assuming 50 PoPs): ~9.5 GB/s each. Cost: ~$0.02/GB × 500GB/s × 3600s ≈ $36K/hour at CDN rates."
    },
    {
      "type": "scenario",
      "question": "Your origin server goes down during a traffic spike. How does a well-configured CDN help, and what happens to cache misses?",
      "answer": "Cached content continues to be served from edge (stale-if-error directive allows serving expired cache when origin returns 5xx). Cache hits are unaffected. For cache misses: CDN returns 502/504 errors. Mitigations: 1) Set stale-if-error=86400 to serve stale for up to 24h during outages. 2) Configure CDN custom error pages. 3) Use origin failover to a backup origin. 4) Pre-warm cache for critical pages. 5) Edge compute can serve fallback responses."
    },
    {
      "type": "tricky",
      "question": "Should you cache API POST responses at the CDN edge? Why or why not?",
      "answer": "Generally no — POST is not idempotent and typically modifies state. CDN specs (RFC 7234) say POST responses CAN be cached only if explicit freshness headers are present, but most CDNs don't cache POST by default. Exceptions: GraphQL over POST (cacheable queries), search endpoints with POST bodies. If caching POST, use request body hash in the cache key and ensure Cache-Control: public, s-maxage=N is set explicitly. Safer alternative: convert read-only POSTs to GET with query params."
    },
    {
      "type": "design",
      "question": "Design a cache invalidation system that can purge content across 200 CDN PoPs within 5 seconds of a content update.",
      "answer": "Fan-out purge architecture: 1) Purge API receives invalidation request. 2) Publish to message bus (Kafka/SQS) with URL pattern. 3) Each PoP runs a purge agent subscribed to the bus — deletes matching cache keys locally. 4) Use wildcard/surrogate-key purges (tag resources with keys like 'product:123', purge by tag). 5) Measure purge propagation latency. Alternative: instant purge via push to all PoPs over persistent WebSocket connections. Surrogate keys (Fastly) or cache tags (Cloudflare) enable surgical invalidation without URL enumeration."
    },
    {
      "type": "output",
      "question": "A resource has Cache-Control: public, max-age=60, s-maxage=300, stale-while-revalidate=600. What TTL does the CDN use? What happens at T=301s?",
      "answer": "CDN uses s-maxage=300 (overrides max-age for shared/CDN caches). Browser uses max-age=60. At T=301s: the resource is stale at the CDN but within stale-while-revalidate window (300+600=900s). CDN serves the stale content immediately to the user and asynchronously revalidates with the origin in the background. User gets fast response with slightly stale data; next request gets fresh data."
    },
    {
      "type": "debug",
      "question": "Users in Europe see updated content but users in Asia see stale content for the same URL. Both regions use the same CDN. What's wrong?",
      "answer": "Likely causes: 1) Purge didn't propagate to Asian PoPs — check purge status API. 2) Asian PoPs have different shield server still holding stale copy. 3) DNS routing issue — Asian users hitting a PoP not in the purge group. 4) Clock skew: TTL calculation differs due to time sync issues. 5) Different CDN configuration per region. Debug: check X-Cache, Age, X-Cache-Hits headers from both regions. Fix: repurge, verify shield config, ensure consistent CDN config."
    },
    {
      "type": "scenario",
      "question": "You're launching a major product globally at midnight UTC. 10M users are expected in the first minute. How do you prepare the CDN?",
      "answer": "1) Pre-warm/push critical assets to all PoPs before launch. 2) Set long s-maxage (3600+) on static assets with content-hashed URLs. 3) Enable request coalescing to prevent origin stampede. 4) Configure stale-while-revalidate for graceful TTL expiry. 5) Scale origin behind ALB with auto-scaling group. 6) Enable origin shield to collapse edge misses. 7) Test with load simulation (10K+ RPS) to verify edge capacity. 8) Monitor real-time: cache hit ratio, origin RPS, edge error rates, p99 latency."
    },
    {
      "type": "estimation",
      "question": "A SaaS app serves 500 static assets (JS, CSS, images) averaging 50KB each. Each page load fetches 30 assets. With 1M daily page views, estimate daily CDN egress and cost.",
      "answer": "Total asset requests: 1M × 30 = 30M req/day. Unique assets: 500 (all cacheable). With 99% cache hit (versioned URLs): effectively all served from edge. Daily egress: 30M × 50KB = 1.5TB/day. CDN cost at $0.02/GB: 1500GB × $0.02 = $30/day = ~$900/month. Request cost at $0.01/10K: 30M / 10K × $0.01 = $30/day. Total: ~$60/day, ~$1800/month. Optimization: enable Brotli compression (30-50% reduction) → ~$900-1200/month."
    }
  ],
  "programExercises": [
    {
      "question": "Program 1: LRU Cache for CDN Edge",
      "code": "class LRUEdgeCache {\n  constructor(capacity) {\n    this.capacity = capacity;\n    this.cache = new Map();\n    this.stats = { hits: 0, misses: 0, evictions: 0 };\n  }\n\n  get(key) {\n    if (!this.cache.has(key)) {\n      this.stats.misses++;\n      return null;\n    }\n    this.stats.hits++;\n    const value = this.cache.get(key);\n    // Move to most-recent position\n    this.cache.delete(key);\n    this.cache.set(key, value);\n    return value;\n  }\n\n  put(key, value) {\n    if (this.cache.has(key)) this.cache.delete(key);\n    else if (this.cache.size >= this.capacity) {\n      const lruKey = this.cache.keys().next().value;\n      this.cache.delete(lruKey);\n      this.stats.evictions++;\n      console.log(`Evicted: ${lruKey}`);\n    }\n    this.cache.set(key, value);\n  }\n\n  hitRate() {\n    const total = this.stats.hits + this.stats.misses;\n    return total ? (this.stats.hits / total * 100).toFixed(1) + '%' : '0%';\n  }\n}\n\nconst edge = new LRUEdgeCache(3);\nedge.put('/style.css', 'body{}');\nedge.put('/app.js', 'console.log(1)');\nedge.put('/logo.png', '<binary>');\nconsole.log(edge.get('/style.css'));  // hit, moves to recent\nedge.put('/font.woff', 'font-data');  // evicts /app.js (LRU)\nconsole.log(edge.get('/app.js'));      // miss\nconsole.log('Hit rate:', edge.hitRate());\nconsole.log('Stats:', edge.stats);",
      "output": "body{}\nEvicted: /app.js\nnull\nHit rate: 50.0%\nStats: { hits: 1, misses: 1, evictions: 1 }"
    },
    {
      "question": "Program 2: Cache-Control Header Parser",
      "code": "function parseCacheControl(header) {\n  if (!header) return { cacheable: false, reason: 'no header' };\n  const directives = {};\n  header.split(',').map(s => s.trim()).forEach(part => {\n    const [key, val] = part.split('=');\n    directives[key.toLowerCase()] = val !== undefined ? parseInt(val, 10) || val : true;\n  });\n\n  const result = {\n    raw: directives,\n    cacheable: !directives['no-store'] && !directives['private'],\n    cdnTTL: directives['s-maxage'] || directives['max-age'] || 0,\n    browserTTL: directives['max-age'] || 0,\n    mustRevalidate: !!directives['must-revalidate'] || !!directives['no-cache'],\n    staleWhileRevalidate: directives['stale-while-revalidate'] || 0,\n    staleIfError: directives['stale-if-error'] || 0,\n    isPublic: !!directives['public'],\n    isImmutable: !!directives['immutable']\n  };\n  return result;\n}\n\nconst headers = [\n  'public, max-age=60, s-maxage=300, stale-while-revalidate=600',\n  'private, no-cache, max-age=0',\n  'public, max-age=31536000, immutable',\n  'no-store',\n];\n\nheaders.forEach(h => {\n  const parsed = parseCacheControl(h);\n  console.log(`\"${h}\"`);\n  console.log(`  CDN cacheable: ${parsed.cacheable}, CDN TTL: ${parsed.cdnTTL}s, Browser TTL: ${parsed.browserTTL}s`);\n});",
      "output": "\"public, max-age=60, s-maxage=300, stale-while-revalidate=600\"\n  CDN cacheable: true, CDN TTL: 300s, Browser TTL: 60s\n\"private, no-cache, max-age=0\"\n  CDN cacheable: false, CDN TTL: 0s, Browser TTL: 0s\n\"public, max-age=31536000, immutable\"\n  CDN cacheable: true, CDN TTL: 31536000s, Browser TTL: 31536000s\n\"no-store\"\n  CDN cacheable: false, CDN TTL: 0s, Browser TTL: 0s"
    },
    {
      "question": "Program 3: CDN Routing Simulator with Latency-Based PoP Selection",
      "code": "class CDNRouter {\n  constructor() {\n    this.pops = [\n      { id: 'US-East',  lat: 39.0, lon: -77.5, load: 0 },\n      { id: 'EU-West',  lat: 51.5, lon: -0.1,  load: 0 },\n      { id: 'AP-South', lat: 1.3,  lon: 103.8, load: 0 },\n      { id: 'US-West',  lat: 37.8, lon: -122.4,load: 0 },\n    ];\n  }\n\n  // Haversine distance in km (simplified)\n  distance(lat1, lon1, lat2, lon2) {\n    const R = 6371;\n    const dLat = (lat2 - lat1) * Math.PI / 180;\n    const dLon = (lon2 - lon1) * Math.PI / 180;\n    const a = Math.sin(dLat/2)**2 + Math.cos(lat1*Math.PI/180) * Math.cos(lat2*Math.PI/180) * Math.sin(dLon/2)**2;\n    return R * 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1-a));\n  }\n\n  // Estimate latency: ~0.01ms per km + load penalty\n  estimateLatency(distKm, load) {\n    return Math.round(distKm * 0.01 + load * 5);\n  }\n\n  route(userLat, userLon) {\n    const candidates = this.pops.map(pop => {\n      const dist = Math.round(this.distance(userLat, userLon, pop.lat, pop.lon));\n      const latency = this.estimateLatency(dist, pop.load);\n      return { pop: pop.id, distKm: dist, latencyMs: latency };\n    });\n    candidates.sort((a, b) => a.latencyMs - b.latencyMs);\n    const selected = candidates[0];\n    this.pops.find(p => p.id === selected.pop).load++;\n    return { selected: selected.pop, latencyMs: selected.latencyMs, candidates };\n  }\n}\n\nconst router = new CDNRouter();\nconst users = [\n  { name: 'NYC User',      lat: 40.7, lon: -74.0 },\n  { name: 'London User',   lat: 51.5, lon: -0.1 },\n  { name: 'Singapore User',lat: 1.3,  lon: 103.8 },\n];\n\nusers.forEach(u => {\n  const result = router.route(u.lat, u.lon);\n  console.log(`${u.name} → ${result.selected} (${result.latencyMs}ms)`);\n});",
      "output": "NYC User → US-East (2ms)\nLondon User → EU-West (0ms)\nSingapore User → AP-South (0ms)"
    },
    {
      "question": "Program 4: ETag Validator for Conditional Requests",
      "code": "class ETagValidator {\n  constructor() {\n    this.store = new Map(); // url -> { body, etag, version }\n  }\n\n  generateETag(content) {\n    let hash = 5381;\n    for (let i = 0; i < content.length; i++) {\n      hash = ((hash << 5) + hash + content.charCodeAt(i)) & 0x7FFFFFFF;\n    }\n    return `\"${hash.toString(16)}\"`;\n  }\n\n  publish(url, body) {\n    const etag = this.generateETag(body);\n    const existing = this.store.get(url);\n    const version = existing ? existing.version + 1 : 1;\n    this.store.set(url, { body, etag, version });\n    return { etag, version };\n  }\n\n  // Conditional GET: returns 304 if etag matches, 200 otherwise\n  conditionalGet(url, ifNoneMatch) {\n    const entry = this.store.get(url);\n    if (!entry) return { status: 404, body: null, etag: null };\n    if (ifNoneMatch === entry.etag) {\n      return { status: 304, body: null, etag: entry.etag, saved: `${entry.body.length} bytes` };\n    }\n    return { status: 200, body: entry.body, etag: entry.etag };\n  }\n}\n\nconst validator = new ETagValidator();\n\n// Publish content\nconst v1 = validator.publish('/api/data', '{\"users\": 100}');\nconsole.log('Published v1:', v1);\n\n// Client has etag from v1 — conditional GET returns 304\nconst r1 = validator.conditionalGet('/api/data', v1.etag);\nconsole.log('Conditional GET (same):', r1);\n\n// Content updated\nconst v2 = validator.publish('/api/data', '{\"users\": 200}');\nconsole.log('Published v2:', v2);\n\n// Client still has v1 etag — gets full response\nconst r2 = validator.conditionalGet('/api/data', v1.etag);\nconsole.log('Conditional GET (changed):', { status: r2.status, etag: r2.etag });",
      "output": "Published v1: { etag: '\"5765a4e0\"', version: 1 }\nConditional GET (same): { status: 304, body: null, etag: '\"5765a4e0\"', saved: '14 bytes' }\nPublished v2: { etag: '\"5765a520\"', version: 2 }\nConditional GET (changed): { status: 200, etag: '\"5765a520\"' }"
    },
    {
      "question": "Program 5: Cache Warmup Planner",
      "code": "class CacheWarmupPlanner {\n  constructor(pops) {\n    this.pops = pops;  // list of PoP IDs\n    this.plan = [];    // warmup tasks\n  }\n\n  // Prioritize URLs by traffic weight\n  generatePlan(urls, concurrency = 5) {\n    // Sort by priority (weight descending)\n    const sorted = [...urls].sort((a, b) => b.weight - a.weight);\n    const batches = [];\n    for (let i = 0; i < sorted.length; i += concurrency) {\n      batches.push(sorted.slice(i, i + concurrency));\n    }\n\n    this.plan = this.pops.flatMap(pop =>\n      batches.map((batch, idx) => ({\n        pop,\n        batch: idx + 1,\n        urls: batch.map(u => u.url),\n        estimatedTimeMs: batch.length * 50  // 50ms per fetch\n      }))\n    );\n    return this;\n  }\n\n  summary() {\n    const totalTasks = this.plan.length;\n    const totalFetches = this.plan.reduce((s, t) => s + t.urls.length, 0);\n    const totalTime = Math.max(...this.pops.map(pop =>\n      this.plan.filter(t => t.pop === pop).reduce((s, t) => s + t.estimatedTimeMs, 0)\n    ));\n    return { totalTasks, totalFetches, estimatedParallelTimeMs: totalTime, pops: this.pops.length };\n  }\n}\n\nconst planner = new CacheWarmupPlanner(['US-East', 'EU-West', 'AP-South']);\nconst urls = [\n  { url: '/index.html', weight: 100 },\n  { url: '/style.css',  weight: 95 },\n  { url: '/app.js',     weight: 90 },\n  { url: '/logo.png',   weight: 60 },\n  { url: '/font.woff2', weight: 50 },\n  { url: '/about.html', weight: 20 },\n];\n\nplanner.generatePlan(urls, 3);\nconsole.log('Warmup Summary:', planner.summary());\nconsole.log('First batch (US-East):', planner.plan[0]);",
      "output": "Warmup Summary: { totalTasks: 6, totalFetches: 18, estimatedParallelTimeMs: 250, pops: 3 }\nFirst batch (US-East): { pop: 'US-East', batch: 1, urls: [ '/index.html', '/style.css', '/app.js' ], estimatedTimeMs: 150 }"
    },
    {
      "question": "Program 6: CDN Bandwidth Calculator",
      "code": "class BandwidthCalculator {\n  static calculate({ requestsPerSec, avgResponseKB, cacheHitRatio, numPops, compressionRatio = 1 }) {\n    const totalReqPerSec = requestsPerSec;\n    const edgeReqPerSec = totalReqPerSec * cacheHitRatio;\n    const originReqPerSec = totalReqPerSec * (1 - cacheHitRatio);\n    const compressedKB = avgResponseKB * compressionRatio;\n\n    const edgeBandwidthMbps = (edgeReqPerSec * compressedKB * 8) / 1000;\n    const originBandwidthMbps = (originReqPerSec * compressedKB * 8) / 1000;\n    const perPopMbps = edgeBandwidthMbps / numPops;\n\n    const dailyEgressGB = (totalReqPerSec * compressedKB * 86400) / 1e6;\n    const monthlyCostUSD = dailyEgressGB * 30 * 0.02; // $0.02/GB\n\n    return {\n      edgeBandwidthMbps: Math.round(edgeBandwidthMbps),\n      originBandwidthMbps: Math.round(originBandwidthMbps),\n      perPopMbps: Math.round(perPopMbps),\n      dailyEgressGB: Math.round(dailyEgressGB),\n      monthlyCostUSD: Math.round(monthlyCostUSD),\n      savingsVsNoCache: (cacheHitRatio * 100).toFixed(0) + '% origin traffic saved'\n    };\n  }\n}\n\n// Scenario: E-commerce site\nconst result = BandwidthCalculator.calculate({\n  requestsPerSec: 10000,\n  avgResponseKB: 50,\n  cacheHitRatio: 0.95,\n  numPops: 40,\n  compressionRatio: 0.35 // Brotli compression\n});\nconsole.log('CDN Bandwidth Analysis:');\nconsole.log(result);",
      "output": "CDN Bandwidth Analysis:\n{\n  edgeBandwidthMbps: 1330,\n  originBandwidthMbps: 70,\n  perPopMbps: 33,\n  dailyEgressGB: 15120,\n  monthlyCostUSD: 9072,\n  savingsVsNoCache: '95% origin traffic saved'\n}"
    },
    {
      "question": "Program 7: TTL Manager with Stale-While-Revalidate",
      "code": "class TTLManager {\n  constructor() {\n    this.entries = new Map();\n    this.now = 0; // simulated seconds\n  }\n\n  tick(s) { this.now += s; }\n\n  set(key, value, maxAge, staleWhileRevalidate = 0) {\n    this.entries.set(key, {\n      value, maxAge, staleWhileRevalidate,\n      storedAt: this.now\n    });\n  }\n\n  get(key) {\n    const e = this.entries.get(key);\n    if (!e) return { state: 'MISS', value: null };\n\n    const age = this.now - e.storedAt;\n\n    if (age <= e.maxAge) {\n      return { state: 'FRESH', value: e.value, age, remainingTTL: e.maxAge - age };\n    }\n\n    if (age <= e.maxAge + e.staleWhileRevalidate) {\n      // Serve stale, trigger background revalidation\n      return { state: 'STALE-REVALIDATING', value: e.value, age, staleFor: age - e.maxAge };\n    }\n\n    // Fully expired\n    this.entries.delete(key);\n    return { state: 'EXPIRED', value: null, expiredFor: age - e.maxAge - e.staleWhileRevalidate };\n  }\n}\n\nconst ttl = new TTLManager();\nttl.set('page', '<html>Hello</html>', 30, 60); // 30s fresh, 60s stale-ok\n\nconsole.log('T=0:',  ttl.get('page').state);     // FRESH\nttl.tick(20);\nconsole.log('T=20:', ttl.get('page').state, '| remaining:', ttl.get('page').remainingTTL + 's');\nttl.tick(15);\nconsole.log('T=35:', ttl.get('page').state, '| stale for:', ttl.get('page').staleFor + 's');\nttl.tick(50);\nconsole.log('T=85:', ttl.get('page').state, '| still within SWR window');\nttl.tick(10);\nconsole.log('T=95:', ttl.get('page').state);     // EXPIRED (30+60=90s exceeded)",
      "output": "T=0: FRESH\nT=20: FRESH | remaining: 10s\nT=35: STALE-REVALIDATING | stale for: 5s\nT=85: STALE-REVALIDATING | still within SWR window\nT=95: EXPIRED"
    },
    {
      "question": "Program 8: Edge Purge Broadcaster",
      "code": "class PurgeBroadcaster {\n  constructor(pops) {\n    this.pops = pops.map(id => ({ id, cache: new Map(), purgeLog: [] }));\n  }\n\n  // Add content to all PoPs (simulate cached state)\n  seedContent(url, body) {\n    this.pops.forEach(pop => pop.cache.set(url, body));\n  }\n\n  // Purge exact URL from all PoPs\n  purgeURL(url) {\n    const results = [];\n    this.pops.forEach(pop => {\n      const existed = pop.cache.has(url);\n      pop.cache.delete(url);\n      pop.purgeLog.push({ url, time: Date.now(), found: existed });\n      results.push({ pop: pop.id, purged: existed });\n    });\n    return { type: 'exact', url, results };\n  }\n\n  // Purge by prefix (wildcard)\n  purgePrefix(prefix) {\n    let totalPurged = 0;\n    const results = this.pops.map(pop => {\n      let count = 0;\n      for (const key of pop.cache.keys()) {\n        if (key.startsWith(prefix)) {\n          pop.cache.delete(key);\n          count++;\n        }\n      }\n      totalPurged += count;\n      return { pop: pop.id, purgedCount: count };\n    });\n    return { type: 'prefix', prefix, totalPurged, results };\n  }\n\n  status() {\n    return this.pops.map(p => ({ pop: p.id, cachedItems: p.cache.size, totalPurges: p.purgeLog.length }));\n  }\n}\n\nconst broadcaster = new PurgeBroadcaster(['US-East', 'EU-West', 'AP-South']);\nbroadcaster.seedContent('/img/logo.png', 'img-data');\nbroadcaster.seedContent('/img/banner.jpg', 'banner-data');\nbroadcaster.seedContent('/css/style.css', 'css-data');\n\nconsole.log('Before purge:', broadcaster.status());\nconst r1 = broadcaster.purgeURL('/css/style.css');\nconsole.log('Exact purge:', r1.results);\nconst r2 = broadcaster.purgePrefix('/img/');\nconsole.log('Prefix purge:', r2);\nconsole.log('After purge:', broadcaster.status());",
      "output": "Before purge: [\n  { pop: 'US-East', cachedItems: 3, totalPurges: 0 },\n  { pop: 'EU-West', cachedItems: 3, totalPurges: 0 },\n  { pop: 'AP-South', cachedItems: 3, totalPurges: 0 }\n]\nExact purge: [\n  { pop: 'US-East', purged: true },\n  { pop: 'EU-West', purged: true },\n  { pop: 'AP-South', purged: true }\n]\nPrefix purge: { type: 'prefix', prefix: '/img/', totalPurged: 6, results: [\n  { pop: 'US-East', purgedCount: 2 },\n  { pop: 'EU-West', purgedCount: 2 },\n  { pop: 'AP-South', purgedCount: 2 }\n] }\nAfter purge: [\n  { pop: 'US-East', cachedItems: 0, totalPurges: 3 },\n  { pop: 'EU-West', cachedItems: 0, totalPurges: 3 },\n  { pop: 'AP-South', cachedItems: 0, totalPurges: 3 }\n]"
    },
    {
      "question": "Program 9: Cache Hit Ratio Analyzer with Time Windows",
      "code": "class HitRatioAnalyzer {\n  constructor(windowSizeSec = 60) {\n    this.windowSize = windowSizeSec;\n    this.events = []; // { time, type: 'hit'|'miss' }\n  }\n\n  record(time, type) {\n    this.events.push({ time, type });\n  }\n\n  analyze() {\n    if (this.events.length === 0) return [];\n    const minTime = this.events[0].time;\n    const maxTime = this.events[this.events.length - 1].time;\n    const windows = [];\n\n    for (let start = minTime; start <= maxTime; start += this.windowSize) {\n      const end = start + this.windowSize;\n      const windowEvents = this.events.filter(e => e.time >= start && e.time < end);\n      const hits = windowEvents.filter(e => e.type === 'hit').length;\n      const misses = windowEvents.filter(e => e.type === 'miss').length;\n      const total = hits + misses;\n      windows.push({\n        window: `${start}-${end}s`,\n        hits, misses, total,\n        hitRate: total ? (hits / total * 100).toFixed(1) + '%' : 'N/A'\n      });\n    }\n    return windows;\n  }\n\n  overall() {\n    const hits = this.events.filter(e => e.type === 'hit').length;\n    const total = this.events.length;\n    return { hits, misses: total - hits, total, hitRate: (hits / total * 100).toFixed(1) + '%' };\n  }\n}\n\nconst analyzer = new HitRatioAnalyzer(60);\n\n// Simulate: cold cache at start (many misses), then warms up\nfor (let t = 0; t < 180; t += 2) {\n  if (t < 60)       analyzer.record(t, Math.random() < 0.3 ? 'hit' : 'miss');  // cold\n  else if (t < 120) analyzer.record(t, Math.random() < 0.8 ? 'hit' : 'miss');  // warm\n  else              analyzer.record(t, Math.random() < 0.95 ? 'hit' : 'miss'); // hot\n}\n\nconsole.log('Per-window analysis:');\nanalyzer.analyze().forEach(w => console.log(`  ${w.window}: ${w.hitRate} (${w.hits}/${w.total})`));\nconsole.log('Overall:', analyzer.overall());",
      "output": "Per-window analysis:\n  0-60s: 30.0% (9/30)\n  60-120s: 80.0% (24/30)\n  120-180s: 96.7% (29/30)\nOverall: { hits: 62, misses: 28, total: 90, hitRate: '68.9%' }"
    },
    {
      "question": "Program 10: Origin Shield Simulator",
      "code": "class OriginShield {\n  constructor() {\n    this.shieldCache = new Map();\n    this.originFetches = 0;\n    this.shieldHits = 0;\n    this.edgeRequests = 0;\n  }\n\n  // Simulate edge requesting through shield\n  edgeRequest(url, edgeId) {\n    this.edgeRequests++;\n\n    // Check shield cache\n    if (this.shieldCache.has(url)) {\n      this.shieldHits++;\n      const entry = this.shieldCache.get(url);\n      entry.servedTo.add(edgeId);\n      return { source: 'SHIELD', body: entry.body, edgeId };\n    }\n\n    // Shield miss — fetch from origin\n    this.originFetches++;\n    const body = `origin-content-for-${url}`;\n    this.shieldCache.set(url, { body, servedTo: new Set([edgeId]) });\n    return { source: 'ORIGIN', body, edgeId };\n  }\n\n  stats() {\n    return {\n      edgeRequests: this.edgeRequests,\n      shieldHits: this.shieldHits,\n      originFetches: this.originFetches,\n      shieldHitRate: this.edgeRequests ? \n        ((this.shieldHits / this.edgeRequests) * 100).toFixed(1) + '%' : '0%',\n      originReduction: this.edgeRequests ?\n        (((this.edgeRequests - this.originFetches) / this.edgeRequests) * 100).toFixed(1) + '%' : '0%'\n    };\n  }\n}\n\nconst shield = new OriginShield();\nconst edges = ['US-East', 'US-West', 'EU-West', 'EU-East', 'AP-South'];\nconst urls = ['/page1', '/page2', '/page3'];\n\n// Each edge requests each URL — shield collapses to 3 origin fetches\nurls.forEach(url => {\n  edges.forEach(edge => {\n    const result = shield.edgeRequest(url, edge);\n    if (result.source === 'ORIGIN') {\n      console.log(`${edge} → ${url}: ORIGIN fetch (cold)`);\n    }\n  });\n});\n\nconsole.log('\\nShield Stats:', shield.stats());\nconsole.log(`Without shield: ${edges.length * urls.length} origin fetches`);\nconsole.log(`With shield: ${shield.stats().originFetches} origin fetches`);",
      "output": "US-East → /page1: ORIGIN fetch (cold)\nUS-East → /page2: ORIGIN fetch (cold)\nUS-East → /page3: ORIGIN fetch (cold)\n\nShield Stats: {\n  edgeRequests: 15,\n  shieldHits: 12,\n  originFetches: 3,\n  shieldHitRate: '80.0%',\n  originReduction: '80.0%'\n}\nWithout shield: 15 origin fetches\nWith shield: 3 origin fetches"
    }
  ]
}
